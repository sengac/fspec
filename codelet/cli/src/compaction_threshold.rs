//! Compaction Threshold Calculation (CLI-020)
//!
//! Provides constants and functions for calculating when context compaction
//! should be triggered, including the autocompact buffer that leaves headroom
//! after compaction to reduce re-compaction frequency.
//!
//! Reference: spec/features/autocompact-buffer.feature

/// Autocompact buffer in tokens
///
/// This buffer defines the target context size AFTER compaction, leaving
/// headroom before the next compaction trigger.
///
/// How it works:
/// - Threshold: calculate_usable_context() → context_window - min(max_output, 32k)
/// - Budget (target after compact): contextWindow - AUTOCOMPACT_BUFFER (e.g., 150k for 200k window)
/// - Headroom: threshold - budget (varies by model)
///
/// This separation ensures:
/// - After compaction, there's headroom before next trigger
/// - Reduces re-compaction frequency by providing buffer space for new interactions
///
/// Example for Claude (200k context, 8k max_output):
/// - Trigger threshold: 191,808 tokens (200k - 8k)
/// - Target after compaction: 150,000 tokens (200k - 50k)
/// - Headroom before re-trigger: 41,808 tokens
pub const AUTOCOMPACT_BUFFER: u64 = 50_000;

/// Calculate the summarization budget for context compaction
///
/// Matches TypeScript implementation in compaction.ts:calculateSummarizationBudget()
///
/// The budget determines how many tokens to target after compaction.
/// It is separate from the threshold calculation.
///
/// Logic:
/// - If context_window <= AUTOCOMPACT_BUFFER: budget = context_window * 0.8
/// - Otherwise: budget = context_window - AUTOCOMPACT_BUFFER
///
/// # Arguments
/// * `context_window` - The provider's context window size in tokens
///
/// # Returns
/// * The budget in tokens to target after compaction
///
/// # Examples
/// ```
/// use codelet_cli::compaction_threshold::calculate_summarization_budget;
///
/// // Claude with 200k context
/// let budget = calculate_summarization_budget(200_000);
/// assert_eq!(budget, 150_000); // 200k - 50k
///
/// // Small context window (40k)
/// let budget = calculate_summarization_budget(40_000);
/// assert_eq!(budget, 32_000); // 40k * 0.8
/// ```
pub fn calculate_summarization_budget(context_window: u64) -> u64 {
    if context_window <= AUTOCOMPACT_BUFFER {
        (context_window as f64 * 0.8) as u64
    } else {
        context_window - AUTOCOMPACT_BUFFER
    }
}

// =============================================================================
// CTX-002: Optimized Compaction Window Limit Trigger
// =============================================================================

/// Session output token maximum
///
/// This constant caps the output reservation to prevent over-reserving context
/// for models with very large max_output values. Set to 32k tokens as a
/// reasonable upper bound for output reservation.
pub const SESSION_OUTPUT_TOKEN_MAX: u64 = 32_000;

/// Token usage for compaction trigger calculation
///
/// Tracks all three token types needed for overflow detection:
/// - input_tokens: Tokens from user messages and system prompts
/// - cache_read_tokens: Tokens read from prompt cache
/// - output_tokens: Tokens generated by the model
#[derive(Debug, Clone, Default)]
pub struct TokenUsage {
    pub input_tokens: u64,
    pub cache_read_tokens: u64,
    pub output_tokens: u64,
}

impl TokenUsage {
    /// Calculate total token count (simple sum, no discounting)
    ///
    /// Algorithm: count = input + cache_read + output
    pub fn total(&self) -> u64 {
        self.input_tokens + self.cache_read_tokens + self.output_tokens
    }
}

/// Calculate usable context given model limits
///
/// Algorithm:
/// 1. output_reservation = min(model_max_output, SESSION_OUTPUT_TOKEN_MAX)
/// 2. If output_reservation == 0, use SESSION_OUTPUT_TOKEN_MAX as fallback
/// 3. usable_context = context_window - output_reservation
///
/// # Arguments
/// * `context_window` - The model's total context window
/// * `model_max_output` - The model's maximum output tokens (0 if unknown)
///
/// # Returns
/// * The usable context in tokens (space available for input/cache/output)
pub fn calculate_usable_context(context_window: u64, model_max_output: u64) -> u64 {
    let output_reservation = model_max_output.min(SESSION_OUTPUT_TOKEN_MAX);
    let output_reservation = if output_reservation == 0 {
        SESSION_OUTPUT_TOKEN_MAX
    } else {
        output_reservation
    };
    context_window.saturating_sub(output_reservation)
}

/// Check if compaction should trigger
///
/// Algorithm (in order):
/// 1. If disable_autocompact is true → return false
/// 2. If context_window == 0 → return false
/// 3. Calculate: token_count = input + cache_read + output
/// 4. Calculate: usable_context = context_window - output_reservation
/// 5. Return: token_count > usable_context (strictly greater than)
///
/// # Arguments
/// * `token_usage` - Current token usage (input, cache_read, output)
/// * `context_window` - The model's total context window
/// * `model_max_output` - The model's maximum output tokens (0 if unknown)
/// * `disable_autocompact` - Flag to disable compaction entirely
///
/// # Returns
/// * true if compaction should trigger, false otherwise
pub fn should_trigger_compaction(
    token_usage: &TokenUsage,
    context_window: u64,
    model_max_output: u64,
    disable_autocompact: bool,
) -> bool {
    // Short-circuit 1: Disable flag
    if disable_autocompact {
        return false;
    }

    // Short-circuit 2: Zero context (no limit)
    if context_window == 0 {
        return false;
    }

    // Calculate token count and usable context
    let token_count = token_usage.total();
    let usable_context = calculate_usable_context(context_window, model_max_output);

    // Trigger when strictly greater than (not >=)
    token_count > usable_context
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_constants_defined() {
        assert_eq!(AUTOCOMPACT_BUFFER, 50_000);
        assert_eq!(SESSION_OUTPUT_TOKEN_MAX, 32_000);
    }

    // =========================================================================
    // CTX-002 Tests: Optimized Compaction Window Limit Trigger
    // Feature: spec/features/optimized-compaction-trigger.feature
    // =========================================================================

    // -------------------------------------------------------------------------
    // Scenario: Calculate usable context for Claude Sonnet
    // -------------------------------------------------------------------------
    #[test]
    fn test_usable_context_claude_sonnet() {
        // @step Given a model with context_window of 200000 tokens
        let context_window = 200_000;

        // @step And the model has max_output_tokens of 8192
        let max_output = 8_192;

        // @step And SESSION_OUTPUT_TOKEN_MAX is 32000
        assert_eq!(SESSION_OUTPUT_TOKEN_MAX, 32_000);

        // @step When I calculate usable context
        let usable = calculate_usable_context(context_window, max_output);

        // @step Then usable context should be 191808 tokens
        // 200,000 - min(8,192, 32,000) = 200,000 - 8,192 = 191,808
        assert_eq!(usable, 191_808);
    }

    // -------------------------------------------------------------------------
    // Scenario: Calculate usable context for GPT-4
    // -------------------------------------------------------------------------
    #[test]
    fn test_usable_context_gpt4() {
        // @step Given a model with context_window of 128000 tokens
        let context_window = 128_000;

        // @step And the model has max_output_tokens of 4096
        let max_output = 4_096;

        // @step And SESSION_OUTPUT_TOKEN_MAX is 32000
        assert_eq!(SESSION_OUTPUT_TOKEN_MAX, 32_000);

        // @step When I calculate usable context
        let usable = calculate_usable_context(context_window, max_output);

        // @step Then usable context should be 123904 tokens
        // 128,000 - min(4,096, 32,000) = 128,000 - 4,096 = 123,904
        assert_eq!(usable, 123_904);
    }

    // -------------------------------------------------------------------------
    // Scenario: SESSION_OUTPUT_MAX caps high-output models
    // -------------------------------------------------------------------------
    #[test]
    fn test_usable_context_high_output_capped() {
        // @step Given a model with context_window of 200000 tokens
        let context_window = 200_000;

        // @step And the model has max_output_tokens of 64000
        let max_output = 64_000;

        // @step And SESSION_OUTPUT_TOKEN_MAX is 32000
        assert_eq!(SESSION_OUTPUT_TOKEN_MAX, 32_000);

        // @step When I calculate usable context
        let usable = calculate_usable_context(context_window, max_output);

        // @step Then usable context should be 168000 tokens
        // 200,000 - min(64,000, 32,000) = 200,000 - 32,000 = 168,000
        assert_eq!(usable, 168_000);
    }

    // -------------------------------------------------------------------------
    // Scenario: Unknown model with zero max_output uses SESSION_OUTPUT_MAX fallback
    // -------------------------------------------------------------------------
    #[test]
    fn test_usable_context_zero_max_output_fallback() {
        // @step Given a model with context_window of 100000 tokens
        let context_window = 100_000;

        // @step And the model has max_output_tokens of 0
        let max_output = 0;

        // @step And SESSION_OUTPUT_TOKEN_MAX is 32000
        assert_eq!(SESSION_OUTPUT_TOKEN_MAX, 32_000);

        // @step When I calculate usable context
        let usable = calculate_usable_context(context_window, max_output);

        // @step Then usable context should be 68000 tokens
        // min(0, 32000) = 0, but 0 triggers fallback to SESSION_OUTPUT_MAX
        // usable = 100,000 - 32,000 = 68,000 (NOT 100,000)
        assert_eq!(usable, 68_000);
    }

    // -------------------------------------------------------------------------
    // Scenario: Token count includes all three token types
    // -------------------------------------------------------------------------
    #[test]
    fn test_token_count_includes_all_types() {
        // @step Given input_tokens of 150000
        // @step And cache_read_tokens of 20000
        // @step And output_tokens of 5000
        let usage = TokenUsage {
            input_tokens: 150_000,
            cache_read_tokens: 20_000,
            output_tokens: 5_000,
        };

        // @step When I calculate total token count
        let total = usage.total();

        // @step Then total token count should be 175000
        // 150,000 + 20,000 + 5,000 = 175,000 (NOT discounted)
        assert_eq!(total, 175_000);
    }

    // -------------------------------------------------------------------------
    // Scenario: Token count does not discount cache tokens
    // -------------------------------------------------------------------------
    #[test]
    fn test_token_count_no_discount() {
        // @step Given input_tokens of 180000
        // @step And cache_read_tokens of 50000
        // @step And output_tokens of 10000
        let usage = TokenUsage {
            input_tokens: 180_000,
            cache_read_tokens: 50_000,
            output_tokens: 10_000,
        };

        // @step When I calculate total token count
        let total = usage.total();

        // @step Then total token count should be 240000
        // 180,000 + 50,000 + 10,000 = 240,000
        // NOT: 180,000 - (50,000 * 0.9) = 135,000 (old broken calculation)
        assert_eq!(total, 240_000);
    }

    // -------------------------------------------------------------------------
    // Scenario: No compaction when under usable context threshold
    // -------------------------------------------------------------------------
    #[test]
    fn test_no_compaction_under_threshold() {
        // @step Given a Claude model with context_window of 200000 and max_output of 8192
        let context_window = 200_000;
        let max_output = 8_192;

        // @step And input_tokens of 150000
        // @step And cache_read_tokens of 20000
        // @step And output_tokens of 5000
        let usage = TokenUsage {
            input_tokens: 150_000,
            cache_read_tokens: 20_000,
            output_tokens: 5_000,
        };

        // @step When I check if compaction should trigger
        let should_trigger = should_trigger_compaction(&usage, context_window, max_output, false);

        // @step Then compaction should NOT trigger
        // total=175,000, usable=191,808 → 175,000 < 191,808 → NO trigger
        assert!(!should_trigger);
    }

    // -------------------------------------------------------------------------
    // Scenario: Trigger compaction when over usable context threshold
    // -------------------------------------------------------------------------
    #[test]
    fn test_trigger_compaction_over_threshold() {
        // @step Given a Claude model with context_window of 200000 and max_output of 8192
        let context_window = 200_000;
        let max_output = 8_192;

        // @step And input_tokens of 170000
        // @step And cache_read_tokens of 20000
        // @step And output_tokens of 5000
        let usage = TokenUsage {
            input_tokens: 170_000,
            cache_read_tokens: 20_000,
            output_tokens: 5_000,
        };

        // @step When I check if compaction should trigger
        let should_trigger = should_trigger_compaction(&usage, context_window, max_output, false);

        // @step Then compaction should trigger
        // total=195,000, usable=191,808 → 195,000 > 191,808 → TRIGGER
        assert!(should_trigger);
    }

    // -------------------------------------------------------------------------
    // Scenario: Compaction triggers later than legacy 90% threshold
    // -------------------------------------------------------------------------
    #[test]
    fn test_compaction_later_than_legacy() {
        // @step Given a Claude model with context_window of 200000 and max_output of 8192
        let context_window = 200_000;
        let max_output = 8_192;

        // @step And input_tokens of 165000
        // @step And cache_read_tokens of 10000
        // @step And output_tokens of 6000
        let usage = TokenUsage {
            input_tokens: 165_000,
            cache_read_tokens: 10_000,
            output_tokens: 6_000,
        };

        // @step When I check if compaction should trigger
        let should_trigger = should_trigger_compaction(&usage, context_window, max_output, false);

        // @step Then compaction should NOT trigger
        // total=181,000, usable=191,808 → no trigger
        assert!(!should_trigger);
    }

    // -------------------------------------------------------------------------
    // Scenario: No compaction when token count exactly equals usable context
    // -------------------------------------------------------------------------
    #[test]
    fn test_no_compaction_at_exact_boundary() {
        // @step Given a Claude model with context_window of 200000 and max_output of 8192
        let context_window = 200_000;
        let max_output = 8_192;

        // @step And input_tokens of 171808
        // @step And cache_read_tokens of 15000
        // @step And output_tokens of 5000
        let usage = TokenUsage {
            input_tokens: 171_808,
            cache_read_tokens: 15_000,
            output_tokens: 5_000,
        };

        // Verify total equals usable
        let usable = calculate_usable_context(context_window, max_output);
        assert_eq!(usage.total(), 191_808);
        assert_eq!(usable, 191_808);

        // @step When I check if compaction should trigger
        let should_trigger = should_trigger_compaction(&usage, context_window, max_output, false);

        // @step Then compaction should NOT trigger
        // total=191,808, usable=191,808 → 191,808 > 191,808 is FALSE
        // Uses strictly greater than (>), not greater-or-equal (>=)
        assert!(!should_trigger);
    }

    // -------------------------------------------------------------------------
    // Scenario: No compaction when context_window is zero
    // -------------------------------------------------------------------------
    #[test]
    fn test_no_compaction_zero_context() {
        // @step Given a model with context_window of 0 tokens
        let context_window = 0;

        // @step And the model has max_output_tokens of 8192
        let max_output = 8_192;

        // @step And input_tokens of 50000
        // @step And cache_read_tokens of 10000
        // @step And output_tokens of 5000
        let usage = TokenUsage {
            input_tokens: 50_000,
            cache_read_tokens: 10_000,
            output_tokens: 5_000,
        };

        // @step When I check if compaction should trigger
        let should_trigger = should_trigger_compaction(&usage, context_window, max_output, false);

        // @step Then compaction should NOT trigger
        // context_window = 0 means no context limit, so no compaction needed
        assert!(!should_trigger);
    }

    // -------------------------------------------------------------------------
    // Scenario: No compaction when disable flag is set
    // -------------------------------------------------------------------------
    #[test]
    fn test_no_compaction_disable_flag() {
        // @step Given a model with context_window of 200000 tokens
        let context_window = 200_000;

        // @step And the model has max_output_tokens of 8192
        let max_output = 8_192;

        // @step And input_tokens of 190000
        // @step And cache_read_tokens of 50000
        // @step And output_tokens of 10000
        let usage = TokenUsage {
            input_tokens: 190_000,
            cache_read_tokens: 50_000,
            output_tokens: 10_000,
        };

        // @step And the disable autocompact flag is set to true
        let disable_autocompact = true;

        // @step When I check if compaction should trigger
        let should_trigger =
            should_trigger_compaction(&usage, context_window, max_output, disable_autocompact);

        // @step Then compaction should NOT trigger
        // Even though total (250,000) far exceeds usable (191,808)
        // The disable flag bypasses all compaction logic
        assert!(!should_trigger);

        // Verify it WOULD trigger without the flag
        let would_trigger = should_trigger_compaction(&usage, context_window, max_output, false);
        assert!(would_trigger);
    }

    #[test]
    fn test_calculate_budget_large_context() {
        // Large context: 200k
        let budget = calculate_summarization_budget(200_000);
        assert_eq!(budget, 150_000); // 200k - 50k
    }

    #[test]
    fn test_calculate_budget_small_context() {
        // Small context: 40k (less than buffer)
        let budget = calculate_summarization_budget(40_000);
        assert_eq!(budget, 32_000); // 40k * 0.8
    }

    #[test]
    fn test_calculate_budget_equal_to_buffer() {
        // Context equals buffer: 50k
        let budget = calculate_summarization_budget(50_000);
        assert_eq!(budget, 40_000); // 50k * 0.8
    }
}
