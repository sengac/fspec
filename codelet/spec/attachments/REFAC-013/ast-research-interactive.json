{
  "matches": [
    {
      "type": "function_item",
      "name": "estimate_tokens",
      "line": 33,
      "column": 0,
      "text": "fn estimate_tokens(text: &str) -> u64 {\n    (text.len() / APPROX_BYTES_PER_TOKEN) as u64\n}"
    },
    {
      "type": "function_item",
      "name": "run_interactive_mode",
      "line": 38,
      "column": 0,
      "text": "pub async fn run_interactive_mode(provider_name: Option<&str>) -> Result<()> {\n    // Initialize session with persistent context (CLI-008)\n    let mut session = Session::new(provider_name)?;\n\n    // CLI-016: Inject context reminders (CLAUDE.md discovery + environment info)\n    session.inject_context_reminders();\n\n    // Display startup card\n    display_startup_card(&session)?;\n\n    // Main REPL loop (raw mode is enabled/disabled per-request, not globally)\n    let result = repl_loop(&mut session).await;\n\n    result\n}"
    },
    {
      "type": "function_item",
      "name": "display_startup_card",
      "line": 55,
      "column": 0,
      "text": "fn display_startup_card(session: &Session) -> Result<()> {\n    let version = env!(\"CARGO_PKG_VERSION\");\n    println!(\"\\nCodelet v{version}\");\n\n    let manager = session.provider_manager();\n    if !manager.has_any_provider() {\n        println!(\"Available models: No providers configured\");\n        println!(\"Please set ANTHROPIC_API_KEY, OPENAI_API_KEY, or other credentials\\n\");\n    } else {\n        let providers = manager.list_available_providers();\n        println!(\"Available models: {}\\n\", providers.join(\", \"));\n    }\n\n    Ok(())\n}"
    },
    {
      "type": "function_item",
      "name": "repl_loop",
      "line": 72,
      "column": 0,
      "text": "async fn repl_loop(session: &mut Session) -> Result<()> {\n    let mut input_queue = InputQueue::new();\n    let is_interrupted = Arc::new(AtomicBool::new(false));\n\n    println!(\"Enter your prompt (or 'exit' to quit):\");\n\n    loop {\n        // Read user input with provider-prefixed prompt\n        print!(\"{}\", session.provider_manager().get_prompt_prefix());\n        std::io::stdout().flush()?;\n\n        let mut input = String::new();\n        std::io::stdin().read_line(&mut input)?;\n        let input = input.trim();\n\n        // Check for exit\n        if matches!(input, \"exit\" | \"/quit\" | \"quit\") {\n            println!(\"Goodbye!\");\n            break;\n        }\n\n        // Handle /debug command - CLI-022\n        if input == \"/debug\" {\n            let result = handle_debug_command();\n            // Set session metadata when enabling debug capture\n            if result.enabled {\n                if let Ok(manager_arc) = get_debug_capture_manager() {\n                    if let Ok(mut manager) = manager_arc.lock() {\n                        manager.set_session_metadata(SessionMetadata {\n                            provider: Some(session.current_provider_name().to_string()),\n                            model: Some(session.current_provider_name().to_string()),\n                            context_window: Some(session.provider_manager().context_window()),\n                            max_output_tokens: None,\n                        });\n                    }\n                }\n            }\n            // CLI-022: Capture command.executed event\n            if let Ok(manager_arc) = get_debug_capture_manager() {\n                if let Ok(mut manager) = manager_arc.lock() {\n                    if manager.is_enabled() {\n                        manager.capture(\n                            \"command.executed\",\n                            serde_json::json!({\n                                \"command\": \"/debug\",\n                                \"result\": if result.enabled { \"enabled\" } else { \"disabled\" },\n                            }),\n                            None,\n                        );\n                    }\n                }\n            }\n            println!(\"{}\\n\", result.message);\n            continue;\n        }\n\n        // Check for provider switch - CLEARS CONTEXT (CLI-008)\n        if input.starts_with('/') {\n            let provider = input.trim_start_matches('/');\n            // Capture provider.switch event - CLI-022\n            if let Ok(manager_arc) = get_debug_capture_manager() {\n                if let Ok(mut manager) = manager_arc.lock() {\n                    if manager.is_enabled() {\n                        manager.capture(\n                            \"provider.switch\",\n                            serde_json::json!({\n                                \"from\": session.current_provider_name(),\n                                \"to\": provider,\n                            }),\n                            None,\n                        );\n                    }\n                }\n            }\n            match session.switch_provider(provider) {\n                Ok(()) => {\n                    info!(\"Provider switched to: {}\", provider);\n                    println!(\"Switched to {provider} provider\\n\");\n                    continue;\n                }\n                Err(e) => {\n                    debug!(\"Provider switch failed: {}\", e);\n                    eprintln!(\"Error switching provider: {e}\\n\");\n                    continue;\n                }\n            }\n        }\n\n        if input.is_empty() {\n            continue;\n        }\n\n        // Capture user.input event - CLI-022\n        if let Ok(manager_arc) = get_debug_capture_manager() {\n            if let Ok(mut manager) = manager_arc.lock() {\n                if manager.is_enabled() {\n                    manager.capture(\n                        \"user.input\",\n                        serde_json::json!({\n                            \"input\": input,\n                            \"inputLength\": input.len(),\n                        }),\n                        None,\n                    );\n                    // Increment turn for each user input\n                    manager.increment_turn();\n                }\n            }\n        }\n\n        // Run agent with interruption support and persistent context (CLI-008)\n        // Enable raw mode only during agent execution for ESC key detection\n        is_interrupted.store(false, Ordering::Relaxed);\n        enable_raw_mode()?;\n        let mut event_stream = create_event_stream();\n\n        let agent_result = run_agent_with_interruption(\n            session,\n            input,\n            &mut event_stream,\n            &mut input_queue,\n            is_interrupted.clone(),\n        )\n        .await;\n\n        // Always disable raw mode after agent completes\n        disable_raw_mode()?;\n\n        match agent_result {\n            Ok(()) => println!(\"\\n\"),\n            Err(e) => eprintln!(\"Error: {e}\\n\"),\n        }\n    }\n\n    Ok(())\n}"
    },
    {
      "type": "function_item",
      "name": "run_agent_with_interruption",
      "line": 210,
      "column": 0,
      "text": "async fn run_agent_with_interruption(\n    session: &mut Session,\n    prompt: &str,\n    event_stream: &mut (dyn futures::Stream<Item = TuiEvent> + Unpin + Send),\n    input_queue: &mut InputQueue,\n    is_interrupted: Arc<AtomicBool>,\n) -> Result<()> {\n    // Get provider name before mutable borrow (to satisfy borrow checker)\n    let provider_name = session.current_provider_name().to_string();\n    let manager = session.provider_manager_mut();\n\n    // Macro to eliminate code duplication across provider branches (DRY principle)\n    // PROV-006: Pass preamble to enable cache_control for API key mode\n    macro_rules! run_with_provider {\n        ($get_provider:ident, $preamble:expr) => {{\n            let provider = manager.$get_provider()?;\n            let rig_agent = provider.create_rig_agent($preamble);\n            let agent = RigAgent::with_default_depth(rig_agent);\n            run_agent_stream_with_interruption(\n                agent,\n                prompt,\n                session, // Pass entire session for token tracking and compaction (CLI-010)\n                event_stream,\n                input_queue,\n                is_interrupted,\n            )\n            .await\n        }};\n    }\n\n    // Dispatch to provider-specific agent\n    // PROV-006: For now pass None - preamble comes from session.messages as user messages\n    // Future enhancement: extract CLAUDE.md content as preamble for API key mode\n    match provider_name.as_str() {\n        \"claude\" => run_with_provider!(get_claude, None),\n        \"openai\" => run_with_provider!(get_openai, None),\n        \"codex\" => run_with_provider!(get_codex, None),\n        \"gemini\" => run_with_provider!(get_gemini, None),\n        _ => Err(anyhow::anyhow!(\"Unknown provider\")),\n    }\n}"
    },
    {
      "type": "function_item",
      "name": "add_assistant_text_message",
      "line": 254,
      "column": 0,
      "text": "fn add_assistant_text_message(messages: &mut Vec<rig::message::Message>, text: String) {\n    use rig::message::{AssistantContent, Message, Text};\n    use rig::OneOrMany;\n\n    messages.push(Message::Assistant {\n        id: None,\n        content: OneOrMany::one(AssistantContent::Text(Text { text })),\n    });\n}"
    },
    {
      "type": "function_item",
      "name": "add_assistant_tool_calls_message",
      "line": 266,
      "column": 0,
      "text": "fn add_assistant_tool_calls_message(\n    messages: &mut Vec<rig::message::Message>,\n    tool_calls: Vec<rig::message::AssistantContent>,\n) -> Result<()> {\n    use rig::message::Message;\n    use rig::OneOrMany;\n    use tracing::error;\n\n    match OneOrMany::many(tool_calls) {\n        Ok(content) => {\n            messages.push(Message::Assistant { id: None, content });\n            Ok(())\n        }\n        Err(e) => {\n            error!(\"Failed to convert tool calls to message: {:?}\", e);\n            Err(anyhow::anyhow!(\"Failed to convert tool calls: {e:?}\"))\n        }\n    }\n}"
    },
    {
      "type": "function_item",
      "name": "handle_text_chunk",
      "line": 287,
      "column": 0,
      "text": "fn handle_text_chunk(\n    text: &str,\n    assistant_text: &mut String,\n    request_id: Option<&str>,\n) -> Result<()> {\n    // CLI-022: Capture api.response.chunk event\n    if let Ok(manager_arc) = get_debug_capture_manager() {\n        if let Ok(mut manager) = manager_arc.lock() {\n            if manager.is_enabled() {\n                manager.capture(\n                    \"api.response.chunk\",\n                    serde_json::json!({\n                        \"chunkLength\": text.len(),\n                    }),\n                    request_id.map(|id| codelet_common::debug_capture::CaptureOptions {\n                        request_id: Some(id.to_string()),\n                    }),\n                );\n            }\n        }\n    }\n\n    // CRITICAL: Accumulate for message history (CLI-008)\n    assistant_text.push_str(text);\n\n    // Print text immediately for real-time streaming\n    // Replace \\n with \\r\\n for proper terminal display in raw mode\n    let display_text = text.replace('\\n', \"\\r\\n\");\n    print!(\"{display_text}\");\n    std::io::stdout().flush()?;\n\n    Ok(())\n}"
    },
    {
      "type": "function_item",
      "name": "handle_tool_call",
      "line": 322,
      "column": 0,
      "text": "fn handle_tool_call(\n    tool_call: &rig::message::ToolCall,\n    messages: &mut Vec<rig::message::Message>,\n    assistant_text: &mut String,\n    tool_calls_buffer: &mut Vec<rig::message::AssistantContent>,\n    last_tool_name: &mut Option<String>,\n) -> Result<()> {\n    use rig::message::AssistantContent;\n\n    // CRITICAL: Add assistant text to messages if we have any (CLI-008)\n    if !assistant_text.is_empty() {\n        add_assistant_text_message(messages, assistant_text.clone());\n        assistant_text.clear();\n    }\n\n    // Display tool name and arguments before execution\n    let tool_name = &tool_call.function.name;\n    let args = &tool_call.function.arguments;\n\n    // CLI-022: Capture tool.call event\n    if let Ok(manager_arc) = get_debug_capture_manager() {\n        if let Ok(mut manager) = manager_arc.lock() {\n            if manager.is_enabled() {\n                manager.capture(\n                    \"tool.call\",\n                    serde_json::json!({\n                        \"toolName\": tool_name,\n                        \"toolId\": tool_call.id,\n                        \"arguments\": args,\n                    }),\n                    None,\n                );\n            }\n        }\n    }\n\n    // Store tool name for debug logging\n    *last_tool_name = Some(tool_name.clone());\n\n    // CRITICAL: Track tool call for message history (CLI-008)\n    tool_calls_buffer.push(AssistantContent::ToolCall(tool_call.clone()));\n\n    // Log full details\n    debug!(\"Tool call: {} with args: {:?}\", tool_name, args);\n\n    // Display tool name\n    print!(\"\\r\\n[Planning to use tool: {tool_name}]\");\n\n    // Display arguments\n    if let Some(obj) = args.as_object() {\n        if !obj.is_empty() {\n            for (key, value) in obj.iter() {\n                // Format value based on type\n                let formatted_value = match value {\n                    serde_json::Value::String(s) => s.clone(),\n                    serde_json::Value::Number(n) => n.to_string(),\n                    serde_json::Value::Bool(b) => b.to_string(),\n                    serde_json::Value::Array(_) => format!(\"{value}\"),\n                    serde_json::Value::Object(_) => format!(\"{value}\"),\n                    serde_json::Value::Null => \"null\".to_string(),\n                };\n                print!(\"\\r\\n  {key}: {formatted_value}\");\n            }\n        }\n    }\n    println!(\"\\r\\n\");\n    std::io::stdout().flush()?;\n\n    Ok(())\n}"
    },
    {
      "type": "function_item",
      "name": "handle_tool_result",
      "line": 394,
      "column": 0,
      "text": "fn handle_tool_result(\n    tool_result: &rig::message::ToolResult,\n    messages: &mut Vec<rig::message::Message>,\n    tool_calls_buffer: &mut Vec<rig::message::AssistantContent>,\n    last_tool_name: &Option<String>,\n) -> Result<()> {\n    use rig::message::{Message, ToolResultContent, UserContent};\n    use rig::OneOrMany;\n\n    // CRITICAL: Add buffered tool calls as assistant message (CLI-008)\n    // This happens ONCE before the first tool result\n    if !tool_calls_buffer.is_empty() {\n        add_assistant_tool_calls_message(messages, tool_calls_buffer.clone())?;\n        tool_calls_buffer.clear();\n    }\n\n    // CRITICAL: Add tool result to message history (CLI-008)\n    let tool_result_clone = tool_result.clone();\n    messages.push(Message::User {\n        content: OneOrMany::one(UserContent::ToolResult(tool_result_clone)),\n    });\n\n    // Display tool result with preview (similar to codelet pattern)\n    debug!(\"Tool result received: {:?}\", tool_result);\n\n    // CLI-022: Capture tool.result event\n    // Determine success from result content (check for error indicators)\n    let is_error = tool_result.content.clone().into_iter().any(|c| match c {\n        ToolResultContent::Text(t) => t.text.contains(\"Error:\") || t.text.contains(\"error:\"),\n        _ => false,\n    });\n\n    if let Ok(manager_arc) = get_debug_capture_manager() {\n        if let Ok(mut manager) = manager_arc.lock() {\n            if manager.is_enabled() {\n                let event_type = if is_error {\n                    \"tool.error\"\n                } else {\n                    \"tool.result\"\n                };\n                manager.capture(\n                    event_type,\n                    serde_json::json!({\n                        \"toolName\": last_tool_name.as_deref().unwrap_or(\"unknown\"),\n                        \"toolId\": tool_result.id,\n                        \"success\": !is_error,\n                    }),\n                    None,\n                );\n            }\n        }\n    }\n\n    // Extract text content from tool result by iterating over OneOrMany\n    let result_parts: Vec<String> = tool_result\n        .content\n        .clone()\n        .into_iter()\n        .map(|content| match content {\n            ToolResultContent::Text(text) => text.text,\n            ToolResultContent::Image(_) => \"[Image]\".to_string(),\n        })\n        .collect();\n\n    let mut result_text = result_parts.join(\"\\n\");\n\n    // Strip surrounding quotes if present (JSON-escaped string)\n    if result_text.starts_with('\"') && result_text.ends_with('\"') {\n        result_text = result_text[1..result_text.len() - 1].to_string();\n    }\n\n    // Unescape common JSON escape sequences\n    result_text = result_text\n        .replace(\"\\\\n\", \"\\n\")\n        .replace(\"\\\\t\", \"\\t\")\n        .replace(\"\\\\r\", \"\\r\")\n        .replace(\"\\\\\\\"\", \"\\\"\")\n        .replace(\"\\\\\\\\\", \"\\\\\");\n\n    // Truncate result if too long (like codelet does at 500 chars)\n    const MAX_PREVIEW_LENGTH: usize = 500;\n    let preview = if result_text.len() > MAX_PREVIEW_LENGTH {\n        format!(\"{}...\", &result_text[..MAX_PREVIEW_LENGTH])\n    } else {\n        result_text\n    };\n\n    // Display with proper formatting for raw mode\n    // Indent each line by 2 spaces and replace \\n with \\r\\n\n    let indented_lines: Vec<String> = preview.lines().map(|line| format!(\"  {line}\")).collect();\n    let formatted_preview = indented_lines.join(\"\\r\\n\");\n\n    print!(\"\\r\\n[Tool result preview]\\r\\n-------\\r\\n{formatted_preview}\\r\\n-------\\r\\n\");\n    std::io::stdout().flush()?;\n\n    Ok(())\n}"
    },
    {
      "type": "function_item",
      "name": "handle_final_response",
      "line": 493,
      "column": 0,
      "text": "fn handle_final_response(\n    assistant_text: &str,\n    messages: &mut Vec<rig::message::Message>,\n) -> Result<()> {\n    // CRITICAL: Add final assistant text to message history (CLI-008)\n    if !assistant_text.is_empty() {\n        add_assistant_text_message(messages, assistant_text.to_owned());\n    }\n\n    Ok(())\n}"
    },
    {
      "type": "function_item",
      "name": "run_agent_stream_with_interruption",
      "line": 508,
      "column": 0,
      "text": "async fn run_agent_stream_with_interruption<M>(\n    agent: RigAgent<M>,\n    prompt: &str,\n    session: &mut Session, // CLI-010: Need full session for token tracking and compaction\n    event_stream: &mut (dyn futures::Stream<Item = TuiEvent> + Unpin + Send),\n    input_queue: &mut InputQueue,\n    is_interrupted: Arc<AtomicBool>,\n) -> Result<()>\nwhere\n    M: CompletionModel,\n{\n    use rig::message::{Message, UserContent};\n    use rig::OneOrMany;\n    use std::time::Instant;\n    use uuid::Uuid;\n\n    // CLI-022: Generate request ID for correlation\n    let request_id = Uuid::new_v4().to_string();\n    let api_start_time = Instant::now();\n\n    // CLI-022: Capture api.request event\n    if let Ok(manager_arc) = get_debug_capture_manager() {\n        if let Ok(mut manager) = manager_arc.lock() {\n            if manager.is_enabled() {\n                manager.capture(\n                    \"api.request\",\n                    serde_json::json!({\n                        \"provider\": session.current_provider_name(),\n                        \"model\": session.current_provider_name(),\n                        \"prompt\": prompt,\n                        \"promptLength\": prompt.len(),\n                        \"messageCount\": session.messages.len(),\n                    }),\n                    Some(codelet_common::debug_capture::CaptureOptions {\n                        request_id: Some(request_id.clone()),\n                    }),\n                );\n            }\n        }\n    }\n\n    // CRITICAL: Add user prompt to message history for persistence (CLI-008)\n    session.messages.push(Message::User {\n        content: OneOrMany::one(UserContent::text(prompt)),\n    });\n\n    // CRITICAL FIX: Pass conversation history to rig for context persistence (CLI-008)\n    let mut stream = agent\n        .prompt_streaming_with_history(prompt, &mut session.messages)\n        .await;\n\n    // CLI-022: Capture api.response.start event\n    if let Ok(manager_arc) = get_debug_capture_manager() {\n        if let Ok(mut manager) = manager_arc.lock() {\n            if manager.is_enabled() {\n                manager.capture(\n                    \"api.response.start\",\n                    serde_json::json!({\n                        \"provider\": session.current_provider_name(),\n                    }),\n                    Some(codelet_common::debug_capture::CaptureOptions {\n                        request_id: Some(request_id.clone()),\n                    }),\n                );\n            }\n        }\n    }\n\n    let status = StatusDisplay::new();\n    let mut status_interval = interval(Duration::from_secs(1));\n\n    // Track assistant response content for adding to messages (CLI-008)\n    let mut assistant_text = String::new();\n    let mut tool_calls_buffer: Vec<rig::message::AssistantContent> = Vec::new();\n\n    // Track last tool call for debug logging\n    let mut last_tool_name: Option<String> = None;\n\n    // CLI-010: Track token usage for compaction\n    let mut turn_input_tokens: u64 = 0;\n    let mut turn_output_tokens: u64 = 0;\n    let mut turn_cache_read_tokens: Option<u64> = None;\n    let mut turn_cache_creation_tokens: Option<u64> = None;\n\n    loop {\n        tokio::select! {\n            // Agent streaming\n            chunk = stream.next() => {\n                if is_interrupted.load(Ordering::Relaxed) {\n                    // Interrupted - show queued inputs\n                    println!(\"\\n⚠️ Agent interrupted\");\n                    let queued = input_queue.dequeue_all();\n                    if queued.is_empty() {\n                        println!(\"Queued inputs: (none)\");\n                    } else {\n                        println!(\"Queued inputs:\\n{}\", queued.join(\"\\n\\n\"));\n                    }\n                    break;\n                }\n\n                match chunk {\n                    Some(Ok(MultiTurnStreamItem::StreamAssistantItem(StreamedAssistantContent::Text(text)))) => {\n                        handle_text_chunk(\n                            &text.text,\n                            &mut assistant_text,\n                            Some(&request_id),\n                        )?;\n                    }\n                    Some(Ok(MultiTurnStreamItem::StreamAssistantItem(StreamedAssistantContent::ToolCall(tool_call)))) => {\n                        handle_tool_call(\n                            &tool_call,\n                            &mut session.messages,\n                            &mut assistant_text,\n                            &mut tool_calls_buffer,\n                            &mut last_tool_name,\n                        )?;\n                    }\n                    Some(Ok(MultiTurnStreamItem::StreamUserItem(StreamedUserContent::ToolResult(tool_result)))) => {\n                        handle_tool_result(\n                            &tool_result,\n                            &mut session.messages,\n                            &mut tool_calls_buffer,\n                            &last_tool_name,\n                        )?;\n                    }\n                    Some(Ok(MultiTurnStreamItem::FinalResponse(final_resp))) => {\n                        // CLI-010: Extract token usage from FinalResponse\n                        let usage = final_resp.usage();\n\n                        // Use API values if available, otherwise estimate (matches codelet fallback pattern)\n                        turn_input_tokens = if usage.input_tokens > 0 {\n                            usage.input_tokens\n                        } else {\n                            estimate_tokens(prompt)\n                        };\n\n                        turn_output_tokens = if usage.output_tokens > 0 {\n                            usage.output_tokens\n                        } else {\n                            estimate_tokens(&assistant_text)\n                        };\n\n                        // PROV-006: Cache token extraction from Anthropic API\n                        //\n                        // REQUEST-SIDE (WORKING): ClaudeProvider.create_rig_agent() uses additional_params\n                        // to transform system prompts to array format with cache_control metadata.\n                        // This enables Anthropic's prompt caching on outgoing requests.\n                        //\n                        // RESPONSE-SIDE (NOW WORKING): Patched rig-core exposes cache tokens in Usage.\n                        // The patch adds cache_read_input_tokens and cache_creation_input_tokens fields\n                        // to rig's generic Usage struct, and extracts them from MessageStart SSE events.\n                        turn_cache_read_tokens = usage.cache_read_input_tokens;\n                        turn_cache_creation_tokens = usage.cache_creation_input_tokens;\n\n                        // CLI-022: Capture api.response.end event with token usage\n                        if let Ok(manager_arc) = get_debug_capture_manager() {\n                            if let Ok(mut manager) = manager_arc.lock() {\n                                if manager.is_enabled() {\n                                    let duration_ms = api_start_time.elapsed().as_millis() as u64;\n                                    manager.capture(\n                                        \"api.response.end\",\n                                        serde_json::json!({\n                                            \"duration\": duration_ms,\n                                            \"usage\": {\n                                                \"inputTokens\": turn_input_tokens,\n                                                \"outputTokens\": turn_output_tokens,\n                                                \"cacheReadInputTokens\": turn_cache_read_tokens,\n                                                \"cacheCreationInputTokens\": turn_cache_creation_tokens,\n                                            },\n                                            \"responseLength\": assistant_text.len(),\n                                        }),\n                                        Some(codelet_common::debug_capture::CaptureOptions {\n                                            request_id: Some(request_id.clone()),\n                                        }),\n                                    );\n\n                                    // CLI-022: Capture token.update event\n                                    // Note: totalInputTokens = inputTokens since we REPLACE (not accumulate)\n                                    manager.capture(\n                                        \"token.update\",\n                                        serde_json::json!({\n                                            \"inputTokens\": turn_input_tokens,\n                                            \"outputTokens\": turn_output_tokens,\n                                            \"cacheReadInputTokens\": turn_cache_read_tokens,\n                                            \"cacheCreationInputTokens\": turn_cache_creation_tokens,\n                                            \"totalInputTokens\": turn_input_tokens,\n                                            \"totalOutputTokens\": turn_output_tokens,\n                                        }),\n                                        None,\n                                    );\n                                }\n                            }\n                        }\n\n                        handle_final_response(\n                            &assistant_text,\n                            &mut session.messages,\n                        )?;\n                        // Stream complete\n                        break;\n                    }\n                    Some(Err(e)) => {\n                        // CLI-022: Capture api.error event\n                        if let Ok(manager_arc) = get_debug_capture_manager() {\n                            if let Ok(mut manager) = manager_arc.lock() {\n                                if manager.is_enabled() {\n                                    manager.capture(\n                                        \"api.error\",\n                                        serde_json::json!({\n                                            \"error\": e.to_string(),\n                                            \"duration\": api_start_time.elapsed().as_millis() as u64,\n                                        }),\n                                        Some(codelet_common::debug_capture::CaptureOptions {\n                                            request_id: Some(request_id.clone()),\n                                        }),\n                                    );\n                                }\n                            }\n                        }\n                        return Err(anyhow::anyhow!(\"Agent error: {e}\"));\n                    }\n                    _ => {\n                        // Other stream items\n                    }\n                }\n            }\n\n            // Terminal events\n            event = event_stream.next() => {\n                match event {\n                    Some(TuiEvent::Key(key)) if key.code == KeyCode::Esc => {\n                        is_interrupted.store(true, Ordering::Relaxed);\n                    }\n                    _ => {}\n                }\n            }\n\n            // Status display updates\n            _ = status_interval.tick() => {\n                // Update status (in real implementation, would render to UI)\n                // For now, just track elapsed time\n                let _ = status.format_status();\n            }\n        }\n    }\n\n    // CLI-010: After stream completes, update tokens and check compaction\n    if !is_interrupted.load(Ordering::Relaxed) {\n        // Replace token tracker with API usage values (matches TypeScript runner.ts:1143)\n        // TypeScript: inputTokens: usage.inputTokens ?? tokenTracker.inputTokens\n        // The API reports total input tokens for the current context, not incremental\n        session.token_tracker.input_tokens = turn_input_tokens;\n        session.token_tracker.output_tokens = turn_output_tokens;\n        if let Some(cache_read) = turn_cache_read_tokens {\n            let current = session.token_tracker.cache_read_input_tokens.unwrap_or(0);\n            session.token_tracker.cache_read_input_tokens = Some(current + cache_read);\n        }\n        if let Some(cache_create) = turn_cache_creation_tokens {\n            let current = session\n                .token_tracker\n                .cache_creation_input_tokens\n                .unwrap_or(0);\n            session.token_tracker.cache_creation_input_tokens = Some(current + cache_create);\n        }\n\n        // CTX-002: Removed eager turn creation - now done lazily during compaction\n        // Turns are created from session.messages inside execute_compaction() following TypeScript implementation\n\n        // Check if compaction should trigger\n        // CLI-015: Use model-specific context window instead of hardcoded value\n        // CLI-020: Apply autocompact buffer to leave headroom after compaction\n        // FIX: Use message estimation instead of rig's aggregated_usage, because rig\n        // accumulates tokens across all tool call iterations in a multi-turn agent call.\n        // For compaction, we need the CURRENT context size, not accumulated API usage.\n        use crate::compaction_threshold::calculate_compaction_threshold;\n        use crate::interactive_helpers::estimate_message_tokens;\n        let context_window = session.provider_manager().context_window() as u64;\n        let threshold = calculate_compaction_threshold(context_window);\n        let effective = estimate_message_tokens(&session.messages);\n\n        if effective > threshold {\n            // CLI-022: Capture compaction.triggered event\n            if let Ok(manager_arc) = get_debug_capture_manager() {\n                if let Ok(mut manager) = manager_arc.lock() {\n                    if manager.is_enabled() {\n                        manager.capture(\n                            \"compaction.triggered\",\n                            serde_json::json!({\n                                \"effectiveTokens\": effective,\n                                \"threshold\": threshold,\n                                \"contextWindow\": context_window,\n                            }),\n                            None,\n                        );\n                    }\n                }\n            }\n\n            println!(\"\\n[Generating summary...]\");\n            std::io::stdout().flush()?;\n\n            // Execute compaction\n            match execute_compaction(session).await {\n                Ok(metrics) => {\n                    // CLI-022: Capture context.update event after compaction\n                    if let Ok(manager_arc) = get_debug_capture_manager() {\n                        if let Ok(mut manager) = manager_arc.lock() {\n                            if manager.is_enabled() {\n                                manager.capture(\n                                    \"context.update\",\n                                    serde_json::json!({\n                                        \"type\": \"compaction\",\n                                        \"originalTokens\": metrics.original_tokens,\n                                        \"compactedTokens\": metrics.compacted_tokens,\n                                        \"compressionRatio\": metrics.compression_ratio,\n                                    }),\n                                    None,\n                                );\n                            }\n                        }\n                    }\n\n                    println!(\n                        \"[Context compacted: {}→{} tokens, {:.0}% compression]\\n\",\n                        metrics.original_tokens,\n                        metrics.compacted_tokens,\n                        metrics.compression_ratio * 100.0\n                    );\n                }\n                Err(e) => {\n                    eprintln!(\"Warning: Compaction failed: {e}\");\n                }\n            }\n        }\n    }\n\n    Ok(())\n}"
    }
  ]
}
