{
  "matches": [
    {
      "type": "function_item",
      "name": "ephemeral",
      "line": 47,
      "column": 4,
      "text": "pub fn ephemeral() -> Self {\n        Self {\n            cache_type: \"ephemeral\".to_string(),\n        }\n    }"
    },
    {
      "type": "function_item",
      "name": "build_cached_system_prompt",
      "line": 71,
      "column": 0,
      "text": "pub fn build_cached_system_prompt(\n    preamble: &str,\n    is_oauth: bool,\n    oauth_prefix: Option<&str>,\n) -> serde_json::Value {\n    if is_oauth {\n        // OAuth mode: first block is prefix without cache_control\n        // second block is preamble with cache_control\n        let prefix = oauth_prefix.unwrap_or(CLAUDE_CODE_PROMPT_PREFIX);\n        json!([\n            {\n                \"type\": \"text\",\n                \"text\": prefix\n            },\n            {\n                \"type\": \"text\",\n                \"text\": preamble,\n                \"cache_control\": { \"type\": \"ephemeral\" }\n            }\n        ])\n    } else {\n        // API key mode: single block with cache_control\n        json!([\n            {\n                \"type\": \"text\",\n                \"text\": preamble,\n                \"cache_control\": { \"type\": \"ephemeral\" }\n            }\n        ])\n    }\n}"
    },
    {
      "type": "function_item",
      "name": "fmt",
      "line": 121,
      "column": 4,
      "text": "fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        f.debug_struct(\"ClaudeProvider\")\n            .field(\"model\", &DEFAULT_MODEL)\n            .field(\"auth_mode\", &self.auth_mode)\n            .finish()\n    }"
    },
    {
      "type": "function_item",
      "name": "new",
      "line": 135,
      "column": 4,
      "text": "pub fn new() -> Result<Self> {\n        // Check for API key first (takes precedence)\n        if let Ok(api_key) = std::env::var(\"ANTHROPIC_API_KEY\") {\n            return Self::from_api_key_with_mode(&api_key, AuthMode::ApiKey);\n        }\n\n        // Fall back to OAuth token\n        if let Ok(oauth_token) = std::env::var(\"CLAUDE_CODE_OAUTH_TOKEN\") {\n            return Self::from_api_key_with_mode(&oauth_token, AuthMode::OAuth);\n        }\n\n        Err(anyhow!(\n            \"No API key found. Set ANTHROPIC_API_KEY or CLAUDE_CODE_OAUTH_TOKEN environment variable\"\n        ))\n    }"
    },
    {
      "type": "function_item",
      "name": "from_api_key",
      "line": 152,
      "column": 4,
      "text": "pub fn from_api_key(api_key: &str) -> Result<Self> {\n        Self::from_api_key_with_mode(api_key, AuthMode::ApiKey)\n    }"
    },
    {
      "type": "function_item",
      "name": "from_api_key_with_mode",
      "line": 157,
      "column": 4,
      "text": "pub fn from_api_key_with_mode(api_key: &str, auth_mode: AuthMode) -> Result<Self> {\n        if api_key.is_empty() {\n            return Err(anyhow!(\"API key cannot be empty\"));\n        }\n\n        // Parse beta headers for rig client\n        let beta_features: Vec<&str> = ANTHROPIC_BETA_HEADER.split(',').collect();\n\n        // Build rig client with beta headers (using default reqwest::Client)\n        let mut rig_client: anthropic::Client = anthropic::Client::builder()\n            .api_key(api_key)\n            .anthropic_betas(&beta_features)\n            .build()\n            .map_err(|e| anyhow!(\"Failed to build Anthropic client: {e}\"))?;\n\n        // For OAuth mode, replace x-api-key header with Bearer auth\n        if auth_mode == AuthMode::OAuth {\n            let mut headers = rig_client.headers().clone();\n\n            // Remove x-api-key header\n            headers.remove(\"x-api-key\");\n\n            // Add Authorization: Bearer header\n            headers.insert(\n                AUTHORIZATION,\n                HeaderValue::from_str(&format!(\"Bearer {api_key}\"))\n                    .map_err(|e| anyhow!(\"Invalid OAuth token: {e}\"))?,\n            );\n\n            // Rebuild client with modified headers\n            rig_client = anthropic::Client::from_parts(\n                rig_client.base_url().to_string(),\n                headers,\n                rig_client.http_client().clone(),\n                rig_client.ext().clone(),\n            );\n        }\n\n        // Create completion model\n        let completion_model =\n            anthropic::completion::CompletionModel::new(rig_client.clone(), DEFAULT_MODEL);\n\n        Ok(Self {\n            completion_model,\n            rig_client,\n            auth_mode,\n        })\n    }"
    },
    {
      "type": "function_item",
      "name": "is_oauth_mode",
      "line": 207,
      "column": 4,
      "text": "pub fn is_oauth_mode(&self) -> bool {\n        self.auth_mode == AuthMode::OAuth\n    }"
    },
    {
      "type": "function_item",
      "name": "client",
      "line": 219,
      "column": 4,
      "text": "pub fn client(&self) -> &anthropic::Client {\n        &self.rig_client\n    }"
    },
    {
      "type": "function_item",
      "name": "system_prompt",
      "line": 227,
      "column": 4,
      "text": "pub fn system_prompt(&self) -> Option<&'static str> {\n        if self.auth_mode == AuthMode::OAuth {\n            Some(CLAUDE_CODE_PROMPT_PREFIX)\n        } else {\n            None\n        }\n    }"
    },
    {
      "type": "function_item",
      "name": "get_system_prompt_prefix",
      "line": 236,
      "column": 4,
      "text": "pub fn get_system_prompt_prefix(&self) -> &'static str {\n        CLAUDE_CODE_PROMPT_PREFIX\n    }"
    },
    {
      "type": "function_item",
      "name": "get_anthropic_beta_header",
      "line": 241,
      "column": 4,
      "text": "pub fn get_anthropic_beta_header(&self) -> &'static str {\n        ANTHROPIC_BETA_HEADER\n    }"
    },
    {
      "type": "function_item",
      "name": "create_rig_agent",
      "line": 254,
      "column": 4,
      "text": "pub fn create_rig_agent(&self) -> rig::agent::Agent<anthropic::completion::CompletionModel> {\n        use codelet_tools::{\n            AstGrepTool, BashTool, EditTool, GlobTool, GrepTool, LsTool, ReadTool, WriteTool,\n        };\n        use rig::client::CompletionClient;\n\n        // Build agent with all 8 tools using rig's builder pattern\n        let mut agent_builder = self\n            .rig_client\n            .agent(DEFAULT_MODEL)\n            .max_tokens(MAX_OUTPUT_TOKENS as u64)\n            .tool(ReadTool::new())\n            .tool(WriteTool::new())\n            .tool(EditTool::new())\n            .tool(BashTool::new())\n            .tool(GrepTool::new())\n            .tool(GlobTool::new())\n            .tool(LsTool::new())\n            .tool(AstGrepTool::new());\n\n        // For OAuth mode, add the Claude Code system prompt prefix\n        // This is required by Claude Code OAuth authentication\n        if let Some(preamble) = self.system_prompt() {\n            agent_builder = agent_builder.preamble(preamble);\n        }\n\n        agent_builder.build()\n    }"
    },
    {
      "type": "function_item",
      "name": "extract_text_from_content",
      "line": 284,
      "column": 4,
      "text": "fn extract_text_from_content(content: &MessageContent) -> String {\n        match content {\n            MessageContent::Text(t) => t.clone(),\n            MessageContent::Parts(parts) => parts\n                .iter()\n                .filter_map(|p| {\n                    if let ContentPart::Text { text } = p {\n                        Some(text.as_str())\n                    } else {\n                        None\n                    }\n                })\n                .collect::<Vec<_>>()\n                .join(\"\\n\"),\n        }\n    }"
    },
    {
      "type": "function_item",
      "name": "extract_prompt_data",
      "line": 302,
      "column": 4,
      "text": "fn extract_prompt_data(&self, messages: &[Message]) -> (Option<String>, String) {\n        let mut system_prompt: Option<String> = None;\n        let mut user_messages: Vec<String> = Vec::new();\n\n        for msg in messages {\n            match msg.role {\n                MessageRole::System => {\n                    let text = Self::extract_text_from_content(&msg.content);\n\n                    // OAuth mode requires prefix (but don't duplicate if already present)\n                    system_prompt = if self.auth_mode == AuthMode::OAuth {\n                        if text.starts_with(CLAUDE_CODE_PROMPT_PREFIX) {\n                            // Already has prefix, use as-is\n                            Some(text)\n                        } else {\n                            // Add prefix\n                            Some(format!(\"{CLAUDE_CODE_PROMPT_PREFIX}\\n\\n{text}\"))\n                        }\n                    } else {\n                        Some(text)\n                    };\n                }\n                MessageRole::User => {\n                    let text = Self::extract_text_from_content(&msg.content);\n                    user_messages.push(text);\n                }\n                MessageRole::Assistant => {\n                    // Multi-turn conversation history (including assistant messages) is out of\n                    // scope for REFAC-003. Multi-turn support will be added in REFAC-004 using\n                    // rig::agent::Agent which handles conversation history automatically.\n                    // For now, we only extract the last user message for single-turn completions.\n                }\n            }\n        }\n\n        let prompt = if user_messages.is_empty() {\n            String::new()\n        } else {\n            user_messages.join(\"\\n\\n\")\n        };\n\n        (system_prompt, prompt)\n    }"
    },
    {
      "type": "function_item",
      "name": "rig_response_to_completion",
      "line": 347,
      "column": 4,
      "text": "fn rig_response_to_completion(\n        &self,\n        response: rig::completion::CompletionResponse<anthropic::completion::CompletionResponse>,\n    ) -> Result<CompletionResponse> {\n        // Convert rig AssistantContent to our ContentPart format\n        let mut content_parts: Vec<ContentPart> = vec![];\n\n        for content in response.choice.into_iter() {\n            match content {\n                rig::completion::AssistantContent::Text(text) => {\n                    content_parts.push(ContentPart::Text { text: text.text });\n                }\n                rig::completion::AssistantContent::ToolCall(tool_call) => {\n                    content_parts.push(ContentPart::ToolUse {\n                        id: tool_call.id,\n                        name: tool_call.function.name,\n                        input: tool_call.function.arguments,\n                    });\n                }\n                rig::completion::AssistantContent::Reasoning(reasoning) => {\n                    // Rig returns reasoning separately, we can include it as text\n                    // or handle it specially if needed\n                    for r in reasoning.reasoning {\n                        content_parts.push(ContentPart::Text { text: r });\n                    }\n                }\n                rig::completion::AssistantContent::Image(_) => {\n                    // Anthropic doesn't support assistant images\n                    return Err(anyhow!(\"Assistant images not supported\"));\n                }\n            }\n        }\n\n        // Map Anthropic's stop_reason to our StopReason enum\n        let stop_reason = match response.raw_response.stop_reason.as_deref() {\n            Some(\"tool_use\") => StopReason::ToolUse,\n            Some(\"max_tokens\") => StopReason::MaxTokens,\n            Some(\"end_turn\") | Some(\"stop_sequence\") | None => StopReason::EndTurn,\n            Some(other) => {\n                // Unknown stop reason - log and default to EndTurn\n                warn!(stop_reason = %other, \"Unknown stop_reason from Anthropic API\");\n                StopReason::EndTurn\n            }\n        };\n\n        Ok(CompletionResponse {\n            content: MessageContent::Parts(content_parts),\n            stop_reason,\n        })\n    }"
    },
    {
      "type": "function_item",
      "name": "name",
      "line": 401,
      "column": 4,
      "text": "fn name(&self) -> &str {\n        \"claude\"\n    }"
    },
    {
      "type": "function_item",
      "name": "model",
      "line": 405,
      "column": 4,
      "text": "fn model(&self) -> &str {\n        DEFAULT_MODEL\n    }"
    },
    {
      "type": "function_item",
      "name": "context_window",
      "line": 409,
      "column": 4,
      "text": "fn context_window(&self) -> usize {\n        CONTEXT_WINDOW\n    }"
    },
    {
      "type": "function_item",
      "name": "max_output_tokens",
      "line": 413,
      "column": 4,
      "text": "fn max_output_tokens(&self) -> usize {\n        MAX_OUTPUT_TOKENS\n    }"
    },
    {
      "type": "function_item",
      "name": "supports_caching",
      "line": 417,
      "column": 4,
      "text": "fn supports_caching(&self) -> bool {\n        true // Claude supports prompt caching\n    }"
    },
    {
      "type": "function_item",
      "name": "supports_streaming",
      "line": 421,
      "column": 4,
      "text": "fn supports_streaming(&self) -> bool {\n        true // Streaming support via rig (REFAC-003)\n    }"
    },
    {
      "type": "function_item",
      "name": "complete",
      "line": 425,
      "column": 4,
      "text": "async fn complete(&self, messages: &[Message]) -> Result<String> {\n        // Reuse complete_with_tools with no tools to avoid code duplication\n        let response = self.complete_with_tools(messages, &[]).await?;\n\n        // Extract text using helper method to maintain DRY\n        Ok(Self::extract_text_from_content(&response.content))\n    }"
    },
    {
      "type": "function_item",
      "name": "complete_with_tools",
      "line": 433,
      "column": 4,
      "text": "async fn complete_with_tools(\n        &self,\n        messages: &[Message],\n        tools: &[OurToolDefinition],\n    ) -> Result<CompletionResponse> {\n        // Extract prompt data\n        let (preamble, prompt) = self.extract_prompt_data(messages);\n\n        // Convert tools to rig format\n        let rig_tools: Vec<rig::completion::ToolDefinition> = tools\n            .iter()\n            .map(|t| rig::completion::ToolDefinition {\n                name: t.name.clone(),\n                description: t.description.clone(),\n                parameters: t.input_schema.clone(),\n            })\n            .collect();\n\n        // Build and send completion request using rig's builder pattern\n        let mut builder = CompletionRequestBuilder::new(self.completion_model.clone(), prompt)\n            .max_tokens(MAX_OUTPUT_TOKENS as u64)\n            .tools(rig_tools);\n\n        if let Some(preamble_text) = preamble {\n            builder = builder.preamble(preamble_text);\n        }\n\n        // Send request and get response\n        let response = builder\n            .send()\n            .await\n            .map_err(|e| anyhow!(\"Rig completion with tools failed: {e}\"))?;\n\n        // Convert rig response to our CompletionResponse format\n        self.rig_response_to_completion(response)\n    }"
    }
  ]
}
