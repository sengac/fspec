/* tslint:disable */
/* eslint-disable */

/* auto-generated by NAPI-RS */

/** Token usage tracking information */
export interface TokenTracker {
  inputTokens: number;
  outputTokens: number;
  cacheReadInputTokens?: number;
  cacheCreationInputTokens?: number;
}
/** Tool call information */
export interface ToolCallInfo {
  id: string;
  name: string;
  input: string;
}
/** Tool result information */
export interface ToolResultInfo {
  toolCallId: string;
  content: string;
  isError: boolean;
}
/** Stream chunk types for streaming responses */
export const enum ChunkType {
  Text = 'Text',
  ToolCall = 'ToolCall',
  ToolResult = 'ToolResult',
  Status = 'Status',
  Interrupted = 'Interrupted',
  Done = 'Done',
  Error = 'Error',
}
/** A chunk of streaming response */
export interface StreamChunk {
  type: string;
  text?: string;
  toolCall?: ToolCallInfo;
  toolResult?: ToolResultInfo;
  status?: string;
  queuedInputs?: Array<string>;
  error?: string;
}
/** Message role enum */
export const enum MessageRole {
  System = 'System',
  User = 'User',
  Assistant = 'Assistant',
}
/** A conversation message (simplified for JS) */
export interface Message {
  role: string;
  content: string;
}
/**
 * CodeletSession - Main class for AI agent interactions
 *
 * Exposes codelet's Rust AI agent functionality to Node.js.
 */
export declare class CodeletSession {
  /**
   * Create a new CodeletSession
   *
   * If provider_name is not specified, auto-detects the highest priority available provider.
   * Priority order: Claude > Gemini > Codex > OpenAI
   */
  constructor(providerName?: string | undefined | null);
  /**
   * Interrupt the current agent execution
   *
   * Call this when the user presses Esc in the TUI.
   * The agent will stop at the next safe point and emit a Done chunk.
   */
  interrupt(): void;
  /**
   * Reset the interrupt flag
   *
   * Called automatically at the start of each prompt, but can be called
   * manually if needed.
   */
  resetInterrupt(): void;
  /** Get the current provider name */
  get currentProviderName(): string;
  /** Get list of available providers */
  get availableProviders(): Array<string>;
  /** Get the token usage tracker */
  get tokenTracker(): TokenTracker;
  /** Get conversation messages (simplified representation) */
  get messages(): Array<Message>;
  /** Switch to a different provider */
  switchProvider(providerName: string): Promise<void>;
  /** Clear conversation history */
  clearHistory(): void;
  /**
   * Send a prompt and stream the response
   *
   * The callback receives StreamChunk objects with type: 'Text', 'ToolCall', 'ToolResult', 'Done', or 'Error'
   *
   * Uses the same streaming infrastructure as codelet-cli:
   * - run_agent_stream for shared streaming logic
   * - StreamOutput trait for polymorphic output
   * - is_interrupted flag for Esc key handling (set via interrupt() method)
   */
  prompt(input: string, callback: (chunk: StreamChunk) => void): Promise<void>;
}
