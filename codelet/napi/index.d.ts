/* auto-generated by NAPI-RS */
/* eslint-disable */
/**
 * CodeletSession - Main class for AI agent interactions
 *
 * Exposes codelet's Rust AI agent functionality to Node.js.
 */
export declare class CodeletSession {
  /**
   * Create a new CodeletSession
   *
   * If provider_name is not specified, auto-detects the highest priority available provider.
   * Priority order: Claude > Gemini > Codex > OpenAI
   */
  constructor(providerName?: string | undefined | null);
  /**
   * Interrupt the current agent execution
   *
   * Call this when the user presses Esc in the TUI.
   * The agent will stop immediately via tokio::sync::Notify (NAPI-004).
   * The notify_one() call wakes the tokio::select! in stream_loop,
   * allowing immediate response to ESC even during blocking operations.
   *
   * IMPORTANT: Uses notify_one() instead of notify_waiters() because:
   * - notify_waiters() only wakes CURRENTLY waiting tasks (notification lost if none waiting)
   * - notify_one() stores a permit if no one waiting, so next notified() returns immediately
   * This eliminates the race condition between flag check and entering tokio::select!
   */
  interrupt(): void;
  /**
   * Reset the interrupt flag
   *
   * Called automatically at the start of each prompt, but can be called
   * manually if needed.
   */
  resetInterrupt(): void;
  /**
   * Toggle debug capture mode (AGENT-021)
   *
   * Mirrors CLI repl_loop.rs:36-67 logic.
   * When enabling, sets session metadata (provider, model, context_window).
   * When disabling, stops capture and returns path to saved session file.
   *
   * If debug_dir is provided, debug files will be written to `{debug_dir}/debug/`
   * instead of the default directory. For fspec, pass `~/.fspec` to write to
   * `~/.fspec/debug/`.
   */
  toggleDebug(debugDir?: string | undefined | null): DebugCommandResult;
  /** Get the current provider name */
  get currentProviderName(): string;
  /** Get list of available providers */
  get availableProviders(): Array<string>;
  /** Get the token usage tracker */
  get tokenTracker(): TokenTracker;
  /** Get conversation messages (simplified representation) */
  get messages(): Array<Message>;
  /** Switch to a different provider */
  switchProvider(providerName: string): Promise<void>;
  /** Clear conversation history */
  clearHistory(): void;
  /**
   * Send a prompt and stream the response
   *
   * The callback receives StreamChunk objects with type: 'Text', 'ToolCall', 'ToolResult', 'Done', or 'Error'
   *
   * Uses the same streaming infrastructure as codelet-cli:
   * - run_agent_stream for shared streaming logic
   * - StreamOutput trait for polymorphic output
   * - is_interrupted flag for Esc key handling (set via interrupt() method)
   */
  prompt(input: string, callback: (chunk: StreamChunk) => void): Promise<void>;
}

/** Stream chunk types for streaming responses */
export declare const enum ChunkType {
  Text = 'Text',
  ToolCall = 'ToolCall',
  ToolResult = 'ToolResult',
  Status = 'Status',
  Interrupted = 'Interrupted',
  TokenUpdate = 'TokenUpdate',
  Done = 'Done',
  Error = 'Error',
}

/**
 * Debug command result (AGENT-021)
 * Returned by toggleDebug() to indicate debug capture state
 */
export interface DebugCommandResult {
  /** Whether debug capture is now enabled */
  enabled: boolean;
  /** Path to the debug session file (if available) */
  sessionFile?: string;
  /** Human-readable message about the result */
  message: string;
}

/** A conversation message (simplified for JS) */
export interface Message {
  role: string;
  content: string;
}

/** Message role enum */
export declare const enum MessageRole {
  System = 'System',
  User = 'User',
  Assistant = 'Assistant',
}

/** A chunk of streaming response */
export interface StreamChunk {
  type: string;
  text?: string;
  toolCall?: ToolCallInfo;
  toolResult?: ToolResultInfo;
  status?: string;
  queuedInputs?: Array<string>;
  tokens?: TokenTracker;
  error?: string;
}

/** Token usage tracking information */
export interface TokenTracker {
  inputTokens: number;
  outputTokens: number;
  cacheReadInputTokens?: number;
  cacheCreationInputTokens?: number;
}

/** Tool call information */
export interface ToolCallInfo {
  id: string;
  name: string;
  input: string;
}

/** Tool result information */
export interface ToolResultInfo {
  toolCallId: string;
  content: string;
  isError: boolean;
}
