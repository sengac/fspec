/* auto-generated by NAPI-RS */
/* eslint-disable */
/**
 * CodeletSession - Main class for AI agent interactions
 *
 * Exposes codelet's Rust AI agent functionality to Node.js.
 */
export declare class CodeletSession {
  /**
   * Create a new CodeletSession
   *
   * If provider_name is not specified, auto-detects the highest priority available provider.
   * Priority order: Claude > Gemini > Codex > OpenAI
   */
  constructor(providerName?: string | undefined | null);
  /**
   * MODEL-001: Create a new CodeletSession with dynamic model selection
   *
   * Creates a session with model support enabled, allowing selection of specific
   * models from models.dev. The model string should be in "provider/model-id" format.
   *
   * # Arguments
   * * `model_string` - Model in "provider/model-id" format (e.g., "anthropic/claude-sonnet-4")
   *
   * # Example
   * ```typescript
   * const session = await CodeletSession.newWithModel("anthropic/claude-sonnet-4");
   * ```
   */
  static newWithModel(modelString: string): Promise<CodeletSession>;
  /**
   * CONFIG-004: Create a new CodeletSession with explicit credentials
   *
   * Creates a session with programmatic credentials passed from TypeScript,
   * without reading from environment variables. This enables API key management
   * via the fspec settings UI.
   *
   * # Arguments
   * * `model_string` - Model in "provider/model-id" format (e.g., "anthropic/claude-sonnet-4")
   * * `provider_config` - Provider configuration with explicit API key
   *
   * # Example
   * ```typescript
   * const session = await CodeletSession.newWithCredentials(
   *   "anthropic/claude-sonnet-4",
   *   { providerId: "anthropic", apiKey: "sk-ant-...", enabled: true }
   * );
   * ```
   */
  static newWithCredentials(
    modelString: string,
    providerConfig: NapiProviderConfig
  ): Promise<CodeletSession>;
  /**
   * Interrupt the current agent execution
   *
   * Call this when the user presses Esc in the TUI.
   * The agent will stop immediately via tokio::sync::Notify (NAPI-004).
   * The notify_one() call wakes the tokio::select! in stream_loop,
   * allowing immediate response to ESC even during blocking operations.
   *
   * IMPORTANT: Uses notify_one() instead of notify_waiters() because:
   * - notify_waiters() only wakes CURRENTLY waiting tasks (notification lost if none waiting)
   * - notify_one() stores a permit if no one waiting, so next notified() returns immediately
   * This eliminates the race condition between flag check and entering tokio::select!
   */
  interrupt(): void;
  /**
   * Reset the interrupt flag
   *
   * Called automatically at the start of each prompt, but can be called
   * manually if needed.
   */
  resetInterrupt(): void;
  /**
   * Toggle debug capture mode (AGENT-021)
   *
   * Mirrors CLI repl_loop.rs:36-67 logic.
   * When enabling, sets session metadata (provider, model, context_window).
   * When disabling, stops capture and returns path to saved session file.
   *
   * If debug_dir is provided, debug files will be written to `{debug_dir}/debug/`
   * instead of the default directory. For fspec, pass `~/.fspec` to write to
   * `~/.fspec/debug/`.
   */
  toggleDebug(debugDir?: string | undefined | null): DebugCommandResult;
  /**
   * Manually trigger context compaction (NAPI-005)
   *
   * Mirrors CLI repl_loop.rs /compact command logic.
   * Calls execute_compaction from interactive_helpers to compress context.
   *
   * Returns CompactionResult with metrics about the compaction operation.
   * Returns error if session is empty (nothing to compact).
   */
  compact(): Promise<CompactionResult>;
  /** Get the current provider name */
  get currentProviderName(): string;
  /**
   * MODEL-001: Get the currently selected model string
   *
   * Returns the model string in "provider/model-id" format (e.g., "anthropic/claude-sonnet-4")
   * if a model was explicitly selected via newWithModel() or selectModel(), otherwise None.
   */
  get selectedModel(): string | null;
  /** Get list of available providers */
  get availableProviders(): Array<string>;
  /** Get the token usage tracker */
  get tokenTracker(): TokenTracker;
  /** Get conversation messages (simplified representation) */
  get messages(): Array<Message>;
  /** Switch to a different provider */
  switchProvider(providerName: string): Promise<void>;
  /**
   * MODEL-001: Select a different model mid-session
   *
   * Changes the model used for subsequent prompts without clearing conversation history.
   * The model string should be in "provider/model-id" format.
   *
   * NOTE: This only works for sessions created via newWithModel(). Sessions created
   * via the default constructor do not have model registry support enabled.
   *
   * # Arguments
   * * `model_string` - Model in "provider/model-id" format (e.g., "anthropic/claude-sonnet-4")
   *
   * # Example
   * ```typescript
   * const session = await CodeletSession.newWithModel("anthropic/claude-sonnet-4");
   * // ... use session ...
   * await session.selectModel("anthropic/claude-opus-4");  // Switch to Opus
   * ```
   */
  selectModel(modelString: string): Promise<void>;
  /**
   * Clear conversation history and reinject context reminders
   *
   * Clears messages, turns, and token tracker, then reinjects context reminders
   * (CLAUDE.md discovery, environment info) to maintain project context.
   *
   * CRITICAL (AGENT-003): Must call inject_context_reminders() after clearing
   * to restore project context (CLAUDE.md, environment info). Without this,
   * the AI loses CLAUDE.md context on the next prompt after /clear.
   */
  clearHistory(): void;
  /**
   * Restore messages from a persisted session (NAPI-003)
   *
   * Restores conversation history from persistence into the CodeletSession's
   * internal message array, enabling the LLM to have context of the restored
   * conversation.
   *
   * CRITICAL: This method must be called when resuming a session to ensure
   * the AI has context of the previous conversation. Without this, the AI
   * would start fresh despite the UI showing historical messages.
   *
   * # Arguments
   * * `messages` - Array of messages to restore (from persistenceGetSessionMessages)
   *
   * # Process
   * 1. Clears existing messages, turns, and token tracker
   * 2. Converts each persistence message to rig::message::Message format
   * 3. Injects context reminders (CLAUDE.md, environment info)
   * 4. Messages are ready for use in next prompt
   */
  restoreMessages(messages: Array<Message>): void;
  /**
   * Restore messages from full envelope JSON strings (NAPI-008)
   *
   * This is the preferred method for restoring sessions as it preserves:
   * - Structured tool_use and tool_result blocks (not just text summaries)
   * - Multi-part message content (text + tool calls)
   * - Turn boundaries for compaction (rebuilt via convert_messages_to_turns)
   *
   * Call restoreTokenState() after this to restore token counts.
   *
   * # Arguments
   * * `envelopes` - Array of envelope JSON strings from persistenceGetSessionMessageEnvelopes
   */
  restoreMessagesFromEnvelopes(envelopes: Array<string>): void;
  /**
   * Restore token state from persisted session (TUI-033, NAPI-008)
   *
   * Call this after restoreMessages() or restoreMessagesFromEnvelopes() to restore
   * the token counts from the persisted session manifest. This ensures getContextFillInfo()
   * returns accurate context fill percentage after session restoration.
   *
   * # Arguments
   * * `input_tokens` - Total input tokens from session manifest
   * * `output_tokens` - Total output tokens from session manifest
   * * `cache_read_tokens` - Cache read tokens from session manifest
   * * `cache_creation_tokens` - Cache creation tokens from session manifest
   */
  restoreTokenState(
    inputTokens: number,
    outputTokens: number,
    cacheReadTokens: number,
    cacheCreationTokens: number,
    cumulativeBilledInput: number,
    cumulativeBilledOutput: number
  ): void;
  /**
   * Get current context fill info (TUI-033)
   *
   * Returns the current context fill percentage and related metrics.
   * Call this after restoreMessages() to get initial context fill state,
   * since restoring messages doesn't trigger streaming events.
   *
   * # Returns
   * * `ContextFillInfo` with fill_percentage, effective_tokens, threshold, context_window
   */
  getContextFillInfo(): ContextFillInfo;
  /**
   * Send a prompt and stream the response
   *
   * The callback receives StreamChunk objects with type: 'Text', 'Thinking', 'ToolCall', 'ToolResult', 'Done', or 'Error'
   *
   * Uses the same streaming infrastructure as codelet-cli:
   * - run_agent_stream for shared streaming logic
   * - StreamOutput trait for polymorphic output
   * - is_interrupted flag for Esc key handling (set via interrupt() method)
   *
   * # Arguments
   * * `input` - The user prompt text
   * * `thinking_config` - Optional JSON string from getThinkingConfig() (TOOL-010)
   * * `callback` - Stream callback for receiving chunks
   */
  prompt(
    input: string,
    thinkingConfig: string | undefined | null,
    callback: (chunk: StreamChunk) => void
  ): Promise<void>;
}

/** Case conversion types for transforms */
export declare const enum AstGrepCaseType {
  LowerCase = 'LowerCase',
  UpperCase = 'UpperCase',
  Capitalize = 'Capitalize',
  CamelCase = 'CamelCase',
  SnakeCase = 'SnakeCase',
  KebabCase = 'KebabCase',
  PascalCase = 'PascalCase',
}

/** Convert transform configuration */
export interface AstGrepConvertTransform {
  /** Source variable (e.g., "$NAME") */
  source: string;
  /** Target case type */
  toCase: AstGrepCaseType;
  /** Optional separators for word splitting */
  separatedBy?: Array<AstGrepSeparator>;
}

/** Match information for replace operations */
export interface AstGrepMatchInfo {
  /** Location in format "file:line:column" */
  location: string;
  /** Original matched code */
  original: string;
  /** Replacement code */
  replacement: string;
}

/** Result of an AST-grep search match */
export interface AstGrepMatchResult {
  /** File path where match was found */
  file: string;
  /** Line number (1-based) */
  line: number;
  /** Column number (1-based) */
  column: number;
  /** Matched text */
  text: string;
}

/**
 * Refactor by moving matched code from source file to target file
 *
 * # Arguments
 * * `pattern` - AST pattern to match (must match exactly 1 node)
 * * `language` - Programming language
 * * `source_file` - Path to source file
 * * `target_file` - Path to target file (will be created)
 *
 * # Returns
 * Result containing the moved code, or error if pattern doesn't match exactly 1 node
 */
export declare function astGrepRefactor(
  pattern: string,
  language: string,
  sourceFile: string,
  targetFile: string
): Promise<AstGrepRefactorResult>;

/** Result of an AST-grep refactor operation (extract mode) */
export interface AstGrepRefactorResult {
  /** Whether the refactor was successful */
  success: boolean;
  /** The code that was moved */
  movedCode: string;
  /** Source file path */
  sourceFile: string;
  /** Target file path */
  targetFile: string;
}

/**
 * Replace matched code in-place with optional transforms
 *
 * # Arguments
 * * `pattern` - AST pattern to match
 * * `language` - Programming language
 * * `source_file` - Path to source file
 * * `replacement` - Replacement template (can reference $NAME, $$$ARGS, and transform outputs)
 * * `transforms` - Optional array of transforms to apply to captured variables
 * * `batch` - If true, replace ALL matches; if false, require exactly one match
 * * `preview` - If true, return what would change without modifying files
 *
 * # Returns
 * Result containing match details and replacement info
 */
export declare function astGrepReplace(
  pattern: string,
  language: string,
  sourceFile: string,
  replacement: string,
  transforms?: Array<AstGrepTransform> | undefined | null,
  batch?: boolean | undefined | null,
  preview?: boolean | undefined | null
): Promise<AstGrepReplaceResult>;

/** Result of an AST-grep replace operation (replace mode) */
export interface AstGrepReplaceResult {
  /** Whether the operation was successful */
  success: boolean;
  /** Mode: "replace" or "extract" */
  mode: string;
  /** Source file path */
  sourceFile: string;
  /** Number of matches replaced (batch mode) */
  matchesCount: number;
  /** Whether this was a preview (dry-run) */
  preview: boolean;
  /** Match details (location, original, replacement) */
  matches: Array<AstGrepMatchInfo>;
}

/** Replace transform configuration */
export interface AstGrepReplaceTransform {
  /** Source variable (e.g., "$NAME") */
  source: string;
  /** Regex pattern to find */
  replace: string;
  /** Replacement string */
  by: string;
}

/**
 * Search for AST pattern matches in files
 *
 * # Arguments
 * * `pattern` - AST pattern to search for (e.g., "function $NAME($$$ARGS)")
 * * `language` - Programming language (e.g., "typescript", "rust")
 * * `paths` - List of file or directory paths to search
 *
 * # Returns
 * Array of match results with file, line, column, and matched text
 */
export declare function astGrepSearch(
  pattern: string,
  language: string,
  paths: Array<string>
): Promise<Array<AstGrepMatchResult>>;

/** Separator options for word splitting */
export declare const enum AstGrepSeparator {
  CaseChange = 'CaseChange',
  Underscore = 'Underscore',
  Dash = 'Dash',
  Dot = 'Dot',
  Slash = 'Slash',
  Space = 'Space',
}

/** Substring transform configuration */
export interface AstGrepSubstringTransform {
  /** Source variable (e.g., "$NAME") */
  source: string;
  /** Start character index (0-based, negative counts from end) */
  startChar?: number;
  /** End character index (negative counts from end) */
  endChar?: number;
}

/** Transform definition - one of substring, replace, or convert */
export interface AstGrepTransform {
  /** Transform name (the variable it creates, e.g., "NEW") */
  name: string;
  /** Substring transform (mutually exclusive with replace/convert) */
  substring?: AstGrepSubstringTransform;
  /** Replace transform (mutually exclusive with substring/convert) */
  replaceTransform?: AstGrepReplaceTransform;
  /** Convert transform (mutually exclusive with substring/replace) */
  convert?: AstGrepConvertTransform;
}

/** Stream chunk types for streaming responses (TOOL-010) */
export declare const enum ChunkType {
  Text = 'Text',
  /** Thinking/reasoning content from extended thinking (TOOL-010) */
  Thinking = 'Thinking',
  ToolCall = 'ToolCall',
  ToolResult = 'ToolResult',
  /** Tool execution progress - streaming output from bash/shell tools (TOOL-011) */
  ToolProgress = 'ToolProgress',
  Status = 'Status',
  Interrupted = 'Interrupted',
  TokenUpdate = 'TokenUpdate',
  ContextFillUpdate = 'ContextFillUpdate',
  Done = 'Done',
  Error = 'Error',
  /** User input message (NAPI-009: for resume/attach to restore user messages) */
  UserInput = 'UserInput',
}

/**
 * Compaction result (NAPI-005)
 * Returned by compact() with metrics about the compaction operation
 */
export interface CompactionResult {
  /** Original token count before compaction */
  originalTokens: number;
  /** Token count after compaction */
  compactedTokens: number;
  /** Compression ratio as percentage (0-100) */
  compressionRatio: number;
  /** Number of turns summarized */
  turnsSummarized: number;
  /** Number of turns kept */
  turnsKept: number;
}

/**
 * Context window fill information (TUI-033)
 * Sent with each token update to show context window usage
 */
export interface ContextFillInfo {
  /** Fill percentage (0-100+, can exceed 100 near compaction) */
  fillPercentage: number;
  /** Effective tokens (after cache discount) - using f64 for NAPI compatibility */
  effectiveTokens: number;
  /** Compaction threshold (usable context after output reservation) - using f64 for NAPI compatibility */
  threshold: number;
  /** Provider's context window size - using f64 for NAPI compatibility */
  contextWindow: number;
}

/**
 * Debug command result (AGENT-021)
 * Returned by toggleDebug() to indicate debug capture state
 */
export interface DebugCommandResult {
  /** Whether debug capture is now enabled */
  enabled: boolean;
  /** Path to the debug session file (if available) */
  sessionFile?: string;
  /** Human-readable message about the result */
  message: string;
}

/**
 * Extract thinking text from a response part.
 *
 * # Arguments
 * * `provider` - Provider identifier: "gemini-3", "gemini-2.5", "claude", etc.
 * * `part_json` - JSON string of the response part
 *
 * # Returns
 * The thinking text if present, null otherwise.
 */
export declare function extractThinkingText(
  provider: string,
  partJson: string
): string | null;

/**
 * Get thinking configuration JSON for a provider at a specific level.
 *
 * # Arguments
 * * `provider` - Provider identifier: "gemini-3", "gemini-2.5", "claude", etc.
 * * `level` - Thinking intensity level
 *
 * # Returns
 * JSON string containing the provider-specific thinking configuration.
 *
 * # Example
 * ```typescript
 * import { getThinkingConfig, JsThinkingLevel } from '@anthropic/codelet-napi';
 *
 * const config = JSON.parse(getThinkingConfig('gemini-3', JsThinkingLevel.High));
 * // { thinkingConfig: { includeThoughts: true, thinkingLevel: "high" } }
 * ```
 */
export declare function getThinkingConfig(
  provider: string,
  level: JsThinkingLevel
): string;

/**
 * Check if a response part contains thinking content.
 *
 * # Arguments
 * * `provider` - Provider identifier: "gemini-3", "gemini-2.5", "claude", etc.
 * * `part_json` - JSON string of the response part
 *
 * # Returns
 * true if the part contains thinking/reasoning content, false otherwise.
 *
 * # Example
 * ```typescript
 * import { isThinkingContent } from '@anthropic/codelet-napi';
 *
 * const part = JSON.stringify({ thought: true, text: "Let me think..." });
 * const isThinking = isThinkingContent('gemini-3', part);
 * // true
 * ```
 */
export declare function isThinkingContent(
  provider: string,
  partJson: string
): boolean;

/** TypeScript-friendly thinking level enum */
export declare const enum JsThinkingLevel {
  /** Disable thinking/reasoning entirely */
  Off = 0,
  /** Minimal thinking (fast responses) */
  Low = 1,
  /** Balanced thinking (default for most tasks) */
  Medium = 2,
  /** Maximum thinking (complex reasoning tasks) */
  High = 3,
}

/** A conversation message (simplified for JS) */
export interface Message {
  role: string;
  content: string;
}

/** Message role enum */
export declare const enum MessageRole {
  System = 'System',
  User = 'User',
  Assistant = 'Assistant',
}

/**
 * Get the current cache directory for model data
 *
 * Returns the custom directory if set via modelsSetCacheDirectory(),
 * otherwise returns ~/.fspec/cache as the default.
 */
export declare function modelsGetCacheDirectory(): string;

/**
 * Get information for a specific model (async)
 *
 * # Arguments
 * * `provider_id` - Provider ID (e.g., "anthropic")
 * * `model_id` - Model ID (e.g., "claude-sonnet-4")
 */
export declare function modelsGetInfo(
  providerId: string,
  modelId: string
): Promise<NapiModelInfo>;

/**
 * List all available models from models.dev (async)
 *
 * Returns models grouped by provider. Uses cached registry for efficiency.
 * First call loads from disk/API, subsequent calls use cached data.
 *
 * Filters out:
 * - Deprecated models (status = "deprecated")
 * - Models older than 18 months
 *
 * Sorts models by release date (newest first).
 */
export declare function modelsListAll(): Promise<Array<NapiProviderModels>>;

/**
 * List models for a specific provider (async)
 *
 * # Arguments
 * * `provider_id` - Provider ID (e.g., "anthropic", "openai", "google")
 */
export declare function modelsListForProvider(
  providerId: string
): Promise<Array<NapiModelInfo>>;

/**
 * Refresh the model cache from models.dev API (async)
 *
 * Forces a fresh fetch from the API, ignoring cached data.
 * NOTE: This does NOT invalidate the in-memory registry cache.
 * For a full refresh, restart the process after calling this.
 *
 * Returns the number of providers loaded.
 */
export declare function modelsRefreshCache(): Promise<number>;

/**
 * Set the cache directory for model data (e.g., ~/.fspec/cache)
 *
 * IMPORTANT: This MUST be called BEFORE any other model operations.
 * The directory setting is captured when the registry is first loaded.
 * Calling this after other model functions will have no effect until
 * modelsRefreshCache() is called.
 *
 * # Arguments
 * * `dir` - The directory path for cache data (models.json will be stored here)
 */
export declare function modelsSetCacheDirectory(dir: string): void;

export interface NapiAppendResult {
  messageId: string;
  session: NapiSessionManifest;
}

export interface NapiCherryPickResult {
  session: NapiSessionManifest;
  importedIndices: Array<number>;
}

export interface NapiCompactionState {
  summary: string;
  compactedBeforeIndex: number;
  compactedAt: string;
}

export interface NapiForkPoint {
  sourceSessionId: string;
  forkAfterIndex: number;
  forkedAt: string;
}

export interface NapiHistoryEntry {
  display: string;
  timestamp: string;
  project: string;
  sessionId: string;
  hasPastedContent: boolean;
}

export interface NapiMergeRecord {
  sourceSessionId: string;
  sourceIndices: Array<number>;
  insertedAt?: number;
  mergedAt: string;
}

/** Model information from models.dev */
export interface NapiModelInfo {
  /** The API model ID (e.g., "claude-sonnet-4-20250514") */
  id: string;
  /** Display name (e.g., "Claude Sonnet 4") */
  name: string;
  /** Model family (e.g., "claude-sonnet") */
  family?: string;
  /** Whether model supports reasoning/thinking */
  reasoning: boolean;
  /** Whether model supports tool calls */
  toolCall: boolean;
  /** Whether model supports file/image attachments */
  attachment: boolean;
  /** Whether model supports temperature parameter */
  temperature: boolean;
  /** Context window size in tokens */
  contextWindow: number;
  /** Maximum output tokens */
  maxOutput: number;
  /** Whether model has vision capability (image input) */
  hasVision: boolean;
}

/**
 * Provider configuration for programmatic credential passing (CONFIG-004)
 *
 * Used by CodeletSession.newWithCredentials() to pass explicit API keys
 * without reading from environment variables.
 */
export interface NapiProviderConfig {
  /** Provider ID (e.g., "anthropic", "openai", "gemini") */
  providerId: string;
  /** API key for the provider */
  apiKey?: string;
  /** Custom base URL (optional) */
  baseUrl?: string;
  /** Whether the provider is enabled */
  enabled: boolean;
  /** Default model (optional) */
  defaultModel?: string;
}

/** Provider with its available models */
export interface NapiProviderModels {
  /** Provider ID (e.g., "anthropic", "openai", "google") */
  providerId: string;
  /** Provider display name (e.g., "Anthropic", "OpenAI", "Google") */
  providerName: string;
  /** List of models available from this provider */
  models: Array<NapiModelInfo>;
}

export interface NapiSessionManifest {
  id: string;
  name: string;
  project: string;
  provider: string;
  createdAt: string;
  updatedAt: string;
  messageCount: number;
  forkedFrom?: NapiForkPoint;
  mergedFrom: Array<NapiMergeRecord>;
  compaction?: NapiCompactionState;
  tokenUsage: NapiTokenUsage;
}

export interface NapiStoredMessage {
  id: string;
  contentHash: string;
  createdAt: string;
  role: string;
  content: string;
  tokenCount?: number;
  blobRefs: Array<string>;
  /** Metadata as a JSON string */
  metadataJson: string;
}

/**
 * Token usage with dual metrics (CTX-003)
 *
 * - `current_context_tokens`: Latest context size (for display and threshold checks)
 * - `cumulative_billed_input`: Sum of all API calls (for billing analytics)
 * - `cumulative_billed_output`: Sum of all API output tokens (for billing analytics)
 */
export interface NapiTokenUsage {
  /**
   * Current context size (latest input_tokens from API - overwritten, not accumulated)
   * CTX-003: This is what should be displayed to users and used for threshold checks
   */
  currentContextTokens: number;
  /**
   * Cumulative billed input tokens (sum of all API calls - for billing analytics)
   * CTX-003: This is the total billed by Anthropic across all API calls
   */
  cumulativeBilledInput: number;
  /** Cumulative billed output tokens (sum of all API calls) */
  cumulativeBilledOutput: number;
  /** Cache read tokens from current API call */
  cacheReadTokens: number;
  /** Cache creation tokens from current API call */
  cacheCreationTokens: number;
}

/** Add a history entry */
export declare function persistenceAddHistory(
  display: string,
  project: string,
  sessionId: string
): void;

/** Append a message to a session */
export declare function persistenceAppendMessage(
  sessionId: string,
  role: string,
  content: string
): NapiAppendResult;

/**
 * Append a message with metadata to a session
 *
 * metadata_json should be a JSON object string, e.g. '{"model": "claude-3", "stop_reason": "end_turn"}'
 */
export declare function persistenceAppendMessageWithMetadata(
  sessionId: string,
  role: string,
  content: string,
  metadataJson: string
): NapiAppendResult;

/** Check if a blob exists */
export declare function persistenceBlobExists(hash: string): boolean;

/** Cherry-pick messages with context */
export declare function persistenceCherryPick(
  targetId: string,
  sourceId: string,
  index: number,
  context: number
): NapiCherryPickResult;

/** Cleanup orphaned messages */
export declare function persistenceCleanupOrphanedMessages(): number;

/** Clear compaction state for a session */
export declare function persistenceClearCompactionState(
  sessionId: string
): NapiSessionManifest;

/** Create a new session */
export declare function persistenceCreateSession(
  name: string,
  project: string
): NapiSessionManifest;

/** Create a new session with a specific provider */
export declare function persistenceCreateSessionWithProvider(
  name: string,
  project: string,
  provider: string
): NapiSessionManifest;

/** Delete a session */
export declare function persistenceDeleteSession(id: string): void;

/** Fork a session at a specific message index */
export declare function persistenceForkSession(
  sessionId: string,
  atIndex: number,
  name: string
): NapiSessionManifest;

/** Get content from blob storage */
export declare function persistenceGetBlob(hash: string): Buffer;

/** Get the current data directory */
export declare function persistenceGetDataDirectory(): string;

/** Get history entries */
export declare function persistenceGetHistory(
  project?: string | undefined | null,
  limit?: number | undefined | null
): Array<NapiHistoryEntry>;

/** Get a message by ID */
export declare function persistenceGetMessage(
  id: string
): NapiStoredMessage | null;

/** Get a message as a full envelope JSON with blob content rehydrated */
export declare function persistenceGetMessageEnvelope(
  id: string
): string | null;

/**
 * Get a message envelope WITHOUT blob rehydration (returns blob references as-is)
 * Use this when you want to inspect the raw stored format with blob:sha256: references.
 */
export declare function persistenceGetMessageEnvelopeRaw(
  id: string
): string | null;

/**
 * Get all messages for a session as envelope JSON array with blob content rehydrated
 * (respects compaction - use for LLM context)
 */
export declare function persistenceGetSessionMessageEnvelopes(
  sessionId: string
): Array<string>;

/** Get all messages for a session as envelope JSON array - FULL history (ignores compaction) */
export declare function persistenceGetSessionMessageEnvelopesFull(
  sessionId: string
): Array<string>;

/**
 * Get all messages for a session WITHOUT blob rehydration (returns blob references as-is)
 * (respects compaction)
 */
export declare function persistenceGetSessionMessageEnvelopesRaw(
  sessionId: string
): Array<string>;

/** Get all messages for a session WITHOUT blob rehydration - FULL history (ignores compaction) */
export declare function persistenceGetSessionMessageEnvelopesRawFull(
  sessionId: string
): Array<string>;

/**
 * Get all messages for a session (respects compaction - use for LLM context)
 *
 * If the session has been compacted, this returns:
 * 1. A synthetic summary message containing the compaction summary
 * 2. Only messages from the compaction boundary onward
 *
 * For the full uncompacted history, use `persistence_get_session_messages_full`.
 */
export declare function persistenceGetSessionMessages(
  sessionId: string
): Array<NapiStoredMessage>;

/**
 * Get ALL messages for a session (ignores compaction - use for debugging/export)
 *
 * This returns the complete message history regardless of compaction state.
 * For LLM context, use `persistence_get_session_messages` which respects compaction.
 */
export declare function persistenceGetSessionMessagesFull(
  sessionId: string
): Array<NapiStoredMessage>;

/** List all sessions for a project */
export declare function persistenceListSessions(
  project: string
): Array<NapiSessionManifest>;

/** Load a session by ID */
export declare function persistenceLoadSession(id: string): NapiSessionManifest;

/** Merge messages from another session */
export declare function persistenceMergeMessages(
  targetId: string,
  sourceId: string,
  indices: Array<number>
): NapiSessionManifest;

/** Rename a session */
export declare function persistenceRenameSession(
  id: string,
  newName: string
): void;

/** Resume the last session for a project */
export declare function persistenceResumeLastSession(
  project: string
): NapiSessionManifest;

/** Search history entries */
export declare function persistenceSearchHistory(
  query: string,
  project?: string | undefined | null
): Array<NapiHistoryEntry>;

/** Set compaction state for a session (after manual or automatic compaction) */
export declare function persistenceSetCompactionState(
  sessionId: string,
  summary: string,
  compactedBeforeIndex: number
): NapiSessionManifest;

/**
 * Set the data directory for persistence (e.g., ~/.fspec or ~/.codelet)
 *
 * This must be called before any other persistence operations if you want
 * to use a custom directory instead of the default ~/.fspec.
 */
export declare function persistenceSetDataDirectory(dir: string): void;

/** Set session token usage (REPLACES existing - use for cumulative totals) */
export declare function persistenceSetSessionTokens(
  sessionId: string,
  input: number,
  output: number,
  cacheRead: number,
  cacheCreate: number,
  cumulativeInput: number,
  cumulativeOutput: number
): NapiSessionManifest;

/** Store content in blob storage */
export declare function persistenceStoreBlob(content: Buffer): string;

/**
 * Store a message envelope as JSON
 *
 * This is the primary function for storing Claude Code format messages.
 * It handles blob storage for large content automatically.
 */
export declare function persistenceStoreMessageEnvelope(
  sessionId: string,
  envelopeJson: string
): NapiAppendResult;

/** Update session token usage (ADDS to existing) */
export declare function persistenceUpdateSessionTokens(
  sessionId: string,
  input: number,
  output: number,
  cacheRead: number,
  cacheCreate: number
): NapiSessionManifest;

/** Attach to a session for live streaming */
export declare function sessionAttach(
  sessionId: string,
  callback: (err: Error | null, arg: StreamChunk) => any
): void;

/**
 * Clear the role for a session (WATCH-004)
 *
 * Returns the session to a regular (non-watcher) state.
 */
export declare function sessionClearRole(sessionId: string): void;

/**
 * Manually trigger context compaction for a background session (NAPI-009 + NAPI-005)
 *
 * Mirrors CodeletSession::compact() behavior but works with background sessions.
 * Calls execute_compaction from interactive_helpers to compress context.
 *
 * Returns CompactionResult with metrics about the compaction operation.
 * Returns error if session is empty (nothing to compact).
 */
export declare function sessionCompact(
  sessionId: string
): Promise<CompactionResult>;

/**
 * Create a watcher session for a parent session (WATCH-007)
 *
 * Creates a new session that watches the specified parent session.
 * The watcher is registered in WatchGraph. Broadcast subscription happens
 * when the watcher loop starts (via parent.subscribe_to_stream()).
 * A role must be set separately via session_set_role.
 */
export declare function sessionCreateWatcher(
  parentId: string,
  model: string,
  project: string,
  name: string
): Promise<string>;

/** Detach from a session (session continues running) */
export declare function sessionDetach(sessionId: string): void;

/** Get buffered output from a session */
export declare function sessionGetBufferedOutput(
  sessionId: string,
  limit: number
): Array<StreamChunk>;

/** Get debug enabled state for a background session */
export declare function sessionGetDebugEnabled(sessionId: string): boolean;

/**
 * Get buffered output with consecutive Text/Thinking chunks merged.
 * This is more efficient for reattachment - JS can process fewer chunks.
 */
export declare function sessionGetMergedOutput(
  sessionId: string
): Array<StreamChunk>;

/** Get the model info for a background session */
export declare function sessionGetModel(sessionId: string): SessionModel;

/**
 * Get the parent session ID for a watcher (WATCH-007)
 *
 * Returns the parent session ID if the session is a watcher, None otherwise.
 */
export declare function sessionGetParent(sessionId: string): string | null;

/**
 * Get pending input text for a background session (TUI-049)
 *
 * Returns the input text that was being typed when the user switched away from this session.
 * Used to restore input field state when switching back to the session.
 */
export declare function sessionGetPendingInput(
  sessionId: string
): string | null;

/**
 * Get the role for a session (WATCH-004)
 *
 * Returns None for regular sessions, role info for watcher sessions.
 */
export declare function sessionGetRole(
  sessionId: string
): SessionRoleInfo | null;

/** Get session status */
export declare function sessionGetStatus(sessionId: string): string;

/** Get cached token counts for a background session */
export declare function sessionGetTokens(sessionId: string): SessionTokens;

/**
 * Get all watcher session IDs for a parent session (WATCH-007)
 *
 * Returns a list of session IDs that are watching the specified parent.
 */
export declare function sessionGetWatchers(sessionId: string): Array<string>;

/** Session info returned to TypeScript */
export interface SessionInfo {
  id: string;
  name: string;
  status: string;
  project: string;
  messageCount: number;
  /** Provider ID (e.g., "anthropic", "openai") */
  providerId?: string;
  /** Model ID (e.g., "claude-sonnet-4", "gpt-4o") */
  modelId?: string;
}

/** Interrupt a session */
export declare function sessionInterrupt(sessionId: string): void;

/** Create a new background session (generates new UUID) */
export declare function sessionManagerCreate(
  model: string,
  project: string
): Promise<string>;

/**
 * Create a background session with a specific ID (for persistence integration).
 *
 * This is used when AgentView creates a session - the ID comes from persistence
 * so that detach/attach can find the session by the same ID used for persistence.
 *
 * Note: This must be async because it uses tokio::spawn internally, which requires
 * a Tokio runtime context. NAPI-RS provides this context for async functions.
 */
export declare function sessionManagerCreateWithId(
  sessionId: string,
  model: string,
  project: string,
  name: string
): Promise<void>;

/** Destroy a background session */
export declare function sessionManagerDestroy(sessionId: string): void;

/** List all background sessions */
export declare function sessionManagerList(): Array<SessionInfo>;

/** Model info returned by session_get_model */
export interface SessionModel {
  /** Provider ID (e.g., "anthropic", "openai") */
  providerId?: string;
  /** Model ID (e.g., "claude-sonnet-4", "gpt-4o") */
  modelId?: string;
}

/**
 * Restore messages to a background session from persisted envelopes.
 *
 * This is used when attaching to a session via /resume - it restores the
 * conversation history so the LLM has context for future prompts.
 */
export declare function sessionRestoreMessages(
  sessionId: string,
  envelopes: Array<string>
): Promise<void>;

/**
 * Restore token state to a background session from persisted values.
 *
 * This is used when attaching to a session via /resume - it restores the
 * token tracking state so context fill percentage and token counts are accurate.
 */
export declare function sessionRestoreTokenState(
  sessionId: string,
  inputTokens: number,
  outputTokens: number,
  cacheReadTokens: number,
  cacheCreationTokens: number,
  cumulativeBilledInput: number,
  cumulativeBilledOutput: number
): Promise<void>;

/** Session role info returned to TypeScript (WATCH-004) */
export interface SessionRoleInfo {
  /** Role name (e.g., "code-reviewer", "supervisor") */
  name: string;
  /** Optional description */
  description?: string;
  /** Authority level ("peer" or "supervisor") */
  authority: string;
}

/** Send input to a session with optional thinking config */
export declare function sessionSendInput(
  sessionId: string,
  input: string,
  thinkingConfig?: string | undefined | null
): void;

/** Set debug enabled state for a background session (without toggling global state) */
export declare function sessionSetDebugEnabled(
  sessionId: string,
  enabled: boolean
): void;

/** Update the model for a background session */
export declare function sessionSetModel(
  sessionId: string,
  providerId: string,
  modelId: string
): Promise<void>;

/**
 * Set pending input text for a background session (TUI-049)
 *
 * Saves the current input field text before switching to another session.
 * Pass None to clear the pending input.
 */
export declare function sessionSetPendingInput(
  sessionId: string,
  input?: string | undefined | null
): void;

/**
 * Set the role for a session (WATCH-004)
 *
 * Used to mark a session as a watcher with a specific role and authority level.
 * Authority must be "peer" or "supervisor" (case-insensitive).
 */
export declare function sessionSetRole(
  sessionId: string,
  roleName: string,
  roleDescription: string | undefined | null,
  authority: string
): void;

/**
 * Toggle debug capture mode for a background session (NAPI-009 + AGENT-021)
 *
 * Mirrors CodeletSession::toggle_debug() behavior but works with background sessions.
 * When enabling, sets session metadata (provider, model, context_window).
 * When disabling, stops capture and returns path to saved session file.
 *
 * If debug_dir is provided, debug files will be written to `{debug_dir}/debug/`
 * instead of the default directory. For fspec, pass `~/.fspec` to write to
 * `~/.fspec/debug/`.
 */
export declare function sessionToggleDebug(
  sessionId: string,
  debugDir?: string | undefined | null
): Promise<DebugCommandResult>;

/** Token info returned by session_get_tokens */
export interface SessionTokens {
  /** Input tokens (context size) */
  inputTokens: number;
  /** Output tokens */
  outputTokens: number;
}

/**
 * Update debug capture metadata with session info.
 *
 * Call this after creating a session if debug was enabled before the session existed.
 */
export declare function sessionUpdateDebugMetadata(
  sessionId: string
): Promise<void>;

/** Set the logging callback from TypeScript and initialize the tracing subscriber */
export declare function setRustLogCallback(callback: LogCallback): void;

/** A chunk of streaming response (TOOL-010: added thinking field, TOOL-011: added tool_progress) */
export interface StreamChunk {
  type: string;
  text?: string;
  /** Thinking/reasoning content from extended thinking (TOOL-010) */
  thinking?: string;
  toolCall?: ToolCallInfo;
  toolResult?: ToolResultInfo;
  /** Tool execution progress - streaming output from bash/shell tools (TOOL-011) */
  toolProgress?: ToolProgressInfo;
  status?: string;
  queuedInputs?: Array<string>;
  tokens?: TokenTracker;
  contextFill?: ContextFillInfo;
  error?: string;
}

/**
 * Toggle debug capture mode without requiring a session.
 *
 * Can be called before a session exists. Session metadata will not be set.
 * Use session_update_debug_metadata after creating a session to add metadata.
 *
 * If debug_dir is provided, debug files will be written to `{debug_dir}/debug/`
 * instead of the default directory. For fspec, pass `~/.fspec` to write to
 * `~/.fspec/debug/`.
 */
export declare function toggleDebug(
  debugDir?: string | undefined | null
): DebugCommandResult;

/** Token usage tracking information */
export interface TokenTracker {
  inputTokens: number;
  outputTokens: number;
  cacheReadInputTokens?: number;
  cacheCreationInputTokens?: number;
  /** Tokens per second (EMA-smoothed, calculated in Rust) */
  tokensPerSecond?: number;
  /** Cumulative billed input tokens (sum of all API calls) */
  cumulativeBilledInput?: number;
  /** Cumulative billed output tokens (sum of all API calls) */
  cumulativeBilledOutput?: number;
}

/** Tool call information */
export interface ToolCallInfo {
  id: string;
  name: string;
  input: string;
}

/**
 * Tool execution progress information (TOOL-011)
 * Streaming output from bash/shell tools during execution
 */
export interface ToolProgressInfo {
  /** Tool call ID this progress is for */
  toolCallId: string;
  /** Tool name (e.g., "bash", "run_shell_command") */
  toolName: string;
  /** Output chunk (new text since last progress event) */
  outputChunk: string;
}

/** Tool result information */
export interface ToolResultInfo {
  toolCallId: string;
  content: string;
  isError: boolean;
}

/**
 * Inject a watcher message into the parent session (WATCH-007)
 *
 * Formats the message with the watcher's role prefix and queues it
 * on the parent session via receive_watcher_input().
 */
export declare function watcherInject(watcherId: string, message: string): void;
