{
  "meta": {
    "version": "1.0.0",
    "lastUpdated": "2025-10-17T01:25:24.422Z"
  },
  "workUnits": {
    "EXMAP-001": {
      "id": "EXMAP-001",
      "title": "Redesign Example Mapping to match BDD technique",
      "status": "done",
      "createdAt": "2025-10-10T22:58:36.526Z",
      "updatedAt": "2025-10-10T23:20:00.252Z",
      "description": "Current implementation is wrong - operates on work units instead of stories. Need to redesign to follow 4-card system (yellow story, blue rules, green examples, red questions) that happens BEFORE writing feature files. Example Mapping should help discover what scenarios to write, not modify existing ones.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T22:58:42.985Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:05:16.853Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:19:16.805Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:19:26.991Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:20:00.252Z"
        }
      ]
    },
    "INIT-001": {
      "id": "INIT-001",
      "title": "Add ensureWorkUnitsFile to ALL 48+ commands",
      "status": "done",
      "createdAt": "2025-10-10T23:23:00.738Z",
      "updatedAt": "2025-10-10T23:30:22.581Z",
      "description": "Following EXMAP-001 pattern, add ensureWorkUnitsFile/ensurePrefixesFile/ensureEpicsFile utilities to ALL commands that read JSON files. This prevents ENOENT errors and improves first-time user experience.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:23:13.046Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:24:25.195Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:30:08.298Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:30:09.868Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:30:22.581Z"
        }
      ],
      "rules": [
        "ALL commands that read spec/work-units.json MUST use ensureWorkUnitsFile",
        "ALL commands that read spec/prefixes.json MUST use ensurePrefixesFile",
        "ALL commands that read spec/epics.json MUST use ensureEpicsFile",
        "Ensure utilities MUST be idempotent - safe to call multiple times",
        "NO command should fail with ENOENT errors when JSON files missing"
      ],
      "examples": [
        "Create epic command auto-creates spec/epics.json when missing",
        "Create prefix command auto-creates spec/prefixes.json when missing",
        "List work units command auto-creates spec/work-units.json when missing",
        "Update work unit command uses ensureWorkUnitsFile instead of direct readFile",
        "Calling ensureWorkUnitsFile multiple times returns same data without overwriting"
      ],
      "questions": [],
      "assumptions": [
        "No - tags.json and foundation.json already auto-create via register-tag and add-diagram commands"
      ]
    },
    "CLI-001": {
      "id": "CLI-001",
      "title": "Verify all CLI commands and help system complete",
      "status": "done",
      "createdAt": "2025-10-10T23:34:14.426Z",
      "updatedAt": "2025-10-11T02:09:46.737Z",
      "description": "VERIFIED: 84 commands registered, help system comprehensive and accurate, all validation checks passing",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:09:01.564Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:09:45.913Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:09:46.189Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:09:46.463Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:09:46.737Z"
        }
      ],
      "rules": [
        "ALL 84 commands MUST be registered in src/index.ts with proper CLI bindings",
        "MUST have comprehensive help text for each command",
        "MUST pass all validation checks (build, validate, validate-tags)"
      ],
      "examples": [
        "All commands registered and accessible",
        "Help system shows all commands",
        "Build succeeds with no errors"
      ]
    },
    "DEP-001": {
      "id": "DEP-001",
      "title": "Work Unit Dependency Management",
      "status": "done",
      "createdAt": "2025-10-10T23:39:22.582Z",
      "updatedAt": "2025-10-10T23:47:00.473Z",
      "description": "Implement dependency tracking between work units including add-dependency, remove-dependency, and dependency validation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:39:38.913Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:42:11.831Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:46:12.749Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:46:19.691Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:47:00.473Z"
        }
      ],
      "rules": [
        "MUST maintain bidirectional consistency (if A blocks B, then B blockedBy A)",
        "MUST detect circular dependencies before creating relationships",
        "MUST prevent deletion of work units that block other work",
        "MUST auto-transition to blocked state when blockedBy work exists",
        "Work units can have 4 relationship types: blocks, blockedBy, dependsOn, relatesTo"
      ],
      "examples": [
        "Add blocks relationship creates bidirectional link",
        "Remove dependency cleans up both sides of relationship",
        "Circular dependency detection prevents A→B→A loops",
        "Adding blockedBy dependency auto-sets work unit to blocked state",
        "Query dependency stats shows metrics across all work units"
      ]
    },
    "EST-001": {
      "id": "EST-001",
      "title": "Work Unit Estimation and Metrics",
      "status": "done",
      "createdAt": "2025-10-10T23:39:24.324Z",
      "updatedAt": "2025-10-10T23:51:10.655Z",
      "description": "Implement estimation and metrics tracking including assign estimates, record tokens, calculate cycle time",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:47:18.974Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:48:44.204Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:51:10.109Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:51:10.383Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:51:10.655Z"
        }
      ],
      "rules": [
        "MUST support Fibonacci story points (1,2,3,5,8,13,21) for estimation",
        "MUST track AI-specific metrics: actualTokens and iterations",
        "MUST calculate cycle time from stateHistory timestamps",
        "MUST compare estimate vs actual to provide accuracy feedback",
        "MUST provide pattern-based estimation recommendations"
      ],
      "examples": [
        "Update work unit with 5-point estimate",
        "Record 45k tokens consumed",
        "Increment iteration count",
        "Query estimate accuracy for work unit",
        "Get estimation guide with patterns"
      ]
    },
    "QRY-001": {
      "id": "QRY-001",
      "title": "Work Unit Query and Reporting",
      "status": "done",
      "createdAt": "2025-10-10T23:39:26.221Z",
      "updatedAt": "2025-10-10T23:52:11.901Z",
      "description": "Implement query and reporting features including compound queries, statistical reports, and data export",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:51:24.531Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:52:11.067Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:52:11.346Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:52:11.624Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:52:11.901Z"
        }
      ],
      "rules": [
        "MUST support compound queries combining multiple filters (status, prefix, epic, tags)",
        "MUST export query results to JSON, CSV, or Markdown formats",
        "MUST generate statistical summary reports across work units",
        "MUST support sorting and pagination for large result sets",
        "MUST provide machine-readable output for CI/CD integration"
      ],
      "examples": [
        "Query by status and prefix",
        "Export work units to JSON",
        "Generate summary report with statistics",
        "Query with sorting by updated date",
        "Export filtered results to CSV"
      ]
    },
    "SPEC-001": {
      "id": "SPEC-001",
      "title": "Complete placeholder scenarios with proper Given/When/Then",
      "status": "done",
      "createdAt": "2025-10-11T02:11:53.337Z",
      "updatedAt": "2025-10-11T02:18:27.489Z",
      "description": "Fill in 24 placeholder scenarios across 6 feature files with concrete Given/When/Then steps",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:12:07.366Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:13:37.952Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:18:26.932Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:18:27.212Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:18:27.489Z"
        }
      ],
      "rules": [
        "Each placeholder scenario MUST have concrete Given/When/Then steps",
        "Steps MUST be specific and testable (no vague descriptions)",
        "Scenarios MUST align with their example mapping source",
        "All scenarios MUST follow Gherkin best practices",
        "Completed scenarios MUST pass validation"
      ],
      "examples": [
        "Fill INIT-001 scenarios (5 scenarios)",
        "Fill DEP-001 scenarios (5 scenarios)",
        "Fill EST-001 scenarios (5 scenarios)",
        "Fill QRY-001 scenarios (5 scenarios)",
        "Fill CLI-001 scenarios (3 scenarios)",
        "Fill add-scenario scenarios (1 scenario)"
      ]
    },
    "TEST-001": {
      "id": "TEST-001",
      "title": "Implement comprehensive test coverage for all commands",
      "status": "done",
      "createdAt": "2025-10-11T02:25:37.571Z",
      "updatedAt": "2025-10-11T03:07:49.878Z",
      "description": "Write tests for remaining untested commands to achieve near-100% test coverage across the CLI",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T03:05:37.421Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T03:06:54.869Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T03:07:39.735Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T03:07:44.751Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T03:07:49.878Z"
        }
      ],
      "rules": [
        "MUST test all CLI commands with valid inputs",
        "MUST test error handling and edge cases",
        "MUST achieve 90%+ code coverage on critical commands",
        "MUST validate file operations (read, write, delete)",
        "MUST test integration points (parser, formatter, validator)"
      ],
      "examples": [
        "Test create-feature with all template variations",
        "Test validation with invalid Gherkin syntax",
        "Test format preserves content and fixes indentation",
        "Test file operations handle missing directories",
        "Test tag registry operations (add, update, delete)"
      ]
    },
    "FEAT-001": {
      "id": "FEAT-001",
      "title": "Implement add-scenario and add-step commands",
      "status": "done",
      "createdAt": "2025-10-11T02:26:06.358Z",
      "updatedAt": "2025-10-11T02:34:00.512Z",
      "description": "Complete implementation of add-scenario and add-step commands for modifying feature files programmatically (phase3)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:26:56.216Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:28:39.953Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:33:59.946Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:34:00.227Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:34:00.512Z"
        }
      ],
      "rules": [
        "MUST parse existing feature file without corrupting content",
        "MUST maintain proper Gherkin formatting and indentation",
        "MUST validate scenario/step syntax before adding",
        "MUST preserve existing tags and metadata",
        "MUST support adding to any position (append, prepend, after scenario)"
      ],
      "examples": [
        "Add scenario to feature file",
        "Add Given step to scenario",
        "Add When step to scenario",
        "Add Then step to scenario",
        "Add scenario with tags"
      ]
    },
    "FEAT-002": {
      "id": "FEAT-002",
      "title": "Implement delete-scenario command",
      "status": "done",
      "createdAt": "2025-10-11T02:37:12.464Z",
      "updatedAt": "2025-10-11T02:43:37.355Z",
      "description": "Complete implementation of delete-scenario command for removing scenarios from feature files (phase4)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:37:48.826Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:40:58.673Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:43:36.723Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:43:37.047Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:43:37.355Z"
        }
      ],
      "rules": [
        "MUST safely delete scenario without corrupting file",
        "MUST preserve other scenarios and structure",
        "MUST support deletion by scenario name or index",
        "MUST handle scenario tags properly during deletion",
        "MUST provide confirmation before deleting"
      ],
      "examples": [
        "Delete scenario by name",
        "Delete scenario by index",
        "Delete multiple scenarios by tag",
        "Confirm before deletion",
        "Preserve remaining scenarios intact"
      ]
    },
    "FEAT-003": {
      "id": "FEAT-003",
      "title": "Implement scenario querying and filtering",
      "status": "done",
      "createdAt": "2025-10-11T02:37:12.740Z",
      "updatedAt": "2025-10-11T02:47:04.736Z",
      "description": "Implement get-scenarios and show-acceptance-criteria commands for querying scenarios by tag (phase4)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:43:45.616Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:44:45.290Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:47:04.171Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:47:04.451Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:47:04.736Z"
        }
      ],
      "rules": [
        "MUST support querying scenarios by single or multiple tags",
        "MUST output scenario list with metadata (feature, tags, steps)",
        "MUST support JSON and plain text output formats",
        "MUST handle AND/OR logic for multiple tags",
        "MUST show acceptance criteria in readable format"
      ],
      "examples": [
        "Get scenarios by single tag",
        "Get scenarios by multiple tags (AND logic)",
        "Show acceptance criteria for tag",
        "Output scenarios as JSON",
        "Query with tag matching pattern"
      ]
    },
    "FEAT-004": {
      "id": "FEAT-004",
      "title": "Implement bulk operations (delete-by-tag, retag)",
      "status": "done",
      "createdAt": "2025-10-11T02:49:30.896Z",
      "updatedAt": "2025-10-11T02:57:58.944Z",
      "description": "Implement bulk delete features/scenarios by tag and bulk retag operations (phase5 high priority)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:50:54.242Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:52:40.455Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:57:58.367Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:57:58.656Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:57:58.944Z"
        }
      ],
      "rules": [
        "MUST support bulk deletion across multiple files",
        "MUST preview changes before executing bulk operations",
        "MUST handle tag renaming with bidirectional updates",
        "MUST preserve file structure during bulk operations",
        "MUST provide detailed summary of changes made"
      ],
      "examples": [
        "Delete all scenarios with @deprecated tag",
        "Delete feature files tagged @phase1",
        "Rename tag from @old-tag to @new-tag",
        "Preview bulk delete before confirmation",
        "Show summary of bulk changes"
      ]
    },
    "FEAT-005": {
      "id": "FEAT-005",
      "title": "Implement update operations (scenario, step)",
      "status": "done",
      "createdAt": "2025-10-11T02:49:31.178Z",
      "updatedAt": "2025-10-11T03:01:38.306Z",
      "description": "Implement update-scenario and update-step commands for modifying existing content (phase5)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:58:07.304Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T03:00:04.811Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T03:01:27.456Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T03:01:32.883Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T03:01:38.306Z"
        }
      ],
      "rules": [
        "MUST support updating scenario name/title",
        "MUST support updating step text",
        "MUST preserve tags and metadata during updates",
        "MUST validate new content before applying",
        "MUST maintain proper Gherkin syntax"
      ],
      "examples": [
        "Update scenario name",
        "Update Given step text",
        "Update When step text",
        "Update Then step text",
        "Update step preserving position"
      ]
    },
    "INIT-002": {
      "id": "INIT-002",
      "title": "Add ensureFoundationFile and ensureTagsFile with proper auto-initialization",
      "status": "done",
      "createdAt": "2025-10-11T03:55:06.491Z",
      "updatedAt": "2025-10-11T04:29:23.795Z",
      "description": "Add ensureFoundationFile() and ensureTagsFile() functions to src/utils/ensure-files.ts and update ALL commands that read foundation.json or tags.json to use these functions instead of manual file checks",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T03:55:27.686Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T04:00:53.724Z",
          "reason": "Feature file tagged with @INIT-002, ready to write tests"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T04:12:03.024Z",
          "reason": "Tests written, ready to implement ensureFoundationFile and ensureTagsFile"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T04:25:49.608Z",
          "reason": "All commands updated to use ensure functions, tests passing"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T04:29:23.795Z",
          "reason": "Implementation complete: ensureFoundationFile() and ensureTagsFile() added, all commands updated, all tests passing"
        }
      ]
    },
    "BOARD-001": {
      "id": "BOARD-001",
      "title": "Implement board command with Ink + React visualization",
      "status": "done",
      "createdAt": "2025-10-11T04:32:31.325Z",
      "updatedAt": "2025-10-11T05:18:44.997Z",
      "description": "Create a Kanban board visualization using Ink + React that displays all work units across 7 workflow states. The board command replaces the old display-board implementation with a responsive terminal UI following React patterns.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T04:32:38.196Z",
          "reason": "Analyzing feature file scenarios and current broken implementation"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T04:43:24.069Z",
          "reason": "Example mapping complete, design agreed: box-drawing columns, 3-item limit, BLOCKED highlighted, all columns shown"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T04:44:20.798Z",
          "reason": "Tests written and passing for data structure, now implementing visual output"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T05:11:08.352Z",
          "reason": "Implementation complete: BoardDisplay component using Ink + React, architecture docs updated, component follows React patterns with useStdout, ready for validation"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T05:13:08.776Z",
          "reason": "Implementation validated: board command displays Kanban board correctly using Ink + React, all tests pass, follows React patterns, architecture docs updated, no issues found"
        }
      ]
    },
    "SAFE-001": {
      "id": "SAFE-001",
      "title": "Prevent spec directory creation outside project root",
      "status": "done",
      "createdAt": "2025-10-12T03:27:57.082Z",
      "updatedAt": "2025-10-12T04:47:39.305Z",
      "description": "Add validation to check if current directory is within project root before creating spec directories",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T03:28:04.689Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T04:43:22.902Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T04:45:14.668Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T04:47:23.341Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T04:47:39.306Z"
        }
      ],
      "rules": [
        "Project root is determined by finding a spec/ directory, but search must stop at a project boundary marker (.git, package.json, etc.)",
        "Search algorithm walks upward from cwd, stopping at project boundary markers: .git, package.json, .gitignore, Cargo.toml, pyproject.toml",
        "If spec/ directory exists within project boundary, use that directory as project root",
        "If no spec/ directory found within project boundary, create spec/ at the project boundary location (not cwd)",
        "If no project boundary marker found after searching to filesystem root, create spec/ in current working directory",
        "Stop at first boundary marker found when searching upward (closest to cwd)",
        "All spec directory creation must go through a centralized utility function that performs project root detection",
        "Search upward with a maximum limit (e.g., 10 directories) to prevent excessive traversal",
        "On permission errors or filesystem issues, gracefully fall back to creating spec/ in current working directory",
        "Centralized utility should automatically create spec/ directory and return the spec path (not project root)",
        "Defer testing refactored callers until core utility is complete. Critical: Do not break existing functionality - ensure backward compatibility so all current tests continue passing. Architecture must support both old and new code paths during transition."
      ],
      "examples": [
        "User at /project/src/commands/, .git at /project/, no spec/ exists → create /project/spec/",
        "User at /project/src/commands/, .git at /project/, spec/ exists at /project/spec/ → use /project/spec/",
        "User at /tmp/random/, no boundary markers found → create /tmp/random/spec/",
        "Monorepo: /monorepo/.git and /monorepo/packages/app/package.json, user at /monorepo/packages/app/src/ → use /monorepo/packages/app/ as root",
        "User at /very/deep/nested/path/a/b/c/d/e/f/g/h/i/j/k/, no boundary within 10 dirs → create spec/ at cwd",
        "User at /project/src/, permission denied reading parent dirs → create spec/ at /project/src/"
      ],
      "questions": [],
      "assumptions": [
        "Need to verify existing ensure-files.ts functions work with new project root detection - may need to refactor callers to use returned spec path instead of manually constructing it"
      ]
    },
    "CLI-002": {
      "id": "CLI-002",
      "title": "Fix missing list-prefixes CLI command registration",
      "status": "done",
      "createdAt": "2025-10-12T03:48:03.694Z",
      "updatedAt": "2025-10-12T03:53:56.776Z",
      "description": "The list-prefixes command is documented in help but not registered in the CLI",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T03:48:12.204Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T03:50:18.426Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T03:51:37.431Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T03:52:38.137Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T03:53:56.776Z"
        }
      ],
      "questions": [],
      "rules": [
        "Yes, consistent with list-epics behavior",
        "Yes, output format should match list-epics for consistency",
        "Yes, return empty list with yellow message if no prefixes.json exists"
      ],
      "examples": [
        "User runs 'fspec list-prefixes' and sees all registered prefixes with their descriptions",
        "User runs 'fspec list-prefixes' and sees work unit counts for each prefix (e.g., 'SAFE: 1/1 (100%)')",
        "User runs 'fspec list-prefixes' when no prefixes.json exists, sees 'No prefixes found' in yellow"
      ]
    },
    "DOC-001": {
      "id": "DOC-001",
      "title": "Add story point estimation guidance",
      "status": "done",
      "createdAt": "2025-10-12T05:13:30.172Z",
      "updatedAt": "2025-10-12T06:58:58.773Z",
      "description": "Add story point estimation guidelines to /fspec command including Fibonacci scale, estimation prompts, and best practices",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T06:57:57.344Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:58:57.916Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:58:58.206Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:58:58.489Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:58:58.773Z"
        }
      ]
    },
    "REMIND-001": {
      "id": "REMIND-001",
      "title": "Implement system-reminder pattern",
      "status": "done",
      "createdAt": "2025-10-12T05:13:30.451Z",
      "updatedAt": "2025-10-12T05:29:04.618Z",
      "description": "Add system-reminder wrapper functions and trigger points to prevent AI drift during long conversations",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:17:36.967Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T05:20:47.043Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:21:53.587Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:23:54.695Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:24:11.995Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:24:29.001Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:25:59.299Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:26:23.102Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:26:44.204Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:27:04.588Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:27:37.721Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:27:52.779Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T05:29:04.618Z"
        }
      ],
      "rules": [
        "System reminders must be wrapped in <system-reminder> tags",
        "Reminders must be invisible to users but visible to Claude",
        "Reminders should only be injected after specific command executions",
        "Each reminder must be context-specific to the command executed",
        "Reminders must be conditional and context-aware - only show when relevant to the current situation",
        "Reminders should be appended AFTER main command output"
      ],
      "examples": [
        "After 'fspec update-work-unit-status UI-001 testing', output includes reminder: 'Write FAILING tests BEFORE any implementation code'",
        "After 'fspec update-work-unit-status UI-001 implementing', output includes reminder: 'Write ONLY enough code to make tests pass'",
        "After 'fspec update-work-unit-estimate UI-001' without an estimate value, output includes reminder: 'Use Fibonacci scale (1,2,3,5,8,13)'",
        "After 'fspec list-work-units --status=backlog' returns empty, output includes reminder: 'Consider creating new work units or checking priorities'"
      ],
      "questions": []
    },
    "TEST-002": {
      "id": "TEST-002",
      "title": "Test system reminders",
      "status": "done",
      "createdAt": "2025-10-12T05:24:45.522Z",
      "updatedAt": "2025-10-12T06:57:17.505Z",
      "description": "Testing if system reminders work correctly",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:24:53.211Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:56:43.819Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:56:44.107Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:56:44.393Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:57:17.505Z"
        }
      ]
    },
    "CLI-003": {
      "id": "CLI-003",
      "title": "Initialize fspec slash command in Claude Code project",
      "status": "done",
      "createdAt": "2025-10-12T05:41:20.177Z",
      "updatedAt": "2025-10-12T06:53:58.304Z",
      "description": "Add 'fspec init' command that installs the /fspec slash command into a Claude Code project by creating/using .claude/commands/ directory and copying fspec.md command file. Should be idempotent and safe to run multiple times.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:42:05.997Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T05:54:31.892Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:51:49.181Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:52:51.675Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:53:58.304Z"
        }
      ],
      "rules": [
        "Command must prompt user to choose: Claude Code or custom location",
        "If Claude Code selected, install to .claude/commands/fspec.md automatically",
        "If custom location selected, prompt for full file path where to save",
        "Template must be generic and reusable across any project (not fspec-specific examples)",
        "Success means file exists at specified location after command completes",
        "Create parent directories if they don't exist",
        "If target file exists, prompt for confirmation before overwriting",
        "Template references fspec commands but uses generic project placeholders (not fspec-specific examples)",
        "Use ink/react for interactive prompts (consistent with existing board UI)",
        "Command works from any directory, installs relative to current working directory",
        "Template uses same structure as .claude/commands/fspec.md but with generic project placeholders",
        "If user cancels overwrite, display 'Installation cancelled' and exit with success (0)",
        "Custom path must be relative to current directory (same or subdirectory, not parent or absolute)",
        "On success, display both confirmation message and next steps for usage",
        "On error (permission denied, disk full, etc), display error message and exit with non-zero code",
        "Use example-project style (lowercase example placeholders)",
        "Include all sections from current fspec.md (complete template with all ACDD workflow, example mapping, estimation, etc)",
        "Allow: ./file.md, file.md, subdir/file.md, subdir/nested/file.md. Reject: ../file.md, /absolute/path, ~/home/path"
      ],
      "examples": [
        "User runs 'fspec init' in project root, selects Claude Code, file created at ./claude/commands/fspec.md",
        "User runs 'fspec init', selects custom location, enters 'docs/ai/fspec.md', file created at ./docs/ai/fspec.md",
        "User runs 'fspec init' when .claude/commands/fspec.md exists, prompted to confirm overwrite, user confirms, file is overwritten",
        "User runs 'fspec init', selects custom location, enters 'some/deep/path/fspec.md', parent directories created automatically",
        "User runs 'fspec init', selects custom location, enters '../parent/fspec.md', validation fails with error about path being outside current directory",
        "User runs 'fspec init' when .claude/commands/fspec.md exists, declines overwrite, command exits with 'Installation cancelled'",
        "User runs 'fspec init', selects Claude Code, command succeeds, displays '✓ Installed /fspec command to .claude/commands/fspec.md' and 'Run /fspec in Claude Code to activate'"
      ],
      "questions": [],
      "estimate": 5
    },
    "TEST-003": {
      "id": "TEST-003",
      "title": "Test answer-question with multiple questions",
      "status": "done",
      "createdAt": "2025-10-12T05:57:24.220Z",
      "updatedAt": "2025-10-12T06:57:49.173Z",
      "description": "Testing that answering multiple questions works correctly with proper index handling",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:57:25.745Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:57:48.309Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:57:48.599Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:57:48.887Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:57:49.173Z"
        }
      ],
      "questions": [],
      "rules": [
        "Use option A for consistency",
        "Edge case X should return error code 400",
        "Not in phase 1, defer to backlog"
      ]
    },
    "SAFE-002": {
      "id": "SAFE-002",
      "title": "Fix race condition in answer-question when run concurrently",
      "status": "done",
      "createdAt": "2025-10-12T06:01:08.064Z",
      "updatedAt": "2025-10-12T06:33:27.231Z",
      "description": "Add file locking or transaction mechanism to prevent race conditions when multiple answer-question commands run in parallel. Currently parallel executions can overwrite each other's changes causing data loss.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T06:01:09.809Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:07:32.863Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:09:49.140Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:32:14.013Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:33:27.232Z"
        }
      ],
      "rules": [
        "Multiple concurrent writes to work-units.json must not corrupt data",
        "When multiple answer-question commands run in parallel, all answers must be saved",
        "Last write must not overwrite changes from earlier writes",
        "Solution must work across platforms (macOS, Linux, Windows)",
        "Question indices must remain stable even after questions are answered",
        "YES - Use stable indices with 'selected' flag. Change questions from string array to object array: [{text: 'question', selected: false}, ...]. When answered, mark as selected:true and add answer field. This eliminates race condition without needing file locks.",
        "Questions use 'selected' property to indicate if answered, not 'answered' property"
      ],
      "examples": [
        "User runs 3 answer-question commands in parallel, all 3 questions are answered and all 3 rules are added",
        "User runs answer-question while another command modifies work-units.json, both changes are preserved",
        "User adds 3 questions (indices 0,1,2), answers question 1, indices remain 0,1,2 but question 1 is marked as answered",
        "Question object structure: {text: '@human: Should we...?', selected: false} becomes {text: '@human: Should we...?', selected: true, answer: 'Yes because...'} when answered"
      ],
      "questions": [],
      "assumptions": [
        "Not needed - stable indices approach eliminates race condition without file locking",
        "Not needed - stable indices approach can be used for all commands, but answer-question is the priority",
        "Not applicable - no lock acquisition with stable indices approach"
      ],
      "estimate": 3
    },
    "CLI-004": {
      "id": "CLI-004",
      "title": "Wire up init command to CLI program",
      "status": "done",
      "createdAt": "2025-10-12T07:09:52.763Z",
      "updatedAt": "2025-10-12T07:21:43.421Z",
      "children": [],
      "description": "The init command implementation exists in src/commands/init.ts but is NOT registered in src/index.ts. This means users cannot run 'fspec init'. Need to: 1) Register command in CLI, 2) Add to help system, 3) Update feature files with complete acceptance criteria, 4) Ensure tests cover end-to-end CLI invocation (not just unit tests), 5) Validate command actually works via CLI before marking done.",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:10:05.831Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:12:12.711Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:20:18.251Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T07:20:25.581Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T07:21:20.272Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T07:21:43.421Z"
        }
      ],
      "rules": [
        "Command must be registered in src/index.ts with .command('init')",
        "Command must support interactive prompts using ink/react (option --type and --path flags)",
        "Command must appear in 'fspec --help' output and 'fspec help setup' section",
        "E2E tests must verify 'fspec init' actually works via CLI, not just unit tests of the function"
      ],
      "examples": [
        "Running 'fspec init' prompts for installation type (Claude Code or Custom)",
        "Running 'fspec init --type=claude-code' installs to .claude/commands/fspec.md",
        "Running 'fspec --help' shows init command in output"
      ]
    },
    "BUG-001": {
      "id": "BUG-001",
      "title": "Scenario-level tagging rejects work unit tags",
      "status": "done",
      "createdAt": "2025-10-12T07:13:53.468Z",
      "updatedAt": "2025-10-12T07:17:29.244Z",
      "description": "add-tag-to-scenario command rejects work unit tags like @CLI-004 even though add-tag-to-feature accepts them. The scenario tagging uses /^@[a-z0-9-#]+$/ regex while feature tagging uses isWorkUnitTag() helper. Need to make scenario tagging use the same work unit tag validation as feature tagging.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:13:56.954Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:14:51.941Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T07:15:26.562Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T07:15:58.002Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T07:17:29.245Z"
        }
      ],
      "rules": [
        "add-tag-to-scenario MUST use isWorkUnitTag() helper for validation, same as add-tag-to-feature",
        "Work unit tags (@PREFIX-NNN format) MUST be accepted at both feature and scenario level"
      ],
      "examples": [
        "Running 'fspec add-tag-to-scenario file.feature \"Scenario\" @CLI-004' should succeed",
        "Work unit tags like @AUTH-001, @BUG-001, @CLI-004 should be accepted"
      ]
    },
    "BUG-002": {
      "id": "BUG-002",
      "title": "generate-scenarios displays 'undefined' instead of count",
      "status": "done",
      "createdAt": "2025-10-12T07:14:42.738Z",
      "updatedAt": "2025-10-12T07:19:58.352Z",
      "description": "When running 'fspec generate-scenarios <work-unit-id>', the success message shows 'Generated undefined scenarios' instead of showing the actual count of scenarios generated. The command should display 'Generated N scenarios' where N is the number of scenarios created.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:18:37.948Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:18:52.782Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T07:19:19.951Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T07:19:35.465Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T07:19:58.353Z"
        }
      ],
      "rules": [
        "generate-scenarios command MUST return the count of scenarios generated",
        "Success message MUST display 'Generated N scenarios' where N is the actual count"
      ],
      "examples": [
        "Running 'fspec generate-scenarios WORK-001' should display 'Generated 3 scenarios' not 'Generated undefined scenarios'"
      ]
    },
    "INIT-003": {
      "id": "INIT-003",
      "title": "Copy CLAUDE.md template to new spec directory",
      "status": "done",
      "createdAt": "2025-10-12T07:58:21.443Z",
      "updatedAt": "2025-10-12T08:20:05.866Z",
      "description": "When fspec init creates a new spec/ directory, it should copy the spec/CLAUDE.md file (bundled with the package) to the target project. This ensures new projects have the complete specification guidelines and workflow documentation from the start. The file is bundled from spec/CLAUDE.md to dist/spec/CLAUDE.md during build - no separate templates/ directory needed.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:58:34.774Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T08:05:45.263Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T08:06:40.200Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T08:09:35.216Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T08:10:49.918Z"
        }
      ],
      "rules": [
        "CLAUDE.md template must be bundled with fspec package in a templates/ directory",
        "CLAUDE.md file must be identical across all projects (no customization)",
        "If spec/CLAUDE.md already exists, overwrite it with the latest template",
        "fspec init command must set up complete spec directory structure with CLAUDE.md and /fspec slash command",
        "Always overwrite - no version checking needed",
        "Show confirmation message in /fspec slash command output (fspec.md), no separate message from fspec init CLI",
        "Enhance existing 'fspec init' command to copy CLAUDE.md template"
      ],
      "examples": [
        "User runs 'fspec init' in empty directory, creates spec/ directory with CLAUDE.md and .claude/commands/fspec.md",
        "User runs 'fspec init' in directory with existing spec/CLAUDE.md, overwrites with latest template",
        "CLAUDE.md template is copied from fspec package's templates/CLAUDE.md to project's spec/CLAUDE.md",
        "fspec init copies templates/CLAUDE.md to spec/CLAUDE.md preserving all content exactly",
        "/fspec slash command shows 'Copied spec/CLAUDE.md specification guidelines' in output",
        "Running 'fspec init' twice overwrites spec/CLAUDE.md with latest template (no prompt, no backup)"
      ],
      "questions": [
        {
          "text": "@human: Should 'fspec init' also check if the CLAUDE.md template in the package is newer than the one in the project and offer to update it?",
          "selected": true,
          "answer": "Always overwrite - no version checking needed"
        },
        {
          "text": "@human: What should happen if the templates/ directory is missing from the fspec package installation?",
          "selected": true,
          "answer": "Templates directory is bundled with package build - if missing, it's a build error (should never happen in production)"
        },
        {
          "text": "@human: Should there be any output message confirming CLAUDE.md was copied/updated?",
          "selected": true,
          "answer": "Show confirmation message in /fspec slash command output (fspec.md), no separate message from fspec init CLI"
        },
        {
          "text": "@human: Looking at existing INIT-002 work unit, should this enhance the existing init command or be separate?",
          "selected": true,
          "answer": "Enhance existing 'fspec init' command to copy CLAUDE.md template"
        }
      ],
      "assumptions": [
        "Templates directory is bundled with package build - if missing, it's a build error (should never happen in production)"
      ],
      "estimate": 2
    },
    "DOC-002": {
      "id": "DOC-002",
      "title": "Provide schema information for foundation.json",
      "status": "done",
      "createdAt": "2025-10-12T11:46:03.860Z",
      "updatedAt": "2025-10-12T23:11:14.375Z",
      "description": "Add schema information to foundation.json to help AI agents draft foundation documents more easily. May require relaxing some schema constraints to make it more flexible for agents.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T11:46:21.581Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T22:56:07.240Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T22:59:39.116Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T23:11:14.091Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T23:11:14.376Z"
        }
      ],
      "rules": [
        "Schema must guide AI agents to write documentation in a specific format that preserves project meaning and prevents drift",
        "Schema must be provided as a separate JSON Schema file (foundation.schema.json)",
        "Schema file must be accessible via CLI command so AI agents can read it",
        "Field names should be flexible (e.g., accept both camelCase and snake_case) while maintaining similar overall structure",
        "Schema must include rich descriptions explaining the intent behind each section",
        "Schema must include examples of good vs. bad content for each field",
        "Schema must include validation rules (e.g., minimum array lengths, required fields)",
        "Schema must include format instructions for structured fields",
        "Must provide both 'fspec show-foundation-schema' to display schema and 'fspec validate-foundation-schema' to validate foundation.json",
        "No backward compatibility required - existing foundation.json files may need migration to new format",
        "Mermaid syntax validation should be handled by Mermaid library (mermaid.parse()), not by JSON Schema. Schema only validates that mermaidCode field exists and is a string.",
        "Schema should allow AI agents to add custom sections beyond the standard ones (project, whatWeAreBuilding, whyWeAreBuildingIt). Use additionalProperties: true for extensibility.",
        "Validation should check semantic content of descriptions. Schema descriptions should guide AI on what to write and what NOT to write (e.g., 'projectOverview should focus on WHAT/HOW, not WHY - business justification belongs in whyWeAreBuildingIt').",
        "Schema should allow additional properties (additionalProperties: true) for future extensibility. AI agents can add custom sections as needed."
      ],
      "examples": [
        "Schema for 'projectOverview' includes description: 'A comprehensive technical overview (2-4 sentences) describing: (1) what systems are being built, (2) who uses them (target users), (3) how the systems integrate. Focus on WHAT and HOW, not WHY. Example: A Kanban-based project management and specification tool for AI agents...'",
        "Schema for 'problemDefinition.primary' includes validation: must contain 'title', 'description', and 'coreProblems' array with minimum 3 items describing distinct problem categories",
        "Schema accepts both camelCase and snake_case for ALL field names. Examples: 'architectureDiagrams' OR 'architecture_diagrams', 'technicalRequirements' OR 'technical_requirements', 'projectOverview' OR 'project_overview'",
        "AI agent runs 'fspec show-foundation-schema' and receives JSON Schema with rich descriptions and examples. Agent uses this to understand how to structure foundation.json sections when running 'fspec update-foundation'",
        "AI agent runs 'fspec validate-foundation-schema' after updating foundation.json. Validation fails with message: 'Field problemDefinition.primary.coreProblems must have at least 3 items (found 2)'. Agent adds another problem and re-validates."
      ],
      "questions": [
        {
          "text": "@human: Should the schema validate Mermaid syntax in architectureDiagrams array, or just validate that mermaidCode field is a string?",
          "selected": true,
          "answer": "Mermaid syntax validation should be handled by Mermaid library (mermaid.parse()), not by JSON Schema. Schema only validates that mermaidCode field exists and is a string."
        },
        {
          "text": "@human: Should the schema enforce specific top-level section names (project, whatWeAreBuilding, whyWeAreBuildingIt) or allow AI agents to add custom sections?",
          "selected": true,
          "answer": "Schema should allow AI agents to add custom sections beyond the standard ones (project, whatWeAreBuilding, whyWeAreBuildingIt). Use additionalProperties: true for extensibility."
        },
        {
          "text": "@human: How detailed should validation be? Should it validate the semantic content of descriptions (e.g., 'projectOverview should not mention business justification') or just structural rules (required fields, types, array lengths)?",
          "selected": true,
          "answer": "Validation should check semantic content of descriptions. Schema descriptions should guide AI on what to write and what NOT to write (e.g., 'projectOverview should focus on WHAT/HOW, not WHY - business justification belongs in whyWeAreBuildingIt')."
        },
        {
          "text": "@human: Should we provide a migration command (e.g., 'fspec migrate-foundation') to convert existing foundation.json to the new flexible format, or should users manually update?",
          "selected": true,
          "answer": "No migration command needed. No backward compatibility - users must manually update foundation.json to new format when schema is introduced."
        },
        {
          "text": "@human: Should the schema allow additional properties beyond the defined ones (additionalProperties: true) to support future extensibility, or be strict (additionalProperties: false)?",
          "selected": true,
          "answer": "Schema should allow additional properties (additionalProperties: true) for future extensibility. AI agents can add custom sections as needed."
        }
      ],
      "assumptions": [
        "No migration command needed. No backward compatibility - users must manually update foundation.json to new format when schema is introduced."
      ],
      "estimate": 5
    },
    "RSPEC-001": {
      "id": "RSPEC-001",
      "title": "Add rspec command for reverse ACDD",
      "status": "done",
      "createdAt": "2025-10-12T11:46:05.565Z",
      "updatedAt": "2025-10-13T00:20:55.500Z",
      "description": "Create new 'rspec' command that performs reverse ACDD by decomposing/reverse engineering existing applications. The command discovers user stories, personas, and acceptance criteria from existing code. Extends the /fspec slash command to tell Claude to read fspec.md and continue with reverse engineering workflow.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T23:11:24.854Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T00:20:36.464Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T00:20:42.594Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T00:20:49.164Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T00:20:55.501Z"
        }
      ],
      "rules": [
        "Must identify user personas who interact with the system",
        "Must identify high-level activities or goals users achieve with the software",
        "Must break down high-level activities into smaller specific tasks or interactions that code supports",
        "Analysis involves: (1) analyzing functionality and mapping to user goals, (2) examining UI elements/features/workflows, (3) grouping related features into epics/journeys, (4) decomposing into individual user stories",
        "Must produce user story map organized visually along user journey (broad activities at top, detailed interactions underneath)",
        "User stories must be expressed as user-centric narratives (As a [persona], I want [goal], So that [benefit])",
        "fspec init must install rspec.md slash command (similar to how it installs fspec.md)",
        "rspec.md first line (after title) must say 'fully read fspec.md' with markdown link to exact fspec.md location",
        "Must create everything fspec can do: work units, epics, prefixes, example maps, features, foundation.json (particularly this, keep updating as it learns), diagrams, unit/integration tests (NOT implemented), test-to-feature links (header comments)",
        "Must create user story map in feature file docstrings or foundation.json (wherever closest to where it needs to be)",
        "Must ONLY create artifacts that use fspec or are tests - nothing else",
        "When encountering incomplete/ambiguous code: reverse engineer as much as possible, then ask human to complete via Example Mapping session",
        "foundation.json must be continuously updated as system learns more about the codebase",
        "Unit tests and integration tests created must NOT be implemented (skeleton only) - AI/human implements them later following ACDD",
        "/rspec is a Claude Code slash command (not CLI command) - user invokes it via /rspec in Claude Code",
        "User story map should be one or more Mermaid diagrams (preferably) plus any supporting artifacts that help visualize the map"
      ],
      "examples": [
        "Skeleton test file header includes: /** Feature: spec/features/[name].feature\\n * This test validates acceptance criteria. Tests map to Gherkin scenarios.\\n */",
        "User runs /rspec in Claude Code → AI reads .claude/commands/rspec.md → First line says 'fully read fspec.md' (with link) → AI follows fspec workflow while reverse engineering",
        "User story map created as Mermaid diagram in foundation.json architectureDiagrams array with section='User Story Map'",
        "Reverse engineered Express.js app: creates epic 'api-management', prefix 'API', work units API-001 'User authentication', API-002 'Data validation', feature files with inferred scenarios, skeleton tests with describe/it blocks (no implementation)"
      ]
    },
    "BUG-003": {
      "id": "BUG-003",
      "title": "Summary report shows 'undefined' instead of file path",
      "status": "done",
      "createdAt": "2025-10-13T05:18:30.471Z",
      "updatedAt": "2025-10-13T07:23:52.363Z",
      "description": "When running 'fspec generate-summary-report --format=markdown', the output shows 'Report generated: undefined' instead of the actual file path where the report was saved.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T05:18:44.355Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T05:22:07.396Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T05:22:44.125Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T05:24:48.456Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T05:25:46.597Z"
        }
      ],
      "rules": [
        "Command output must show the actual file path where the report was generated",
        "When --output option is provided, show that specific path",
        "When --output option is NOT provided, show the default generated path",
        "Function must return outputFile property containing the path where report was written",
        "Function must accept format (markdown, json, html) and output (file path) options",
        "Function must write report to file system in the specified format",
        "Default output path should be spec/summary-report.{format}"
      ],
      "examples": [
        "User runs 'fspec generate-summary-report --format=markdown', sees 'Report generated: spec/summary-report.md'",
        "User runs 'fspec generate-summary-report --format=markdown --output=custom.md', sees 'Report generated: custom.md'",
        "Currently shows 'Report generated: undefined' instead of actual path",
        "Function currently returns SummaryReport object without outputFile property",
        "CLI calls result.outputFile which is undefined",
        "Function signature currently missing format and output parameters"
      ],
      "estimate": 2
    },
    "CLI-005": {
      "id": "CLI-005",
      "title": "Add --help support to all fspec commands",
      "status": "done",
      "createdAt": "2025-10-13T05:32:26.029Z",
      "updatedAt": "2025-10-13T05:56:38.745Z",
      "description": "Currently commands like 'fspec create-epic --help' fail with 'unknown option --help'. Every fspec command should support --help flag that displays detailed usage information, options, arguments, and practical examples for that specific command. This includes all ~80+ commands across specs, work, discovery, metrics, and setup groups.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T05:32:33.248Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T05:44:40.837Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T05:46:16.843Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T05:55:36.370Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T05:56:38.746Z"
        }
      ],
      "rules": [
        "Help output must include: command description, all options with descriptions, required vs optional arguments, practical examples, and related commands",
        "Help formatting must use custom colored output matching 'fspec help specs' style, optimized for AI agent readability",
        "Number of examples should be contextually appropriate per command complexity",
        "Individual command help (--help) must be separate from group help (fspec help specs/work/etc)",
        "Main fspec --help output must mention that each command supports its own --help flag",
        "Must use custom help system, not Commander.js built-in help (insufficient quality)",
        "Help must include AI-optimized sections when applicable: WHEN TO USE, WHEN NOT TO USE, COMMON PATTERNS, TYPICAL WORKFLOW, PREREQUISITES, related workflow states",
        "Examples must show both command and expected output for clarity",
        "Help templates must vary by command complexity: Simple (1-2 examples), Medium (2-3 examples), Complex (4-5 examples showing different modes)",
        "Help must include COMMON ERRORS section with error messages and fixes",
        "Related commands section must only show highly related commands with whatever format makes sense (syntax/names/workflow context)",
        "No validation or schema enforcement needed - help text should be inline in command code",
        "Whatever is most elegant while retaining exact same functionality - ultrathink this",
        "Create help infrastructure first, then implement each command help individually",
        "Yes, refactor into shared help utilities module for consistency",
        "Infrastructure first: build help system, then implement per command",
        "Infrastructure first: build help system, then implement per command"
      ],
      "examples": [
        "User runs 'fspec create-epic --help' and sees: description, usage syntax, options (none), arguments (<name> <title>), 2 examples with output, related commands (list-epics, show-epic, create-work-unit)",
        "User runs 'fspec list-work-units --help' and sees: WHEN TO USE section, all options (--status, --prefix, --epic), 3 examples showing different filters with sample output, TYPICAL WORKFLOW mentioning backlog → specifying flow",
        "User runs 'fspec add-dependency --help' and sees: description explaining dependency types, 5 examples showing shorthand vs --blocks vs --blocked-by vs --depends-on vs --relates-to, COMMON ERRORS section for 'work unit not found', related commands (remove-dependency, dependencies, export-dependencies)",
        "User runs 'fspec update-work-unit-status --help' and sees: PREREQUISITES (work unit must exist), WHEN TO USE (moving through ACDD workflow), valid status values listed, TYPICAL WORKFLOW showing backlog→specifying→testing→implementing→validating→done, example with output showing status change",
        "User runs 'fspec --help' and sees updated main help with note: 'Get detailed help for any command with: fspec <command> --help'",
        "User runs 'fspec add-question --help' and sees: WHEN TO USE (during Example Mapping in specifying phase), COMMON PATTERNS (use @human: prefix for questions directed at human), example showing question with answer flow, related commands (answer-question, add-rule, add-example, generate-scenarios)"
      ],
      "questions": [
        {
          "text": "@human: How should we handle the --help flag given the custom help system that overrides Commander?",
          "selected": true,
          "answer": "Whatever works best - could be smoke tests, integration tests, or manual testing"
        },
        {
          "text": "@human: Should we refactor existing help command formatting utilities into shared module?",
          "selected": true,
          "answer": "Integration tests that verify help output contains required sections and examples"
        },
        {
          "text": "@human: Should we implement help for all 80+ commands at once or incrementally?",
          "selected": true,
          "answer": "Infrastructure first: build help system, then implement per command"
        },
        {
          "text": "@human: What testing strategy should we use for help output?",
          "selected": true,
          "answer": "Integration tests that verify help output contains required sections and examples"
        }
      ],
      "assumptions": [
        "Whatever works best given current setup and custom help system that overrides Commander's, and existing fspec --help",
        "Whatever works best - could be smoke tests, integration tests, or manual testing",
        "Integration tests that verify help output contains required sections and examples",
        "Integration tests that verify help output contains required sections and examples"
      ]
    },
    "CLI-006": {
      "id": "CLI-006",
      "title": "Implement scalable help system for all commands",
      "status": "done",
      "createdAt": "2025-10-13T06:06:34.397Z",
      "updatedAt": "2025-10-13T06:26:59.486Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T06:06:40.458Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T06:12:23.135Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T06:13:25.161Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T06:25:58.574Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T06:26:59.487Z"
        }
      ],
      "rules": [
        "Help system must automatically discover and register help configs without manual registration in index.ts",
        "Each command should have its help config in a dedicated file (command-name-help.ts) co-located with command implementation",
        "Commander.js should automatically handle --help flag for all commands without explicit handlers in action callbacks",
        "Help configs should use a naming convention that maps to command names (e.g., remove-tag-from-scenario -> remove-tag-from-scenario-help.ts)",
        "Missing help config files should fall back to Commander.js default help (current behavior) rather than error"
      ],
      "examples": [
        "When user runs 'fspec remove-tag-from-scenario --help' and help config exists at src/commands/remove-tag-from-scenario-help.ts, display detailed help from config",
        "When user runs 'fspec some-command --help' and no help config file exists, fall back to Commander.js default help"
      ],
      "questions": [
        {
          "text": "@human: Should we use Commander.js custom help configuration or a global --help interceptor to avoid modifying 91 command registrations?",
          "selected": true,
          "answer": "Use process-level help interceptor with registry Set. Intercept --help before Commander.js, use dynamic imports, graceful fallback for missing configs, zero modifications to 91 command registrations."
        }
      ]
    },
    "BUG-004": {
      "id": "BUG-004",
      "title": "Fix generate-scenarios to use capability-based feature file names",
      "status": "done",
      "createdAt": "2025-10-13T07:23:50.426Z",
      "updatedAt": "2025-10-13T07:31:08.560Z",
      "description": "The generate-scenarios command currently defaults to using work unit ID as feature file name (e.g., auth-001.feature) which violates the naming principle. Should require --feature flag or use work unit title as default.",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T07:24:10.294Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T07:26:43.645Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T07:27:36.963Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T07:30:19.171Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T07:31:08.561Z"
        }
      ],
      "rules": [
        "Feature files must be named after capabilities, NOT work unit IDs",
        "Work unit title should be used as default suggestion when --feature not provided",
        "Command should fail with helpful error if --feature not provided and AI needs to choose name",
        "Auto-default to work unit title (kebab-cased). User can override with --feature flag if they want a different name.",
        "Throw error requiring --feature flag with helpful message suggesting capability-based name."
      ],
      "examples": [
        "User runs 'fspec generate-scenarios AUTH-001', command suggests using work unit title as feature name",
        "User runs 'fspec generate-scenarios AUTH-001 --feature=user-authentication', creates spec/features/user-authentication.feature",
        "Work unit AUTH-001 has title 'User Login', defaults to spec/features/user-login.feature when --feature not provided"
      ],
      "questions": [
        {
          "text": "@human: Should we make --feature flag required, or auto-default to work unit title?",
          "selected": true,
          "answer": "Auto-default to work unit title (kebab-cased). User can override with --feature flag if they want a different name."
        },
        {
          "text": "@human: What should happen if work unit title is empty or not set?",
          "selected": true,
          "answer": "Throw error requiring --feature flag with helpful message suggesting capability-based name."
        }
      ]
    },
    "REMIND-002": {
      "id": "REMIND-002",
      "title": "Comprehensive System-Reminder Overhaul",
      "status": "done",
      "createdAt": "2025-10-13T07:56:29.390Z",
      "updatedAt": "2025-10-13T08:19:36.823Z",
      "description": "Audit existing system-reminders, expand to all critical commands based on analysis, add file naming detection, tag validation, and discovery phase reminders",
      "children": [
        "REMIND-003",
        "REMIND-004",
        "REMIND-005",
        "REMIND-006",
        "REMIND-007"
      ],
      "estimate": 13,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:18:35.217Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:19:35.726Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:19:36.092Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:19:36.462Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:19:36.824Z"
        }
      ],
      "rules": [
        "All child work units (REMIND-003, 004, 005, 006, 007) must be in done status",
        "System-reminder functions implemented in src/utils/system-reminder.ts",
        "System-reminders integrated into create-feature, add-tag-to-feature, generate-scenarios, show-work-unit, and update-work-unit-status commands"
      ],
      "examples": [
        "All 5 child work units completed successfully with tests passing",
        "Build passing with 843 tests, all system-reminder functionality working"
      ]
    },
    "REMIND-003": {
      "id": "REMIND-003",
      "title": "File Naming Anti-Pattern Detection",
      "status": "done",
      "createdAt": "2025-10-13T07:56:47.607Z",
      "updatedAt": "2025-10-13T08:02:40.554Z",
      "description": "Add system-reminders to create-feature command to detect task-based naming (implement-, add-, create-, work-unit-ID) and remind to use capability-based naming",
      "parent": "REMIND-002",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T07:57:27.395Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T07:58:22.240Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T07:58:32.755Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:01:48.189Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:02:40.555Z"
        }
      ],
      "rules": [
        "System-reminders must detect task-based file naming patterns (implement-, add-, create-, fix-, build-)",
        "System-reminders must detect work unit ID patterns in file names (e.g., AUTH-001, REMIND-003)",
        "Reminders must provide correct examples of capability-based naming"
      ],
      "examples": [
        "User runs 'fspec create-feature implement-authentication', reminder shows '❌ WRONG: implement-authentication → ✅ CORRECT: user-authentication'",
        "User runs 'fspec create-feature AUTH-001', reminder shows work unit IDs are not capability names",
        "User runs 'fspec create-feature user-authentication', no reminder (correct naming)"
      ]
    },
    "REMIND-004": {
      "id": "REMIND-004",
      "title": "Tag Validation Reminders",
      "status": "done",
      "createdAt": "2025-10-13T07:56:49.298Z",
      "updatedAt": "2025-10-13T13:01:25.736Z",
      "description": "Add reminders to add-tag-to-feature for unregistered tags and missing required tags",
      "parent": "REMIND-002",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:06:04.788Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:06:29.915Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:06:31.632Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:07:43.185Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:07:44.888Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:46.258Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:50.474Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:07.724Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:25.737Z"
        }
      ],
      "rules": [
        "System-reminders must check if tag exists in tags.json before adding to feature file",
        "System-reminders must check for missing required tags after adding a tag",
        "Required tags are: phase tag, component tag, and feature-group tag"
      ],
      "examples": [
        "User runs 'fspec add-tag-to-feature login.feature @unregistered-tag', reminder shows 'Tag not registered in tags.json'",
        "User runs 'fspec add-tag-to-feature login.feature @phase1', no unregistered tag reminder but may show missing required tags reminder",
        "User adds all required tags, no reminder shown"
      ]
    },
    "REMIND-005": {
      "id": "REMIND-005",
      "title": "Discovery Phase Reminders",
      "status": "done",
      "createdAt": "2025-10-13T07:56:51.073Z",
      "updatedAt": "2025-10-13T13:01:28.324Z",
      "description": "Add reminders to generate-scenarios for unanswered questions, empty Example Mapping, and post-generation validation",
      "parent": "REMIND-002",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:08:01.105Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:08:14.931Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:08:15.225Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:09:45.064Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:09:45.355Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:55.259Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:52.611Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:10.713Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:28.325Z"
        }
      ],
      "rules": [
        "System-reminders must check for unanswered questions before allowing scenario generation",
        "System-reminders must check for empty Example Mapping (no rules AND no examples)",
        "System-reminders must provide post-generation guidance after successful scenario generation"
      ],
      "examples": [
        "User runs 'fspec generate-scenarios WORK-001' with unanswered questions, reminder blocks generation",
        "User runs 'fspec generate-scenarios WORK-001' with no rules or examples, reminder suggests adding Example Mapping data",
        "After successful generation, reminder shows next steps (validate, add tags, move to testing)"
      ]
    },
    "REMIND-006": {
      "id": "REMIND-006",
      "title": "Show Work Unit Reminders",
      "status": "done",
      "createdAt": "2025-10-13T07:56:52.746Z",
      "updatedAt": "2025-10-13T13:01:30.534Z",
      "description": "Add reminders to show-work-unit for missing estimates, empty Example Mapping in specifying phase, and long duration warnings",
      "parent": "REMIND-002",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:10:17.524Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:16:22.073Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:16:28.519Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:16:34.669Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:17:10.348Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:55.554Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:54.822Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:12.669Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:30.535Z"
        }
      ],
      "rules": [
        "Display system-reminder when work unit is missing estimate",
        "Display system-reminder when work unit in specifying status has empty Example Mapping (no rules AND no examples)",
        "Display system-reminder when work unit has been in current state for more than 24 hours"
      ],
      "examples": [
        "Show work unit without estimate displays missing estimate reminder",
        "Show work unit in specifying with no rules/examples displays Example Mapping reminder",
        "Show work unit that has been in specifying for 25 hours displays long duration reminder"
      ]
    },
    "REMIND-007": {
      "id": "REMIND-007",
      "title": "Update Status Reminder Enhancement",
      "status": "done",
      "createdAt": "2025-10-13T07:56:54.417Z",
      "updatedAt": "2025-10-13T13:01:32.609Z",
      "description": "Enhanced status reminders with blocked and done states - completed as part of REMIND-003",
      "parent": "REMIND-002",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:10:15.372Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:18:08.040Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:18:08.403Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:18:08.765Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:18:13.970Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:55.851Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:56.856Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:15.325Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:32.610Z"
        }
      ],
      "rules": [
        "Enhance getStatusChangeReminder to include 'done' state reminder about feature file tag updates",
        "Enhance getStatusChangeReminder to include 'blocked' state reminder about documenting blocker reasons"
      ],
      "examples": [
        "Update status to 'done' displays reminder to update feature file tags",
        "Update status to 'blocked' displays reminder to document blocker reason"
      ]
    },
    "REMIND-008": {
      "id": "REMIND-008",
      "title": "Feature File Prefill Detection and CLI Enforcement",
      "status": "done",
      "createdAt": "2025-10-13T08:31:34.385Z",
      "updatedAt": "2025-10-13T08:52:57.425Z",
      "description": "Detect when feature files contain placeholder/prefill text and emit system-reminders instructing LLMs to use CLI commands. Block workflow state transitions if prefill remains.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:31:52.511Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:47:32.759Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:52:11.546Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:52:44.911Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:52:57.426Z"
        }
      ],
      "rules": [
        "Example Mapping must capture the complete user story (role, action, benefit) as the yellow card",
        "fspec generate-scenarios should generate complete user story from example map data, not placeholders",
        "Prefill detection should identify ALL placeholder patterns: [role], [action], TODO:, @phase1, @component, etc.",
        "System-reminders must suggest specific CLI commands to fix detected prefill",
        "Workflow state transitions must be blocked if linked feature files contain prefill placeholders",
        "generate-scenarios should only run AFTER user story is complete (no [role], [action], [benefit] placeholders in Background)",
        "Yes, add explicit userStory fields (role, action, benefit) to work-units.json schema and update JSON Schema validation",
        "Write-time only, when all information has been collected. Detect prefill during fspec create-feature and fspec generate-scenarios, emit system-reminders with CLI commands to fix.",
        "Yes, BOTH write-time and read-time. Write-time for immediate feedback when creating/generating. Read-time for ongoing reminders when showing features, validating, or advancing work unit status.",
        "Until fixed - keep showing system-reminders every time a command interacts with a feature file that has prefill, until the prefill is completely removed.",
        "Hard error (exit 1) - Command must fail completely when trying to advance work unit status if linked feature file contains prefill. Forces LLM to fix prefill before proceeding.",
        "Hybrid approach - Try to intelligently extract Given/When/Then from example text (e.g., 'User logs in with valid credentials' → Given/When/Then steps). Fall back to prefill with system-reminders if parsing fails.",
        "Work units need CLI commands to set user story fields: fspec set-user-story <work-unit-id> --role='...' --action='...' --benefit='...'"
      ],
      "examples": [
        "LLM runs 'fspec create-feature Auth' and gets file with [role], [action], [benefit] placeholders. System-reminder tells LLM to use 'fspec add-background' instead of Edit tool",
        "LLM runs 'fspec generate-scenarios AUTH-001' and gets scenarios with [precondition], [action], [expected outcome]. System-reminder tells LLM to use 'fspec add-step' instead of Write tool",
        "Work unit AUTH-001 has user story in Example Mapping: role='developer', action='authenticate users', benefit='secure access'. generate-scenarios uses this data to create complete Background section without placeholders",
        "LLM tries 'fspec update-work-unit-status AUTH-001 testing' but linked feature file has [role] placeholder. Command fails with error: 'Cannot advance: feature file contains prefill. Use fspec add-background to complete user story.'",
        "LLM completes Example Mapping with user story fields. Runs 'fspec generate-scenarios AUTH-001'. Scenarios are generated BUT steps still have [precondition], [action], [outcome]. System-reminder tells LLM to use 'fspec add-step' for each scenario."
      ],
      "questions": [
        {
          "text": "@human: Should Example Mapping capture user story fields (role, action, benefit) as explicit fields in work-units.json?",
          "selected": true,
          "answer": "Yes, add explicit userStory fields (role, action, benefit) to work-units.json schema and update JSON Schema validation"
        },
        {
          "text": "@human: Should prefill detection happen at read-time (when showing feature) or write-time (when creating feature)?",
          "selected": true,
          "answer": "Write-time only, when all information has been collected. Detect prefill during fspec create-feature and fspec generate-scenarios, emit system-reminders with CLI commands to fix."
        },
        {
          "text": "@human: Should system-reminders for prefill appear every time or only once per session/work unit?",
          "selected": true,
          "answer": "Until fixed - keep showing system-reminders every time a command interacts with a feature file that has prefill, until the prefill is completely removed."
        },
        {
          "text": "@human: Should workflow blocking be a hard error (exits 1) or a warning (exits 0 with reminder)?",
          "selected": true,
          "answer": "Hard error (exit 1) - Command must fail completely when trying to advance work unit status if linked feature file contains prefill. Forces LLM to fix prefill before proceeding."
        },
        {
          "text": "@human: Should generate-scenarios create scenarios with prefill steps OR should it extract Given/When/Then from the example text itself?",
          "selected": true,
          "answer": "Hybrid approach - Try to intelligently extract Given/When/Then from example text (e.g., 'User logs in with valid credentials' → Given/When/Then steps). Fall back to prefill with system-reminders if parsing fails."
        },
        {
          "text": "@human: Going back to question 1 - actually BOTH read-time and write-time?",
          "selected": true,
          "answer": "Yes, BOTH write-time and read-time. Write-time for immediate feedback when creating/generating. Read-time for ongoing reminders when showing features, validating, or advancing work unit status."
        }
      ],
      "estimate": 5,
      "userStory": {
        "role": "AI agent (LLM) using fspec",
        "action": "detect and fix feature file prefill using CLI commands",
        "benefit": "proper workflow enforcement and no direct file editing"
      }
    },
    "COV-001": {
      "id": "COV-001",
      "title": "Feature-to-Code Coverage Tracking",
      "status": "done",
      "createdAt": "2025-10-13T09:49:22.476Z",
      "updatedAt": "2025-10-13T12:30:18.223Z",
      "description": "Create .coverage files that map Gherkin scenarios to test files and implementation code lines, with statistics and AI-assisted verification",
      "epic": "coverage-tracking",
      "children": [
        "COV-002",
        "COV-003",
        "COV-004",
        "COV-005",
        "COV-006"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T09:49:22.866Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:24:55.611Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:25:17.670Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:30:17.638Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:30:17.932Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:30:18.224Z"
        }
      ],
      "userStory": {
        "role": "developer using ACDD",
        "action": "track which test files and implementation code lines map to each Gherkin scenario",
        "benefit": "I can see exactly what code is covered by acceptance criteria and identify gaps"
      },
      "rules": [
        "Every .feature file must have a corresponding .feature.coverage file",
        "Coverage files must be in JSON format with scenario-to-test-to-code mappings",
        "Coverage files must include calculated statistics (total scenarios, covered scenarios, coverage percentage)",
        "Automatically create .feature.coverage files when feature files are created via create-feature command",
        "AI discovers test-to-scenario mappings using reverse ACDD (rspec.md) for existing code, or tracks mappings during forward ACDD. fspec provides CLI commands for AI to record these mappings",
        "fspec prompts AI agent via interactive 'link-coverage' command (or similar name) to specify which implementation files and lines are covered by tests",
        "Use 'audit-coverage' command that works with AI agent in a loop, prompting it to verify each file's mappings one by one. AI looks up current line numbers and updates coverage file",
        "All statistics: coverage percentage, uncovered scenarios, number of test cases per scenario, implementation files touched, lines covered per file",
        "Separate commands since coverage tracking is interactive and requires AI agent collaboration (link-coverage, audit-coverage, show-coverage, etc.)",
        "JSON schema: {scenarios: [{name, testMappings: [{file, lines, implMappings: [{file, lines}]}]}], stats: {totalScenarios, coveredScenarios, coveragePercent, testFiles, implFiles, totalLinesCovered}}",
        "Yes to both: scenarios can have multiple test files (array of testMappings), and test files can appear in multiple scenario mappings (many-to-many relationship)",
        "Yes, show uncovered scenarios with empty testMappings array. Integrate with ACDD: block work units from moving to 'done' if linked feature has uncovered scenarios. Emit system-reminder to prompt AI to add coverage",
        "Yes, validate file paths exist when linking coverage. Fail with clear error if test file or implementation file path is invalid"
      ],
      "examples": [
        "Feature file 'user-login.feature' has companion file 'user-login.feature.coverage' in same directory",
        "Coverage file maps scenario 'Login with valid credentials' to test file 'src/__tests__/auth.test.ts' lines 45-62",
        "Coverage file shows test at lines 45-62 covers implementation file 'src/auth/login.ts' lines 10,11,12,15,20",
        "User runs 'fspec create-feature User Login', creates user-login.feature AND user-login.feature.coverage automatically",
        "AI runs 'fspec link-coverage user-login --scenario \"Login with valid credentials\" --test-file src/__tests__/auth.test.ts --test-lines 45-62', fspec prompts AI for implementation files",
        "AI runs 'fspec audit-coverage user-login', fspec shows first mapping and asks AI to verify line numbers are still correct, repeats for all mappings",
        "Developer runs 'fspec show-coverage user-login', sees output: 5 scenarios, 4 covered (80%), 2 test files, 3 implementation files, 45 lines covered"
      ],
      "questions": [
        {
          "text": "@human: Should coverage files be created automatically when a feature file is created (via create-feature), or on-demand with a separate command (like init-coverage)?",
          "selected": true,
          "answer": "Automatically create .feature.coverage files when feature files are created via create-feature command"
        },
        {
          "text": "@human: How should the system discover which test files map to which scenarios? Should AI read test files and match them to scenario names, or should users manually link them with a command?",
          "selected": true,
          "answer": "AI discovers test-to-scenario mappings using reverse ACDD (rspec.md) for existing code, or tracks mappings during forward ACDD. fspec provides CLI commands for AI to record these mappings"
        },
        {
          "text": "@human: How should we track which implementation code lines are covered? Should AI parse test code to find which files are imported/used, or should this be manually specified?",
          "selected": true,
          "answer": "fspec prompts AI agent via interactive 'link-coverage' command (or similar name) to specify which implementation files and lines are covered by tests"
        },
        {
          "text": "@human: What happens when code changes and line numbers shift? Should we store line numbers at all, or use some other identifier (like function names, AST nodes, code hashes)?",
          "selected": true,
          "answer": "Use 'audit-coverage' command that works with AI agent in a loop, prompting it to verify each file's mappings one by one. AI looks up current line numbers and updates coverage file"
        },
        {
          "text": "@human: What does 'AI-assisted verification' mean exactly? Should the AI read coverage files and suggest corrections, or interactively ask the developer to confirm mappings?",
          "selected": true,
          "answer": "AI does all verification work during audit-coverage command by reading files, checking line numbers, and confirming mappings are correct"
        },
        {
          "text": "@human: What statistics are most important? Coverage percentage, uncovered scenarios, number of test cases, implementation files touched, something else?",
          "selected": true,
          "answer": "All statistics: coverage percentage, uncovered scenarios, number of test cases per scenario, implementation files touched, lines covered per file"
        },
        {
          "text": "@human: Should coverage validation be integrated into existing commands (like 'fspec check', 'fspec validate'), or be separate commands?",
          "selected": true,
          "answer": "Separate commands since coverage tracking is interactive and requires AI agent collaboration (link-coverage, audit-coverage, show-coverage, etc.)"
        },
        {
          "text": "@human: What should the JSON schema look like? Should it be: {scenarios: [{name, testMappings: [{file, lines, implMappings: [{file, lines}]}]}], stats: {...}}?",
          "selected": true,
          "answer": "JSON schema: {scenarios: [{name, testMappings: [{file, lines, implMappings: [{file, lines}]}]}], stats: {totalScenarios, coveredScenarios, coveragePercent, testFiles, implFiles, totalLinesCovered}}"
        },
        {
          "text": "@human: Can one scenario map to multiple test files? Can one test file cover multiple scenarios?",
          "selected": true,
          "answer": "Yes to both: scenarios can have multiple test files (array of testMappings), and test files can appear in multiple scenario mappings (many-to-many relationship)"
        },
        {
          "text": "@human: What if a scenario has no tests yet (ACDD testing phase not started)? Should coverage file show it as uncovered with empty test mappings?",
          "selected": true,
          "answer": "Yes, show uncovered scenarios with empty testMappings array. Integrate with ACDD: block work units from moving to 'done' if linked feature has uncovered scenarios. Emit system-reminder to prompt AI to add coverage"
        },
        {
          "text": "@human: Should we validate that test files and implementation files actually exist when linking coverage? Fail if file paths are invalid?",
          "selected": true,
          "answer": "Yes, validate file paths exist when linking coverage. Fail with clear error if test file or implementation file path is invalid"
        },
        {
          "text": "@human: Should coverage files be formatted/validated like feature files? Should there be 'fspec validate-coverage' command?",
          "selected": true,
          "answer": "No validation command needed. Coverage files are only modified by fspec commands (link-coverage, audit-coverage), never manually edited. fspec maintains file integrity automatically"
        }
      ],
      "assumptions": [
        "AI does all verification work during audit-coverage command by reading files, checking line numbers, and confirming mappings are correct",
        "No validation command needed. Coverage files are only modified by fspec commands (link-coverage, audit-coverage), never manually edited. fspec maintains file integrity automatically"
      ],
      "estimate": 8
    },
    "COV-002": {
      "id": "COV-002",
      "title": "Auto-create Coverage Files",
      "status": "done",
      "createdAt": "2025-10-13T10:04:49.597Z",
      "updatedAt": "2025-10-13T10:30:26.647Z",
      "description": "Modify create-feature command to automatically generate .feature.coverage JSON files alongside feature files with empty scenario mappings",
      "epic": "coverage-tracking",
      "children": [],
      "parent": "COV-001",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T10:08:21.423Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T10:22:20.882Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T10:25:15.136Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T10:29:47.242Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T10:30:26.647Z"
        }
      ],
      "userStory": {
        "role": "developer creating feature files",
        "action": "have .feature.coverage files automatically created when I run create-feature",
        "benefit": "I don't have to manually create coverage tracking files"
      },
      "rules": [
        "Coverage files must be auto-created when create-feature command runs",
        "Coverage file must be named <feature-name>.feature.coverage (same name as .feature file with .coverage extension)",
        "Coverage file must be in same directory as .feature file (spec/features/)",
        "Coverage file must be valid JSON with schema: {scenarios: [{name, testMappings: []}], stats: {totalScenarios, coveredScenarios, coveragePercent, testFiles, implFiles, totalLinesCovered}}",
        "Initial coverage file must have empty testMappings arrays (no coverage yet)",
        "Scenarios array must be populated from feature file scenarios (read from Gherkin AST)",
        "Stats must be calculated: totalScenarios=count, coveredScenarios=0, coveragePercent=0, testFiles=[], implFiles=[], totalLinesCovered=0",
        "Display message: 'Created <filename>.feature.coverage' so user knows coverage file was generated",
        "If .coverage file exists: read and validate JSON. If valid, skip creation (preserve existing coverage). If invalid JSON, overwrite with fresh coverage file",
        "Scenario names must exactly match Gherkin scenario names (case-sensitive, preserve whitespace) for accurate mapping"
      ],
      "examples": [
        "Run 'fspec create-feature User Login', creates spec/features/user-login.feature AND spec/features/user-login.feature.coverage",
        "Coverage file contains {scenarios: [{name: 'Login with valid credentials', testMappings: []}], stats: {totalScenarios: 1, coveredScenarios: 0, coveragePercent: 0, testFiles: [], implFiles: [], totalLinesCovered: 0}}",
        "Feature file with 3 scenarios creates coverage file with 3 entries in scenarios array, totalScenarios: 3",
        "If create-feature fails (invalid name), no .coverage file should be created",
        "Coverage file exists with valid JSON, create-feature skips creation and displays 'Skipped user-login.feature.coverage (already exists)'",
        "Coverage file exists with invalid JSON, create-feature overwrites it and displays 'Recreated user-login.feature.coverage (previous file was invalid)'"
      ],
      "questions": [
        {
          "text": "@human: Should coverage file creation be silent (no output), or should create-feature display 'Created user-login.feature.coverage'?",
          "selected": true,
          "answer": "Display message: 'Created <filename>.feature.coverage' so user knows coverage file was generated"
        },
        {
          "text": "@human: What if a .coverage file already exists? Should we overwrite it, skip it, or error?",
          "selected": true,
          "answer": "If .coverage file exists: read and validate JSON. If valid, skip creation (preserve existing coverage). If invalid JSON, overwrite with fresh coverage file"
        },
        {
          "text": "@human: Should scenario names in coverage file exactly match Gherkin scenario names (including case/whitespace), or should they be normalized?",
          "selected": true,
          "answer": "Scenario names must exactly match Gherkin scenario names (case-sensitive, preserve whitespace) for accurate mapping"
        }
      ]
    },
    "COV-003": {
      "id": "COV-003",
      "title": "Link Coverage Command",
      "status": "done",
      "createdAt": "2025-10-13T10:04:51.632Z",
      "updatedAt": "2025-10-13T11:25:03.758Z",
      "description": "Implement 'fspec link-coverage' command for mapping scenarios to test files and implementation files with interactive AI prompting and file path validation",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-002"
      ],
      "parent": "COV-001",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T11:03:16.421Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T11:17:50.164Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T11:19:34.215Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T11:24:59.487Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T11:25:03.759Z"
        }
      ],
      "questions": [
        {
          "text": "@human: Should one command support BOTH adding test mapping AND implementation mapping, or separate them into distinct operations?",
          "selected": true,
          "answer": "Non-interactive command-line interface. Support partial additions (test-only, or test+impl). After execution, display helpful message showing how to add more mappings or remove existing ones. No interactive prompts that wait for user input. All operations complete immediately with instructional output."
        },
        {
          "text": "@human: How should the link-coverage command be invoked? (all-in-one, two-step, or interactive prompting?)",
          "selected": true,
          "answer": "Single flexible link-coverage command. Support three modes: (1) test-only (--test-file + --test-lines), (2) impl-only (--impl-file + --impl-lines), (3) both at once (all four flags). Command validates required flag combinations and provides helpful error messages if incorrect combination provided."
        },
        {
          "text": "@human: When adding impl-only (no test flags), which test mapping should it attach to? Most recent test for that scenario, or require test file specification?",
          "selected": true,
          "answer": "Always require --test-file when adding implementation mappings. Implementation mappings attach to specific test mappings, so test file must be specified to identify which test mapping to update. This ensures explicit, unambiguous attachment."
        },
        {
          "text": "@human: For line numbers, should we support ranges (45-62), individual lines (10,11,12), or both? Should format be consistent between test and impl lines?",
          "selected": true,
          "answer": "Test lines: range format only (e.g., '45-62'). Implementation lines: comma-separated primary (e.g., '10,11,12,15,20'), but also accept ranges as convenience (e.g., '10-15' expands to [10,11,12,13,14,15]). This matches storage format and mirrors reality: tests are contiguous, impl can be scattered."
        },
        {
          "text": "@human: Should file paths be validated (check if they exist on disk) before adding to coverage? Error if missing, or allow with warning?",
          "selected": true,
          "answer": "Validate file paths by default (error if file doesn't exist). Support --skip-validation flag to bypass validation for forward planning scenarios. When validation fails, display clear error with file path and suggestion. When --skip-validation used, show warning that file doesn't exist but continue."
        },
        {
          "text": "@human: What happens if you try to link a test mapping that already exists (same scenario + same test file)? Overwrite, append, or error?",
          "selected": true,
          "answer": "Append mode: allow multiple test mappings for the same file in one scenario. Each mapping is independent with its own line range and impl mappings. Display message showing all mappings for that file. This supports scenarios where one scenario is tested multiple times in the same file (e.g., different test suites or contexts)."
        },
        {
          "text": "@human: When adding impl mapping to existing test, what if that test already has impl mappings? Append to the array or replace?",
          "selected": true,
          "answer": "Smart append: check if impl file already exists in the test mapping's implMappings array. If exists, update the line numbers for that file. If doesn't exist, append as new impl mapping. Display whether updated or added. This allows one test to cover multiple impl files while preventing duplicate entries."
        },
        {
          "text": "@human: Should the command support removing/unlinking mappings, or should that be a separate command (like unlink-coverage or remove-coverage)?",
          "selected": true,
          "answer": "Separate command for removal. link-coverage only adds/updates mappings. Display helpful message after linking showing how to remove: 'To remove this mapping: fspec unlink-coverage <feature> --scenario ... --test-file ...'. Removal command (unlink-coverage) is separate work unit, follows fspec pattern of separate add/remove commands."
        }
      ],
      "rules": [
        "Non-interactive command-line interface. Support partial additions (test-only, or test+impl). After execution, display helpful message showing how to add more mappings or remove existing ones. No interactive prompts that wait for user input. All operations complete immediately with instructional output.",
        "Single flexible link-coverage command. Support three modes: (1) test-only (--test-file + --test-lines), (2) impl-only (--impl-file + --impl-lines), (3) both at once (all four flags). Command validates required flag combinations and provides helpful error messages if incorrect combination provided.",
        "Always require --test-file when adding implementation mappings. Implementation mappings attach to specific test mappings, so test file must be specified to identify which test mapping to update. This ensures explicit, unambiguous attachment.",
        "Test lines: range format only (e.g., '45-62'). Implementation lines: comma-separated primary (e.g., '10,11,12,15,20'), but also accept ranges as convenience (e.g., '10-15' expands to [10,11,12,13,14,15]). This matches storage format and mirrors reality: tests are contiguous, impl can be scattered.",
        "Validate file paths by default (error if file doesn't exist). Support --skip-validation flag to bypass validation for forward planning scenarios. When validation fails, display clear error with file path and suggestion. When --skip-validation used, show warning that file doesn't exist but continue.",
        "Append mode: allow multiple test mappings for the same file in one scenario. Each mapping is independent with its own line range and impl mappings. Display message showing all mappings for that file. This supports scenarios where one scenario is tested multiple times in the same file (e.g., different test suites or contexts).",
        "Smart append: check if impl file already exists in the test mapping's implMappings array. If exists, update the line numbers for that file. If doesn't exist, append as new impl mapping. Display whether updated or added. This allows one test to cover multiple impl files while preventing duplicate entries.",
        "Separate command for removal. link-coverage only adds/updates mappings. Display helpful message after linking showing how to remove: 'To remove this mapping: fspec unlink-coverage <feature> --scenario ... --test-file ...'. Removal command (unlink-coverage) is separate work unit, follows fspec pattern of separate add/remove commands."
      ],
      "examples": [
        "User runs 'fspec link-coverage user-login --scenario \"Login with valid credentials\" --test-file src/__tests__/auth.test.ts --test-lines 45-62', creates test mapping, displays success and helpful message",
        "User runs 'fspec link-coverage user-login --scenario \"Login with valid credentials\" --test-file src/__tests__/auth.test.ts --impl-file src/auth/login.ts --impl-lines 10,11,12', adds impl mapping to existing test",
        "User runs command with both test and impl flags at once, creates test mapping with impl mapping in one operation",
        "Test file doesn't exist, validation fails with error and suggestion to use --skip-validation",
        "User provides --skip-validation flag with non-existent file, command succeeds with warning message",
        "Impl lines '10-15' (range format) expands to array [10,11,12,13,14,15] in coverage file",
        "Adding impl file that already exists in test mapping updates line numbers instead of creating duplicate entry",
        "Adding test mapping with same test file but different lines appends as second mapping"
      ],
      "userStory": {
        "role": "developer tracking test coverage",
        "action": "link scenarios to test files and implementation files",
        "benefit": "I can track which code covers which acceptance criteria"
      }
    },
    "COV-004": {
      "id": "COV-004",
      "title": "Show Coverage Statistics",
      "status": "done",
      "createdAt": "2025-10-13T10:04:53.307Z",
      "updatedAt": "2025-10-13T11:01:35.541Z",
      "description": "Implement 'fspec show-coverage' command to display coverage statistics including percentage, test files, implementation files, and line counts",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-002"
      ],
      "parent": "COV-001",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T10:35:18.928Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T10:58:41.331Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T10:59:49.378Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T11:01:24.285Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T11:01:35.542Z"
        }
      ],
      "questions": [
        {
          "text": "@human: What output format(s) should show-coverage support? (text/json/markdown, with --format flag?)",
          "selected": true,
          "answer": "Markdown and JSON output formats. Default to markdown. Use --format flag (--format=json for JSON output, --format=markdown or no flag for markdown)"
        },
        {
          "text": "@human: For text output, what level of detail by default? (summary only, full breakdown, or configurable with --verbose?)",
          "selected": true,
          "answer": "Full breakdown always shown by default in markdown. Include summary stats + scenario-by-scenario coverage details (test files, implementation files, line numbers). Show which scenarios are covered and uncovered."
        },
        {
          "text": "@human: Should uncovered scenarios be highlighted in red and/or listed separately?",
          "selected": true,
          "answer": "Use both visual symbols (✅ for covered, ❌ for uncovered) throughout scenario list AND create a separate 'Coverage Gaps' section at the end listing all uncovered scenarios with action items"
        },
        {
          "text": "@human: Should show-coverage work on single file, all files, or both? (Usage: fspec show-coverage [file])",
          "selected": true,
          "answer": "Support both modes: show all files when no argument provided, show specific file when file path is provided. File path can be relative (user-login.feature) or full path (spec/features/user-login.feature)"
        },
        {
          "text": "@human: If showing all files, display aggregated stats, per-feature breakdown, or both?",
          "selected": true,
          "answer": "Both: show aggregated project summary at top (overall coverage, total features/scenarios, features overview table), then full per-feature breakdowns with scenario details for each feature file"
        },
        {
          "text": "@human: How to calculate covered scenarios? (has test mapping, or test + impl mappings?)",
          "selected": true,
          "answer": "Three-tier coverage system: 'Fully Covered' (has test mapping AND implementation mappings), 'Partially Covered' (has test mapping but empty implMappings), 'Uncovered' (no test mappings). Statistics should count fully covered + partially covered as total covered scenarios."
        },
        {
          "text": "@human: For line counts, count impl lines only, or test + impl lines separately?",
          "selected": true,
          "answer": "Separate counts for test lines and implementation lines. Display 'Test Lines', 'Implementation Lines', and 'Total Lines' in statistics. Parse line ranges (e.g., '45-62' = 18 lines) and count individual lines in arrays."
        },
        {
          "text": "@human: Should we validate that mapped files/lines still exist? (always, never, or --validate flag?)",
          "selected": true,
          "answer": "Always validate file paths exist when displaying coverage. Check that test files and implementation files exist on disk. Display warnings for missing files but still show the coverage data. This ensures users are immediately aware of stale mappings."
        },
        {
          "text": "@human: What happens if .coverage file doesn't exist? (error, show 0% with message, or suggest creating?)",
          "selected": true,
          "answer": "Error and exit with code 1 when .coverage file doesn't exist. Display clear error message with suggestion to create coverage file using appropriate command (fspec create-feature or manually). This ensures explicit coverage tracking setup."
        },
        {
          "text": "@human: What happens if .coverage file has invalid JSON? (error, warning, or try to parse?)",
          "selected": true,
          "answer": "Error and exit with code 1 when .coverage file has invalid JSON. Display parse error details (line number, error message) and suggest validating/recreating the file. Keep error message focused on the parse failure."
        }
      ],
      "rules": [
        "Markdown and JSON output formats. Default to markdown. Use --format flag (--format=json for JSON output, --format=markdown or no flag for markdown)",
        "Full breakdown always shown by default in markdown. Include summary stats + scenario-by-scenario coverage details (test files, implementation files, line numbers). Show which scenarios are covered and uncovered.",
        "Use both visual symbols (✅ for covered, ❌ for uncovered) throughout scenario list AND create a separate 'Coverage Gaps' section at the end listing all uncovered scenarios with action items",
        "Support both modes: show all files when no argument provided, show specific file when file path is provided. File path can be relative (user-login.feature) or full path (spec/features/user-login.feature)",
        "Both: show aggregated project summary at top (overall coverage, total features/scenarios, features overview table), then full per-feature breakdowns with scenario details for each feature file",
        "Three-tier coverage system: 'Fully Covered' (has test mapping AND implementation mappings), 'Partially Covered' (has test mapping but empty implMappings), 'Uncovered' (no test mappings). Statistics should count fully covered + partially covered as total covered scenarios.",
        "Separate counts for test lines and implementation lines. Display 'Test Lines', 'Implementation Lines', and 'Total Lines' in statistics. Parse line ranges (e.g., '45-62' = 18 lines) and count individual lines in arrays.",
        "Always validate file paths exist when displaying coverage. Check that test files and implementation files exist on disk. Display warnings for missing files but still show the coverage data. This ensures users are immediately aware of stale mappings.",
        "Error and exit with code 1 when .coverage file doesn't exist. Display clear error message with suggestion to create coverage file using appropriate command (fspec create-feature or manually). This ensures explicit coverage tracking setup.",
        "Error and exit with code 1 when .coverage file has invalid JSON. Display parse error details (line number, error message) and suggest validating/recreating the file. Keep error message focused on the parse failure."
      ],
      "examples": [
        "User runs 'fspec show-coverage user-login.feature', displays markdown report with 80% coverage (4/5 scenarios), full breakdown with symbols, and Coverage Gaps section",
        "User runs 'fspec show-coverage user-login.feature --format=json', outputs JSON with scenarios array, stats object, three-tier coverage status",
        "User runs 'fspec show-coverage' (no args), displays project summary with aggregated stats + per-feature breakdown for all .coverage files",
        "Scenario has test mapping with empty implMappings array, displayed as '⚠️ PARTIALLY COVERED' with warning icon",
        "Test file path doesn't exist on disk, display '⚠️ File not found: src/__tests__/deleted.test.ts' warning but still show coverage",
        "Line range '45-62' counts as 18 test lines, array [10,11,12,15,20] counts as 5 impl lines, displayed separately in stats",
        "User runs 'fspec show-coverage missing.feature', .coverage file doesn't exist, error with exit code 1 and suggestion message",
        ".coverage file has invalid JSON, command fails with parse error showing line number and suggestion to recreate"
      ],
      "userStory": {
        "role": "developer tracking test coverage",
        "action": "view coverage statistics for feature files",
        "benefit": "I can identify gaps in test coverage and track testing progress"
      }
    },
    "COV-005": {
      "id": "COV-005",
      "title": "Audit Coverage Command",
      "status": "done",
      "createdAt": "2025-10-13T10:04:55.178Z",
      "updatedAt": "2025-10-13T12:13:39.422Z",
      "description": "Implement 'fspec audit-coverage' command with interactive AI loop to verify and update line number mappings when code changes",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-002"
      ],
      "parent": "COV-001",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T11:58:47.194Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:09:52.214Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:10:30.001Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:12:54.205Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:13:39.422Z"
        }
      ],
      "userStory": {
        "role": "developer maintaining coverage tracking",
        "action": "audit and update line number mappings when code changes",
        "benefit": "I keep coverage data accurate as code evolves"
      },
      "questions": [
        {
          "text": "@human: Should audit-coverage automatically update line numbers if it detects they've shifted, or prompt AI to manually verify?",
          "selected": true,
          "answer": "Prompt AI to change (but unclear how to detect line shifts automatically)"
        },
        {
          "text": "@human: Should audit-coverage check that test files and implementation files still exist?",
          "selected": true,
          "answer": "Yes, verify that test files and implementation files exist"
        },
        {
          "text": "@human: Should audit-coverage be interactive or just display a report?",
          "selected": true,
          "answer": "Display good information on what to do next if something's not right (report with actionable recommendations)"
        }
      ],
      "assumptions": [
        "Prompt AI to change (but unclear how to detect line shifts automatically)"
      ],
      "rules": [
        "Yes, verify that test files and implementation files exist",
        "Display good information on what to do next if something's not right (report with actionable recommendations)",
        "Audit command must validate that all test files referenced in coverage exist on disk",
        "Audit command must validate that all implementation files referenced in coverage exist on disk",
        "Report must show missing files with clear actionable recommendations (remove stale mappings or restore deleted files)",
        "Command accepts feature file name as argument (e.g., 'fspec audit-coverage user-login')",
        "Output format: markdown report with sections for each scenario's mappings and issues found"
      ],
      "examples": [
        "Run 'fspec audit-coverage user-login', checks all files exist, displays report showing 3/3 files found, all mappings valid",
        "Audit finds test file missing, displays '❌ Test file not found: src/__tests__/deleted.test.ts' with recommendation to remove mapping",
        "Audit finds impl file missing, displays '❌ Implementation file not found: src/auth/deleted.ts' with recommendation"
      ]
    },
    "COV-006": {
      "id": "COV-006",
      "title": "ACDD Workflow Integration",
      "status": "done",
      "createdAt": "2025-10-13T10:04:57.016Z",
      "updatedAt": "2025-10-13T12:24:09.837Z",
      "description": "Integrate coverage tracking with ACDD workflow: block work unit progression to 'done' if coverage incomplete, emit system-reminders for uncovered scenarios",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-003",
        "COV-004",
        "COV-005"
      ],
      "parent": "COV-001",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T12:15:18.461Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:18:09.260Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:19:26.284Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:22:37.057Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:24:09.838Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec with ACDD workflow",
        "action": "ensure work units cannot be marked done when coverage is incomplete",
        "benefit": "I maintain quality standards and prevent incomplete work from being considered complete"
      },
      "rules": [
        "Block work unit status update to 'done' if linked feature file has uncovered scenarios (scenarios with empty testMappings array)",
        "Emit system-reminder when work unit cannot advance to done due to incomplete coverage, showing which scenarios lack coverage",
        "System-reminder must include specific commands to add coverage (e.g., 'fspec link-coverage <feature> --scenario ...')",
        "Check coverage completeness by reading .feature.coverage file and looking for scenarios with empty testMappings arrays",
        "Coverage checking is always enforced (no optional flag) to maintain consistent quality standards",
        "If .coverage file doesn't exist, allow status update with warning. If .coverage file exists, enforce coverage completeness.",
        "Only check coverage when moving to 'done' status, not when moving to 'validating'"
      ],
      "examples": [
        "Work unit AUTH-001 linked to user-login.feature with all 5 scenarios covered (all have testMappings), status update to 'done' succeeds",
        "Work unit AUTH-001 linked to user-login.feature with 2/5 scenarios uncovered (empty testMappings), status update to 'done' fails with error message and system-reminder",
        "System-reminder displays: '❌ Cannot mark work unit done: 2 scenarios uncovered in user-login.feature' with list of uncovered scenario names"
      ],
      "questions": [
        {
          "text": "@human: Should this blocking behavior be optional (via flag) or always enforced?",
          "selected": true,
          "answer": "Always enforced - this maintains quality standards consistently"
        },
        {
          "text": "@human: What happens if the .coverage file doesn't exist for a linked feature - should that block the status update?",
          "selected": true,
          "answer": "If .coverage file doesn't exist, allow the status update with a warning (coverage tracking is optional). But if .coverage file exists, enforce coverage completeness."
        },
        {
          "text": "@human: Should we only check coverage when moving to 'done' status, or also when moving to 'validating'?",
          "selected": true,
          "answer": "Only check coverage when moving to 'done' status - validating is still part of the development process"
        }
      ]
    },
    "BUG-005": {
      "id": "BUG-005",
      "title": "Remove work unit ID tags from generate-scenarios",
      "status": "done",
      "createdAt": "2025-10-13T11:30:51.399Z",
      "updatedAt": "2025-10-13T11:55:59.660Z",
      "description": "Fixed generate-scenarios to add work unit IDs as FEATURE-LEVEL tags only (not scenario-level). Modified check.ts to use proper validateTags function. Removed scenario-level work unit ID tags from all feature files. This implements the optimal two-tier linking system: feature-level tags for coarse-grained work unit → feature association, with coverage files providing fine-grained scenario traceability.",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T11:31:08.692Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T11:55:24.402Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T11:55:30.552Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T11:55:36.124Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T11:55:59.661Z"
        }
      ],
      "userStory": {
        "role": "developer maintaining fspec",
        "action": "verify that generate-scenarios adds work unit ID tags only at feature level",
        "benefit": "I ensure the two-tier linking system (feature-level tags + coverage files) works correctly"
      },
      "rules": [
        "Work unit ID tags must appear at feature level only, not scenario level",
        "generate-scenarios command must add work unit ID as feature-level tag",
        "Existing feature files must not have scenario-level work unit ID tags",
        "check.ts validation must use proper validateTags function",
        "Yes, add automated tests to verify generate-scenarios adds work unit ID at feature level only (check if tests already exist first)",
        "Yes, create validation rule to reject scenario-level work unit ID tags. However, many existing features already have work unit IDs, so the script (Q3) must fix them first before validation can be enforced",
        "Write a script to scan all feature files and move scenario-level work unit ID tags to feature level. This must run before validation enforcement"
      ],
      "examples": [
        "Run generate-scenarios for a work unit, verify the generated feature file has work unit ID as feature-level tag (e.g., @BUG-005 at top)",
        "Run generate-scenarios for a work unit, verify generated scenarios do NOT have work unit ID tags at scenario level",
        "Check existing feature files to verify no scenario-level work unit ID tags remain (like @COV-001 on individual scenarios)",
        "Verify check.ts uses validateTags() function instead of inline validation logic",
        "Write script that scans spec/features/*.feature files, finds scenario-level work unit ID tags (like @COV-001 on scenarios), moves them to feature-level tags",
        "After script runs, validate-tags command should reject any feature file with scenario-level work unit ID tags (pattern: @[A-Z]+-[0-9]+)"
      ],
      "questions": [
        {
          "text": "@human: Should we add automated tests to verify generate-scenarios adds work unit ID at feature level only?",
          "selected": true,
          "answer": "Yes, add automated tests to verify generate-scenarios adds work unit ID at feature level only (check if tests already exist first)"
        },
        {
          "text": "@human: Should we create a validation rule in check.ts or validate-tags to reject scenario-level work unit ID tags?",
          "selected": true,
          "answer": "Yes, create validation rule to reject scenario-level work unit ID tags. However, many existing features already have work unit IDs, so the script (Q3) must fix them first before validation can be enforced"
        },
        {
          "text": "@human: Is manual verification of existing feature files sufficient, or should we write a script to scan all feature files?",
          "selected": true,
          "answer": "Write a script to scan all feature files and move scenario-level work unit ID tags to feature level. This must run before validation enforcement"
        }
      ]
    },
    "BUG-006": {
      "id": "BUG-006",
      "title": "Parent work units shouldn't require scenarios",
      "status": "done",
      "createdAt": "2025-10-13T12:26:15.841Z",
      "updatedAt": "2025-10-13T12:30:03.560Z",
      "description": "Parent work units without linkedFeatures should only require all children to be done, not require scenarios to exist when moving to testing status",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T12:26:21.933Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:29:49.558Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:29:49.849Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:29:50.141Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:30:03.561Z"
        }
      ],
      "userStory": {
        "role": "developer working on parent work units",
        "action": "move parent work units through workflow without requiring scenarios",
        "benefit": "parent work units are containers that don't need their own feature files"
      },
      "rules": [
        "Parent work units (work units with children array) should skip scenario validation when moving to testing",
        "checkScenariosExist function should return true immediately if work unit has children",
        "Only leaf work units (no children) need to have scenarios tagged with @WORK-UNIT-ID",
        "Parent work units can only move to done when ALL children are done (existing validation)"
      ],
      "examples": [
        "COV-001 (parent with 5 children all done) can move from specifying -> testing -> implementing -> validating -> done without scenario validation",
        "COV-002 (leaf work unit, no children) requires @COV-002 tag in feature file to move to testing",
        "Parent work unit with incomplete children (COV-001 with COV-006 still in implementing) cannot move to done"
      ]
    },
    "COV-007": {
      "id": "COV-007",
      "title": "Generate Coverage Files for Existing Features",
      "status": "done",
      "createdAt": "2025-10-13T22:05:01.056Z",
      "updatedAt": "2025-10-13T22:14:08.318Z",
      "description": "Add a command to generate .feature.coverage files for existing feature files that don't have coverage tracking yet",
      "epic": "coverage-tracking",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T22:05:07.139Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T22:10:05.598Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T22:11:20.482Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T22:13:34.764Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T22:14:08.318Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for coverage tracking",
        "action": "generate coverage files for existing feature files that lack them",
        "benefit": "I can start tracking test coverage for features created before coverage tracking was implemented"
      },
      "rules": [
        "Command must scan spec/features/ directory for .feature files",
        "For each .feature file without a corresponding .feature.coverage file, generate one",
        "Skip files that already have valid .feature.coverage files (preserve existing coverage data)",
        "Overwrite .feature.coverage files that have invalid JSON (corrupted files)",
        "Generated coverage files must have same JSON schema as auto-created coverage files from create-feature",
        "Display summary: X files created, Y files skipped, Z files recreated (invalid JSON)",
        "Support --dry-run flag to preview what would be generated without creating files"
      ],
      "examples": [
        "Project has 66 .feature files, 0 .coverage files → command creates 66 .coverage files",
        "Project has 50 .feature files, 30 valid .coverage files → command creates 20 new .coverage files, skips 30",
        "Project has user-login.feature with 5 scenarios → generates user-login.feature.coverage with 5 entries in scenarios array, all with empty testMappings",
        "Run with --dry-run flag → displays what would be created but doesn't create any files",
        "Corrupted .coverage file with invalid JSON → overwrites with valid empty coverage file, displays 'Recreated'"
      ]
    },
    "COV-008": {
      "id": "COV-008",
      "title": "Unlink Coverage Mappings",
      "status": "done",
      "createdAt": "2025-10-13T22:20:53.067Z",
      "updatedAt": "2025-10-13T22:29:19.706Z",
      "description": "Add unlink-coverage command to remove test and implementation mappings from scenarios",
      "epic": "coverage-tracking",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T22:22:54.879Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T22:25:51.670Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T22:26:42.302Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T22:28:53.095Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T22:29:19.707Z"
        }
      ],
      "userStory": {
        "role": "developer managing coverage tracking",
        "action": "remove incorrect or outdated test and implementation mappings from scenarios",
        "benefit": "I can correct mistakes and update coverage as code evolves without manual JSON editing"
      },
      "rules": [
        "Support --all flag to remove all mappings for a scenario (reset to uncovered)",
        "Support removing specific test mapping by test-file path",
        "Support removing only implementation mapping while keeping test mapping",
        "Removing test mapping must also remove all its implementation mappings",
        "Must recalculate stats after any removal operation",
        "Error if scenario not found in coverage file"
      ],
      "examples": [
        "Remove all mappings: unlink-coverage user-login --scenario 'Login' --all → scenario becomes uncovered, stats recalculated",
        "Remove test mapping: unlink-coverage user-login --scenario 'Login' --test-file src/__tests__/auth.test.ts → removes test and all its impl mappings",
        "Remove only impl: unlink-coverage user-login --scenario 'Login' --test-file src/__tests__/auth.test.ts --impl-file src/auth/old.ts → keeps test mapping",
        "Error if scenario not found → displays available scenarios"
      ]
    },
    "DOC-003": {
      "id": "DOC-003",
      "title": "Clarify backward movement in workflow documentation",
      "status": "done",
      "createdAt": "2025-10-14T01:57:04.564Z",
      "updatedAt": "2025-10-14T10:51:21.943Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-14T01:57:11.127Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-14T10:47:23.806Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-14T10:50:35.138Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-14T10:50:42.296Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-14T10:51:21.944Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec workflow",
        "action": "understand backward state transitions",
        "benefit": "I can confidently move work backward when fixing mistakes"
      },
      "rules": [
        "Cannot skip states forward (ACDD enforcement)",
        "CAN move backward from validating to implementing or specifying to fix issues",
        "CAN move backward from done to any previous state when mistakes discovered",
        "Cannot move back to backlog (use blocked state instead)",
        "Blocked state can transition back to any non-done state",
        "Just text - CLI help should be text-based for terminal readability"
      ],
      "examples": [
        "Move from testing to specifying when tests revealed incomplete acceptance criteria",
        "Move from implementing to testing when test cases need refactoring",
        "Move from validating to implementing when quality checks fail",
        "Move from done to implementing when bug discovered in completed feature",
        "Try to move from backlog to testing - blocked (must go through specifying)"
      ],
      "questions": [
        {
          "text": "@human: Should help include visual state diagram or just text describing backward transitions?",
          "selected": true,
          "answer": "Just text - CLI help should be text-based for terminal readability"
        }
      ],
      "estimate": 2
    },
    "COV-010": {
      "id": "COV-010",
      "title": "Test: Example mapping commands auto-create work-units.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:11.075Z",
      "updatedAt": "2025-10-15T00:24:35.178Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. Need to create tests and implementation for example mapping commands using ensure utilities.",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:17:47.933Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:24:28.002Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:24:34.500Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:24:34.830Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:24:35.179Z"
        }
      ],
      "estimate": 2,
      "epic": "test-coverage"
    },
    "COV-011": {
      "id": "COV-011",
      "title": "Test: Dependency commands auto-create work-units.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:12.810Z",
      "updatedAt": "2025-10-15T00:25:55.102Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Implementation exists in ensure-files.ts, need tests to verify dependency commands use it.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:25:53.922Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:25:54.220Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:25:54.512Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:25:54.805Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:25:55.102Z"
        }
      ]
    },
    "COV-012": {
      "id": "COV-012",
      "title": "Test: Ensure utilities validate JSON structure",
      "status": "done",
      "createdAt": "2025-10-15T00:10:14.369Z",
      "updatedAt": "2025-10-15T00:29:07.394Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No tests found for validation within ensure utilities. Tests verify creation but not schema validation.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:27:05.485Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:27:54.504Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:28:30.230Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:29:07.099Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:29:07.395Z"
        }
      ],
      "rules": [
        "Ensure utilities must detect corrupted JSON files",
        "Ensure utilities must provide helpful error messages indicating what went wrong"
      ],
      "examples": [
        "Corrupted JSON with trailing comma throws parse error with file path",
        "Invalid JSON with missing closing brace throws parse error with line number"
      ],
      "estimate": 3
    },
    "COV-013": {
      "id": "COV-013",
      "title": "Test: All 48+ commands use ensure utilities",
      "status": "done",
      "createdAt": "2025-10-15T00:10:16.274Z",
      "updatedAt": "2025-10-15T00:33:46.472Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Need integration tests to verify all commands use ensure utilities instead of direct file reads.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:31:57.735Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:32:52.803Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:33:40.011Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:33:46.175Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:33:46.473Z"
        }
      ],
      "estimate": 2
    },
    "COV-014": {
      "id": "COV-014",
      "title": "Test: List work units command auto-creates work-units.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:17.732Z",
      "updatedAt": "2025-10-15T00:34:01.759Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Implementation exists (ensureWorkUnitsFile), need test to verify list-work-units command uses it.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:32:40.879Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:00.881Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:01.174Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:01.467Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:01.760Z"
        }
      ],
      "estimate": 2
    },
    "COV-015": {
      "id": "COV-015",
      "title": "Test: Update work unit uses ensureWorkUnitsFile",
      "status": "done",
      "createdAt": "2025-10-15T00:10:19.515Z",
      "updatedAt": "2025-10-15T00:34:03.243Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Need to verify update-work-unit command implementation uses ensure utility.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:32:42.787Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:02.357Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:02.648Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:02.942Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:03.243Z"
        }
      ],
      "estimate": 2
    },
    "COV-016": {
      "id": "COV-016",
      "title": "Test: Register tag auto-creates tags.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:31.606Z",
      "updatedAt": "2025-10-15T00:34:04.720Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Implementation likely exists but no specific test for register-tag using ensure utilities.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:32:44.610Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:03.831Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:04.127Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:04.425Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:04.720Z"
        }
      ],
      "estimate": 2
    },
    "COV-017": {
      "id": "COV-017",
      "title": "Test: Update foundation auto-creates foundation.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:31.907Z",
      "updatedAt": "2025-10-15T00:34:38.486Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No ensure utility or test found for foundation.json auto-creation.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:35.262Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:37.605Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:37.899Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:38.193Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:38.486Z"
        }
      ]
    },
    "COV-018": {
      "id": "COV-018",
      "title": "Test: List tags auto-creates tags.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:32.205Z",
      "updatedAt": "2025-10-15T00:34:39.662Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No test found verifying list-tags auto-creates tags.json.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:35.845Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:38.783Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:39.078Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:39.371Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:39.662Z"
        }
      ]
    },
    "COV-019": {
      "id": "COV-019",
      "title": "Test: Show foundation auto-creates foundation.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:32.497Z",
      "updatedAt": "2025-10-15T00:34:40.844Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No test found verifying show-foundation auto-creates foundation.json.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:36.429Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:39.958Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:40.255Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:40.549Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:40.845Z"
        }
      ]
    },
    "COV-020": {
      "id": "COV-020",
      "title": "Test: Register example mapping commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:42.265Z",
      "updatedAt": "2025-10-15T00:40:47.452Z",
      "description": "Feature: cli-command-registration. Status: CREATE_BOTH. Test file only verifies 39 commands excluding example mapping. Need to add example mapping commands to registration test.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:59.479Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:40:24.923Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:40:46.567Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:40:46.863Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:40:47.453Z"
        }
      ],
      "rules": [
        "Example mapping commands must be registered in CLI"
      ],
      "examples": [
        "add-rule, add-example, add-question commands should be accessible via CLI"
      ]
    },
    "COV-021": {
      "id": "COV-021",
      "title": "Test: Register workflow automation commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:42.555Z",
      "updatedAt": "2025-10-15T00:43:06.614Z",
      "description": "Feature: cli-command-registration. Status: CREATE_BOTH. No tests found for workflow automation command registration.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:01.240Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:42:15.799Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:42:39.547Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:42:59.849Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:43:06.615Z"
        }
      ],
      "rules": [
        "Workflow commands must be registered: auto-advance, board, workflow-automation"
      ],
      "examples": [
        "Running 'fspec workflow-automation' should show workflow automation options"
      ]
    },
    "COV-022": {
      "id": "COV-022",
      "title": "Test: Register validation commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:42.849Z",
      "updatedAt": "2025-10-15T00:43:28.938Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. Validation commands likely registered but no specific test verifies registration.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:03.008Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:43:21.439Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:43:28.062Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:43:28.356Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:43:28.938Z"
        }
      ],
      "rules": [
        "Validation commands must be registered: validate-spec-alignment, validate-work-units, repair-work-units"
      ],
      "examples": [
        "Running 'fspec validate-work-units' should verify work unit data integrity"
      ]
    },
    "COV-023": {
      "id": "COV-023",
      "title": "Test: Register assumption management command",
      "status": "done",
      "createdAt": "2025-10-15T00:10:43.142Z",
      "updatedAt": "2025-10-15T00:43:46.185Z",
      "description": "Feature: cli-command-registration. Status: CREATE_BOTH. No tests found for assumption management command.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:04.770Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:43:45.014Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:43:45.311Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:43:45.603Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:43:46.185Z"
        }
      ],
      "rules": [
        "Assumption management command must be registered: add-assumption"
      ],
      "examples": [
        "Running 'fspec add-assumption feature-name \"assumption\"' should add assumption to feature file"
      ]
    },
    "COV-024": {
      "id": "COV-024",
      "title": "Test: Update help text for all command categories",
      "status": "done",
      "createdAt": "2025-10-15T00:10:53.824Z",
      "updatedAt": "2025-10-15T00:44:02.469Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. Need test to verify help text is complete for all categories.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:06.523Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:44:01.294Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:44:01.588Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:44:01.883Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:44:02.469Z"
        }
      ],
      "rules": [
        "Help text must include all commands in their respective categories"
      ],
      "examples": [
        "Running 'fspec help project' should show all work unit commands"
      ]
    },
    "COV-025": {
      "id": "COV-025",
      "title": "Test: Help system shows all commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:54.124Z",
      "updatedAt": "2025-10-15T00:44:19.832Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. No test verifies help output includes all commands.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:08.285Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:44:18.664Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:44:18.959Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:44:19.250Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:44:19.833Z"
        }
      ],
      "rules": [
        "Help output must list all available commands organized by category"
      ],
      "examples": [
        "Running 'fspec --help' should show commands for spec, tags, foundation, query, and project management"
      ]
    },
    "COV-026": {
      "id": "COV-026",
      "title": "Test: Build succeeds with no errors",
      "status": "done",
      "createdAt": "2025-10-15T00:10:54.426Z",
      "updatedAt": "2025-10-15T00:44:52.043Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. Integration test needed to verify build success.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:10.042Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:44:50.873Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:44:51.164Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:44:51.457Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:44:52.044Z"
        }
      ],
      "rules": [
        "Build must succeed with exit code 0 after command registration changes"
      ],
      "examples": [
        "Running 'npm run build' should create dist/index.js with no TypeScript errors"
      ]
    },
    "COV-027": {
      "id": "COV-027",
      "title": "Test: System-reminder after create-feature with prefill",
      "status": "done",
      "createdAt": "2025-10-15T00:10:54.737Z",
      "updatedAt": "2025-10-15T00:45:17.872Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_TEST_ONLY. Tests verify prefill detection but no integration test for create-feature command displaying the reminder.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:11.805Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:16.989Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:17.286Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:17.579Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:17.873Z"
        }
      ],
      "rules": [
        "System-reminder must appear when create-feature generates prefill"
      ],
      "examples": [
        "After creating feature, reminder suggests 'fspec set-user-story' for [role]/[action]/[benefit] placeholders"
      ]
    },
    "COV-028": {
      "id": "COV-028",
      "title": "Test: System-reminder after generate-scenarios with prefill",
      "status": "done",
      "createdAt": "2025-10-15T00:11:05.298Z",
      "updatedAt": "2025-10-15T00:45:28.016Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_TEST_ONLY. Need integration test for generate-scenarios command.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:13.572Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:27.132Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:27.426Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:27.723Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:28.017Z"
        }
      ],
      "rules": [
        "System-reminder must appear when generate-scenarios creates prefill steps"
      ],
      "examples": [
        "After generating scenarios, reminder suggests 'fspec add-step' for placeholder steps"
      ]
    },
    "COV-029": {
      "id": "COV-029",
      "title": "Test: User story from Example Mapping generates complete Background",
      "status": "done",
      "createdAt": "2025-10-15T00:11:05.606Z",
      "updatedAt": "2025-10-15T00:45:38.597Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_BOTH. No tests found for Example Mapping user story to Background conversion.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:15.340Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:37.713Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:38.009Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:38.302Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:38.598Z"
        }
      ],
      "rules": [
        "User story from Example Mapping must generate complete Background without placeholders"
      ],
      "examples": [
        "When work unit has role/action/benefit set, generated Background should contain full user story"
      ]
    },
    "COV-030": {
      "id": "COV-030",
      "title": "Test: Workflow blocking prevents status change with prefill",
      "status": "done",
      "createdAt": "2025-10-15T00:11:05.899Z",
      "updatedAt": "2025-10-15T00:45:48.589Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_BOTH. No tests found for workflow blocking based on prefill detection.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:17.102Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:47.707Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:48.003Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:48.298Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:48.590Z"
        }
      ],
      "rules": [
        "Workflow status change must be blocked when linked feature file has prefill"
      ],
      "examples": [
        "Trying to move work unit to testing status should fail with error if feature file has [role]/[action] placeholders"
      ]
    },
    "COV-031": {
      "id": "COV-031",
      "title": "Test: Support custom output path for generate-foundation-md",
      "status": "done",
      "createdAt": "2025-10-15T00:11:06.192Z",
      "updatedAt": "2025-10-15T05:20:19.824Z",
      "description": "Feature: generate-foundation-md. Status: CREATE_TEST_ONLY. No test found for custom output path option.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:18.861Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T05:19:25.404Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:19:33.637Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:20:18.071Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:20:19.824Z"
        }
      ],
      "rules": [
        "generate-foundation-md must support custom output path option"
      ],
      "examples": [
        "'fspec generate-foundation-md --output custom/path.md' should create file at custom path"
      ]
    },
    "COV-032": {
      "id": "COV-032",
      "title": "Test: Support custom output path for generate-tags-md",
      "status": "done",
      "createdAt": "2025-10-15T00:11:16.150Z",
      "updatedAt": "2025-10-15T00:46:36.449Z",
      "description": "Feature: generate-tags-md. Status: CREATE_TEST_ONLY. No test found for custom output path option.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:20.631Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:46:35.511Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:46:35.806Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:46:36.103Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:46:36.450Z"
        }
      ],
      "rules": [
        "generate-tags-md must support custom output path option"
      ],
      "examples": [
        "'fspec generate-tags-md --output custom/path.md' should create file at custom path"
      ]
    },
    "COV-033": {
      "id": "COV-033",
      "title": "Test: List all scenarios for multiple work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:16.442Z",
      "updatedAt": "2025-10-15T05:24:22.365Z",
      "description": "Feature: get-scenarios. Status: CREATE_TEST_ONLY. No test found for listing scenarios from multiple work units simultaneously.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:22.406Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T05:24:21.188Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:24:21.481Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:24:22.071Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:24:22.366Z"
        }
      ],
      "rules": [
        "get-scenarios must support listing scenarios from multiple work units"
      ],
      "examples": [
        "'fspec get-scenarios AUTH-001 AUTH-002' should list scenarios from both work units"
      ]
    },
    "COV-034": {
      "id": "COV-034",
      "title": "Test: Rollback if markdown generation fails",
      "status": "done",
      "createdAt": "2025-10-15T00:11:16.747Z",
      "updatedAt": "2025-10-15T00:47:53.359Z",
      "description": "Feature: register-tag-json-backed. Status: CREATE_TEST_ONLY. No test found for rollback behavior on TAGS.md generation failure.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:24.174Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:47:52.447Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:47:52.752Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:47:53.056Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:47:53.360Z"
        }
      ],
      "rules": [
        "Tag registration must rollback if TAGS.md generation fails"
      ],
      "examples": [
        "If TAGS.md generation errors, tags.json should revert to previous state"
      ]
    },
    "COV-035": {
      "id": "COV-035",
      "title": "Test: Update statistics after registering tag",
      "status": "done",
      "createdAt": "2025-10-15T00:11:17.039Z",
      "updatedAt": "2025-10-15T00:48:04.694Z",
      "description": "Feature: register-tag-json-backed. Status: CREATE_TEST_ONLY. No test verifies statistics section is updated when registering tags.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:25.928Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:48:03.784Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:48:04.090Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:48:04.395Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:48:04.694Z"
        }
      ],
      "rules": [
        "Statistics section must be updated when tag is registered"
      ],
      "examples": [
        "After registering new tag, TAGS.md statistics should show incremented tag count"
      ]
    },
    "COV-036": {
      "id": "COV-036",
      "title": "Test: List scenario tags with category information",
      "status": "done",
      "createdAt": "2025-10-15T00:11:27.483Z",
      "updatedAt": "2025-10-15T00:49:36.550Z",
      "description": "Feature: scenario-level-tag-management. Status: CREATE_TEST_ONLY. Test exists for listing tags but doesn't verify category information is shown.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:27.690Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:49:35.622Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:49:35.928Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:49:36.234Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:49:36.550Z"
        }
      ],
      "rules": [
        "Scenario tags must be listed with category information"
      ],
      "examples": [
        "Tag display should show category grouping"
      ]
    },
    "COV-037": {
      "id": "COV-037",
      "title": "Test: Show steps with proper indentation (text format)",
      "status": "done",
      "createdAt": "2025-10-15T00:11:27.777Z",
      "updatedAt": "2025-10-15T03:17:39.051Z",
      "description": "Feature: show-acceptance-criteria. Status: CREATE_TEST_ONLY. Tests exist for markdown format but no specific test for text format indentation.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:29.448Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:27.565Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:38.457Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:38.756Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:39.052Z"
        }
      ]
    },
    "COV-038": {
      "id": "COV-038",
      "title": "Test: Handle malformed JSON file",
      "status": "done",
      "createdAt": "2025-10-15T00:11:28.072Z",
      "updatedAt": "2025-10-15T05:26:37.315Z",
      "description": "Feature: validate-json-schema. Status: CREATE_TEST_ONLY. No test found for malformed/unparseable JSON files.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:31.213Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T05:26:12.060Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:26:36.715Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:26:37.018Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:26:37.315Z"
        }
      ]
    },
    "COV-039": {
      "id": "COV-039",
      "title": "Test: Show work unit with all dependencies",
      "status": "done",
      "createdAt": "2025-10-15T00:11:28.367Z",
      "updatedAt": "2025-10-15T03:17:41.481Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No dedicated show/display test for work unit with all dependency types visible.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:32.974Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:30.931Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:40.880Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:41.181Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:41.482Z"
        }
      ]
    },
    "COV-040": {
      "id": "COV-040",
      "title": "Test: Display dependency graph for single work unit",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.027Z",
      "updatedAt": "2025-10-15T03:17:44.118Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. Export dependency graph test exists but not display for single work unit.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:34.742Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:32.661Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:43.518Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:43.817Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:44.119Z"
        }
      ]
    },
    "COV-041": {
      "id": "COV-041",
      "title": "Test: Show all work units blocked by specific unit",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.336Z",
      "updatedAt": "2025-10-15T03:17:46.469Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No query test for finding all work units blocked by a specific unit.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:36.502Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.064Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:45.868Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:46.173Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:46.469Z"
        }
      ]
    },
    "COV-042": {
      "id": "COV-042",
      "title": "Test: Find all currently blocked work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.639Z",
      "updatedAt": "2025-10-15T03:17:48.816Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No test for querying all blocked work units.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:38.265Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.372Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:48.218Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:48.519Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:48.816Z"
        }
      ]
    },
    "COV-043": {
      "id": "COV-043",
      "title": "Test: Show impact analysis when completing work unit",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.944Z",
      "updatedAt": "2025-10-15T03:17:52.275Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No test for impact analysis feature.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:40.036Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.678Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:51.680Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:51.977Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:52.276Z"
        }
      ]
    },
    "COV-044": {
      "id": "COV-044",
      "title": "Test: Show dependency chain depth",
      "status": "done",
      "createdAt": "2025-10-15T00:11:48.157Z",
      "updatedAt": "2025-10-15T03:18:04.022Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No test for calculating/displaying dependency chain depth.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:41.799Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.978Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:03.423Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:03.725Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:04.023Z"
        }
      ]
    },
    "COV-045": {
      "id": "COV-045",
      "title": "Test: Calculate critical path",
      "status": "done",
      "createdAt": "2025-10-15T00:11:48.451Z",
      "updatedAt": "2025-10-15T03:18:06.429Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_BOTH. No tests or implementation found for critical path calculation.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:43.559Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:43.290Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:05.829Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:06.128Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:06.429Z"
        }
      ]
    },
    "COV-046": {
      "id": "COV-046",
      "title": "Test: Identify bottleneck work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:48.741Z",
      "updatedAt": "2025-10-15T04:54:36.576Z",
      "description": "COMPLETED: Tests written, implementation done, coverage linked. query-bottlenecks.ts working correctly.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:45.332Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T04:04:02.216Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T04:52:38.745Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T04:54:16.382Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T04:54:36.588Z"
        }
      ],
      "rules": [
        "A bottleneck is a work unit that blocks multiple other work units (directly or transitively)",
        "Only work units NOT in 'done' status are bottlenecks (completed work doesn't block)",
        "Bottleneck score = total work units blocked (direct blocks + transitive blocks)",
        "Rank bottlenecks by score (highest to lowest) to prioritize what to complete first",
        "Only blocks/blockedBy relationships. dependsOn is a soft dependency that doesn't prevent work from starting, so it shouldn't factor into bottleneck calculation.",
        "Include bottlenecks with score >= 2 (blocking 2+ work units). A work unit blocking only 1 other is not significant enough to be called a bottleneck.",
        "No. Work units in 'blocked' status cannot be progressed, so they should not be identified as bottlenecks to prioritize. Only consider work units in states that can be actively worked on (backlog, specifying, testing, implementing, validating)."
      ],
      "examples": [
        "AUTH-001 blocks API-001 and UI-001 directly → bottleneck score: 2 (blocks 2 work units)",
        "DB-001 blocks API-001, API-001 blocks UI-001 → DB-001 bottleneck score: 2 (1 direct + 1 transitive)",
        "AUTH-001 blocks API-001, API-002, API-003, and API-001 blocks UI-001 → AUTH-001 score: 4 (highest bottleneck)",
        "DEPLOY-001 status='done' and blocks UI-001 → NOT a bottleneck (already complete)",
        "UI-001 has no 'blocks' relationships → bottleneck score: 0 (not a bottleneck)"
      ],
      "questions": [
        {
          "text": "@human: Should bottleneck calculation include 'dependsOn' relationships or only 'blocks/blockedBy'?",
          "selected": true,
          "answer": "No. Work units in 'blocked' status cannot be progressed, so they should not be identified as bottlenecks to prioritize. Only consider work units in states that can be actively worked on (backlog, specifying, testing, implementing, validating)."
        },
        {
          "text": "@human: Should we consider work unit estimates when ranking bottlenecks (e.g., 8-point story blocks more value than 1-point)?",
          "selected": true,
          "answer": "Only blocks/blockedBy relationships. dependsOn is a soft dependency that doesn't prevent work from starting, so it shouldn't factor into bottleneck calculation."
        },
        {
          "text": "@human: What is the minimum bottleneck score to be included in output (1+, 2+, 3+)?",
          "selected": true,
          "answer": "No. For simplicity, rank bottlenecks by count of blocked work units only. Estimate weighting could be a future enhancement."
        },
        {
          "text": "@human: Should work units in 'blocked' status be considered bottlenecks even though they can't progress themselves?",
          "selected": true,
          "answer": "Include bottlenecks with score >= 2 (blocking 2+ work units). A work unit blocking only 1 other is not significant enough to be called a bottleneck."
        }
      ],
      "userStory": {
        "role": "project manager or AI agent",
        "action": "identify bottleneck work units blocking the most work",
        "benefit": "I can prioritize completing high-impact work to unblock the project"
      },
      "assumptions": [
        "No. For simplicity, rank bottlenecks by count of blocked work units only. Estimate weighting could be a future enhancement."
      ]
    },
    "COV-047": {
      "id": "COV-047",
      "title": "Test: Auto-suggest dependency relationships",
      "status": "done",
      "createdAt": "2025-10-15T00:11:49.033Z",
      "updatedAt": "2025-10-15T05:05:29.014Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_BOTH. No tests or implementation found for auto-suggesting dependencies.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:47.103Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T04:04:03.849Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:04:14.467Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:05:25.400Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:05:29.015Z"
        }
      ],
      "rules": [
        "Auto-suggest analyzes work unit metadata (title, description, epic, prefix) to recommend likely dependency relationships",
        "Sequential IDs in same prefix suggest dependency (AUTH-001 → AUTH-002 implies AUTH-002 depends on AUTH-001)",
        "Build/Test pairs suggest dependency (work with 'Test X' depends on 'Build X')",
        "Infrastructure before features (e.g., 'Setup Auth' should be suggested as blocker for 'Login Flow')",
        "Suggestions are recommendations only - user must confirm before creating dependency relationships"
      ],
      "examples": [
        "AUTH-001 'Setup OAuth' and AUTH-002 'Login Flow' → Suggest: AUTH-002 depends on AUTH-001 (sequential IDs)",
        "'Build User API' and 'Test User API' → Suggest: 'Test User API' depends on 'Build User API' (build/test pair)",
        "'Database Schema Migration' and 'Add User Data' → Suggest: 'Add User Data' depends on 'Database Schema Migration' (infrastructure first)",
        "Work units in same epic 'User Management' → Suggest: relatesTo relationships for context",
        "AUTH-003 with no semantic relationship to AUTH-001 or AUTH-002 → No suggestion (avoid false positives)"
      ],
      "questions": [
        {
          "text": "@human: Should auto-suggest use AI/LLM for semantic analysis or only rule-based heuristics?",
          "selected": true,
          "answer": "Start with rule-based heuristics only (simpler, faster, no external dependencies). AI/LLM integration could be a future enhancement."
        },
        {
          "text": "@human: What confidence threshold should be used for suggestions (e.g., only suggest if >70% confidence)?",
          "selected": true,
          "answer": "No confidence scoring initially. Suggest only when rules match clearly (e.g., exact sequential IDs, exact 'Build X'/'Test X' match). Avoid ambiguous suggestions."
        },
        {
          "text": "@human: Should suggestions be presented interactively or in batch for approval?",
          "selected": true,
          "answer": "Batch mode. Display all suggestions and let user review/approve them together. Interactive mode could be added later with --interactive flag."
        },
        {
          "text": "@human: Should the system learn from user acceptance/rejection of suggestions over time?",
          "selected": true,
          "answer": "No learning capability in v1. Keep it simple and deterministic. Machine learning could be considered for future versions."
        }
      ],
      "userStory": {
        "role": "AI agent or developer",
        "action": "receive automatic suggestions for dependency relationships between work units",
        "benefit": "I can quickly establish connections without manually analyzing all work units"
      },
      "assumptions": [
        "Start with rule-based heuristics only (simpler, faster, no external dependencies). AI/LLM integration could be a future enhancement.",
        "No confidence scoring initially. Suggest only when rules match clearly (e.g., exact sequential IDs, exact 'Build X'/'Test X' match). Avoid ambiguous suggestions.",
        "Batch mode. Display all suggestions and let user review/approve them together. Interactive mode could be added later with --interactive flag.",
        "No learning capability in v1. Keep it simple and deterministic. Machine learning could be considered for future versions."
      ]
    },
    "COV-048": {
      "id": "COV-048",
      "title": "Test: Detect orphaned work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:58.176Z",
      "updatedAt": "2025-10-15T05:15:43.344Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_BOTH. No tests or implementation found for orphan detection.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:48.863Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T04:04:05.720Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:15:23.827Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:15:41.265Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:15:43.345Z"
        }
      ],
      "rules": [
        "An orphaned work unit has NO dependency relationships (no blocks, blockedBy, dependsOn, or relatesTo)",
        "An orphaned work unit has NO epic assignment (epic field is null or empty)",
        "Orphaned work units are isolated from the project context and may indicate abandoned or misconfigured work",
        "Detecting orphans helps identify work that should be connected, reassigned, or deleted",
        "No. Prefix alone does not provide sufficient context. A work unit must have either an epic OR at least one relationship to not be considered orphaned.",
        "Yes. Show suggested actions: 'Assign to epic', 'Add relationship to related work', 'Delete if no longer needed'. Make it actionable, not just informational."
      ],
      "examples": [
        "UI-999 has no epic, no blocks, no blockedBy, no dependsOn, no relatesTo → ORPHANED (completely isolated)",
        "AUTH-001 has epic='user-management' but no relationships → NOT orphaned (has epic context)",
        "API-001 has no epic but dependsOn DB-001 → NOT orphaned (has dependency relationship)",
        "TEST-042 has no epic, no relationships, status='done' → ORPHANED (even done work can be orphaned)",
        "MISC-005 has relatesTo relationship to SEC-001 → NOT orphaned (any relationship counts)"
      ],
      "questions": [
        {
          "text": "@human: Should work units with only a prefix (but no epic or relationships) be considered orphaned?",
          "selected": true,
          "answer": "No. Prefix alone does not provide sufficient context. A work unit must have either an epic OR at least one relationship to not be considered orphaned."
        },
        {
          "text": "@human: Should orphan detection exclude work units in 'done' status (completed work may not need connections)?",
          "selected": true,
          "answer": "No. Include all work units regardless of status. Even 'done' work can be orphaned and may indicate cleanup needed. Use --exclude-done flag if user wants to filter them out."
        },
        {
          "text": "@human: Should the command suggest actions for orphaned work (e.g., 'assign epic', 'add dependency', 'delete')?",
          "selected": true,
          "answer": "Yes. Show suggested actions: 'Assign to epic', 'Add relationship to related work', 'Delete if no longer needed'. Make it actionable, not just informational."
        }
      ],
      "userStory": {
        "role": "project manager or AI agent",
        "action": "detect orphaned work units with no epic or dependency relationships",
        "benefit": "I can identify isolated work that needs to be connected, reassigned, or cleaned up"
      },
      "assumptions": [
        "No. Include all work units regardless of status. Even 'done' work can be orphaned and may indicate cleanup needed. Use --exclude-done flag if user wants to filter them out."
      ]
    },
    "COV-049": {
      "id": "COV-049",
      "title": "Test: Query by status and prefix",
      "status": "done",
      "createdAt": "2025-10-15T00:11:58.467Z",
      "updatedAt": "2025-10-15T03:18:09.151Z",
      "description": "Feature: work-unit-query-and-reporting. Status: CREATE_TEST_ONLY. Status query exists, epic query exists, but no prefix query test.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:50.614Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:45.037Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:08.555Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:08.852Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:09.152Z"
        }
      ]
    },
    "COV-050": {
      "id": "COV-050",
      "title": "Test: Query with sorting by updated date",
      "status": "done",
      "createdAt": "2025-10-15T00:11:58.760Z",
      "updatedAt": "2025-10-15T03:18:11.671Z",
      "description": "Feature: work-unit-query-and-reporting. Status: CREATE_TEST_ONLY. No test found for sorting functionality.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:52.377Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:45.345Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:11.075Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:11.374Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:11.672Z"
        }
      ]
    },
    "COV-051": {
      "id": "COV-051",
      "title": "Test: Export filtered results to CSV",
      "status": "done",
      "createdAt": "2025-10-15T00:11:59.052Z",
      "updatedAt": "2025-10-15T03:18:14.131Z",
      "description": "Feature: work-unit-query-and-reporting. Status: CREATE_TEST_ONLY. JSON export exists but no CSV export test.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:54.123Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:45.650Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:13.529Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:13.832Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:14.132Z"
        }
      ]
    },
    "BUG-007": {
      "id": "BUG-007",
      "title": "generate-coverage does not detect new scenarios in existing feature files",
      "status": "done",
      "createdAt": "2025-10-15T04:09:40.314Z",
      "updatedAt": "2025-10-15T14:28:00.000Z",
      "description": "When new scenarios are added to an existing feature file, the generate-coverage command does not update the .coverage file to include them. This blocks the link-coverage workflow in ACDD.",
      "epic": "test-coverage",
      "children": [],
      "userStory": {
        "role": "developer following ACDD workflow",
        "action": "have generate-coverage detect and add new scenarios to existing .coverage files",
        "benefit": "I can link test coverage for new scenarios without manual JSON editing"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T04:10:11.653Z"
        }
      ],
      "rules": [
        "generate-coverage should compare feature file scenarios against coverage file scenarios",
        "If feature file has MORE scenarios than coverage file, add missing scenarios with empty testMappings array",
        "If coverage file has scenarios NOT in feature file, remove them (cleanup orphaned entries)",
        "Preserve existing test/impl mappings for unchanged scenarios (don't overwrite)",
        "Update stats section to reflect new scenario count and coverage percentage",
        "Yes. generate-coverage must be idempotent - safe to run multiple times. It should UPDATE existing coverage files, not overwrite them."
      ],
      "examples": [
        "REPRODUCTION: work-unit-dependency-management.feature has 42 scenarios, but .coverage file only has 39 scenario entries",
        "MISSING: Scenario 'Identify bottleneck work units blocking the most work' (line 501-518) NOT in coverage file",
        "MISSING: Scenario 'Auto-suggest dependency relationships based on work unit metadata' (line 520-536) NOT in coverage file",
        "MISSING: Scenario 'Detect orphaned work units with no epic or dependencies' (line 538-553) NOT in coverage file",
        "COMMAND RESULT: 'fspec generate-coverage' runs without error but does NOT add missing scenarios",
        "ERROR WHEN LINKING: 'fspec link-coverage work-unit-dependency-management --scenario \"Identify bottleneck...\"' fails with 'Scenario not found'",
        "FILE: spec/features/work-unit-dependency-management.feature - grep shows 42 scenarios: 'grep -c \"^  Scenario:\" spec/features/work-unit-dependency-management.feature' returns 42",
        "FILE: spec/features/work-unit-dependency-management.feature.coverage - only has 39 entries in scenarios array (verified by reading JSON)",
        "EXACT LINE: Feature file line 501: '@COV-046' tag, Scenario: 'Identify bottleneck work units blocking the most work' - MISSING from coverage",
        "EXACT LINE: Feature file line 520: '@COV-047' tag, Scenario: 'Auto-suggest dependency relationships based on work unit metadata' - MISSING from coverage",
        "EXACT LINE: Feature file line 538: '@COV-048' tag, Scenario: 'Detect orphaned work units with no epic or dependencies' - MISSING from coverage",
        "COMMAND TO REPRODUCE: 1) Add new scenario to existing .feature file 2) Run 'fspec generate-coverage' 3) Check .coverage file - new scenario NOT added 4) Try 'fspec link-coverage <feature> --scenario <name>' - ERROR: Scenario not found"
      ],
      "questions": [
        {
          "text": "@human: Should generate-coverage be idempotent (safe to run multiple times without data loss)?",
          "selected": true,
          "answer": "Yes. generate-coverage must be idempotent - safe to run multiple times. It should UPDATE existing coverage files, not overwrite them."
        },
        {
          "text": "@human: Should generate-coverage create backup of .coverage file before modifying?",
          "selected": true,
          "answer": "No backup needed. Since it's idempotent and git tracks changes, users can revert if needed."
        },
        {
          "text": "@human: Should there be a --force flag to overwrite coverage files vs update-only mode?",
          "selected": true,
          "answer": "No. Default behavior should be update mode (merge new scenarios). Keep it simple."
        }
      ],
      "estimate": 3,
      "assumptions": [
        "No backup needed. Since it's idempotent and git tracks changes, users can revert if needed.",
        "No. Default behavior should be update mode (merge new scenarios). Keep it simple."
      ]
    },
    "BUG-008": {
      "id": "BUG-008",
      "title": "generate-scenarios produces malformed Gherkin steps from example titles",
      "status": "done",
      "createdAt": "2025-10-15T04:16:17.565Z",
      "updatedAt": "2025-10-15T14:24:00.000Z",
      "description": "The generate-scenarios command is creating scenarios with malformed Given/When/Then steps that include the entire example title text instead of proper Gherkin syntax. This results in invalid scenarios with prefill placeholders and prevents moving work units through the workflow.",
      "children": [],
      "userStory": {
        "role": "developer using fspec with Example Mapping",
        "action": "have generate-scenarios create proper Gherkin Given/When/Then steps from example titles",
        "benefit": "generated scenarios are valid and don't block workflow progression with prefill errors"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T04:16:39.895Z"
        }
      ],
      "rules": [
        "Example titles that start with keywords like 'REPRODUCTION:', 'MISSING:', 'ERROR WHEN:', 'COMMAND RESULT:' should be parsed to extract the actual scenario content, not used verbatim as Given steps",
        "Generated scenarios must follow proper Gherkin structure: Given [precondition] / When [action] / Then [expected outcome]",
        "Steps should never include the full example title - they should be semantically meaningful Given/When/Then statements",
        "Scenario titles must be cleaned by removing common prefixes (REPRODUCTION, MISSING, ERROR WHEN, COMMAND RESULT, FILE, EXACT LINE, COMMAND TO REPRODUCE) to create readable scenario names",
        "Original example text must be preserved as a comment (# Example: ...) above each scenario to maintain traceability to Example Mapping"
      ],
      "examples": [
        "CURRENT: Example 'REPRODUCTION: work-unit-dependency-management.feature has 42 scenarios' → Scenario with 'Given REPRODUCTION: work-unit-dependency-management.feature has 42 scenarios, but .coverage file only has 39 scenario entries' | EXPECTED: → Scenario with 'Given a feature file exists with 42 scenarios / When I check the coverage file / Then it should have 42 scenario entries'",
        "CURRENT: Example 'MISSING: Scenario X (line 501-518) NOT in coverage file' → Generates 'Given [precondition] / When [action] / Then [expected outcome]' (placeholders\\!) | EXPECTED: → 'Given a scenario exists in feature file at lines 501-518 / When I run generate-coverage / Then the scenario should be added to the coverage file'",
        "CURRENT: Example 'ERROR WHEN LINKING: fspec link-coverage fails with Scenario not found' → Generates 'Given I have an invalid condition / When I execute ERROR WHEN LINKING...' (malformed\\!) | EXPECTED: → 'Given a scenario is missing from coverage file / When I run fspec link-coverage with that scenario name / Then it should fail with error Scenario not found'",
        "CURRENT: Example 'COMMAND RESULT: fspec generate-coverage runs without error but does NOT add missing scenarios' → 'Given I am COMMAND RESULT: fspec generate-coverage / When I runs without error...' (grammatically broken\\!) | EXPECTED: → 'Given I have a feature file with new scenarios / When I run fspec generate-coverage / Then it should run without error / And it should NOT add missing scenarios to existing coverage files' (documents the bug behavior)",
        "CURRENT: Example 'FILE: spec/features/work-unit.feature - grep shows 42 scenarios' → 'Given I am FILE: spec/features... / When I shows 42 scenarios...' (nonsensical grammar\\!) | EXPECTED: → 'Given a feature file spec/features/work-unit.feature exists / When I count scenarios using grep / Then it should return 42 scenarios'",
        "CURRENT: Example 'COMMAND TO REPRODUCE: 1) Add scenario 2) Run command 3) Check file 4) Try link' → 'Given I am COMMAND TO REPRODUCE: 1) / When I Add new scenario...' (truncated and malformed\\!) | EXPECTED: → 'Given I add a new scenario to an existing feature file / When I run fspec generate-coverage / And I check the coverage file / Then the new scenario should NOT be added / When I try to link coverage for the scenario / Then it should fail with Scenario not found'"
      ],
      "questions": [
        {
          "text": "Should generate-scenarios attempt to parse example titles to extract semantic meaning, or should users write proper Given/When/Then examples in the first place?",
          "selected": true,
          "answer": "Clean scenario titles by removing prefixes like 'REPRODUCTION:', 'MISSING:', etc. Keep full example as comment. Use existing extractStepsFromExample() for parsing."
        },
        {
          "text": "If examples contain complex reproduction steps (multiple actions), should generate-scenarios create multiple Given/When/Then steps or a single scenario outline?",
          "selected": true,
          "answer": "Use existing extractStepsFromExample() which already generates multiple Given/When/Then steps based on pattern matching. No changes needed - current system handles this."
        },
        {
          "text": "What should happen if an example title doesn't fit the Given/When/Then structure at all (e.g., purely descriptive)?",
          "selected": true,
          "answer": "Fall back to [placeholders] which triggers prefill detection. This is already implemented in extractStepsFromExample(). No changes needed."
        }
      ],
      "estimate": 2
    },
    "FEAT-006": {
      "id": "FEAT-006",
      "title": "Work item type system - Core foundation",
      "status": "done",
      "createdAt": "2025-10-15T05:44:47.532Z",
      "updatedAt": "2025-10-15T06:39:15.374Z",
      "description": "Add support for different work item types (story, task, bug) similar to JIRA, allowing better categorization of work units based on their nature (user-facing features vs operational work vs defects)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T05:54:25.542Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T06:06:59.919Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T06:09:03.428Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-15T06:15:05.862Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T06:25:53.799Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T06:26:03.435Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T06:26:09.298Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T06:39:12.885Z",
          "reason": "All child work units complete (FEAT-007, 008, 009, 010 all done)"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T06:39:15.377Z",
          "reason": "All child work units done, full test suite passes (1002/1002), build succeeds"
        }
      ],
      "userStory": {
        "role": "AI agent managing project work with fspec",
        "action": "categorize work units by type (story, task, bug)",
        "benefit": "I can track meta-work and housekeeping through Kanban without violating ACDD discipline for user-facing features"
      },
      "rules": [
        "Work units must have a type field: 'story', 'task', or 'bug'",
        "Default type is 'story' for backward compatibility with existing work units",
        "Stories require full ACDD workflow: backlog → specifying → testing → implementing → validating → done",
        "Tasks use simplified workflow: backlog → in-progress → done (+ blocked)",
        "Bugs use same ACDD workflow as stories but may skip Example Mapping in favor of reproduction scenarios",
        "Stories must have linked feature file before moving to testing state",
        "Tasks do not require feature files or tests",
        "Bugs must have reproduction scenario in feature file before moving to testing state",
        "Yes, existing work units without type field automatically get type='story' (backward compatible). New work units default to 'story' unless --type specified.",
        "Tasks CANNOT have feature files. Feature files represent user stories with acceptance criteria, which makes them stories by definition. Tasks are for operational work without user-facing behavior.",
        "Bugs MUST link to an existing feature file. If no feature file exists for the buggy behavior, it's a story, not a bug. Bugs fix/update existing documented features. Validation error should explain: 'Bugs must link to existing feature file. If feature has no spec, create a story instead.'",
        "Tasks support Example Mapping fields (rules, examples, questions) but they are OPTIONAL and only for clarity about what needs to be done. Unlike stories, tasks don't require these fields to be filled before progressing.",
        "Treat all estimates the same way (combined velocity), but reporting commands should have ability to break down metrics by type (--type=story, --type=task, --type=bug) or show combined.",
        "Type is immutable once set. If wrong, work unit must be deleted and recreated with correct type. This prevents confusion about workflow rules changing mid-flight.",
        "All work unit types can use 'in-progress' state. Stories map: specifying/testing/implementing/validating → all represent 'in-progress'. Tasks use 'in-progress' explicitly. Bugs follow story states. This provides consistency across types.",
        "Tasks use workflow: backlog → specifying → implementing → validating → done (+ blocked). They skip 'testing' state since no tests are required.",
        "Tasks in specifying state do NOT require feature files (unlike stories). Specifying is for internal clarity only - can use description, rules, examples fields.",
        "Yes, remove old rule #4. The corrected workflow is: backlog → specifying → implementing → validating → done. Tasks need 'specifying' for clarity but skip 'testing' since no tests required."
      ],
      "examples": [
        "Create story work unit: 'fspec create-work-unit AUTH \"User Login\" --type=story' creates AUTH-XXX with type='story'",
        "Create task work unit: 'fspec create-work-unit CLEAN \"Audit coverage files\" --type=task' creates CLEAN-XXX with type='task'",
        "Create bug work unit: 'fspec create-work-unit BUG \"Login fails with @ symbol\" --type=bug' creates BUG-XXX with type='bug'",
        "Default type: 'fspec create-work-unit AUTH \"Feature\"' creates work unit with type='story' (backward compatible)",
        "Filter by type: 'fspec list-work-units --type=task' shows only task work units",
        "Task workflow: CLEAN-001 moves backlog → in-progress → done (skipping specifying/testing/implementing/validating)",
        "Story validation: Moving AUTH-001 (type=story) to testing without feature file shows error 'Cannot move to testing: no feature file linked'",
        "Task flexibility: CLEAN-001 (type=task) can move from backlog directly to done without any validation errors",
        "Board visualization: 'fspec board' shows three sections: STORIES (full workflow), TASKS (simplified), BUGS (full workflow)",
        "Task workflow detail: CLEAN-001 (type=task) moves backlog → specifying (clarify what to do) → implementing (do the work) → validating (verify done) → done",
        "Task specifying phase: CLEAN-001 in specifying state can use optional Example Mapping (rules, examples) to clarify work scope before implementing"
      ],
      "questions": [
        {
          "text": "@human: Should existing work units without a type field automatically get type='story', or should we require manual migration?",
          "selected": true,
          "answer": "Yes, existing work units without type field automatically get type='story' (backward compatible). New work units default to 'story' unless --type specified."
        },
        {
          "text": "@human: Can a task optionally have a feature file linked for documentation purposes, or should tasks be completely prohibited from having feature files?",
          "selected": true,
          "answer": "Tasks CANNOT have feature files. Feature files represent user stories with acceptance criteria, which makes them stories by definition. Tasks are for operational work without user-facing behavior."
        },
        {
          "text": "@human: Should the board command show all three types together, or should it have separate views/sections for each type?",
          "selected": true,
          "answer": "No changes to board visualization. All types shown in same board view with their respective workflow states."
        },
        {
          "text": "@human: For bugs, should we enforce that they must link to an existing feature file (the one with the bug), or should they create a separate bug-fix feature file?",
          "selected": true,
          "answer": "Bugs MUST link to an existing feature file. If no feature file exists for the buggy behavior, it's a story, not a bug. Bugs fix/update existing documented features. Validation error should explain: 'Bugs must link to existing feature file. If feature has no spec, create a story instead.'"
        },
        {
          "text": "@human: Should tasks support Example Mapping fields (rules, examples, questions), or should those be story/bug-only features?",
          "selected": true,
          "answer": "Tasks support Example Mapping fields (rules, examples, questions) but they are OPTIONAL and only for clarity about what needs to be done. Unlike stories, tasks don't require these fields to be filled before progressing."
        },
        {
          "text": "@human: Should we track different velocity metrics for stories vs tasks vs bugs, or treat all estimates the same way?",
          "selected": true,
          "answer": "Treat all estimates the same way (combined velocity), but reporting commands should have ability to break down metrics by type (--type=story, --type=task, --type=bug) or show combined."
        },
        {
          "text": "@human: Can a work unit's type be changed after creation, or is it immutable once set?",
          "selected": true,
          "answer": "Type is immutable once set. If wrong, work unit must be deleted and recreated with correct type. This prevents confusion about workflow rules changing mid-flight."
        },
        {
          "text": "@human: Should 'in-progress' state be available for ALL work unit types, or should it remain task-only?",
          "selected": true,
          "answer": "All work unit types can use 'in-progress' state. Stories map: specifying/testing/implementing/validating → all represent 'in-progress'. Tasks use 'in-progress' explicitly. Bugs follow story states. This provides consistency across types."
        },
        {
          "text": "@human: Should I remove the old rule #4 that says 'Tasks use simplified workflow: backlog → in-progress → done' since it's been superseded by the corrected workflow?",
          "selected": true,
          "answer": "Yes, remove old rule #4. The corrected workflow is: backlog → specifying → implementing → validating → done. Tasks need 'specifying' for clarity but skip 'testing' since no tests required."
        }
      ],
      "assumptions": [
        "No changes to board visualization. All types shown in same board view with their respective workflow states."
      ],
      "estimate": 5,
      "epic": "work-item-types"
    },
    "FEAT-011": {
      "id": "FEAT-011",
      "title": "Prevent retroactive state walking - enforce temporal ordering",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T06:49:06.299Z",
      "updatedAt": "2025-10-15T07:07:46.452Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T06:49:30.983Z",
          "reason": "Need to add Example Mapping rules"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T07:06:20.805Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T07:06:36.424Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T07:06:42.872Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T07:07:46.453Z"
        }
      ],
      "rules": [
        "System must prevent AI agents from doing all work first, then retroactively walking through states as theater",
        "When moving to testing state: system must verify tests were created AFTER entering testing state, not before",
        "When moving to implementing state: system must verify tests currently FAIL (red phase). Tests failing proves they actually test something.",
        "When moving to validating state: system must verify tests now PASS (green phase) and implementation was modified AFTER entering implementing",
        "If work unit has artifacts (specs/tests/code) all timestamped BEFORE entering testing state, then: either delete the work unit if it has no unique value OR move it back to backlog and require proper ACDD workflow"
      ],
      "examples": [
        "FEAT-007, FEAT-008, FEAT-009, FEAT-010: All work (specs, tests, code) completed in previous session. Current session: AI moved each through specifying→testing→implementing→validating→done in 5 seconds each. System allowed it because @WORK-UNIT-ID tags existed in feature file and tests passed. Result: ACDD completely bypassed.",
        "work-item-types-for-stories-tasks-and-bugs.feature: Created before any child work units. Tests written before testing state. Implementation completed before implementing state. Feature file tagged with @FEAT-007 @FEAT-008 @FEAT-009 @FEAT-010 retroactively. checkScenariosExist() found tags and allowed testing state entry.",
        "System checks: (1) Does @WORK-UNIT-ID exist? YES. (2) Is state transition valid? YES. (3) Are children done? YES. Missing checks: (1) When was feature file created? (2) When were tests written? (3) Did tests fail first? (4) Was implementation written after tests?",
        "AI behavior enabled by current system: (1) Write all code in one session. (2) Tag feature file with work unit IDs. (3) Run tests to ensure they pass. (4) Walk through states as formality. (5) System approves everything. This is the opposite of ACDD.",
        "Correct ACDD sequence: (1) Enter specifying: write feature file. (2) Enter testing: write FAILING tests. (3) Run tests: verify they fail. (4) Enter implementing: write minimal code. (5) Run tests: verify they pass. (6) Enter validating: run full suite. System must enforce this temporal ordering."
      ],
      "userStory": {
        "role": "AI agent using fspec for ACDD workflow",
        "action": "ensure work is done in the correct temporal order",
        "benefit": "ACDD methodology is actually enforced, not just theatrical state walking"
      }
    },
    "BUG-009": {
      "id": "BUG-009",
      "title": "remove-tag-from-scenario command doesn't properly remove tags",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T07:11:37.663Z",
      "updatedAt": "2025-10-16T23:24:13.114Z",
      "description": "The remove-tag-from-scenario command is not working correctly - it claims to remove tags but they remain at scenario level in the feature files. This breaks tag validation because work unit ID tags (@COV-XXX) must be at feature level only.",
      "children": [],
      "userStory": {
        "role": "developer using fspec",
        "action": "remove scenario-level tags that should be at feature level",
        "benefit": "tag validation passes and work unit tags are correctly positioned"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T07:14:19.063Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T07:22:07.019Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T07:24:11.287Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T07:25:32.534Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T07:26:51.372Z"
        }
      ],
      "rules": [
        "Command must actually remove tags from scenario lines in the feature file, not just claim success",
        "Command output should show success message when tags are removed",
        "If tag doesn't exist on scenario, command should still succeed (idempotent)",
        "Command must preserve file formatting and not corrupt Gherkin syntax",
        "Must handle scenario names with special characters or partial matches",
        "Use Edit tool for proper validation and formatting. Avoid sed/grep/perl for file modifications per CLAUDE.md guidelines.",
        "Succeed silently (idempotent behavior). If scenario not found, log a warning but exit with code 0. This matches Rule 3 idempotency requirement.",
        "Remove all occurrences of the tag from the scenario line. If '@COV-010 @COV-010' appears, both should be removed in a single operation."
      ],
      "examples": [
        "Run 'fspec remove-tag-from-scenario spec/features/test.feature \"Login scenario\" @COV-010' and tag is actually removed from file",
        "Tag appears on scenario line with 2-space indentation: '  @COV-010', command removes entire line",
        "Multiple tags on scenario, remove one specific tag, other tags remain intact",
        "Remove tag from scenario using wildcard scenario name '*', removes from all matching scenarios",
        "Tag validation shows '@COV-010 must be at feature level', run remove command, validation passes after removal"
      ],
      "questions": [
        {
          "text": "@human: Should the command use Edit tool or direct file manipulation (sed/grep/perl)?",
          "selected": true,
          "answer": "Use Edit tool for proper validation and formatting. Avoid sed/grep/perl for file modifications per CLAUDE.md guidelines."
        },
        {
          "text": "@human: Should command fail if scenario name not found, or succeed silently?",
          "selected": true,
          "answer": "Succeed silently (idempotent behavior). If scenario not found, log a warning but exit with code 0. This matches Rule 3 idempotency requirement."
        },
        {
          "text": "@human: What should happen if tag appears multiple times on same scenario line?",
          "selected": true,
          "answer": "Remove all occurrences of the tag from the scenario line. If '@COV-010 @COV-010' appears, both should be removed in a single operation."
        }
      ],
      "assumptions": [
        "Issue only affects scenario-level tags, not feature-level tags",
        "Bug was discovered during tag validation fix for FEAT-011 temporal ordering",
        "Workaround exists using grep/sed/perl for manual removal",
        "Bug affects all fspec versions with remove-tag-from-scenario command"
      ],
      "estimate": 2
    },
    "DOC-004": {
      "id": "DOC-004",
      "title": "Validate Mermaid diagrams during foundation.json regeneration",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T07:36:09.439Z",
      "updatedAt": "2025-10-15T07:54:01.712Z",
      "description": "The generate-foundation-md command should validate all Mermaid diagrams in foundation.json before regenerating FOUNDATION.md. If any diagram has invalid syntax, the command should fail with detailed error information including the position in the JSON file and the specific Mermaid validation error, guiding the AI to fix and regenerate.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T07:36:16.916Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T07:45:13.894Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T07:47:31.554Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T07:51:32.720Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T07:54:01.712Z"
        }
      ],
      "userStory": {
        "role": "developer maintaining foundation.json documentation",
        "action": "validate all Mermaid diagrams when regenerating FOUNDATION.md",
        "benefit": "I catch syntax errors immediately with precise error locations and can fix them before the markdown file is written"
      },
      "rules": [
        "All Mermaid diagrams in foundation.json MUST be validated before writing FOUNDATION.md",
        "Validation errors MUST include the JSON position (architectureDiagrams array index) of the failing diagram",
        "Validation errors MUST include the diagram title for easy identification",
        "Validation errors MUST include the detailed Mermaid error message from mermaid.parse()",
        "The command MUST exit with code 1 if any diagram validation fails",
        "Error output MUST guide the AI to fix the diagram in foundation.json and regenerate",
        "Diagram validation MUST use the existing validateMermaidSyntax() function from add-diagram.ts",
        "After JSON schema validation - validate diagrams after the schema check passes",
        "Validate all diagrams at once and show all errors together - don't fail fast",
        "Yes, extract validateMermaidSyntax to src/utils/mermaid-validation.ts for reuse"
      ],
      "examples": [
        "Running 'fspec generate-foundation-md' with valid diagrams completes successfully and generates FOUNDATION.md",
        "Running 'fspec generate-foundation-md' with an invalid diagram at architectureDiagrams[2] shows: 'Error at architectureDiagrams[2] (title: \"Data Flow\"): Invalid Mermaid syntax: unexpected token' and exits with code 1",
        "Running 'fspec generate-foundation-md' with multiple invalid diagrams shows all failures with their positions, titles, and error messages",
        "Error message includes guidance: 'Fix the diagram(s) in spec/foundation.json and run fspec generate-foundation-md again'",
        "After fixing invalid diagrams in foundation.json and running 'fspec generate-foundation-md' again, the command succeeds and generates FOUNDATION.md"
      ],
      "questions": [
        {
          "text": "@human: Should validation happen BEFORE or AFTER JSON schema validation?",
          "selected": true,
          "answer": "After JSON schema validation - validate diagrams after the schema check passes"
        },
        {
          "text": "@human: Should we stop at the first invalid diagram or validate all diagrams and show all errors at once?",
          "selected": true,
          "answer": "Validate all diagrams at once and show all errors together - don't fail fast"
        },
        {
          "text": "@human: Should the validateMermaidSyntax function be extracted to a shared utility file for reuse?",
          "selected": true,
          "answer": "Yes, extract validateMermaidSyntax to src/utils/mermaid-validation.ts for reuse"
        }
      ],
      "estimate": 3
    },
    "BUG-010": {
      "id": "BUG-010",
      "title": "fspec init performs unnecessary string replacements on generic slash command template",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-15T08:07:58.029Z",
      "updatedAt": "2025-10-15T08:13:07.810Z",
      "description": "The init command replaces fspec-specific examples (user-authentication.feature, CLI-003, etc.) with generic placeholders (example-feature.feature, EXAMPLE-001). These replacements are unnecessary because the slash command file contains illustrative examples that work for any project. The replacements also cause issues when running init from fspec's own directory, overwriting the original examples. Solution: Remove all string replacement logic from generateTemplate() function.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T08:08:12.311Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T08:11:59.282Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T08:12:08.189Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T08:12:08.484Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T08:13:07.810Z"
        }
      ],
      "rules": [
        "The slash command file is generic guidance that works for any project",
        "Examples in the file are illustrative only - showing patterns not specific project details",
        "String replacements provide no value and cause issues when run from fspec directory"
      ],
      "examples": [
        "Running init from fspec dir overwrites original examples with generic ones",
        "External projects see user-authentication.feature in examples which works fine as illustration"
      ]
    },
    "EXMAP-002": {
      "id": "EXMAP-002",
      "title": "Preserve example mapping context as comments in generated feature files",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T08:34:45.292Z",
      "updatedAt": "2025-10-15T09:00:08.967Z",
      "description": "When generate-scenarios runs, embed full example mapping data (rules, examples, questions, assumptions) as comment blocks that persist through format cycles. This provides permanent context for AI and humans writing scenarios.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T08:34:53.790Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T08:39:15.384Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T08:44:19.099Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T08:57:40.553Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T09:00:08.967Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec for ACDD workflow",
        "action": "see full example mapping context when writing scenarios",
        "benefit": "I can write meaningful Given/When/Then steps based on business rules and concrete examples"
      },
      "rules": [
        "Comments in Gherkin AST MUST be preserved through format cycles",
        "Example mapping context embedded as comments MUST NOT conflict with add-architecture doc strings",
        "Generated feature files MUST contain zero scenarios initially (context-only)",
        "System-reminder MUST guide AI to write scenarios based on embedded examples",
        "Comment blocks MUST be visually distinct and easy to locate",
        "All example mapping data (rules, examples, questions, assumptions) MUST be embedded"
      ],
      "examples": [
        "FORMATTER PRESERVES COMMENTS: AI runs generate-scenarios, gets file with # comments, runs fspec format, comments are still present in file",
        "COMMENTS DON'T CONFLICT WITH ARCHITECTURE: File has # example mapping comments AND \"\"\" architecture notes doc string, both coexist without overwriting",
        "CONTEXT-ONLY GENERATION: generate-scenarios produces file with # comments + Background but ZERO scenarios, AI writes scenarios using Edit tool",
        "USER STORY IN TWO PLACES: User story appears in # comments AND in Background section, both updated when set-user-story runs",
        "SYSTEM-REMINDER GUIDES AI: After generate-scenarios, system-reminder tells AI 'write scenarios based on # EXAMPLES section', AI sees reminder and writes proper scenarios",
        "RULES IN COMMENTS INFORM SCENARIOS: # BUSINESS RULES says 'password 8+ chars', AI writes scenario with Given step checking password length",
        "ANSWERED QUESTIONS PRESERVED: # QUESTIONS section shows 'Q: OAuth support? A: Phase 2', developer reading file understands deferred decisions",
        "ASSUMPTIONS DOCUMENTED: # ASSUMPTIONS says 'email verification external', AI doesn't write scenarios for email verification",
        "VISUAL SEPARATION WITH BORDERS: Comment block has # === borders at top/bottom, easy to spot when scrolling through file",
        "MULTIPLE EXAMPLES TO SCENARIOS: # EXAMPLES has 3 items, AI writes 3 separate scenarios OR combines related ones into single scenario",
        "ADD-SCENARIO DOESN'T TOUCH COMMENTS: File has # example mapping comments, user runs add-scenario, comments remain untouched at top",
        "ADD-BACKGROUND DOESN'T TOUCH COMMENTS: File has # comments before Background, user runs add-background to update user story, comments persist",
        "PARSER PRESERVES COMMENTS IN AST: Gherkin parser reads file with # comments, ast.comments array contains comment objects with line numbers and text",
        "FORMATTER OUTPUTS COMMENTS FROM AST: formatGherkinDocument receives AST with comments, inserts comment lines at correct positions in output",
        "EMPTY EXAMPLE MAP HANDLED: Work unit has no rules/examples, generate-scenarios creates minimal comment block saying 'No example mapping data captured'",
        "PREFILL DETECTION STILL WORKS: Generated Background has [role] placeholder, prefill detector emits system-reminder about using set-user-story",
        "GIT DIFF SHOWS CONTEXT: Developer reviews PR, sees # example mapping comments in diff, understands why scenarios were written",
        "EXISTING COMMENT HANDLING: Feature file already has some # comments, generate-scenarios appends its comment block without conflict",
        "NO SCENARIOS MEANS FILE INCOMPLETE: generate-scenarios creates file with # comments + Background + zero scenarios, system-reminder says 'now write scenarios'",
        "AI USES EDIT TOOL WITH CONTEXT: AI reads file, sees # EXAMPLES: '1. User logs in with valid creds', writes Scenario with proper Given/When/Then using Edit tool"
      ],
      "assumptions": [
        "Gherkin parser (@cucumber/gherkin) already captures comments in AST",
        "Current formatter (gherkin-formatter.ts) ignores ast.comments field",
        "Comments use # syntax (Gherkin standard)",
        "Doc strings use triple quotes (architecture notes)",
        "AI agents have Edit tool access to feature files"
      ],
      "estimate": 5
    },
    "EXMAP-003": {
      "id": "EXMAP-003",
      "title": "Add system-reminder to generate-coverage command",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T08:49:29.798Z",
      "updatedAt": "2025-10-15T13:26:45.264Z",
      "description": "When generate-coverage creates coverage files, emit a system-reminder explaining that the LLM must manually link coverage using link-coverage command",
      "epic": "coverage-tracking",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T09:06:38.009Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T09:09:37.200Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T09:10:49.274Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T09:13:24.474Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T09:13:36.457Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-15T09:22:46.765Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T13:24:08.180Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T13:24:50.326Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:24:55.615Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:26:45.266Z"
        }
      ],
      "rules": [
        "Coverage files must be populated manually using link-coverage",
        "System reminder must be displayed after generate-coverage command",
        "Reminder must explain that coverage files are empty until linked",
        "Reminder must show example link-coverage commands",
        "Yes, reminder should be shown for both modes with contextual examples",
        "Yes, should mention show-coverage as verification step",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them",
        "Yes, should mention show-coverage as verification step",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
      ],
      "examples": [
        "User runs generate-coverage with no arguments and sees reminder",
        "User runs generate-coverage --dry-run and sees reminder",
        "User runs generate-coverage feature-name and sees reminder with feature-specific examples",
        "Reminder includes link-coverage command syntax with test file example",
        "Reminder includes link-coverage command syntax with implementation file example",
        "Reminder explains three-step ACDD workflow: write specs → link tests → link implementation"
      ],
      "questions": [
        {
          "text": "Should the reminder be shown for both single-feature and all-features modes?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        },
        {
          "text": "Should the reminder include show-coverage command as next step?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        },
        {
          "text": "Should the reminder be suppressible with a --quiet flag?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        },
        {
          "text": "Should the reminder explain the difference between generate-coverage and link-coverage?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        }
      ],
      "assumptions": [
        "No, reminder should always be shown as it's critical for ACDD workflow",
        "No, reminder should always be shown as it's critical for ACDD workflow",
        "No, reminder should always be shown as it's critical for ACDD workflow"
      ],
      "userStory": {
        "role": "developer using fspec with ACDD workflow",
        "action": "be reminded to manually link coverage after running generate-coverage",
        "benefit": "I don't forget the critical step of linking tests and implementation to scenarios"
      }
    },
    "HOOK-001": {
      "id": "HOOK-001",
      "title": "Kanban Lifecycle Hooks System",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T10:55:43.651Z",
      "updatedAt": "2025-10-15T13:28:40.738Z",
      "description": "Implement a hooks system similar to Claude Code hooks that allows executing custom commands before/after Kanban state transitions. Hooks are configured in spec/fspec-hooks.json and scripts live in spec/hooks/ directory. Enables quality gates, test automation, notifications, and CI/CD integration at each ACDD workflow stage.",
      "children": [
        "HOOK-002",
        "HOOK-003",
        "HOOK-004",
        "HOOK-005",
        "HOOK-006",
        "HOOK-007",
        "HOOK-008",
        "HOOK-009"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T10:55:52.838Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T13:28:29.038Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T13:28:40.015Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:28:40.379Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:28:40.739Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "configure lifecycle hooks to run custom scripts at Kanban transition points",
        "benefit": "I can automate quality gates, testing, notifications, and CI/CD workflows throughout the ACDD process"
      },
      "rules": [
        "Hooks are configured in spec/fspec-hooks.json file",
        "Hook scripts live in spec/hooks/ directory",
        "Hooks trigger before and after Kanban state transitions (pre-* and post-*)",
        "Hooks can be blocking (prevent transition on failure) or non-blocking (run but don't block)",
        "Hooks receive work unit context as JSON via stdin",
        "Hooks can trigger on Example Mapping actions (add-rule, add-example, add-question, answer-question)",
        "Hooks can trigger on generation commands (generate-scenarios, generate-coverage, generate-foundation-md, generate-tags-md)",
        "Hooks can trigger on coverage operations (link-coverage, unlink-coverage, audit-coverage)",
        "Hooks can block create operations (prevent resource creation if conditions not met)",
        "Hooks can block delete operations (prevent accidental deletion of critical resources)",
        "Hooks can return structured system messages that fspec passes back to the AI agent",
        "Blocking hooks that fail will halt the command and return an error with the hook's system message",
        "Hook system messages can include instructions, warnings, suggestions, or error details for the AI to act upon",
        "Hooks can return structured feedback (JSON) that AI agents consume to improve ACDD workflow",
        "Hooks enforce ACDD ordering by blocking transitions when prerequisites are not met",
        "Hooks can spawn separate Claude Code sessions with specific personas (roles) for peer review and validation",
        "Multi-agent hooks enable AI pair programming with different expertise (reviewer, QA, security, BDD expert, product owner)",
        "fspec provides the hooks framework and execution engine, users write their own hook scripts",
        "Hook scripts can be in any language (bash, python, node, etc) as long as they are executable",
        "fspec passes work unit context to hooks via stdin (JSON) and environment variables",
        "Hook scripts return exit codes and optional JSON output to fspec for processing",
        "Hooks can trigger on program lifecycle events (startup and exit)",
        "Startup hooks run before command logic executes (for setup, validation, or blocking)",
        "Exit hooks receive command output and can intercept, modify, or augment the response before returning to user",
        "Sequential execution only. Hooks for the same event run one after another in the order defined in fspec-hooks.json. This provides predictable execution order, easier debugging, and allows later hooks to depend on earlier hooks' side effects.",
        "No skip mechanism. When a blocking hook fails, the command is blocked and the user must fix the issue. To bypass a hook, the user must edit spec/fspec-hooks.json to remove or disable it (more intentional than a flag). This maintains discipline and ensures hooks enforce their intended policies.",
        "Always run for all work units. No matcher system. This keeps the framework simple and predictable. If users need conditional execution, they can implement it inside their hook scripts by reading the work unit context and exiting early if conditions aren't met.",
        "Default timeout is 60 seconds (matching Claude Code). Hooks can override with 'timeout' field in fspec-hooks.json. Global default can be set in 'global.timeout'. When timeout is exceeded, the hook process is killed and an error is returned.",
        "Plain stdout/stderr only. Exit code determines success (0) or failure (non-zero). Hook output is displayed as-is to the user. If blocking hook fails (exit != 0), fspec shows stderr in a system-reminder block for AI agent consumption. This keeps hooks simple and works with any tool.",
        "No dry-run mode. Users can use 'fspec list-hooks' to see configured hooks and 'fspec validate-hooks' to validate configuration syntax. To test a hook, users can temporarily make it non-blocking or run it manually outside of fspec.",
        "CLI commands 'fspec add-hook' and 'fspec remove-hook' manage hooks in fspec-hooks.json programmatically",
        "No chaining. Each hook receives the same original work unit context via stdin. Hooks execute sequentially but independently. If users need chaining logic, they can implement it inside their hook scripts (e.g., read files left by previous hooks or use pipes within the script).",
        "No chaining for any hooks. All hooks (event hooks and exit hooks) receive the original context/output via stdin. Hooks execute sequentially but independently for side effects (validation, logging, notifications). The original command output is returned to the user unchanged by hooks.",
        "Hooks inherit the parent process environment naturally (as spawned child processes). fspec does NOT set custom FSPEC_* environment variables. Hooks receive all context via stdin as JSON. Hooks are independent programs that manage their own environment.",
        "Support optional conditions in hook configuration. Hooks can specify 'condition' object with fields like 'tags', 'prefix', 'epic', 'estimateMin', 'estimateMax'. If condition doesn't match, hook is skipped. If no condition specified, hook always runs. This allows context-aware hooks without requiring logic in every script.",
        "Support hooks for ANY fspec command using convention: 'pre-<command-name>' and 'post-<command-name>'. Examples: pre-create-work-unit, post-add-rule, pre-link-coverage, post-generate-scenarios. Plus special lifecycle hooks: pre-start (before any command) and pre-exit (before returning output). This makes the system extensible for current and future commands.",
        "Yes. When a blocking hook fails (exit code != 0), fspec wraps the stderr output in a <system-reminder> block for AI agent consumption. This allows hooks to provide guidance, suggestions, and instructions to AI through plain text stderr output. Non-blocking hooks just display output normally.",
        "No standard schema. Hooks output freeform text to stdout/stderr. AI agents read and interpret the text naturally. This maximizes flexibility for hook authors and keeps the framework simple. Documentation can provide examples of effective hook output patterns.",
        "No. fspec provides the hooks framework only. Users can implement multi-agent patterns (spawning multiple Claude sessions, parallel execution, etc.) in their hook scripts using standard shell tools. This keeps fspec focused and avoids framework bloat."
      ],
      "examples": [
        "Developer configures post-implementing hook to run ESLint before allowing transition to validating",
        "Developer configures post-testing hook to run Playwright tests to verify E2E scenarios work",
        "Developer configures post-done hook to send Slack notification that work unit is complete",
        "Developer configures pre-validating hook to check test coverage is above 80%",
        "Developer configures post-add-rule hook to check if rule needs clarification (AI analysis)",
        "Developer configures post-generate-scenarios hook to auto-format generated feature files",
        "Developer configures post-generate-coverage hook to run test suite with coverage reporter and extract actual line mappings",
        "Developer configures post-answer-question hook to automatically add answer as rule or assumption based on AI classification",
        "Developer configures pre-generate-scenarios hook to validate that all questions are answered before allowing scenario generation",
        "Developer configures post-link-coverage hook to verify linked files exist and line ranges are valid",
        "Developer configures pre-create-work-unit hook to block creation if work unit title contains placeholder text like TODO or TBD",
        "Developer configures pre-delete-work-unit hook to prevent deletion of work units with status 'implementing' or 'validating'",
        "Developer configures pre-unlink-coverage hook to confirm before removing coverage mappings (safety check)",
        "Developer configures pre-delete-scenario hook to block deletion if scenario has existing test coverage",
        "Code quality hook fails with message: 'BLOCKED: TypeScript errors in src/auth.ts:42. Fix type annotation for loginUser function before proceeding to validating state.'",
        "Coverage hook returns: 'WARNING: Test coverage is 65%, below 80% threshold. Consider adding tests for edge cases in src/validator.ts:23-45 before moving to validating.'",
        "Example mapping hook suggests: 'SUGGESTION: Question 0 contains implementation details. Consider rephrasing to focus on behavior: What should happen when... instead of How should we implement...'",
        "AI uses post-testing hook to analyze test failures and suggest missing scenarios or edge cases",
        "AI uses post-implementing hook to compare code against acceptance criteria and flag deviations",
        "AI uses post-generate-scenarios hook to review generated Gherkin and suggest improvements for clarity",
        "AI uses pre-implementing hook to verify all scenarios have corresponding test mappings before allowing code to be written",
        "AI uses post-add-example hook to detect duplicate or conflicting examples and suggest consolidation",
        "AI uses post-validating hook to analyze coverage gaps and suggest missing test scenarios",
        "Developer configures post-implementing hook to spawn a separate Claude Code session as a 'code reviewer' persona to review implementation before validating",
        "Developer configures post-generate-scenarios hook to spawn Claude Code as 'BDD expert' persona to critique Gherkin quality",
        "Developer configures post-testing hook to spawn Claude Code as 'QA engineer' persona to review test coverage and suggest edge cases",
        "Developer configures post-add-example hook to spawn Claude Code as 'product owner' persona to validate examples match business requirements",
        "Developer configures pre-done hook to spawn Claude Code as 'security auditor' persona to review code for security vulnerabilities",
        "User writes custom bash hook in spec/hooks/check-quality.sh that runs ESLint and returns JSON feedback",
        "User writes Python hook in spec/hooks/analyze-coverage.py that uses pytest-cov to generate coverage reports",
        "User writes Node.js hook in spec/hooks/validate-api.js that spawns separate Claude session for review",
        "User configures startup hook to validate project configuration and block fspec execution if settings are invalid",
        "User configures startup hook to initialize external services (database connection, API tokens) before fspec runs",
        "User configures exit hook to send fspec command results to external dashboard or logging service",
        "User configures exit hook to intercept validation errors and add project-specific troubleshooting guidance to AI agent",
        "User configures exit hook to format fspec output for different consumers (JSON for CI, markdown for humans, structured for AI)",
        "User runs 'fspec add-hook post-implementing code-quality spec/hooks/check-quality.sh --blocking' to add a new hook to configuration",
        "User runs 'fspec remove-hook post-implementing code-quality' to remove a hook from configuration"
      ],
      "questions": [
        {
          "text": "@human: Should hooks for the same event run in parallel (all at once) or sequentially (one after another)? Claude Code runs them in parallel.",
          "selected": true,
          "answer": "Sequential execution only. Hooks for the same event run one after another in the order defined in fspec-hooks.json. This provides predictable execution order, easier debugging, and allows later hooks to depend on earlier hooks' side effects."
        },
        {
          "text": "@human: When a blocking hook fails, should we provide a way for the user to override and force the transition anyway (like --skip-hooks flag)?",
          "selected": true,
          "answer": "No skip mechanism. When a blocking hook fails, the command is blocked and the user must fix the issue. To bypass a hook, the user must edit spec/fspec-hooks.json to remove or disable it (more intentional than a flag). This maintains discipline and ensures hooks enforce their intended policies."
        },
        {
          "text": "@human: Should hooks be able to match specific work units (e.g., only run for AUTH-* prefixes or specific epics)? Or always run for all work units?",
          "selected": true,
          "answer": "Always run for all work units. No matcher system. This keeps the framework simple and predictable. If users need conditional execution, they can implement it inside their hook scripts by reading the work unit context and exiting early if conditions aren't met."
        },
        {
          "text": "@human: What should the default timeout be? Claude Code uses 60 seconds. Should we allow per-hook timeout overrides?",
          "selected": true,
          "answer": "Default timeout is 60 seconds (matching Claude Code). Hooks can override with 'timeout' field in fspec-hooks.json. Global default can be set in 'global.timeout'. When timeout is exceeded, the hook process is killed and an error is returned."
        },
        {
          "text": "@human: Should hook scripts be able to return structured output (JSON) that fspec displays to the user, or just stdout/stderr?",
          "selected": true,
          "answer": "Plain stdout/stderr only. Exit code determines success (0) or failure (non-zero). Hook output is displayed as-is to the user. If blocking hook fails (exit != 0), fspec shows stderr in a system-reminder block for AI agent consumption. This keeps hooks simple and works with any tool."
        },
        {
          "text": "@human: Do you want a dry-run mode to test hooks without actually running them (just show what would execute)?",
          "selected": true,
          "answer": "No dry-run mode. Users can use 'fspec list-hooks' to see configured hooks and 'fspec validate-hooks' to validate configuration syntax. To test a hook, users can temporarily make it non-blocking or run it manually outside of fspec."
        },
        {
          "text": "@human: Should we support hook chaining where one hook's output becomes the next hook's input?",
          "selected": true,
          "answer": "No chaining for any hooks. All hooks (event hooks and exit hooks) receive the original context/output via stdin. Hooks execute sequentially but independently for side effects (validation, logging, notifications). The original command output is returned to the user unchanged by hooks."
        },
        {
          "text": "@human: What environment variables should be available to hooks? (e.g., FSPEC_WORK_UNIT_ID, FSPEC_STATUS, FSPEC_FEATURE_FILES, etc.)",
          "selected": true,
          "answer": "Hooks inherit the parent process environment naturally (as spawned child processes). fspec does NOT set custom FSPEC_* environment variables. Hooks receive all context via stdin as JSON. Hooks are independent programs that manage their own environment."
        },
        {
          "text": "@human: Should we support hook conditions (e.g., only run if estimate > 5 points, or only for @critical tagged features)?",
          "selected": true,
          "answer": "Support optional conditions in hook configuration. Hooks can specify 'condition' object with fields like 'tags', 'prefix', 'epic', 'estimateMin', 'estimateMax'. If condition doesn't match, hook is skipped. If no condition specified, hook always runs. This allows context-aware hooks without requiring logic in every script."
        },
        {
          "text": "@human: Do you want hooks for non-transition events like create-work-unit, add-dependency, or link-coverage?",
          "selected": true,
          "answer": "Support hooks for ANY fspec command using convention: 'pre-<command-name>' and 'post-<command-name>'. Examples: pre-create-work-unit, post-add-rule, pre-link-coverage, post-generate-scenarios. Plus special lifecycle hooks: pre-start (before any command) and pre-exit (before returning output). This makes the system extensible for current and future commands."
        },
        {
          "text": "@human: Should we have hooks that run on commands like create-work-unit, add-dependency, or prioritize-work-unit for workflow automation?",
          "selected": true,
          "answer": "Yes - already answered in Question 9. All fspec commands support pre/post hooks including create-work-unit, add-dependency, prioritize-work-unit, etc. This enables workflow automation like auto-prioritizing critical work units or validating dependencies."
        },
        {
          "text": "@human: Should hooks be able to provide AI-consumable feedback that influences the next steps (e.g., suggest missing scenarios, recommend refactoring)?",
          "selected": true,
          "answer": "Yes. When a blocking hook fails (exit code != 0), fspec wraps the stderr output in a <system-reminder> block for AI agent consumption. This allows hooks to provide guidance, suggestions, and instructions to AI through plain text stderr output. Non-blocking hooks just display output normally."
        },
        {
          "text": "@human: Should we provide a standard schema for hook output that includes 'suggestions', 'warnings', 'blockers', and 'insights' for AI consumption?",
          "selected": true,
          "answer": "No standard schema. Hooks output freeform text to stdout/stderr. AI agents read and interpret the text naturally. This maximizes flexibility for hook authors and keeps the framework simple. Documentation can provide examples of effective hook output patterns."
        },
        {
          "text": "@human: Should hooks support spawning multiple Claude Code sessions in parallel for multi-perspective review (e.g., security + performance + maintainability reviewers)?",
          "selected": true,
          "answer": "No. fspec provides the hooks framework only. Users can implement multi-agent patterns (spawning multiple Claude sessions, parallel execution, etc.) in their hook scripts using standard shell tools. This keeps fspec focused and avoids framework bloat."
        }
      ],
      "assumptions": [
        "Yes - already answered in Question 9. All fspec commands support pre/post hooks including create-work-unit, add-dependency, prioritize-work-unit, etc. This enables workflow automation like auto-prioritizing critical work units or validating dependencies."
      ],
      "estimate": 13,
      "epic": "hooks-system"
    },
    "HOOK-002": {
      "id": "HOOK-002",
      "title": "Hook configuration schema and validation",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:40.720Z",
      "updatedAt": "2025-10-15T11:57:55.780Z",
      "description": "Create JSON schema for spec/fspec-hooks.json. Implement configuration loading, validation, and error handling. Support hook definition with name, command, blocking flag, timeout, and conditions.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T11:50:26.414Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T11:53:06.432Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T11:55:57.393Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T11:56:34.878Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T11:57:55.781Z"
        }
      ],
      "userStory": {
        "role": "fspec developer",
        "action": "define hook configuration in spec/fspec-hooks.json",
        "benefit": "the hooks system knows which scripts to execute at which events"
      },
      "rules": [
        "Configuration file is spec/fspec-hooks.json in JSON format",
        "Each hook has: name (string), command (path to executable), blocking (boolean, default false), timeout (number in seconds, default 60)",
        "Hooks can have optional condition object with: tags (array), prefix (array), epic (string), estimateMin (number), estimateMax (number)",
        "Configuration must be valid JSON and conform to hooks schema",
        "Hook command paths must point to executable files",
        "Global defaults can be set in 'global' object: timeout, shell"
      ],
      "examples": [
        "Valid config with single hook: {hooks: {'post-implementing': [{name: 'lint', command: 'spec/hooks/lint.sh', blocking: true}]}}",
        "Hook with timeout override: {name: 'e2e-tests', command: 'test.sh', timeout: 300}",
        "Hook with conditions: {name: 'security', command: 'audit.sh', condition: {tags: ['@security'], prefix: ['AUTH']}}",
        "Invalid JSON causes validation error with helpful message",
        "Non-existent hook command path causes validation error",
        "Missing hook file returns clear error: 'Hook command not found: spec/hooks/missing.sh'"
      ]
    },
    "HOOK-003": {
      "id": "HOOK-003",
      "title": "Hook execution engine",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:44.580Z",
      "updatedAt": "2025-10-15T12:09:58.633Z",
      "description": "Implement core hook execution: spawn processes, pass context via stdin JSON, collect stdout/stderr, handle exit codes, implement 60s default timeout with override support, sequential execution of hooks.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:00:26.203Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:03:56.276Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:05:03.823Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:08:33.750Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:09:58.633Z"
        }
      ],
      "userStory": {
        "role": "fspec developer",
        "action": "execute hook scripts at lifecycle events",
        "benefit": "I can run custom automation, quality gates, and notifications during fspec commands"
      },
      "rules": [
        "Hook execution engine spawns child processes for each hook script",
        "Hook context is passed as JSON to stdin (workUnitId, event, timestamp, etc.)",
        "stdout and stderr are captured and displayed to user/AI agent",
        "Exit code 0 indicates success, non-zero indicates failure",
        "Hooks timeout after configured duration (default 60s)",
        "Blocking hooks halt command execution on failure (non-zero exit)",
        "Hooks execute sequentially in the order defined in config",
        "Hook processes inherit parent environment variables"
      ],
      "examples": [
        "Execute single non-blocking hook that succeeds (exit 0) - output shown, command continues",
        "Execute single non-blocking hook that fails (exit 1) - warning shown, command continues",
        "Execute blocking hook that fails - command halted, error returned to user/AI",
        "Hook times out after 60s - process killed, timeout error shown",
        "Hook receives context via stdin: {\"workUnitId\":\"AUTH-001\",\"event\":\"post-implementing\",\"timestamp\":\"2025-01-15T10:30:00Z\"}",
        "Multiple hooks execute sequentially - first runs to completion, then second starts",
        "Hook stdout/stderr captured and displayed: 'Running tests...' visible to user"
      ]
    },
    "HOOK-004": {
      "id": "HOOK-004",
      "title": "Hook discovery and event naming",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:48.300Z",
      "updatedAt": "2025-10-15T12:17:01.555Z",
      "description": "Implement hook discovery for any command using pre-/post- convention. Support special lifecycle hooks: pre-start and pre-exit. Build event name from command name dynamically.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:11:00.282Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:14:07.598Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:14:54.286Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:15:29.403Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:17:01.555Z"
        }
      ],
      "userStory": {
        "role": "fspec system",
        "action": "discover and execute hooks for lifecycle events",
        "benefit": "hooks can be triggered at the right moments during command execution"
      },
      "rules": [
        "Event names follow pre-/post- convention: pre-<command-name>, post-<command-name>",
        "Special lifecycle hooks: pre-start (before any command), pre-exit (before returning output)",
        "Hook discovery searches config.hooks for matching event name",
        "If no hooks match event name, return empty array (no error)",
        "Event names are case-sensitive (pre-implementing != pre-Implementing)",
        "Command name extraction: 'fspec update-work-unit-status' -> 'update-work-unit-status'"
      ],
      "examples": [
        "Discover hooks for 'post-implementing' event - returns array of matching hooks",
        "Discover hooks for 'pre-start' special lifecycle event - returns global pre-start hooks",
        "Discover hooks for non-existent event 'pre-xyz' - returns empty array (no error)",
        "Event name for command 'update-work-unit-status' generates 'pre-update-work-unit-status' and 'post-update-work-unit-status'",
        "Case-sensitive matching: 'post-implementing' finds hooks, 'post-Implementing' does not",
        "Multiple hooks for same event - returns all matching hooks in config order"
      ]
    },
    "HOOK-005": {
      "id": "HOOK-005",
      "title": "Hook condition evaluation",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:52.221Z",
      "updatedAt": "2025-10-15T12:24:15.115Z",
      "description": "Implement optional condition matching: tags, prefix, epic, estimateMin, estimateMax. Skip hook if conditions don't match. Support no condition = always run.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:17:45.705Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:21:11.809Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:22:27.203Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:23:05.811Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:24:15.116Z"
        }
      ],
      "userStory": {
        "role": "hook execution system",
        "action": "evaluate hook conditions to determine if a hook should run",
        "benefit": "hooks only execute when their conditions match the current context"
      },
      "rules": [
        "Hooks with no condition always match (condition is optional)",
        "Condition with tags: hook runs if work unit has ANY of the specified tags (OR logic)",
        "Condition with prefix: hook runs if work unit ID starts with ANY of the specified prefixes (OR logic)",
        "Condition with epic: hook runs if work unit belongs to specified epic",
        "Condition with estimateMin/estimateMax: hook runs if work unit estimate is within range",
        "Multiple condition fields use AND logic (all must match)",
        "If context has no workUnitId, only hooks without conditions run"
      ],
      "examples": [
        "Hook with no condition matches any context - always runs",
        "Hook with tags:[@security] matches work unit with @security tag",
        "Hook with prefix:[AUTH,SEC] matches AUTH-001 but not DASH-001",
        "Hook with epic:'user-management' matches work unit in that epic",
        "Hook with estimateMin:5, estimateMax:13 matches work unit with estimate 8",
        "Hook with tags:[@security] AND prefix:[AUTH] - both must match (AND logic)",
        "Context with no workUnitId - only unconditional hooks match"
      ]
    },
    "HOOK-006": {
      "id": "HOOK-006",
      "title": "System reminder formatting for AI",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:56.257Z",
      "updatedAt": "2025-10-15T12:32:11.238Z",
      "description": "When blocking hook fails, wrap stderr in <system-reminder> block for AI consumption. Display hook name, exit code, and error message. Include 'DO NOT mention this reminder to the user' footer.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:26:08.503Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:29:26.029Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:30:18.689Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:30:56.713Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:32:11.239Z"
        }
      ],
      "userStory": {
        "role": "fspec system",
        "action": "format blocking hook stderr as system-reminders for AI agents",
        "benefit": "AI agents receive actionable feedback when hooks fail"
      },
      "rules": [
        "Blocking hook stderr is wrapped in <system-reminder> tags",
        "Non-blocking hook stderr is displayed as-is (no wrapping)",
        "System-reminder content includes hook name, exit code, and stderr output",
        "Empty stderr produces no system-reminder (only if stderr has content)",
        "System-reminder is appended to command output (not replacing it)"
      ],
      "examples": [
        "Blocking hook fails with stderr 'Invalid config' - wrapped in system-reminder",
        "Non-blocking hook fails with stderr - displayed as-is, no wrapping",
        "Blocking hook succeeds - no system-reminder generated",
        "Blocking hook fails with empty stderr - no system-reminder",
        "System-reminder includes: hook name 'validate', exit code 1, stderr content"
      ]
    },
    "HOOK-007": {
      "id": "HOOK-007",
      "title": "Hook management CLI commands",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:45:00.480Z",
      "updatedAt": "2025-10-15T12:51:50.899Z",
      "description": "Implement: fspec list-hooks, fspec validate-hooks, fspec add-hook, fspec remove-hook. List shows all configured hooks. Validate checks config syntax. Add/remove modify fspec-hooks.json.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:42:06.760Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:47:49.741Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:48:36.967Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:49:21.484Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:51:50.899Z"
        }
      ],
      "userStory": {
        "role": "fspec user",
        "action": "manage hooks via CLI commands",
        "benefit": "I can list, validate, add, and remove hooks without manually editing JSON"
      },
      "rules": [
        "list-hooks command displays all configured hooks grouped by event",
        "validate-hooks command checks config syntax and verifies hook scripts exist",
        "add-hook command adds a hook to config and creates the event array if needed",
        "remove-hook command removes a hook by name and event",
        "Commands fail gracefully if spec/fspec-hooks.json does not exist",
        "add-hook command requires: name, event, command (path to script)"
      ],
      "examples": [
        "list-hooks displays: post-implementing: lint, test",
        "validate-hooks passes - all scripts exist, JSON valid",
        "validate-hooks fails - missing script spec/hooks/missing.sh",
        "add-hook --name lint --event post-implementing --command spec/hooks/lint.sh --blocking",
        "remove-hook --name lint --event post-implementing - hook removed from config",
        "list-hooks when no config file - displays friendly message"
      ]
    },
    "HOOK-008": {
      "id": "HOOK-008",
      "title": "Integrate hooks into all commands",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:45:04.467Z",
      "updatedAt": "2025-10-15T13:01:53.657Z",
      "description": "Add hook execution to every fspec command. Call runHooks() before/after command logic. Support pre-start lifecycle hook. Support pre-exit lifecycle hook. Pass appropriate context to each hook.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:56:41.998Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:58:43.162Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:59:55.073Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:00:34.477Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:01:53.657Z"
        }
      ],
      "userStory": {
        "role": "fspec CLI user",
        "action": "have hooks execute automatically with every command",
        "benefit": "I can enforce policies and automations without manually invoking hooks"
      },
      "rules": [
        "Commands execute pre- hooks before main logic and post- hooks after main logic",
        "Hook event names follow pattern: pre-{command} and post-{command}",
        "Hooks receive context with workUnitId (if applicable), event name, and timestamp",
        "Blocking hook failures prevent command execution (pre-hooks) or prevent exit with success (post-hooks)",
        "Non-blocking hook failures do not prevent command execution or success",
        "Hooks are filtered by conditions before execution (tags, prefix, epic, estimate)",
        "Hook output is displayed using formatHookOutput() with system-reminders for blocking failures"
      ],
      "examples": [
        "Command update-work-unit-status triggers pre-update-work-unit-status and post-update-work-unit-status hooks",
        "Pre-hook validates work unit has feature file before allowing status change to testing",
        "Post-hook runs tests after implementing status change",
        "Blocking pre-hook failure prevents command from executing",
        "Non-blocking post-hook failure allows command to succeed",
        "Hook with tag condition only runs for work units with matching tag",
        "Hook output formatted with system-reminder shows blocking hook failure details"
      ]
    },
    "HOOK-009": {
      "id": "HOOK-009",
      "title": "Hook system documentation and examples",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:45:08.399Z",
      "updatedAt": "2025-10-15T13:08:41.103Z",
      "description": "Write comprehensive documentation: configuration format, hook script examples (bash/python/node), best practices for output, example hooks for common use cases (linting, testing, notifications).",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T13:02:40.697Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T13:04:34.908Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T13:05:21.697Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:07:19.458Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:08:41.104Z"
        }
      ],
      "userStory": {
        "role": "fspec user writing hook scripts",
        "action": "have comprehensive documentation and working examples",
        "benefit": "I can quickly create custom hooks without trial and error"
      },
      "rules": [
        "Documentation explains hook configuration JSON schema with all fields",
        "Example hooks provided for bash, python, and node.js",
        "Documentation explains hook context JSON passed via stdin",
        "Best practices documented for stdout/stderr usage and exit codes",
        "Common use case examples: linting, testing, notifications, validation",
        "Documentation includes troubleshooting section for common errors"
      ],
      "examples": [
        "Configuration doc shows complete fspec-hooks.json with global defaults and multiple hooks",
        "Bash hook reads JSON context from stdin and validates work unit has feature file",
        "Python hook parses JSON stdin and runs pytest on work unit tests",
        "Node.js hook reads stdin and sends Slack notification about status change",
        "Lint hook example shows proper exit codes: 0 for success, 1 for lint errors",
        "Troubleshooting doc explains 'Hook command not found' error and solution"
      ]
    },
    "BUG-011": {
      "id": "BUG-011",
      "title": "generate-scenarios missing architecture docstring",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T22:51:07.833Z",
      "updatedAt": "2025-10-15T23:10:52.876Z",
      "description": "The generate-scenarios command creates feature files without architecture docstrings, violating CLAUDE.md requirements. Older files created with create-feature have docstrings, but newer files created with generate-scenarios are missing them.",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T22:51:16.440Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T22:53:06.162Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T22:53:45.139Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:09:40.344Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:10:52.876Z"
        }
      ],
      "userStory": {
        "role": "developer using generate-scenarios",
        "action": "have feature files with architecture docstrings",
        "benefit": "all feature files meet CLAUDE.md requirements and have consistent structure"
      },
      "rules": [
        "All feature files MUST have architecture docstrings (CLAUDE.md requirement)",
        "generate-scenarios output MUST match create-feature template structure",
        "Docstring MUST come before example mapping comments",
        "Docstring MUST include TODO placeholders for architecture notes"
      ],
      "examples": [
        "User runs generate-scenarios, file contains both docstring and example mapping comments",
        "Generated file matches structure: tags → feature → docstring → comments → background",
        "Existing tests pass with new docstring addition"
      ]
    },
    "FEAT-012": {
      "id": "FEAT-012",
      "title": "Capture architecture notes during Example Mapping",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T22:58:05.227Z",
      "updatedAt": "2025-10-15T23:23:02.738Z",
      "description": "Add ability to capture architecture notes and non-functional requirements during Example Mapping discovery phase, and populate feature file docstrings with this information during generate-scenarios.",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T22:58:14.705Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T23:15:36.150Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T23:16:21.173Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:21:08.805Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:23:02.739Z"
        }
      ],
      "userStory": {
        "role": "AI agent doing Example Mapping",
        "action": "capture architecture notes and non-functional requirements",
        "benefit": "generated feature files have complete technical context in docstrings"
      },
      "rules": [
        "Architecture notes must be stored in WorkUnit during Example Mapping",
        "Architecture notes must populate docstring in generate-scenarios output",
        "Must support adding/removing/viewing architecture notes via CLI",
        "Architecture notes should include: dependencies, performance reqs, security considerations, implementation constraints"
      ],
      "examples": [
        "User runs 'fspec add-architecture-note WORK-001 \"Uses @cucumber/gherkin parser\"' during Example Mapping",
        "User runs 'fspec generate-scenarios WORK-001' and docstring contains captured architecture notes instead of TODO placeholders",
        "User runs 'fspec show-work-unit WORK-001' and sees architecture notes section with all captured notes",
        "Generated docstring includes sections for dependencies, performance, security based on captured notes"
      ],
      "questions": [
        {
          "text": "@human: Should architectureNotes be a separate array field in WorkUnit, or reuse assumptions field?",
          "selected": true,
          "answer": "Separate architectureNotes array field in WorkUnit (clearer separation from assumptions)"
        },
        {
          "text": "@human: Should we ask about architecture notes as a separate Example Mapping step (purple cards), or integrate with existing steps?",
          "selected": true,
          "answer": "Integrate with existing steps - ask architecture questions during Step 3 (Ask Questions phase) for natural flow"
        },
        {
          "text": "@human: What specific NFR questions should AI ask during discovery? (performance, security, dependencies, scalability, etc.)",
          "selected": true,
          "answer": "Ask about: libraries/dependencies, code that should be refactored/shared, code quality considerations, UI/UX examples (websites/screenshots), implementation patterns to follow"
        },
        {
          "text": "@human: Should architecture notes have categories/types, or just be free-form strings?",
          "selected": true,
          "answer": "Free-form strings initially - users can prefix naturally (e.g., 'Dependency: ...', 'Refactoring: ...'). Add categorization later if needed."
        }
      ]
    },
    "FEAT-013": {
      "id": "FEAT-013",
      "title": "Attachment support for discovery process",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T23:42:01.192Z",
      "updatedAt": "2025-10-15T23:47:36.516Z",
      "description": "Add ability to attach files (diagrams, mockups, documents) to work units during Example Mapping to supplement architecture notes and NFRs",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T23:42:21.297Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T23:42:57.989Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T23:43:10.317Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:43:11.875Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:44:54.141Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-15T23:46:00.822Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T23:46:24.484Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T23:47:32.452Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:47:34.074Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:47:36.517Z"
        }
      ],
      "userStory": {
        "role": "AI agent or developer using fspec",
        "action": "attach files to work units during Example Mapping",
        "benefit": "I can supplement architecture notes and NFRs with diagrams, mockups, and documents"
      },
      "rules": [
        "Attachments must be stored in spec/attachments/<work-unit-id>/ directory",
        "Attachment paths must be stored as relative paths from project root",
        "Source file must exist before copying to attachments directory"
      ],
      "examples": [
        "User runs 'fspec add-attachment AUTH-001 diagrams/auth-flow.png', file is copied to spec/attachments/AUTH-001/ and tracked in work unit",
        "User runs 'fspec list-attachments AUTH-001', sees all attached files with sizes and modification dates",
        "User runs 'fspec remove-attachment AUTH-001 diagram.png', file is deleted and tracking entry removed"
      ],
      "architectureNotes": [
        "Attachments array added to WorkUnit interface in src/types/index.ts",
        "Three new commands: add-attachment, list-attachments, remove-attachment",
        "Uses fs/promises for file operations (copyFile, stat, unlink)"
      ]
    },
    "HOOK-010": {
      "id": "HOOK-010",
      "title": "Migrate hook execution to use execa library",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T00:49:47.693Z",
      "updatedAt": "2025-10-16T01:18:17.009Z",
      "description": "Replace Node.js child_process.spawn with execa library for hook execution, following the patterns used in the cage project for better process management and cross-platform compatibility",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T00:49:52.619Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T00:55:20.542Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T00:57:07.118Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T01:06:35.448Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T01:18:17.009Z"
        }
      ],
      "userStory": {
        "role": "fspec developer",
        "action": "use execa for hook execution instead of child_process.spawn",
        "benefit": "better process management, improved error handling, and cross-platform compatibility"
      },
      "rules": [
        "Hook execution must maintain timeout behavior (default 60s)",
        "Hook context must be passed to stdin as JSON",
        "stdout and stderr must be captured separately",
        "Hook execution results must include hookName, success, exitCode, stdout, stderr, timedOut, duration",
        "execa library must be installed as a dependency",
        "All existing hook tests must continue to pass",
        "Non-detached behavior - hooks run attached to fspec process",
        "Keep custom timeout implementation integrated with execa - use AbortController signal to cancel subprocess",
        "Use execa's input option for passing JSON context - it's the best practice and handles stream management automatically"
      ],
      "examples": [
        "Hook executes successfully and returns exitCode 0 with captured stdout/stderr",
        "Hook times out after configured timeout period and is killed",
        "Hook fails with non-zero exit code and error message in stderr",
        "Hook receives context via stdin as JSON string",
        "Multiple hooks execute sequentially in order"
      ],
      "architectureNotes": [
        "Use execa library (same as cage project) for better process management",
        "Modify src/hooks/executor.ts executeHook() function",
        "Install execa as dependency in package.json",
        "Reference cage's server.ts implementation for execa usage patterns"
      ],
      "questions": [
        {
          "text": "@human: Should we support detached processes like cage does for server.ts, or keep the current non-detached behavior?",
          "selected": true,
          "answer": "Non-detached behavior - hooks run attached to fspec process"
        },
        {
          "text": "@human: Should we use execa's built-in timeout option or keep the custom timeout implementation?",
          "selected": true,
          "answer": "Keep custom timeout implementation integrated with execa - use AbortController signal to cancel subprocess"
        },
        {
          "text": "@human: Should we use execa's input option for passing context or stick with stdin.write()?",
          "selected": true,
          "answer": "Use execa's input option for passing JSON context - it's the best practice and handles stream management automatically"
        }
      ],
      "estimate": 3
    },
    "TEST-004": {
      "id": "TEST-004",
      "title": "Write missing tests for partially covered features",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-16T01:54:24.619Z",
      "updatedAt": "2025-10-16T11:07:03.554Z",
      "description": "Complete test coverage for 3 features: architecture-notes-in-example-mapping (2 scenarios), generate-scenarios-include-architecture-docstring (1 scenario), and preserve-example-mapping-context-as-comments-in-generated-feature-files (11 scenarios). Total: 14 uncovered scenarios that need tests.",
      "children": [],
      "estimate": 8,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T10:32:36.675Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T10:40:42.515Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T10:50:27.809Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T10:50:43.392Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T10:57:29.589Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T11:07:03.243Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T11:07:03.554Z"
        }
      ],
      "questions": [
        {
          "text": "@human: For these uncovered scenarios, should I write (A) full test implementations (traditional forward ACDD) or (B) skeleton tests (reverse ACDD style - structure only with TODOs)?",
          "selected": true,
          "answer": "Forward ACDD where there's no implementation/tests, reverse ACDD where there's no tests/features"
        },
        {
          "text": "@human: Should I examine the implementation files (e.g., generate-scenarios.ts, show-work-unit.ts) to infer what the tests should validate for scenarios that have existing code?",
          "selected": true,
          "answer": "Yes, examine implementation files to infer what the tests should validate. Figure out what code the test is running by analyzing existing implementation."
        },
        {
          "text": "@human: Are there any specific testing patterns or conventions in this codebase I should follow when writing tests for the generate-scenarios and example mapping commands?",
          "selected": true,
          "answer": "Follow the ACDD process - no special testing patterns beyond what's defined in CLAUDE.md"
        },
        {
          "text": "@human: I see the third feature has 11 uncovered scenarios. Should I tackle all 14 scenarios (2 from architecture-notes + 1 from generate-scenarios-include-architecture + 11 from preserve-example-mapping) in this single work unit, or should I break this into smaller work units?",
          "selected": true,
          "answer": "Do all 14 scenarios in one work unit - don't break it up"
        }
      ],
      "rules": [
        "Forward ACDD where there's no implementation/tests, reverse ACDD where there's no tests/features",
        "Yes, examine implementation files to infer what the tests should validate. Figure out what code the test is running by analyzing existing implementation.",
        "Do all 14 scenarios in one work unit - don't break it up"
      ],
      "assumptions": [
        "Follow the ACDD process - no special testing patterns beyond what's defined in CLAUDE.md"
      ],
      "examples": [
        "For 'View architecture notes in work unit' scenario - check show-work-unit command displays architecture notes added during example mapping",
        "For scenarios in preserve-example-mapping feature - test that add-scenario and add-background commands don't remove existing example mapping comments"
      ]
    },
    "FOUND-001": {
      "id": "FOUND-001",
      "title": "Design Generic Foundation Schema",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:12:53.931Z",
      "updatedAt": "2025-10-17T00:05:44.115Z",
      "description": "Create new TypeScript types and JSON schema for generic PRD structure focusing on WHY and WHAT",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:13:02.563Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T23:23:00.347Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:00:17.011Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T00:05:04.272Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T00:05:44.116Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for any project type",
        "action": "create a generic foundation document that captures WHY and WHAT",
        "benefit": "I have clear product requirements without mixing in implementation details"
      },
      "questions": [],
      "assumptions": [
        "Unlimited personas allowed, but suggest 3-7 in documentation as best practice. No hard limits enforced by schema."
      ],
      "rules": [
        "Multiple problems supported. Complex products can have thousands of problems. Foundation.json can reference external sub-foundation documents for scalability (all built from single foundation.json). This creates a hierarchical PRD structure.",
        "Broad capabilities only (3-7 high-level abilities). Granular features belong in .feature files. Example: 'User Authentication' is a capability in foundation.json, 'Login with OAuth' is a feature in user-authentication.feature.",
        "REQUIRED: project identity, problem statement, solution overview. OPTIONAL: architecture diagrams, constraints, detailed personas. This ensures minimum viable PRD while allowing detailed documentation.",
        "Schema must focus ONLY on WHY (problem) and WHAT (solution), never HOW (implementation)",
        "Schema must work for ANY project type: web apps, CLI tools, libraries, services, mobile apps",
        "Mermaid diagram validation must be preserved from current implementation",
        "JSON Schema must use Ajv for validation with clear error messages"
      ],
      "examples": [
        "Web app foundation includes personas: 'End User', 'Admin', 'API Consumer'",
        "CLI tool foundation includes persona: 'Developer using CLI in terminal'",
        "Library foundation includes persona: 'Developer integrating library into their codebase'",
        "Problem space includes multiple problems with impact ratings (high/medium/low)",
        "Solution includes 3-7 high-level capabilities like 'User Authentication', 'Data Visualization', 'API Integration'",
        "Foundation.json can reference sub-foundations: { 'subFoundations': ['spec/foundations/auth-subsystem.foundation.json'] }"
      ],
      "architectureNotes": [
        "TypeScript interfaces must map exactly to JSON Schema definitions",
        "Use Ajv with ajv-formats for validation (uri, email, date-time formats)",
        "Hierarchical foundations: parent foundation.json can reference child foundations in subFoundations array",
        "Migration path needed: old schema → new schema with backward compatibility flag",
        "Mermaid validation must use mermaid.parse() with jsdom (existing pattern)"
      ]
    },
    "FOUND-002": {
      "id": "FOUND-002",
      "title": "Implement Automated Discovery - Code Analysis",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:35.741Z",
      "updatedAt": "2025-10-17T00:38:38.932Z",
      "description": "Scan existing codebase to infer project type, personas, and capabilities using reverse ACDD techniques",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 8,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T00:09:59.672Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T00:29:37.164Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:34:52.164Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T00:37:07.269Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T00:38:38.932Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec to document an existing codebase",
        "action": "automatically discover project structure and infer personas/capabilities",
        "benefit": "I can quickly bootstrap a foundation document without manual analysis"
      },
      "rules": [
        "Code analysis must detect project type (web app, CLI tool, library, service, mobile app, desktop app, API)",
        "Code analysis must infer personas from user-facing interactions (routes, commands, UI components, API endpoints)",
        "Code analysis must infer capabilities from code structure (high-level features, not implementation details)",
        "Analysis must be fast enough for interactive use (< 5 seconds for typical projects)",
        "fspec provides GUIDANCE to AI, not implementation - AI decides how to analyze code",
        "Discovery must infer: project type, personas, capabilities, AND problems/pain points",
        "Support monorepos - AI analyzes all packages that are part of the same project"
      ],
      "examples": [
        "CLI tool with commander.js commands → project type: cli-tool, persona: Developer using CLI",
        "Express.js with /api routes → project type: web-app, personas: API Consumer, End User",
        "Package with exports in package.json → project type: library, persona: Developer integrating library",
        "React components in src/ → capability: User Interface, not implementation detail like 'Uses React hooks'",
        "AI discovers React app → infers problem: 'Users need interactive web UI' not 'Code needs React'"
      ],
      "questions": [
        {
          "text": "@human: Should code analysis support monorepos with multiple package.json files, or just single-project repositories?",
          "selected": true,
          "answer": "Yes, support monorepos - analyze all package.json files that are part of the same project"
        },
        {
          "text": "@human: What file patterns should we analyze to detect project type? (package.json, tsconfig.json, Cargo.toml, go.mod, etc.)",
          "selected": true,
          "answer": "AI decides file patterns - fspec guides AI to discover project type using available clues, not prescriptive tool list"
        },
        {
          "text": "@human: Should we infer problems/pain points from code, or only project type and personas?",
          "selected": true,
          "answer": "Yes, infer everything: project type, personas, capabilities, AND problems/pain points - all critical for complete foundation"
        },
        {
          "text": "@human: How deep should directory traversal go? Should we limit to specific directories (src/, lib/, cmd/) or scan entire project?",
          "selected": true,
          "answer": "AI decides traversal depth - fspec guides AI to intelligently explore codebase, not prescriptive directory limits"
        }
      ]
    },
    "FOUND-003": {
      "id": "FOUND-003",
      "title": "Implement Interactive Questionnaire",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:36.482Z",
      "updatedAt": "2025-10-17T00:55:12.776Z",
      "description": "Build Ink-based CLI questionnaire to gather WHY/WHAT information from users",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:20:17.487Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T00:45:42.074Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:47:44.622Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T00:54:48.957Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T00:55:12.776Z"
        }
      ],
      "architectureNotes": [
        "Questionnaire must guide AI through structured discovery workflow with specific question templates",
        "Section 1: Vision Questions - 'What is the core purpose?', 'Who are the primary users?', 'What problem does this solve?'",
        "Section 2: Problem Space - 'What are the top 3-5 pain points?', 'What is the impact?', 'What is the frequency?'",
        "Section 3: Solution Space - 'What are the 3-7 key capabilities?', 'What makes this solution unique?', 'What is out of scope?'",
        "Section 4: Architecture - 'What is the tech stack?' (optional if detected), 'What are system boundaries?', 'What are external dependencies?'",
        "Section 5: Constraints - 'Business constraints?', 'Technical constraints?', 'Timeline/budget constraints?'",
        "Prefill mode: If code analysis detected values, show as defaults with [DETECTED] tag, allow AI to confirm/edit/skip",
        "AI guidance: Each question includes HELP text explaining WHY it's asked and EXAMPLES of good answers"
      ],
      "rules": [
        "Questions must be grouped by section with progress indicator (Question 3 of 15)",
        "Must support both prefilled mode (--from-discovery) and blank slate (--interactive)",
        "Must validate answers before accepting (e.g. non-empty strings, valid format)"
      ],
      "examples": [
        "Vision question with help: 'What is the core purpose? [HELP: One sentence elevator pitch. Example: fspec helps AI agents follow ACDD workflow]'",
        "Prefilled answer: 'Primary user: Developer using CLI [DETECTED from code analysis] - Keep/Edit/Skip?'"
      ],
      "userStory": {
        "role": "developer using fspec with AI to bootstrap foundation documents",
        "action": "gather WHY/WHAT information through structured questionnaire",
        "benefit": "I can create complete foundation.json without manual analysis"
      }
    },
    "FOUND-004": {
      "id": "FOUND-004",
      "title": "Implement discover-foundation Command",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:37.238Z",
      "updatedAt": "2025-10-17T01:01:53.733Z",
      "description": "Orchestrate code analysis + questionnaire to generate foundation.json with validation",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 8,
      "dependsOn": [
        "FOUND-001",
        "FOUND-002",
        "FOUND-003"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:20:49.620Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T00:58:37.167Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:59:52.936Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:01:33.811Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:01:53.733Z"
        }
      ],
      "architectureNotes": [
        "System-reminder integration: Wrap questionnaire output in <system-reminder> tags when running in AI context (detectable via environment)",
        "System-reminder triggers: (1) After code analysis completes - show detected personas/capabilities (2) During questionnaire - provide examples of good answers (3) After foundation.json generated - next steps guidance",
        "System-reminder content: 'Code analysis detected 3 personas [list]. Review and confirm during questionnaire. Focus on WHY/WHAT, not HOW. See CLAUDE.md for boundary guidance.'"
      ],
      "rules": [
        "Must emit system-reminders to guide AI through discovery process (persona review, WHY/WHAT boundary, next steps)"
      ],
      "examples": [
        "After code analysis: <system-reminder>Detected 3 user personas from routes: End User, Admin, API Consumer. Review in questionnaire. Use 'fspec show-work-unit FOUND-002' for details.</system-reminder>"
      ],
      "userStory": {
        "role": "developer using fspec with AI to bootstrap foundation documents",
        "action": "run discover-foundation command to orchestrate analysis and questionnaire",
        "benefit": "I get a complete validated foundation.json without manual work"
      }
    },
    "FOUND-005": {
      "id": "FOUND-005",
      "title": "Migrate Existing foundation.json",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:38.001Z",
      "updatedAt": "2025-10-17T01:09:17.482Z",
      "description": "Extract WHY/WHAT from current fspec foundation.json, move HOW content elsewhere, automated migration",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 3,
      "dependsOn": [
        "FOUND-001"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T01:03:24.343Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T01:05:56.004Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:07:10.808Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:08:03.028Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:09:17.482Z"
        }
      ],
      "userStory": {
        "role": "developer migrating fspec to generic foundation schema",
        "action": "migrate existing foundation.json to v2.0.0 format",
        "benefit": "foundation document follows the new generic schema and supports all project types"
      },
      "rules": [
        "Must preserve all existing architecture diagrams in architectureDiagrams array",
        "WHY/WHAT content stays in foundation.json, HOW content moves to CLAUDE.md or other docs",
        "Migration must be automated via CLI command 'fspec migrate-foundation'",
        "Migrated foundation.json must pass generic foundation schema validation"
      ],
      "examples": [
        "Current 'whatWeAreBuilding.projectOverview' maps to 'project.vision'",
        "Current 'whyWeAreBuildingIt.problemDefinition.primary' maps to 'problemSpace.primaryProblem'",
        "Current 'architectureDiagrams' array preserved as-is (already compatible)",
        "HOW content like 'technicalRequirements.coreTechnologies' moves to CLAUDE.md"
      ]
    },
    "FOUND-006": {
      "id": "FOUND-006",
      "title": "Update Documentation and Help",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:38.837Z",
      "updatedAt": "2025-10-17T01:23:48.715Z",
      "description": "Update CLAUDE.md, help system, and create discovery guide with examples",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 3,
      "dependsOn": [
        "FOUND-004"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T01:09:42.788Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T01:11:37.151Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:12:53.339Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:12:53.748Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:14:09.494Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:16:23.508Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:23:09.031Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:23:48.716Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for foundation document discovery",
        "action": "have comprehensive documentation and help for discovery commands",
        "benefit": "I can effectively use discover-foundation, questionnaire, and code analysis features"
      },
      "rules": [
        "CLAUDE.md must document discover-foundation workflow with examples",
        "Help system must have comprehensive --help output for discover-foundation command",
        "Discovery guide must explain code analysis patterns (CLI tool, web app, library)",
        "Documentation must show integration with Example Mapping workflow"
      ],
      "examples": [
        "CLAUDE.md shows: 'Run discover-foundation to analyze codebase and generate foundation.json'",
        "Help output includes WHEN TO USE, WORKFLOW, and EXAMPLES sections",
        "Discovery guide explains CLI tool pattern: bin field in package.json, commander usage"
      ]
    },
    "BUG-012": {
      "id": "BUG-012",
      "title": "Fix show-epic command returning undefined",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-16T23:24:12.754Z",
      "updatedAt": "2025-10-16T23:28:27.652Z",
      "description": "The show-epic command accepts invalid epic IDs and returns 'undefined' for epic and title instead of showing proper error message or help text",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:25:18.576Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T23:25:51.736Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T23:26:50.136Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T23:27:29.673Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T23:28:27.652Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "see a clear error when querying non-existent epics",
        "benefit": "I understand what went wrong and how to fix it"
      },
      "rules": [
        "Command must validate epic ID exists before attempting to display",
        "Must show clear error message with epic ID when not found",
        "Must exit with non-zero code on error"
      ],
      "examples": [
        "Run 'fspec show-epic invalid-epic' shows error: Epic 'invalid-epic' not found",
        "Error message suggests 'fspec list-epics' to see available epics",
        "Valid epic ID works correctly: 'fspec show-epic user-management' displays epic details"
      ]
    },
    "BUG-013": {
      "id": "BUG-013",
      "title": "Prevent story point estimation before feature file completion",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:34:28.036Z",
      "updatedAt": "2025-10-16T23:44:51.565Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:34:32.599Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T23:36:34.521Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T23:37:23.155Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T23:44:34.790Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T23:44:51.565Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec",
        "action": "be prevented from estimating story points before feature file is complete",
        "benefit": "I follow ACDD properly and estimate based on actual acceptance criteria"
      },
      "rules": [
        "Story and Bug work units CANNOT be estimated until feature file exists and is complete (specifying phase finished)",
        "Task work units CAN be estimated at any stage (tasks don't require feature files)",
        "When AI attempts invalid estimation, emit system-reminder explaining ACDD estimation rules",
        "Estimation requires completed feature file to understand complexity from acceptance criteria"
      ],
      "examples": [
        "Story work unit AUTH-001 in 'backlog' state with no feature file → estimation BLOCKED with system-reminder",
        "Story work unit AUTH-001 in 'testing' state with completed feature file → estimation ALLOWED",
        "Task work unit TASK-001 in 'backlog' state with no feature file → estimation ALLOWED (tasks exempt)",
        "Bug work unit BUG-001 in 'specifying' state but feature file has placeholders → estimation BLOCKED until prefill removed"
      ],
      "architectureNotes": [
        "Check work unit type: if type='task', skip validation (tasks don't require feature files)",
        "For story/bug types: find linked feature file via work unit ID tag (e.g., @AUTH-001)",
        "If no feature file found OR file has prefill placeholders, block estimation and emit system-reminder",
        "System-reminder should explain: ACDD requires feature file completion before estimation, suggest completing specifying phase first",
        "Reuse existing prefill detection logic from temporal validation (similar pattern)"
      ],
      "estimate": 2
    },
    "FOUND-007": {
      "id": "FOUND-007",
      "title": "Foundation existence check in commands",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-17T01:22:59.515Z",
      "updatedAt": "2025-10-17T01:49:42.199Z",
      "description": "Add check for foundation.json existence in key commands (board, create-work-unit, etc.). Commands should exit with helpful message if foundation.json missing, directing user to run discover-foundation first. CRITICAL: System reminder must tell AI agent to return to the original task after completing discover-foundation command.",
      "epic": "foundation-document-redesign",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T01:25:10.420Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T01:30:47.830Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:32:38.194Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:38:39.487Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:38:58.984Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:43:25.715Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:49:24.427Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:49:42.199Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec",
        "action": "ensure foundation.json exists before running project management commands",
        "benefit": "I prevent work from proceeding without proper project foundation and can resume my original task after discovery"
      },
      "rules": [
        "Commands that manage work units MUST check for foundation.json existence before executing",
        "If foundation.json is missing, command MUST exit with error code 1 and display helpful message",
        "Error message MUST direct user to run 'fspec discover-foundation' command",
        "System reminder MUST tell AI agent to return to original task after discover-foundation completes",
        "Check applies to: fspec board, create-work-unit, update-work-unit-status, create-epic, and other PM commands",
        "Yes, include exact command arguments. System reminders in Claude Code are used for actionable guidance - including the original command makes it clear what to retry after discover-foundation completes.",
        "No, only create/modify commands need foundation.json. Read-only commands like show-foundation, list-features, validate can run without foundation.json.",
        "Check only spec/foundation.json - this is the canonical location used by show-foundation, update-foundation, and generate-foundation-md commands."
      ],
      "examples": [
        "AI runs 'fspec board' without foundation.json → Command exits with error, displays message with discover-foundation instructions, system reminder tells AI to run board again after discovery",
        "AI runs 'fspec create-work-unit AUTH \"Login\"' without foundation.json → Command exits with error, system reminder includes original command to retry",
        "AI runs 'fspec board' with foundation.json present → Command executes normally, no check triggered",
        "AI runs 'fspec validate' (non-PM command) without foundation.json → Command executes normally, foundation check not required for spec-only commands"
      ],
      "questions": [
        {
          "text": "@human: Should the system reminder include the exact command arguments that were originally attempted?",
          "selected": true,
          "answer": "Yes, include exact command arguments. System reminders in Claude Code are used for actionable guidance - including the original command makes it clear what to retry after discover-foundation completes."
        },
        {
          "text": "@human: Should read-only commands like 'fspec show-foundation' also require foundation.json, or only commands that create/modify work units?",
          "selected": true,
          "answer": "No, only create/modify commands need foundation.json. Read-only commands like show-foundation, list-features, validate can run without foundation.json."
        },
        {
          "text": "@human: Should the check look for BOTH foundation.json AND spec/foundation.json paths, or just spec/foundation.json?",
          "selected": true,
          "answer": "Check only spec/foundation.json - this is the canonical location used by show-foundation, update-foundation, and generate-foundation-md commands."
        }
      ],
      "estimate": 3
    }
  },
  "states": {
    "backlog": [],
    "specifying": [],
    "testing": [],
    "implementing": [],
    "validating": [],
    "done": [
      "BUG-007",
      "BUG-008",
      "EXMAP-001",
      "INIT-001",
      "DEP-001",
      "EST-001",
      "QRY-001",
      "CLI-001",
      "SPEC-001",
      "FEAT-001",
      "FEAT-002",
      "FEAT-003",
      "FEAT-004",
      "FEAT-005",
      "TEST-001",
      "INIT-002",
      "BOARD-001",
      "CLI-002",
      "SAFE-001",
      "REMIND-001",
      "SAFE-002",
      "CLI-003",
      "TEST-002",
      "TEST-003",
      "DOC-001",
      "BUG-001",
      "BUG-002",
      "CLI-004",
      "INIT-003",
      "DOC-002",
      "RSPEC-001",
      "BUG-003",
      "CLI-005",
      "CLI-006",
      "BUG-004",
      "REMIND-003",
      "REMIND-002",
      "REMIND-008",
      "COV-002",
      "COV-004",
      "COV-003",
      "BUG-005",
      "COV-005",
      "COV-006",
      "BUG-006",
      "COV-001",
      "REMIND-004",
      "REMIND-005",
      "REMIND-006",
      "REMIND-007",
      "COV-007",
      "COV-008",
      "DOC-003",
      "COV-010",
      "COV-011",
      "COV-012",
      "COV-013",
      "COV-014",
      "COV-015",
      "COV-016",
      "COV-017",
      "COV-018",
      "COV-019",
      "COV-020",
      "COV-021",
      "COV-022",
      "COV-023",
      "COV-024",
      "COV-025",
      "COV-026",
      "COV-027",
      "COV-028",
      "COV-029",
      "COV-030",
      "COV-032",
      "COV-034",
      "COV-035",
      "COV-036",
      "COV-037",
      "COV-039",
      "COV-040",
      "COV-041",
      "COV-042",
      "COV-043",
      "COV-044",
      "COV-045",
      "COV-049",
      "COV-050",
      "COV-051",
      "COV-046",
      "COV-047",
      "COV-048",
      "COV-031",
      "COV-033",
      "COV-038",
      "FEAT-006",
      "FEAT-011",
      "BUG-009",
      "DOC-004",
      "BUG-010",
      "EXMAP-002",
      "HOOK-002",
      "HOOK-003",
      "HOOK-004",
      "HOOK-005",
      "HOOK-006",
      "HOOK-007",
      "HOOK-008",
      "HOOK-009",
      "EXMAP-003",
      "HOOK-001",
      "BUG-011",
      "FEAT-012",
      "FEAT-013",
      "HOOK-010",
      "TEST-004",
      "BUG-012",
      "BUG-013",
      "FOUND-001",
      "FOUND-002",
      "FOUND-003",
      "FOUND-004",
      "FOUND-005",
      "FOUND-006",
      "FOUND-007"
    ],
    "blocked": []
  }
}