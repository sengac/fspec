{
  "meta": {
    "version": "1.0.0",
    "lastUpdated": "2025-10-28T05:14:23.264Z"
  },
  "workUnits": {
    "EXMAP-001": {
      "id": "EXMAP-001",
      "title": "Redesign Example Mapping to match BDD technique",
      "status": "done",
      "createdAt": "2025-10-10T22:58:36.526Z",
      "updatedAt": "2025-10-10T23:20:00.252Z",
      "description": "Current implementation is wrong - operates on work units instead of stories. Need to redesign to follow 4-card system (yellow story, blue rules, green examples, red questions) that happens BEFORE writing feature files. Example Mapping should help discover what scenarios to write, not modify existing ones.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T22:58:42.985Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:05:16.853Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:19:16.805Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:19:26.991Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:20:00.252Z"
        }
      ]
    },
    "INIT-001": {
      "id": "INIT-001",
      "title": "Add ensureWorkUnitsFile to ALL 48+ commands",
      "status": "done",
      "createdAt": "2025-10-10T23:23:00.738Z",
      "updatedAt": "2025-10-10T23:30:22.581Z",
      "description": "Following EXMAP-001 pattern, add ensureWorkUnitsFile/ensurePrefixesFile/ensureEpicsFile utilities to ALL commands that read JSON files. This prevents ENOENT errors and improves first-time user experience.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:23:13.046Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:24:25.195Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:30:08.298Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:30:09.868Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:30:22.581Z"
        }
      ],
      "rules": [
        "ALL commands that read spec/work-units.json MUST use ensureWorkUnitsFile",
        "ALL commands that read spec/prefixes.json MUST use ensurePrefixesFile",
        "ALL commands that read spec/epics.json MUST use ensureEpicsFile",
        "Ensure utilities MUST be idempotent - safe to call multiple times",
        "NO command should fail with ENOENT errors when JSON files missing"
      ],
      "examples": [
        "Create epic command auto-creates spec/epics.json when missing",
        "Create prefix command auto-creates spec/prefixes.json when missing",
        "List work units command auto-creates spec/work-units.json when missing",
        "Update work unit command uses ensureWorkUnitsFile instead of direct readFile",
        "Calling ensureWorkUnitsFile multiple times returns same data without overwriting"
      ],
      "questions": [],
      "assumptions": [
        "No - tags.json and foundation.json already auto-create via register-tag and add-diagram commands"
      ]
    },
    "CLI-001": {
      "id": "CLI-001",
      "title": "Verify all CLI commands and help system complete",
      "status": "done",
      "createdAt": "2025-10-10T23:34:14.426Z",
      "updatedAt": "2025-10-11T02:09:46.737Z",
      "description": "VERIFIED: 84 commands registered, help system comprehensive and accurate, all validation checks passing",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:09:01.564Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:09:45.913Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:09:46.189Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:09:46.463Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:09:46.737Z"
        }
      ],
      "rules": [
        "ALL 84 commands MUST be registered in src/index.ts with proper CLI bindings",
        "MUST have comprehensive help text for each command",
        "MUST pass all validation checks (build, validate, validate-tags)"
      ],
      "examples": [
        "All commands registered and accessible",
        "Help system shows all commands",
        "Build succeeds with no errors"
      ]
    },
    "DEP-001": {
      "id": "DEP-001",
      "title": "Work Unit Dependency Management",
      "status": "done",
      "createdAt": "2025-10-10T23:39:22.582Z",
      "updatedAt": "2025-10-10T23:47:00.473Z",
      "description": "Implement dependency tracking between work units including add-dependency, remove-dependency, and dependency validation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:39:38.913Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:42:11.831Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:46:12.749Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:46:19.691Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:47:00.473Z"
        }
      ],
      "rules": [
        "MUST maintain bidirectional consistency (if A blocks B, then B blockedBy A)",
        "MUST detect circular dependencies before creating relationships",
        "MUST prevent deletion of work units that block other work",
        "MUST auto-transition to blocked state when blockedBy work exists",
        "Work units can have 4 relationship types: blocks, blockedBy, dependsOn, relatesTo"
      ],
      "examples": [
        "Add blocks relationship creates bidirectional link",
        "Remove dependency cleans up both sides of relationship",
        "Circular dependency detection prevents A→B→A loops",
        "Adding blockedBy dependency auto-sets work unit to blocked state",
        "Query dependency stats shows metrics across all work units"
      ]
    },
    "EST-001": {
      "id": "EST-001",
      "title": "Work Unit Estimation and Metrics",
      "status": "done",
      "createdAt": "2025-10-10T23:39:24.324Z",
      "updatedAt": "2025-10-10T23:51:10.655Z",
      "description": "Implement estimation and metrics tracking including assign estimates, record tokens, calculate cycle time",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:47:18.974Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:48:44.204Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:51:10.109Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:51:10.383Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:51:10.655Z"
        }
      ],
      "rules": [
        "MUST support Fibonacci story points (1,2,3,5,8,13,21) for estimation",
        "MUST track AI-specific metrics: actualTokens and iterations",
        "MUST calculate cycle time from stateHistory timestamps",
        "MUST compare estimate vs actual to provide accuracy feedback",
        "MUST provide pattern-based estimation recommendations"
      ],
      "examples": [
        "Update work unit with 5-point estimate",
        "Record 45k tokens consumed",
        "Increment iteration count",
        "Query estimate accuracy for work unit",
        "Get estimation guide with patterns"
      ]
    },
    "QRY-001": {
      "id": "QRY-001",
      "title": "Work Unit Query and Reporting",
      "status": "done",
      "createdAt": "2025-10-10T23:39:26.221Z",
      "updatedAt": "2025-10-10T23:52:11.901Z",
      "description": "Implement query and reporting features including compound queries, statistical reports, and data export",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:51:24.531Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:52:11.067Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:52:11.346Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:52:11.624Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:52:11.901Z"
        }
      ],
      "rules": [
        "MUST support compound queries combining multiple filters (status, prefix, epic, tags)",
        "MUST export query results to JSON, CSV, or Markdown formats",
        "MUST generate statistical summary reports across work units",
        "MUST support sorting and pagination for large result sets",
        "MUST provide machine-readable output for CI/CD integration"
      ],
      "examples": [
        "Query by status and prefix",
        "Export work units to JSON",
        "Generate summary report with statistics",
        "Query with sorting by updated date",
        "Export filtered results to CSV"
      ]
    },
    "SPEC-001": {
      "id": "SPEC-001",
      "title": "Complete placeholder scenarios with proper Given/When/Then",
      "status": "done",
      "createdAt": "2025-10-11T02:11:53.337Z",
      "updatedAt": "2025-10-11T02:18:27.489Z",
      "description": "Fill in 24 placeholder scenarios across 6 feature files with concrete Given/When/Then steps",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:12:07.366Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:13:37.952Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:18:26.932Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:18:27.212Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:18:27.489Z"
        }
      ],
      "rules": [
        "Each placeholder scenario MUST have concrete Given/When/Then steps",
        "Steps MUST be specific and testable (no vague descriptions)",
        "Scenarios MUST align with their example mapping source",
        "All scenarios MUST follow Gherkin best practices",
        "Completed scenarios MUST pass validation"
      ],
      "examples": [
        "Fill INIT-001 scenarios (5 scenarios)",
        "Fill DEP-001 scenarios (5 scenarios)",
        "Fill EST-001 scenarios (5 scenarios)",
        "Fill QRY-001 scenarios (5 scenarios)",
        "Fill CLI-001 scenarios (3 scenarios)",
        "Fill add-scenario scenarios (1 scenario)"
      ]
    },
    "TEST-001": {
      "id": "TEST-001",
      "title": "Implement comprehensive test coverage for all commands",
      "status": "done",
      "createdAt": "2025-10-11T02:25:37.571Z",
      "updatedAt": "2025-10-11T03:07:49.878Z",
      "description": "Write tests for remaining untested commands to achieve near-100% test coverage across the CLI",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T03:05:37.421Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T03:06:54.869Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T03:07:39.735Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T03:07:44.751Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T03:07:49.878Z"
        }
      ],
      "rules": [
        "MUST test all CLI commands with valid inputs",
        "MUST test error handling and edge cases",
        "MUST achieve 90%+ code coverage on critical commands",
        "MUST validate file operations (read, write, delete)",
        "MUST test integration points (parser, formatter, validator)"
      ],
      "examples": [
        "Test create-feature with all template variations",
        "Test validation with invalid Gherkin syntax",
        "Test format preserves content and fixes indentation",
        "Test file operations handle missing directories",
        "Test tag registry operations (add, update, delete)"
      ]
    },
    "FEAT-001": {
      "id": "FEAT-001",
      "title": "Implement add-scenario and add-step commands",
      "status": "done",
      "createdAt": "2025-10-11T02:26:06.358Z",
      "updatedAt": "2025-10-11T02:34:00.512Z",
      "description": "Complete implementation of add-scenario and add-step commands for modifying feature files programmatically (phase3)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:26:56.216Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:28:39.953Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:33:59.946Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:34:00.227Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:34:00.512Z"
        }
      ],
      "rules": [
        "MUST parse existing feature file without corrupting content",
        "MUST maintain proper Gherkin formatting and indentation",
        "MUST validate scenario/step syntax before adding",
        "MUST preserve existing tags and metadata",
        "MUST support adding to any position (append, prepend, after scenario)"
      ],
      "examples": [
        "Add scenario to feature file",
        "Add Given step to scenario",
        "Add When step to scenario",
        "Add Then step to scenario",
        "Add scenario with tags"
      ]
    },
    "FEAT-002": {
      "id": "FEAT-002",
      "title": "Implement delete-scenario command",
      "status": "done",
      "createdAt": "2025-10-11T02:37:12.464Z",
      "updatedAt": "2025-10-11T02:43:37.355Z",
      "description": "Complete implementation of delete-scenario command for removing scenarios from feature files (phase4)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:37:48.826Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:40:58.673Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:43:36.723Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:43:37.047Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:43:37.355Z"
        }
      ],
      "rules": [
        "MUST safely delete scenario without corrupting file",
        "MUST preserve other scenarios and structure",
        "MUST support deletion by scenario name or index",
        "MUST handle scenario tags properly during deletion",
        "MUST provide confirmation before deleting"
      ],
      "examples": [
        "Delete scenario by name",
        "Delete scenario by index",
        "Delete multiple scenarios by tag",
        "Confirm before deletion",
        "Preserve remaining scenarios intact"
      ]
    },
    "FEAT-003": {
      "id": "FEAT-003",
      "title": "Implement scenario querying and filtering",
      "status": "done",
      "createdAt": "2025-10-11T02:37:12.740Z",
      "updatedAt": "2025-10-11T02:47:04.736Z",
      "description": "Implement get-scenarios and show-acceptance-criteria commands for querying scenarios by tag (phase4)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:43:45.616Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:44:45.290Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:47:04.171Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:47:04.451Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:47:04.736Z"
        }
      ],
      "rules": [
        "MUST support querying scenarios by single or multiple tags",
        "MUST output scenario list with metadata (feature, tags, steps)",
        "MUST support JSON and plain text output formats",
        "MUST handle AND/OR logic for multiple tags",
        "MUST show acceptance criteria in readable format"
      ],
      "examples": [
        "Get scenarios by single tag",
        "Get scenarios by multiple tags (AND logic)",
        "Show acceptance criteria for tag",
        "Output scenarios as JSON",
        "Query with tag matching pattern"
      ]
    },
    "FEAT-004": {
      "id": "FEAT-004",
      "title": "Implement bulk operations (delete-by-tag, retag)",
      "status": "done",
      "createdAt": "2025-10-11T02:49:30.896Z",
      "updatedAt": "2025-10-11T02:57:58.944Z",
      "description": "Implement bulk delete features/scenarios by tag and bulk retag operations (phase5 high priority)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:50:54.242Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:52:40.455Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:57:58.367Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:57:58.656Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:57:58.944Z"
        }
      ],
      "rules": [
        "MUST support bulk deletion across multiple files",
        "MUST preview changes before executing bulk operations",
        "MUST handle tag renaming with bidirectional updates",
        "MUST preserve file structure during bulk operations",
        "MUST provide detailed summary of changes made"
      ],
      "examples": [
        "Delete all scenarios with @deprecated tag",
        "Delete feature files tagged @phase1",
        "Rename tag from @old-tag to @new-tag",
        "Preview bulk delete before confirmation",
        "Show summary of bulk changes"
      ]
    },
    "FEAT-005": {
      "id": "FEAT-005",
      "title": "Implement update operations (scenario, step)",
      "status": "done",
      "createdAt": "2025-10-11T02:49:31.178Z",
      "updatedAt": "2025-10-11T03:01:38.306Z",
      "description": "Implement update-scenario and update-step commands for modifying existing content (phase5)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:58:07.304Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T03:00:04.811Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T03:01:27.456Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T03:01:32.883Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T03:01:38.306Z"
        }
      ],
      "rules": [
        "MUST support updating scenario name/title",
        "MUST support updating step text",
        "MUST preserve tags and metadata during updates",
        "MUST validate new content before applying",
        "MUST maintain proper Gherkin syntax"
      ],
      "examples": [
        "Update scenario name",
        "Update Given step text",
        "Update When step text",
        "Update Then step text",
        "Update step preserving position"
      ]
    },
    "INIT-002": {
      "id": "INIT-002",
      "title": "Add ensureFoundationFile and ensureTagsFile with proper auto-initialization",
      "status": "done",
      "createdAt": "2025-10-11T03:55:06.491Z",
      "updatedAt": "2025-10-11T04:29:23.795Z",
      "description": "Add ensureFoundationFile() and ensureTagsFile() functions to src/utils/ensure-files.ts and update ALL commands that read foundation.json or tags.json to use these functions instead of manual file checks",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T03:55:27.686Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T04:00:53.724Z",
          "reason": "Feature file tagged with @INIT-002, ready to write tests"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T04:12:03.024Z",
          "reason": "Tests written, ready to implement ensureFoundationFile and ensureTagsFile"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T04:25:49.608Z",
          "reason": "All commands updated to use ensure functions, tests passing"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T04:29:23.795Z",
          "reason": "Implementation complete: ensureFoundationFile() and ensureTagsFile() added, all commands updated, all tests passing"
        }
      ]
    },
    "BOARD-001": {
      "id": "BOARD-001",
      "title": "Implement board command with Ink + React visualization",
      "status": "done",
      "createdAt": "2025-10-11T04:32:31.325Z",
      "updatedAt": "2025-10-11T05:18:44.997Z",
      "description": "Create a Kanban board visualization using Ink + React that displays all work units across 7 workflow states. The board command replaces the old display-board implementation with a responsive terminal UI following React patterns.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T04:32:38.196Z",
          "reason": "Analyzing feature file scenarios and current broken implementation"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T04:43:24.069Z",
          "reason": "Example mapping complete, design agreed: box-drawing columns, 3-item limit, BLOCKED highlighted, all columns shown"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T04:44:20.798Z",
          "reason": "Tests written and passing for data structure, now implementing visual output"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T05:11:08.352Z",
          "reason": "Implementation complete: BoardDisplay component using Ink + React, architecture docs updated, component follows React patterns with useStdout, ready for validation"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T05:13:08.776Z",
          "reason": "Implementation validated: board command displays Kanban board correctly using Ink + React, all tests pass, follows React patterns, architecture docs updated, no issues found"
        }
      ]
    },
    "SAFE-001": {
      "id": "SAFE-001",
      "title": "Prevent spec directory creation outside project root",
      "status": "done",
      "createdAt": "2025-10-12T03:27:57.082Z",
      "updatedAt": "2025-10-12T04:47:39.305Z",
      "description": "Add validation to check if current directory is within project root before creating spec directories",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T03:28:04.689Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T04:43:22.902Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T04:45:14.668Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T04:47:23.341Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T04:47:39.306Z"
        }
      ],
      "rules": [
        "Project root is determined by finding a spec/ directory, but search must stop at a project boundary marker (.git, package.json, etc.)",
        "Search algorithm walks upward from cwd, stopping at project boundary markers: .git, package.json, .gitignore, Cargo.toml, pyproject.toml",
        "If spec/ directory exists within project boundary, use that directory as project root",
        "If no spec/ directory found within project boundary, create spec/ at the project boundary location (not cwd)",
        "If no project boundary marker found after searching to filesystem root, create spec/ in current working directory",
        "Stop at first boundary marker found when searching upward (closest to cwd)",
        "All spec directory creation must go through a centralized utility function that performs project root detection",
        "Search upward with a maximum limit (e.g., 10 directories) to prevent excessive traversal",
        "On permission errors or filesystem issues, gracefully fall back to creating spec/ in current working directory",
        "Centralized utility should automatically create spec/ directory and return the spec path (not project root)",
        "Defer testing refactored callers until core utility is complete. Critical: Do not break existing functionality - ensure backward compatibility so all current tests continue passing. Architecture must support both old and new code paths during transition."
      ],
      "examples": [
        "User at /project/src/commands/, .git at /project/, no spec/ exists → create /project/spec/",
        "User at /project/src/commands/, .git at /project/, spec/ exists at /project/spec/ → use /project/spec/",
        "User at /tmp/random/, no boundary markers found → create /tmp/random/spec/",
        "Monorepo: /monorepo/.git and /monorepo/packages/app/package.json, user at /monorepo/packages/app/src/ → use /monorepo/packages/app/ as root",
        "User at /very/deep/nested/path/a/b/c/d/e/f/g/h/i/j/k/, no boundary within 10 dirs → create spec/ at cwd",
        "User at /project/src/, permission denied reading parent dirs → create spec/ at /project/src/"
      ],
      "questions": [],
      "assumptions": [
        "Need to verify existing ensure-files.ts functions work with new project root detection - may need to refactor callers to use returned spec path instead of manually constructing it"
      ]
    },
    "CLI-002": {
      "id": "CLI-002",
      "title": "Fix missing list-prefixes CLI command registration",
      "status": "done",
      "createdAt": "2025-10-12T03:48:03.694Z",
      "updatedAt": "2025-10-12T03:53:56.776Z",
      "description": "The list-prefixes command is documented in help but not registered in the CLI",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T03:48:12.204Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T03:50:18.426Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T03:51:37.431Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T03:52:38.137Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T03:53:56.776Z"
        }
      ],
      "questions": [],
      "rules": [
        "Yes, consistent with list-epics behavior",
        "Yes, output format should match list-epics for consistency",
        "Yes, return empty list with yellow message if no prefixes.json exists"
      ],
      "examples": [
        "User runs 'fspec list-prefixes' and sees all registered prefixes with their descriptions",
        "User runs 'fspec list-prefixes' and sees work unit counts for each prefix (e.g., 'SAFE: 1/1 (100%)')",
        "User runs 'fspec list-prefixes' when no prefixes.json exists, sees 'No prefixes found' in yellow"
      ]
    },
    "DOC-001": {
      "id": "DOC-001",
      "title": "Add story point estimation guidance",
      "status": "done",
      "createdAt": "2025-10-12T05:13:30.172Z",
      "updatedAt": "2025-10-12T06:58:58.773Z",
      "description": "Add story point estimation guidelines to /fspec command including Fibonacci scale, estimation prompts, and best practices",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T06:57:57.344Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:58:57.916Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:58:58.206Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:58:58.489Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:58:58.773Z"
        }
      ]
    },
    "REMIND-001": {
      "id": "REMIND-001",
      "title": "Implement system-reminder pattern",
      "status": "done",
      "createdAt": "2025-10-12T05:13:30.451Z",
      "updatedAt": "2025-10-12T05:29:04.618Z",
      "description": "Add system-reminder wrapper functions and trigger points to prevent AI drift during long conversations",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:17:36.967Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T05:20:47.043Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:21:53.587Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:23:54.695Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:24:11.995Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:24:29.001Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:25:59.299Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:26:23.102Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:26:44.204Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:27:04.588Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:27:37.721Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:27:52.779Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T05:29:04.618Z"
        }
      ],
      "rules": [
        "System reminders must be wrapped in <system-reminder> tags",
        "Reminders must be invisible to users but visible to Claude",
        "Reminders should only be injected after specific command executions",
        "Each reminder must be context-specific to the command executed",
        "Reminders must be conditional and context-aware - only show when relevant to the current situation",
        "Reminders should be appended AFTER main command output"
      ],
      "examples": [
        "After 'fspec update-work-unit-status UI-001 testing', output includes reminder: 'Write FAILING tests BEFORE any implementation code'",
        "After 'fspec update-work-unit-status UI-001 implementing', output includes reminder: 'Write ONLY enough code to make tests pass'",
        "After 'fspec update-work-unit-estimate UI-001' without an estimate value, output includes reminder: 'Use Fibonacci scale (1,2,3,5,8,13)'",
        "After 'fspec list-work-units --status=backlog' returns empty, output includes reminder: 'Consider creating new work units or checking priorities'"
      ],
      "questions": []
    },
    "TEST-002": {
      "id": "TEST-002",
      "title": "Test system reminders",
      "status": "done",
      "createdAt": "2025-10-12T05:24:45.522Z",
      "updatedAt": "2025-10-12T06:57:17.505Z",
      "description": "Testing if system reminders work correctly",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:24:53.211Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:56:43.819Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:56:44.107Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:56:44.393Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:57:17.505Z"
        }
      ]
    },
    "CLI-003": {
      "id": "CLI-003",
      "title": "Initialize fspec slash command in Claude Code project",
      "status": "done",
      "createdAt": "2025-10-12T05:41:20.177Z",
      "updatedAt": "2025-10-12T06:53:58.304Z",
      "description": "Add 'fspec init' command that installs the /fspec slash command into a Claude Code project by creating/using .claude/commands/ directory and copying fspec.md command file. Should be idempotent and safe to run multiple times.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:42:05.997Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T05:54:31.892Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:51:49.181Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:52:51.675Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:53:58.304Z"
        }
      ],
      "rules": [
        "Command must prompt user to choose: Claude Code or custom location",
        "If Claude Code selected, install to .claude/commands/fspec.md automatically",
        "If custom location selected, prompt for full file path where to save",
        "Template must be generic and reusable across any project (not fspec-specific examples)",
        "Success means file exists at specified location after command completes",
        "Create parent directories if they don't exist",
        "If target file exists, prompt for confirmation before overwriting",
        "Template references fspec commands but uses generic project placeholders (not fspec-specific examples)",
        "Use ink/react for interactive prompts (consistent with existing board UI)",
        "Command works from any directory, installs relative to current working directory",
        "Template uses same structure as .claude/commands/fspec.md but with generic project placeholders",
        "If user cancels overwrite, display 'Installation cancelled' and exit with success (0)",
        "Custom path must be relative to current directory (same or subdirectory, not parent or absolute)",
        "On success, display both confirmation message and next steps for usage",
        "On error (permission denied, disk full, etc), display error message and exit with non-zero code",
        "Use example-project style (lowercase example placeholders)",
        "Include all sections from current fspec.md (complete template with all ACDD workflow, example mapping, estimation, etc)",
        "Allow: ./file.md, file.md, subdir/file.md, subdir/nested/file.md. Reject: ../file.md, /absolute/path, ~/home/path"
      ],
      "examples": [
        "User runs 'fspec init' in project root, selects Claude Code, file created at ./claude/commands/fspec.md",
        "User runs 'fspec init', selects custom location, enters 'docs/ai/fspec.md', file created at ./docs/ai/fspec.md",
        "User runs 'fspec init' when .claude/commands/fspec.md exists, prompted to confirm overwrite, user confirms, file is overwritten",
        "User runs 'fspec init', selects custom location, enters 'some/deep/path/fspec.md', parent directories created automatically",
        "User runs 'fspec init', selects custom location, enters '../parent/fspec.md', validation fails with error about path being outside current directory",
        "User runs 'fspec init' when .claude/commands/fspec.md exists, declines overwrite, command exits with 'Installation cancelled'",
        "User runs 'fspec init', selects Claude Code, command succeeds, displays '✓ Installed /fspec command to .claude/commands/fspec.md' and 'Run /fspec in Claude Code to activate'"
      ],
      "questions": [],
      "estimate": 5
    },
    "TEST-003": {
      "id": "TEST-003",
      "title": "Test answer-question with multiple questions",
      "status": "done",
      "createdAt": "2025-10-12T05:57:24.220Z",
      "updatedAt": "2025-10-12T06:57:49.173Z",
      "description": "Testing that answering multiple questions works correctly with proper index handling",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:57:25.745Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:57:48.309Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:57:48.599Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:57:48.887Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:57:49.173Z"
        }
      ],
      "questions": [],
      "rules": [
        "Use option A for consistency",
        "Edge case X should return error code 400",
        "Not in phase 1, defer to backlog"
      ]
    },
    "SAFE-002": {
      "id": "SAFE-002",
      "title": "Fix race condition in answer-question when run concurrently",
      "status": "done",
      "createdAt": "2025-10-12T06:01:08.064Z",
      "updatedAt": "2025-10-12T06:33:27.231Z",
      "description": "Add file locking or transaction mechanism to prevent race conditions when multiple answer-question commands run in parallel. Currently parallel executions can overwrite each other's changes causing data loss.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T06:01:09.809Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:07:32.863Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:09:49.140Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:32:14.013Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:33:27.232Z"
        }
      ],
      "rules": [
        "Multiple concurrent writes to work-units.json must not corrupt data",
        "When multiple answer-question commands run in parallel, all answers must be saved",
        "Last write must not overwrite changes from earlier writes",
        "Solution must work across platforms (macOS, Linux, Windows)",
        "Question indices must remain stable even after questions are answered",
        "YES - Use stable indices with 'selected' flag. Change questions from string array to object array: [{text: 'question', selected: false}, ...]. When answered, mark as selected:true and add answer field. This eliminates race condition without needing file locks.",
        "Questions use 'selected' property to indicate if answered, not 'answered' property"
      ],
      "examples": [
        "User runs 3 answer-question commands in parallel, all 3 questions are answered and all 3 rules are added",
        "User runs answer-question while another command modifies work-units.json, both changes are preserved",
        "User adds 3 questions (indices 0,1,2), answers question 1, indices remain 0,1,2 but question 1 is marked as answered",
        "Question object structure: {text: '@human: Should we...?', selected: false} becomes {text: '@human: Should we...?', selected: true, answer: 'Yes because...'} when answered"
      ],
      "questions": [],
      "assumptions": [
        "Not needed - stable indices approach eliminates race condition without file locking",
        "Not needed - stable indices approach can be used for all commands, but answer-question is the priority",
        "Not applicable - no lock acquisition with stable indices approach"
      ],
      "estimate": 3
    },
    "CLI-004": {
      "id": "CLI-004",
      "title": "Wire up init command to CLI program",
      "status": "done",
      "createdAt": "2025-10-12T07:09:52.763Z",
      "updatedAt": "2025-10-12T07:21:43.421Z",
      "children": [],
      "description": "The init command implementation exists in src/commands/init.ts but is NOT registered in src/index.ts. This means users cannot run 'fspec init'. Need to: 1) Register command in CLI, 2) Add to help system, 3) Update feature files with complete acceptance criteria, 4) Ensure tests cover end-to-end CLI invocation (not just unit tests), 5) Validate command actually works via CLI before marking done.",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:10:05.831Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:12:12.711Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:20:18.251Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T07:20:25.581Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T07:21:20.272Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T07:21:43.421Z"
        }
      ],
      "rules": [
        "Command must be registered in src/index.ts with .command('init')",
        "Command must support interactive prompts using ink/react (option --type and --path flags)",
        "Command must appear in 'fspec --help' output and 'fspec help setup' section",
        "E2E tests must verify 'fspec init' actually works via CLI, not just unit tests of the function"
      ],
      "examples": [
        "Running 'fspec init' prompts for installation type (Claude Code or Custom)",
        "Running 'fspec init --type=claude-code' installs to .claude/commands/fspec.md",
        "Running 'fspec --help' shows init command in output"
      ]
    },
    "BUG-001": {
      "id": "BUG-001",
      "title": "Scenario-level tagging rejects work unit tags",
      "status": "done",
      "createdAt": "2025-10-12T07:13:53.468Z",
      "updatedAt": "2025-10-12T07:17:29.244Z",
      "description": "add-tag-to-scenario command rejects work unit tags like @CLI-004 even though add-tag-to-feature accepts them. The scenario tagging uses /^@[a-z0-9-#]+$/ regex while feature tagging uses isWorkUnitTag() helper. Need to make scenario tagging use the same work unit tag validation as feature tagging.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:13:56.954Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:14:51.941Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T07:15:26.562Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T07:15:58.002Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T07:17:29.245Z"
        }
      ],
      "rules": [
        "add-tag-to-scenario MUST use isWorkUnitTag() helper for validation, same as add-tag-to-feature",
        "Work unit tags (@PREFIX-NNN format) MUST be accepted at both feature and scenario level"
      ],
      "examples": [
        "Running 'fspec add-tag-to-scenario file.feature \"Scenario\" @CLI-004' should succeed",
        "Work unit tags like @AUTH-001, @BUG-001, @CLI-004 should be accepted"
      ]
    },
    "BUG-002": {
      "id": "BUG-002",
      "title": "generate-scenarios displays 'undefined' instead of count",
      "status": "done",
      "createdAt": "2025-10-12T07:14:42.738Z",
      "updatedAt": "2025-10-12T07:19:58.352Z",
      "description": "When running 'fspec generate-scenarios <work-unit-id>', the success message shows 'Generated undefined scenarios' instead of showing the actual count of scenarios generated. The command should display 'Generated N scenarios' where N is the number of scenarios created.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:18:37.948Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:18:52.782Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T07:19:19.951Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T07:19:35.465Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T07:19:58.353Z"
        }
      ],
      "rules": [
        "generate-scenarios command MUST return the count of scenarios generated",
        "Success message MUST display 'Generated N scenarios' where N is the actual count"
      ],
      "examples": [
        "Running 'fspec generate-scenarios WORK-001' should display 'Generated 3 scenarios' not 'Generated undefined scenarios'"
      ]
    },
    "INIT-003": {
      "id": "INIT-003",
      "title": "Copy CLAUDE.md template to new spec directory",
      "status": "done",
      "createdAt": "2025-10-12T07:58:21.443Z",
      "updatedAt": "2025-10-12T08:20:05.866Z",
      "description": "When fspec init creates a new spec/ directory, it should copy the spec/CLAUDE.md file (bundled with the package) to the target project. This ensures new projects have the complete specification guidelines and workflow documentation from the start. The file is bundled from spec/CLAUDE.md to dist/spec/CLAUDE.md during build - no separate templates/ directory needed.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:58:34.774Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T08:05:45.263Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T08:06:40.200Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T08:09:35.216Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T08:10:49.918Z"
        }
      ],
      "rules": [
        "CLAUDE.md template must be bundled with fspec package in a templates/ directory",
        "CLAUDE.md file must be identical across all projects (no customization)",
        "If spec/CLAUDE.md already exists, overwrite it with the latest template",
        "fspec init command must set up complete spec directory structure with CLAUDE.md and /fspec slash command",
        "Always overwrite - no version checking needed",
        "Show confirmation message in /fspec slash command output (fspec.md), no separate message from fspec init CLI",
        "Enhance existing 'fspec init' command to copy CLAUDE.md template"
      ],
      "examples": [
        "User runs 'fspec init' in empty directory, creates spec/ directory with CLAUDE.md and .claude/commands/fspec.md",
        "User runs 'fspec init' in directory with existing spec/CLAUDE.md, overwrites with latest template",
        "CLAUDE.md template is copied from fspec package's templates/CLAUDE.md to project's spec/CLAUDE.md",
        "fspec init copies templates/CLAUDE.md to spec/CLAUDE.md preserving all content exactly",
        "/fspec slash command shows 'Copied spec/CLAUDE.md specification guidelines' in output",
        "Running 'fspec init' twice overwrites spec/CLAUDE.md with latest template (no prompt, no backup)"
      ],
      "questions": [
        {
          "text": "@human: Should 'fspec init' also check if the CLAUDE.md template in the package is newer than the one in the project and offer to update it?",
          "selected": true,
          "answer": "Always overwrite - no version checking needed"
        },
        {
          "text": "@human: What should happen if the templates/ directory is missing from the fspec package installation?",
          "selected": true,
          "answer": "Templates directory is bundled with package build - if missing, it's a build error (should never happen in production)"
        },
        {
          "text": "@human: Should there be any output message confirming CLAUDE.md was copied/updated?",
          "selected": true,
          "answer": "Show confirmation message in /fspec slash command output (fspec.md), no separate message from fspec init CLI"
        },
        {
          "text": "@human: Looking at existing INIT-002 work unit, should this enhance the existing init command or be separate?",
          "selected": true,
          "answer": "Enhance existing 'fspec init' command to copy CLAUDE.md template"
        }
      ],
      "assumptions": [
        "Templates directory is bundled with package build - if missing, it's a build error (should never happen in production)"
      ],
      "estimate": 2
    },
    "DOC-002": {
      "id": "DOC-002",
      "title": "Provide schema information for foundation.json",
      "status": "done",
      "createdAt": "2025-10-12T11:46:03.860Z",
      "updatedAt": "2025-10-12T23:11:14.375Z",
      "description": "Add schema information to foundation.json to help AI agents draft foundation documents more easily. May require relaxing some schema constraints to make it more flexible for agents.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T11:46:21.581Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T22:56:07.240Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T22:59:39.116Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T23:11:14.091Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T23:11:14.376Z"
        }
      ],
      "rules": [
        "Schema must guide AI agents to write documentation in a specific format that preserves project meaning and prevents drift",
        "Schema must be provided as a separate JSON Schema file (foundation.schema.json)",
        "Schema file must be accessible via CLI command so AI agents can read it",
        "Field names should be flexible (e.g., accept both camelCase and snake_case) while maintaining similar overall structure",
        "Schema must include rich descriptions explaining the intent behind each section",
        "Schema must include examples of good vs. bad content for each field",
        "Schema must include validation rules (e.g., minimum array lengths, required fields)",
        "Schema must include format instructions for structured fields",
        "Must provide both 'fspec show-foundation-schema' to display schema and 'fspec validate-foundation-schema' to validate foundation.json",
        "No backward compatibility required - existing foundation.json files may need migration to new format",
        "Mermaid syntax validation should be handled by Mermaid library (mermaid.parse()), not by JSON Schema. Schema only validates that mermaidCode field exists and is a string.",
        "Schema should allow AI agents to add custom sections beyond the standard ones (project, whatWeAreBuilding, whyWeAreBuildingIt). Use additionalProperties: true for extensibility.",
        "Validation should check semantic content of descriptions. Schema descriptions should guide AI on what to write and what NOT to write (e.g., 'projectOverview should focus on WHAT/HOW, not WHY - business justification belongs in whyWeAreBuildingIt').",
        "Schema should allow additional properties (additionalProperties: true) for future extensibility. AI agents can add custom sections as needed."
      ],
      "examples": [
        "Schema for 'projectOverview' includes description: 'A comprehensive technical overview (2-4 sentences) describing: (1) what systems are being built, (2) who uses them (target users), (3) how the systems integrate. Focus on WHAT and HOW, not WHY. Example: A Kanban-based project management and specification tool for AI agents...'",
        "Schema for 'problemDefinition.primary' includes validation: must contain 'title', 'description', and 'coreProblems' array with minimum 3 items describing distinct problem categories",
        "Schema accepts both camelCase and snake_case for ALL field names. Examples: 'architectureDiagrams' OR 'architecture_diagrams', 'technicalRequirements' OR 'technical_requirements', 'projectOverview' OR 'project_overview'",
        "AI agent runs 'fspec show-foundation-schema' and receives JSON Schema with rich descriptions and examples. Agent uses this to understand how to structure foundation.json sections when running 'fspec update-foundation'",
        "AI agent runs 'fspec validate-foundation-schema' after updating foundation.json. Validation fails with message: 'Field problemDefinition.primary.coreProblems must have at least 3 items (found 2)'. Agent adds another problem and re-validates."
      ],
      "questions": [
        {
          "text": "@human: Should the schema validate Mermaid syntax in architectureDiagrams array, or just validate that mermaidCode field is a string?",
          "selected": true,
          "answer": "Mermaid syntax validation should be handled by Mermaid library (mermaid.parse()), not by JSON Schema. Schema only validates that mermaidCode field exists and is a string."
        },
        {
          "text": "@human: Should the schema enforce specific top-level section names (project, whatWeAreBuilding, whyWeAreBuildingIt) or allow AI agents to add custom sections?",
          "selected": true,
          "answer": "Schema should allow AI agents to add custom sections beyond the standard ones (project, whatWeAreBuilding, whyWeAreBuildingIt). Use additionalProperties: true for extensibility."
        },
        {
          "text": "@human: How detailed should validation be? Should it validate the semantic content of descriptions (e.g., 'projectOverview should not mention business justification') or just structural rules (required fields, types, array lengths)?",
          "selected": true,
          "answer": "Validation should check semantic content of descriptions. Schema descriptions should guide AI on what to write and what NOT to write (e.g., 'projectOverview should focus on WHAT/HOW, not WHY - business justification belongs in whyWeAreBuildingIt')."
        },
        {
          "text": "@human: Should we provide a migration command (e.g., 'fspec migrate-foundation') to convert existing foundation.json to the new flexible format, or should users manually update?",
          "selected": true,
          "answer": "No migration command needed. No backward compatibility - users must manually update foundation.json to new format when schema is introduced."
        },
        {
          "text": "@human: Should the schema allow additional properties beyond the defined ones (additionalProperties: true) to support future extensibility, or be strict (additionalProperties: false)?",
          "selected": true,
          "answer": "Schema should allow additional properties (additionalProperties: true) for future extensibility. AI agents can add custom sections as needed."
        }
      ],
      "assumptions": [
        "No migration command needed. No backward compatibility - users must manually update foundation.json to new format when schema is introduced."
      ],
      "estimate": 5
    },
    "RSPEC-001": {
      "id": "RSPEC-001",
      "title": "Add rspec command for reverse ACDD",
      "status": "done",
      "createdAt": "2025-10-12T11:46:05.565Z",
      "updatedAt": "2025-10-13T00:20:55.500Z",
      "description": "Create new 'rspec' command that performs reverse ACDD by decomposing/reverse engineering existing applications. The command discovers user stories, personas, and acceptance criteria from existing code. Extends the /fspec slash command to tell Claude to read fspec.md and continue with reverse engineering workflow.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T23:11:24.854Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T00:20:36.464Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T00:20:42.594Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T00:20:49.164Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T00:20:55.501Z"
        }
      ],
      "rules": [
        "Must identify user personas who interact with the system",
        "Must identify high-level activities or goals users achieve with the software",
        "Must break down high-level activities into smaller specific tasks or interactions that code supports",
        "Analysis involves: (1) analyzing functionality and mapping to user goals, (2) examining UI elements/features/workflows, (3) grouping related features into epics/journeys, (4) decomposing into individual user stories",
        "Must produce user story map organized visually along user journey (broad activities at top, detailed interactions underneath)",
        "User stories must be expressed as user-centric narratives (As a [persona], I want [goal], So that [benefit])",
        "fspec init must install rspec.md slash command (similar to how it installs fspec.md)",
        "rspec.md first line (after title) must say 'fully read fspec.md' with markdown link to exact fspec.md location",
        "Must create everything fspec can do: work units, epics, prefixes, example maps, features, foundation.json (particularly this, keep updating as it learns), diagrams, unit/integration tests (NOT implemented), test-to-feature links (header comments)",
        "Must create user story map in feature file docstrings or foundation.json (wherever closest to where it needs to be)",
        "Must ONLY create artifacts that use fspec or are tests - nothing else",
        "When encountering incomplete/ambiguous code: reverse engineer as much as possible, then ask human to complete via Example Mapping session",
        "foundation.json must be continuously updated as system learns more about the codebase",
        "Unit tests and integration tests created must NOT be implemented (skeleton only) - AI/human implements them later following ACDD",
        "/rspec is a Claude Code slash command (not CLI command) - user invokes it via /rspec in Claude Code",
        "User story map should be one or more Mermaid diagrams (preferably) plus any supporting artifacts that help visualize the map"
      ],
      "examples": [
        "Skeleton test file header includes: /** Feature: spec/features/[name].feature\\n * This test validates acceptance criteria. Tests map to Gherkin scenarios.\\n */",
        "User runs /rspec in Claude Code → AI reads .claude/commands/rspec.md → First line says 'fully read fspec.md' (with link) → AI follows fspec workflow while reverse engineering",
        "User story map created as Mermaid diagram in foundation.json architectureDiagrams array with section='User Story Map'",
        "Reverse engineered Express.js app: creates epic 'api-management', prefix 'API', work units API-001 'User authentication', API-002 'Data validation', feature files with inferred scenarios, skeleton tests with describe/it blocks (no implementation)"
      ]
    },
    "BUG-003": {
      "id": "BUG-003",
      "title": "Summary report shows 'undefined' instead of file path",
      "status": "done",
      "createdAt": "2025-10-13T05:18:30.471Z",
      "updatedAt": "2025-10-13T07:23:52.363Z",
      "description": "When running 'fspec generate-summary-report --format=markdown', the output shows 'Report generated: undefined' instead of the actual file path where the report was saved.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T05:18:44.355Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T05:22:07.396Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T05:22:44.125Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T05:24:48.456Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T05:25:46.597Z"
        }
      ],
      "rules": [
        "Command output must show the actual file path where the report was generated",
        "When --output option is provided, show that specific path",
        "When --output option is NOT provided, show the default generated path",
        "Function must return outputFile property containing the path where report was written",
        "Function must accept format (markdown, json, html) and output (file path) options",
        "Function must write report to file system in the specified format",
        "Default output path should be spec/summary-report.{format}"
      ],
      "examples": [
        "User runs 'fspec generate-summary-report --format=markdown', sees 'Report generated: spec/summary-report.md'",
        "User runs 'fspec generate-summary-report --format=markdown --output=custom.md', sees 'Report generated: custom.md'",
        "Currently shows 'Report generated: undefined' instead of actual path",
        "Function currently returns SummaryReport object without outputFile property",
        "CLI calls result.outputFile which is undefined",
        "Function signature currently missing format and output parameters"
      ],
      "estimate": 2
    },
    "CLI-005": {
      "id": "CLI-005",
      "title": "Add --help support to all fspec commands",
      "status": "done",
      "createdAt": "2025-10-13T05:32:26.029Z",
      "updatedAt": "2025-10-13T05:56:38.745Z",
      "description": "Currently commands like 'fspec create-epic --help' fail with 'unknown option --help'. Every fspec command should support --help flag that displays detailed usage information, options, arguments, and practical examples for that specific command. This includes all ~80+ commands across specs, work, discovery, metrics, and setup groups.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T05:32:33.248Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T05:44:40.837Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T05:46:16.843Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T05:55:36.370Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T05:56:38.746Z"
        }
      ],
      "rules": [
        "Help output must include: command description, all options with descriptions, required vs optional arguments, practical examples, and related commands",
        "Help formatting must use custom colored output matching 'fspec help specs' style, optimized for AI agent readability",
        "Number of examples should be contextually appropriate per command complexity",
        "Individual command help (--help) must be separate from group help (fspec help specs/work/etc)",
        "Main fspec --help output must mention that each command supports its own --help flag",
        "Must use custom help system, not Commander.js built-in help (insufficient quality)",
        "Help must include AI-optimized sections when applicable: WHEN TO USE, WHEN NOT TO USE, COMMON PATTERNS, TYPICAL WORKFLOW, PREREQUISITES, related workflow states",
        "Examples must show both command and expected output for clarity",
        "Help templates must vary by command complexity: Simple (1-2 examples), Medium (2-3 examples), Complex (4-5 examples showing different modes)",
        "Help must include COMMON ERRORS section with error messages and fixes",
        "Related commands section must only show highly related commands with whatever format makes sense (syntax/names/workflow context)",
        "No validation or schema enforcement needed - help text should be inline in command code",
        "Whatever is most elegant while retaining exact same functionality - ultrathink this",
        "Create help infrastructure first, then implement each command help individually",
        "Yes, refactor into shared help utilities module for consistency",
        "Infrastructure first: build help system, then implement per command",
        "Infrastructure first: build help system, then implement per command"
      ],
      "examples": [
        "User runs 'fspec create-epic --help' and sees: description, usage syntax, options (none), arguments (<name> <title>), 2 examples with output, related commands (list-epics, show-epic, create-work-unit)",
        "User runs 'fspec list-work-units --help' and sees: WHEN TO USE section, all options (--status, --prefix, --epic), 3 examples showing different filters with sample output, TYPICAL WORKFLOW mentioning backlog → specifying flow",
        "User runs 'fspec add-dependency --help' and sees: description explaining dependency types, 5 examples showing shorthand vs --blocks vs --blocked-by vs --depends-on vs --relates-to, COMMON ERRORS section for 'work unit not found', related commands (remove-dependency, dependencies, export-dependencies)",
        "User runs 'fspec update-work-unit-status --help' and sees: PREREQUISITES (work unit must exist), WHEN TO USE (moving through ACDD workflow), valid status values listed, TYPICAL WORKFLOW showing backlog→specifying→testing→implementing→validating→done, example with output showing status change",
        "User runs 'fspec --help' and sees updated main help with note: 'Get detailed help for any command with: fspec <command> --help'",
        "User runs 'fspec add-question --help' and sees: WHEN TO USE (during Example Mapping in specifying phase), COMMON PATTERNS (use @human: prefix for questions directed at human), example showing question with answer flow, related commands (answer-question, add-rule, add-example, generate-scenarios)"
      ],
      "questions": [
        {
          "text": "@human: How should we handle the --help flag given the custom help system that overrides Commander?",
          "selected": true,
          "answer": "Whatever works best - could be smoke tests, integration tests, or manual testing"
        },
        {
          "text": "@human: Should we refactor existing help command formatting utilities into shared module?",
          "selected": true,
          "answer": "Integration tests that verify help output contains required sections and examples"
        },
        {
          "text": "@human: Should we implement help for all 80+ commands at once or incrementally?",
          "selected": true,
          "answer": "Infrastructure first: build help system, then implement per command"
        },
        {
          "text": "@human: What testing strategy should we use for help output?",
          "selected": true,
          "answer": "Integration tests that verify help output contains required sections and examples"
        }
      ],
      "assumptions": [
        "Whatever works best given current setup and custom help system that overrides Commander's, and existing fspec --help",
        "Whatever works best - could be smoke tests, integration tests, or manual testing",
        "Integration tests that verify help output contains required sections and examples",
        "Integration tests that verify help output contains required sections and examples"
      ]
    },
    "CLI-006": {
      "id": "CLI-006",
      "title": "Implement scalable help system for all commands",
      "status": "done",
      "createdAt": "2025-10-13T06:06:34.397Z",
      "updatedAt": "2025-10-13T06:26:59.486Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T06:06:40.458Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T06:12:23.135Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T06:13:25.161Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T06:25:58.574Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T06:26:59.487Z"
        }
      ],
      "rules": [
        "Help system must automatically discover and register help configs without manual registration in index.ts",
        "Each command should have its help config in a dedicated file (command-name-help.ts) co-located with command implementation",
        "Commander.js should automatically handle --help flag for all commands without explicit handlers in action callbacks",
        "Help configs should use a naming convention that maps to command names (e.g., remove-tag-from-scenario -> remove-tag-from-scenario-help.ts)",
        "Missing help config files should fall back to Commander.js default help (current behavior) rather than error"
      ],
      "examples": [
        "When user runs 'fspec remove-tag-from-scenario --help' and help config exists at src/commands/remove-tag-from-scenario-help.ts, display detailed help from config",
        "When user runs 'fspec some-command --help' and no help config file exists, fall back to Commander.js default help"
      ],
      "questions": [
        {
          "text": "@human: Should we use Commander.js custom help configuration or a global --help interceptor to avoid modifying 91 command registrations?",
          "selected": true,
          "answer": "Use process-level help interceptor with registry Set. Intercept --help before Commander.js, use dynamic imports, graceful fallback for missing configs, zero modifications to 91 command registrations."
        }
      ]
    },
    "BUG-004": {
      "id": "BUG-004",
      "title": "Fix generate-scenarios to use capability-based feature file names",
      "status": "done",
      "createdAt": "2025-10-13T07:23:50.426Z",
      "updatedAt": "2025-10-13T07:31:08.560Z",
      "description": "The generate-scenarios command currently defaults to using work unit ID as feature file name (e.g., auth-001.feature) which violates the naming principle. Should require --feature flag or use work unit title as default.",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T07:24:10.294Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T07:26:43.645Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T07:27:36.963Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T07:30:19.171Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T07:31:08.561Z"
        }
      ],
      "rules": [
        "Feature files must be named after capabilities, NOT work unit IDs",
        "Work unit title should be used as default suggestion when --feature not provided",
        "Command should fail with helpful error if --feature not provided and AI needs to choose name",
        "Auto-default to work unit title (kebab-cased). User can override with --feature flag if they want a different name.",
        "Throw error requiring --feature flag with helpful message suggesting capability-based name."
      ],
      "examples": [
        "User runs 'fspec generate-scenarios AUTH-001', command suggests using work unit title as feature name",
        "User runs 'fspec generate-scenarios AUTH-001 --feature=user-authentication', creates spec/features/user-authentication.feature",
        "Work unit AUTH-001 has title 'User Login', defaults to spec/features/user-login.feature when --feature not provided"
      ],
      "questions": [
        {
          "text": "@human: Should we make --feature flag required, or auto-default to work unit title?",
          "selected": true,
          "answer": "Auto-default to work unit title (kebab-cased). User can override with --feature flag if they want a different name."
        },
        {
          "text": "@human: What should happen if work unit title is empty or not set?",
          "selected": true,
          "answer": "Throw error requiring --feature flag with helpful message suggesting capability-based name."
        }
      ]
    },
    "REMIND-002": {
      "id": "REMIND-002",
      "title": "Comprehensive System-Reminder Overhaul",
      "status": "done",
      "createdAt": "2025-10-13T07:56:29.390Z",
      "updatedAt": "2025-10-13T08:19:36.823Z",
      "description": "Audit existing system-reminders, expand to all critical commands based on analysis, add file naming detection, tag validation, and discovery phase reminders",
      "children": [
        "REMIND-003",
        "REMIND-004",
        "REMIND-005",
        "REMIND-006",
        "REMIND-007"
      ],
      "estimate": 13,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:18:35.217Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:19:35.726Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:19:36.092Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:19:36.462Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:19:36.824Z"
        }
      ],
      "rules": [
        "All child work units (REMIND-003, 004, 005, 006, 007) must be in done status",
        "System-reminder functions implemented in src/utils/system-reminder.ts",
        "System-reminders integrated into create-feature, add-tag-to-feature, generate-scenarios, show-work-unit, and update-work-unit-status commands"
      ],
      "examples": [
        "All 5 child work units completed successfully with tests passing",
        "Build passing with 843 tests, all system-reminder functionality working"
      ]
    },
    "REMIND-003": {
      "id": "REMIND-003",
      "title": "File Naming Anti-Pattern Detection",
      "status": "done",
      "createdAt": "2025-10-13T07:56:47.607Z",
      "updatedAt": "2025-10-13T08:02:40.554Z",
      "description": "Add system-reminders to create-feature command to detect task-based naming (implement-, add-, create-, work-unit-ID) and remind to use capability-based naming",
      "parent": "REMIND-002",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T07:57:27.395Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T07:58:22.240Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T07:58:32.755Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:01:48.189Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:02:40.555Z"
        }
      ],
      "rules": [
        "System-reminders must detect task-based file naming patterns (implement-, add-, create-, fix-, build-)",
        "System-reminders must detect work unit ID patterns in file names (e.g., AUTH-001, REMIND-003)",
        "Reminders must provide correct examples of capability-based naming"
      ],
      "examples": [
        "User runs 'fspec create-feature implement-authentication', reminder shows '❌ WRONG: implement-authentication → ✅ CORRECT: user-authentication'",
        "User runs 'fspec create-feature AUTH-001', reminder shows work unit IDs are not capability names",
        "User runs 'fspec create-feature user-authentication', no reminder (correct naming)"
      ]
    },
    "REMIND-004": {
      "id": "REMIND-004",
      "title": "Tag Validation Reminders",
      "status": "done",
      "createdAt": "2025-10-13T07:56:49.298Z",
      "updatedAt": "2025-10-13T13:01:25.736Z",
      "description": "Add reminders to add-tag-to-feature for unregistered tags and missing required tags",
      "parent": "REMIND-002",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:06:04.788Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:06:29.915Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:06:31.632Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:07:43.185Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:07:44.888Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:46.258Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:50.474Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:07.724Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:25.737Z"
        }
      ],
      "rules": [
        "System-reminders must check if tag exists in tags.json before adding to feature file",
        "System-reminders must check for missing required tags after adding a tag",
        "Required tags are: phase tag, component tag, and feature-group tag"
      ],
      "examples": [
        "User runs 'fspec add-tag-to-feature login.feature @unregistered-tag', reminder shows 'Tag not registered in tags.json'",
        "User runs 'fspec add-tag-to-feature login.feature @phase1', no unregistered tag reminder but may show missing required tags reminder",
        "User adds all required tags, no reminder shown"
      ]
    },
    "REMIND-005": {
      "id": "REMIND-005",
      "title": "Discovery Phase Reminders",
      "status": "done",
      "createdAt": "2025-10-13T07:56:51.073Z",
      "updatedAt": "2025-10-13T13:01:28.324Z",
      "description": "Add reminders to generate-scenarios for unanswered questions, empty Example Mapping, and post-generation validation",
      "parent": "REMIND-002",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:08:01.105Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:08:14.931Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:08:15.225Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:09:45.064Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:09:45.355Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:55.259Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:52.611Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:10.713Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:28.325Z"
        }
      ],
      "rules": [
        "System-reminders must check for unanswered questions before allowing scenario generation",
        "System-reminders must check for empty Example Mapping (no rules AND no examples)",
        "System-reminders must provide post-generation guidance after successful scenario generation"
      ],
      "examples": [
        "User runs 'fspec generate-scenarios WORK-001' with unanswered questions, reminder blocks generation",
        "User runs 'fspec generate-scenarios WORK-001' with no rules or examples, reminder suggests adding Example Mapping data",
        "After successful generation, reminder shows next steps (validate, add tags, move to testing)"
      ]
    },
    "REMIND-006": {
      "id": "REMIND-006",
      "title": "Show Work Unit Reminders",
      "status": "done",
      "createdAt": "2025-10-13T07:56:52.746Z",
      "updatedAt": "2025-10-13T13:01:30.534Z",
      "description": "Add reminders to show-work-unit for missing estimates, empty Example Mapping in specifying phase, and long duration warnings",
      "parent": "REMIND-002",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:10:17.524Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:16:22.073Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:16:28.519Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:16:34.669Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:17:10.348Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:55.554Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:54.822Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:12.669Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:30.535Z"
        }
      ],
      "rules": [
        "Display system-reminder when work unit is missing estimate",
        "Display system-reminder when work unit in specifying status has empty Example Mapping (no rules AND no examples)",
        "Display system-reminder when work unit has been in current state for more than 24 hours"
      ],
      "examples": [
        "Show work unit without estimate displays missing estimate reminder",
        "Show work unit in specifying with no rules/examples displays Example Mapping reminder",
        "Show work unit that has been in specifying for 25 hours displays long duration reminder"
      ]
    },
    "REMIND-007": {
      "id": "REMIND-007",
      "title": "Update Status Reminder Enhancement",
      "status": "done",
      "createdAt": "2025-10-13T07:56:54.417Z",
      "updatedAt": "2025-10-13T13:01:32.609Z",
      "description": "Enhanced status reminders with blocked and done states - completed as part of REMIND-003",
      "parent": "REMIND-002",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:10:15.372Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:18:08.040Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:18:08.403Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:18:08.765Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:18:13.970Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:55.851Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:56.856Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:15.325Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:32.610Z"
        }
      ],
      "rules": [
        "Enhance getStatusChangeReminder to include 'done' state reminder about feature file tag updates",
        "Enhance getStatusChangeReminder to include 'blocked' state reminder about documenting blocker reasons"
      ],
      "examples": [
        "Update status to 'done' displays reminder to update feature file tags",
        "Update status to 'blocked' displays reminder to document blocker reason"
      ]
    },
    "REMIND-008": {
      "id": "REMIND-008",
      "title": "Feature File Prefill Detection and CLI Enforcement",
      "status": "done",
      "createdAt": "2025-10-13T08:31:34.385Z",
      "updatedAt": "2025-10-13T08:52:57.425Z",
      "description": "Detect when feature files contain placeholder/prefill text and emit system-reminders instructing LLMs to use CLI commands. Block workflow state transitions if prefill remains.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:31:52.511Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:47:32.759Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:52:11.546Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:52:44.911Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:52:57.426Z"
        }
      ],
      "rules": [
        "Example Mapping must capture the complete user story (role, action, benefit) as the yellow card",
        "fspec generate-scenarios should generate complete user story from example map data, not placeholders",
        "Prefill detection should identify ALL placeholder patterns: [role], [action], TODO:, @phase1, @component, etc.",
        "System-reminders must suggest specific CLI commands to fix detected prefill",
        "Workflow state transitions must be blocked if linked feature files contain prefill placeholders",
        "generate-scenarios should only run AFTER user story is complete (no [role], [action], [benefit] placeholders in Background)",
        "Yes, add explicit userStory fields (role, action, benefit) to work-units.json schema and update JSON Schema validation",
        "Write-time only, when all information has been collected. Detect prefill during fspec create-feature and fspec generate-scenarios, emit system-reminders with CLI commands to fix.",
        "Yes, BOTH write-time and read-time. Write-time for immediate feedback when creating/generating. Read-time for ongoing reminders when showing features, validating, or advancing work unit status.",
        "Until fixed - keep showing system-reminders every time a command interacts with a feature file that has prefill, until the prefill is completely removed.",
        "Hard error (exit 1) - Command must fail completely when trying to advance work unit status if linked feature file contains prefill. Forces LLM to fix prefill before proceeding.",
        "Hybrid approach - Try to intelligently extract Given/When/Then from example text (e.g., 'User logs in with valid credentials' → Given/When/Then steps). Fall back to prefill with system-reminders if parsing fails.",
        "Work units need CLI commands to set user story fields: fspec set-user-story <work-unit-id> --role='...' --action='...' --benefit='...'"
      ],
      "examples": [
        "LLM runs 'fspec create-feature Auth' and gets file with [role], [action], [benefit] placeholders. System-reminder tells LLM to use 'fspec add-background' instead of Edit tool",
        "LLM runs 'fspec generate-scenarios AUTH-001' and gets scenarios with [precondition], [action], [expected outcome]. System-reminder tells LLM to use 'fspec add-step' instead of Write tool",
        "Work unit AUTH-001 has user story in Example Mapping: role='developer', action='authenticate users', benefit='secure access'. generate-scenarios uses this data to create complete Background section without placeholders",
        "LLM tries 'fspec update-work-unit-status AUTH-001 testing' but linked feature file has [role] placeholder. Command fails with error: 'Cannot advance: feature file contains prefill. Use fspec add-background to complete user story.'",
        "LLM completes Example Mapping with user story fields. Runs 'fspec generate-scenarios AUTH-001'. Scenarios are generated BUT steps still have [precondition], [action], [outcome]. System-reminder tells LLM to use 'fspec add-step' for each scenario."
      ],
      "questions": [
        {
          "text": "@human: Should Example Mapping capture user story fields (role, action, benefit) as explicit fields in work-units.json?",
          "selected": true,
          "answer": "Yes, add explicit userStory fields (role, action, benefit) to work-units.json schema and update JSON Schema validation"
        },
        {
          "text": "@human: Should prefill detection happen at read-time (when showing feature) or write-time (when creating feature)?",
          "selected": true,
          "answer": "Write-time only, when all information has been collected. Detect prefill during fspec create-feature and fspec generate-scenarios, emit system-reminders with CLI commands to fix."
        },
        {
          "text": "@human: Should system-reminders for prefill appear every time or only once per session/work unit?",
          "selected": true,
          "answer": "Until fixed - keep showing system-reminders every time a command interacts with a feature file that has prefill, until the prefill is completely removed."
        },
        {
          "text": "@human: Should workflow blocking be a hard error (exits 1) or a warning (exits 0 with reminder)?",
          "selected": true,
          "answer": "Hard error (exit 1) - Command must fail completely when trying to advance work unit status if linked feature file contains prefill. Forces LLM to fix prefill before proceeding."
        },
        {
          "text": "@human: Should generate-scenarios create scenarios with prefill steps OR should it extract Given/When/Then from the example text itself?",
          "selected": true,
          "answer": "Hybrid approach - Try to intelligently extract Given/When/Then from example text (e.g., 'User logs in with valid credentials' → Given/When/Then steps). Fall back to prefill with system-reminders if parsing fails."
        },
        {
          "text": "@human: Going back to question 1 - actually BOTH read-time and write-time?",
          "selected": true,
          "answer": "Yes, BOTH write-time and read-time. Write-time for immediate feedback when creating/generating. Read-time for ongoing reminders when showing features, validating, or advancing work unit status."
        }
      ],
      "estimate": 5,
      "userStory": {
        "role": "AI agent (LLM) using fspec",
        "action": "detect and fix feature file prefill using CLI commands",
        "benefit": "proper workflow enforcement and no direct file editing"
      }
    },
    "COV-001": {
      "id": "COV-001",
      "title": "Feature-to-Code Coverage Tracking",
      "status": "done",
      "createdAt": "2025-10-13T09:49:22.476Z",
      "updatedAt": "2025-10-13T12:30:18.223Z",
      "description": "Create .coverage files that map Gherkin scenarios to test files and implementation code lines, with statistics and AI-assisted verification",
      "epic": "coverage-tracking",
      "children": [
        "COV-002",
        "COV-003",
        "COV-004",
        "COV-005",
        "COV-006"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T09:49:22.866Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:24:55.611Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:25:17.670Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:30:17.638Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:30:17.932Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:30:18.224Z"
        }
      ],
      "userStory": {
        "role": "developer using ACDD",
        "action": "track which test files and implementation code lines map to each Gherkin scenario",
        "benefit": "I can see exactly what code is covered by acceptance criteria and identify gaps"
      },
      "rules": [
        "Every .feature file must have a corresponding .feature.coverage file",
        "Coverage files must be in JSON format with scenario-to-test-to-code mappings",
        "Coverage files must include calculated statistics (total scenarios, covered scenarios, coverage percentage)",
        "Automatically create .feature.coverage files when feature files are created via create-feature command",
        "AI discovers test-to-scenario mappings using reverse ACDD (rspec.md) for existing code, or tracks mappings during forward ACDD. fspec provides CLI commands for AI to record these mappings",
        "fspec prompts AI agent via interactive 'link-coverage' command (or similar name) to specify which implementation files and lines are covered by tests",
        "Use 'audit-coverage' command that works with AI agent in a loop, prompting it to verify each file's mappings one by one. AI looks up current line numbers and updates coverage file",
        "All statistics: coverage percentage, uncovered scenarios, number of test cases per scenario, implementation files touched, lines covered per file",
        "Separate commands since coverage tracking is interactive and requires AI agent collaboration (link-coverage, audit-coverage, show-coverage, etc.)",
        "JSON schema: {scenarios: [{name, testMappings: [{file, lines, implMappings: [{file, lines}]}]}], stats: {totalScenarios, coveredScenarios, coveragePercent, testFiles, implFiles, totalLinesCovered}}",
        "Yes to both: scenarios can have multiple test files (array of testMappings), and test files can appear in multiple scenario mappings (many-to-many relationship)",
        "Yes, show uncovered scenarios with empty testMappings array. Integrate with ACDD: block work units from moving to 'done' if linked feature has uncovered scenarios. Emit system-reminder to prompt AI to add coverage",
        "Yes, validate file paths exist when linking coverage. Fail with clear error if test file or implementation file path is invalid"
      ],
      "examples": [
        "Feature file 'user-login.feature' has companion file 'user-login.feature.coverage' in same directory",
        "Coverage file maps scenario 'Login with valid credentials' to test file 'src/__tests__/auth.test.ts' lines 45-62",
        "Coverage file shows test at lines 45-62 covers implementation file 'src/auth/login.ts' lines 10,11,12,15,20",
        "User runs 'fspec create-feature User Login', creates user-login.feature AND user-login.feature.coverage automatically",
        "AI runs 'fspec link-coverage user-login --scenario \"Login with valid credentials\" --test-file src/__tests__/auth.test.ts --test-lines 45-62', fspec prompts AI for implementation files",
        "AI runs 'fspec audit-coverage user-login', fspec shows first mapping and asks AI to verify line numbers are still correct, repeats for all mappings",
        "Developer runs 'fspec show-coverage user-login', sees output: 5 scenarios, 4 covered (80%), 2 test files, 3 implementation files, 45 lines covered"
      ],
      "questions": [
        {
          "text": "@human: Should coverage files be created automatically when a feature file is created (via create-feature), or on-demand with a separate command (like init-coverage)?",
          "selected": true,
          "answer": "Automatically create .feature.coverage files when feature files are created via create-feature command"
        },
        {
          "text": "@human: How should the system discover which test files map to which scenarios? Should AI read test files and match them to scenario names, or should users manually link them with a command?",
          "selected": true,
          "answer": "AI discovers test-to-scenario mappings using reverse ACDD (rspec.md) for existing code, or tracks mappings during forward ACDD. fspec provides CLI commands for AI to record these mappings"
        },
        {
          "text": "@human: How should we track which implementation code lines are covered? Should AI parse test code to find which files are imported/used, or should this be manually specified?",
          "selected": true,
          "answer": "fspec prompts AI agent via interactive 'link-coverage' command (or similar name) to specify which implementation files and lines are covered by tests"
        },
        {
          "text": "@human: What happens when code changes and line numbers shift? Should we store line numbers at all, or use some other identifier (like function names, AST nodes, code hashes)?",
          "selected": true,
          "answer": "Use 'audit-coverage' command that works with AI agent in a loop, prompting it to verify each file's mappings one by one. AI looks up current line numbers and updates coverage file"
        },
        {
          "text": "@human: What does 'AI-assisted verification' mean exactly? Should the AI read coverage files and suggest corrections, or interactively ask the developer to confirm mappings?",
          "selected": true,
          "answer": "AI does all verification work during audit-coverage command by reading files, checking line numbers, and confirming mappings are correct"
        },
        {
          "text": "@human: What statistics are most important? Coverage percentage, uncovered scenarios, number of test cases, implementation files touched, something else?",
          "selected": true,
          "answer": "All statistics: coverage percentage, uncovered scenarios, number of test cases per scenario, implementation files touched, lines covered per file"
        },
        {
          "text": "@human: Should coverage validation be integrated into existing commands (like 'fspec check', 'fspec validate'), or be separate commands?",
          "selected": true,
          "answer": "Separate commands since coverage tracking is interactive and requires AI agent collaboration (link-coverage, audit-coverage, show-coverage, etc.)"
        },
        {
          "text": "@human: What should the JSON schema look like? Should it be: {scenarios: [{name, testMappings: [{file, lines, implMappings: [{file, lines}]}]}], stats: {...}}?",
          "selected": true,
          "answer": "JSON schema: {scenarios: [{name, testMappings: [{file, lines, implMappings: [{file, lines}]}]}], stats: {totalScenarios, coveredScenarios, coveragePercent, testFiles, implFiles, totalLinesCovered}}"
        },
        {
          "text": "@human: Can one scenario map to multiple test files? Can one test file cover multiple scenarios?",
          "selected": true,
          "answer": "Yes to both: scenarios can have multiple test files (array of testMappings), and test files can appear in multiple scenario mappings (many-to-many relationship)"
        },
        {
          "text": "@human: What if a scenario has no tests yet (ACDD testing phase not started)? Should coverage file show it as uncovered with empty test mappings?",
          "selected": true,
          "answer": "Yes, show uncovered scenarios with empty testMappings array. Integrate with ACDD: block work units from moving to 'done' if linked feature has uncovered scenarios. Emit system-reminder to prompt AI to add coverage"
        },
        {
          "text": "@human: Should we validate that test files and implementation files actually exist when linking coverage? Fail if file paths are invalid?",
          "selected": true,
          "answer": "Yes, validate file paths exist when linking coverage. Fail with clear error if test file or implementation file path is invalid"
        },
        {
          "text": "@human: Should coverage files be formatted/validated like feature files? Should there be 'fspec validate-coverage' command?",
          "selected": true,
          "answer": "No validation command needed. Coverage files are only modified by fspec commands (link-coverage, audit-coverage), never manually edited. fspec maintains file integrity automatically"
        }
      ],
      "assumptions": [
        "AI does all verification work during audit-coverage command by reading files, checking line numbers, and confirming mappings are correct",
        "No validation command needed. Coverage files are only modified by fspec commands (link-coverage, audit-coverage), never manually edited. fspec maintains file integrity automatically"
      ],
      "estimate": 8
    },
    "COV-002": {
      "id": "COV-002",
      "title": "Auto-create Coverage Files",
      "status": "done",
      "createdAt": "2025-10-13T10:04:49.597Z",
      "updatedAt": "2025-10-13T10:30:26.647Z",
      "description": "Modify create-feature command to automatically generate .feature.coverage JSON files alongside feature files with empty scenario mappings",
      "epic": "coverage-tracking",
      "children": [],
      "parent": "COV-001",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T10:08:21.423Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T10:22:20.882Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T10:25:15.136Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T10:29:47.242Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T10:30:26.647Z"
        }
      ],
      "userStory": {
        "role": "developer creating feature files",
        "action": "have .feature.coverage files automatically created when I run create-feature",
        "benefit": "I don't have to manually create coverage tracking files"
      },
      "rules": [
        "Coverage files must be auto-created when create-feature command runs",
        "Coverage file must be named <feature-name>.feature.coverage (same name as .feature file with .coverage extension)",
        "Coverage file must be in same directory as .feature file (spec/features/)",
        "Coverage file must be valid JSON with schema: {scenarios: [{name, testMappings: []}], stats: {totalScenarios, coveredScenarios, coveragePercent, testFiles, implFiles, totalLinesCovered}}",
        "Initial coverage file must have empty testMappings arrays (no coverage yet)",
        "Scenarios array must be populated from feature file scenarios (read from Gherkin AST)",
        "Stats must be calculated: totalScenarios=count, coveredScenarios=0, coveragePercent=0, testFiles=[], implFiles=[], totalLinesCovered=0",
        "Display message: 'Created <filename>.feature.coverage' so user knows coverage file was generated",
        "If .coverage file exists: read and validate JSON. If valid, skip creation (preserve existing coverage). If invalid JSON, overwrite with fresh coverage file",
        "Scenario names must exactly match Gherkin scenario names (case-sensitive, preserve whitespace) for accurate mapping"
      ],
      "examples": [
        "Run 'fspec create-feature User Login', creates spec/features/user-login.feature AND spec/features/user-login.feature.coverage",
        "Coverage file contains {scenarios: [{name: 'Login with valid credentials', testMappings: []}], stats: {totalScenarios: 1, coveredScenarios: 0, coveragePercent: 0, testFiles: [], implFiles: [], totalLinesCovered: 0}}",
        "Feature file with 3 scenarios creates coverage file with 3 entries in scenarios array, totalScenarios: 3",
        "If create-feature fails (invalid name), no .coverage file should be created",
        "Coverage file exists with valid JSON, create-feature skips creation and displays 'Skipped user-login.feature.coverage (already exists)'",
        "Coverage file exists with invalid JSON, create-feature overwrites it and displays 'Recreated user-login.feature.coverage (previous file was invalid)'"
      ],
      "questions": [
        {
          "text": "@human: Should coverage file creation be silent (no output), or should create-feature display 'Created user-login.feature.coverage'?",
          "selected": true,
          "answer": "Display message: 'Created <filename>.feature.coverage' so user knows coverage file was generated"
        },
        {
          "text": "@human: What if a .coverage file already exists? Should we overwrite it, skip it, or error?",
          "selected": true,
          "answer": "If .coverage file exists: read and validate JSON. If valid, skip creation (preserve existing coverage). If invalid JSON, overwrite with fresh coverage file"
        },
        {
          "text": "@human: Should scenario names in coverage file exactly match Gherkin scenario names (including case/whitespace), or should they be normalized?",
          "selected": true,
          "answer": "Scenario names must exactly match Gherkin scenario names (case-sensitive, preserve whitespace) for accurate mapping"
        }
      ]
    },
    "COV-003": {
      "id": "COV-003",
      "title": "Link Coverage Command",
      "status": "done",
      "createdAt": "2025-10-13T10:04:51.632Z",
      "updatedAt": "2025-10-13T11:25:03.758Z",
      "description": "Implement 'fspec link-coverage' command for mapping scenarios to test files and implementation files with interactive AI prompting and file path validation",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-002"
      ],
      "parent": "COV-001",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T11:03:16.421Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T11:17:50.164Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T11:19:34.215Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T11:24:59.487Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T11:25:03.759Z"
        }
      ],
      "questions": [
        {
          "text": "@human: Should one command support BOTH adding test mapping AND implementation mapping, or separate them into distinct operations?",
          "selected": true,
          "answer": "Non-interactive command-line interface. Support partial additions (test-only, or test+impl). After execution, display helpful message showing how to add more mappings or remove existing ones. No interactive prompts that wait for user input. All operations complete immediately with instructional output."
        },
        {
          "text": "@human: How should the link-coverage command be invoked? (all-in-one, two-step, or interactive prompting?)",
          "selected": true,
          "answer": "Single flexible link-coverage command. Support three modes: (1) test-only (--test-file + --test-lines), (2) impl-only (--impl-file + --impl-lines), (3) both at once (all four flags). Command validates required flag combinations and provides helpful error messages if incorrect combination provided."
        },
        {
          "text": "@human: When adding impl-only (no test flags), which test mapping should it attach to? Most recent test for that scenario, or require test file specification?",
          "selected": true,
          "answer": "Always require --test-file when adding implementation mappings. Implementation mappings attach to specific test mappings, so test file must be specified to identify which test mapping to update. This ensures explicit, unambiguous attachment."
        },
        {
          "text": "@human: For line numbers, should we support ranges (45-62), individual lines (10,11,12), or both? Should format be consistent between test and impl lines?",
          "selected": true,
          "answer": "Test lines: range format only (e.g., '45-62'). Implementation lines: comma-separated primary (e.g., '10,11,12,15,20'), but also accept ranges as convenience (e.g., '10-15' expands to [10,11,12,13,14,15]). This matches storage format and mirrors reality: tests are contiguous, impl can be scattered."
        },
        {
          "text": "@human: Should file paths be validated (check if they exist on disk) before adding to coverage? Error if missing, or allow with warning?",
          "selected": true,
          "answer": "Validate file paths by default (error if file doesn't exist). Support --skip-validation flag to bypass validation for forward planning scenarios. When validation fails, display clear error with file path and suggestion. When --skip-validation used, show warning that file doesn't exist but continue."
        },
        {
          "text": "@human: What happens if you try to link a test mapping that already exists (same scenario + same test file)? Overwrite, append, or error?",
          "selected": true,
          "answer": "Append mode: allow multiple test mappings for the same file in one scenario. Each mapping is independent with its own line range and impl mappings. Display message showing all mappings for that file. This supports scenarios where one scenario is tested multiple times in the same file (e.g., different test suites or contexts)."
        },
        {
          "text": "@human: When adding impl mapping to existing test, what if that test already has impl mappings? Append to the array or replace?",
          "selected": true,
          "answer": "Smart append: check if impl file already exists in the test mapping's implMappings array. If exists, update the line numbers for that file. If doesn't exist, append as new impl mapping. Display whether updated or added. This allows one test to cover multiple impl files while preventing duplicate entries."
        },
        {
          "text": "@human: Should the command support removing/unlinking mappings, or should that be a separate command (like unlink-coverage or remove-coverage)?",
          "selected": true,
          "answer": "Separate command for removal. link-coverage only adds/updates mappings. Display helpful message after linking showing how to remove: 'To remove this mapping: fspec unlink-coverage <feature> --scenario ... --test-file ...'. Removal command (unlink-coverage) is separate work unit, follows fspec pattern of separate add/remove commands."
        }
      ],
      "rules": [
        "Non-interactive command-line interface. Support partial additions (test-only, or test+impl). After execution, display helpful message showing how to add more mappings or remove existing ones. No interactive prompts that wait for user input. All operations complete immediately with instructional output.",
        "Single flexible link-coverage command. Support three modes: (1) test-only (--test-file + --test-lines), (2) impl-only (--impl-file + --impl-lines), (3) both at once (all four flags). Command validates required flag combinations and provides helpful error messages if incorrect combination provided.",
        "Always require --test-file when adding implementation mappings. Implementation mappings attach to specific test mappings, so test file must be specified to identify which test mapping to update. This ensures explicit, unambiguous attachment.",
        "Test lines: range format only (e.g., '45-62'). Implementation lines: comma-separated primary (e.g., '10,11,12,15,20'), but also accept ranges as convenience (e.g., '10-15' expands to [10,11,12,13,14,15]). This matches storage format and mirrors reality: tests are contiguous, impl can be scattered.",
        "Validate file paths by default (error if file doesn't exist). Support --skip-validation flag to bypass validation for forward planning scenarios. When validation fails, display clear error with file path and suggestion. When --skip-validation used, show warning that file doesn't exist but continue.",
        "Append mode: allow multiple test mappings for the same file in one scenario. Each mapping is independent with its own line range and impl mappings. Display message showing all mappings for that file. This supports scenarios where one scenario is tested multiple times in the same file (e.g., different test suites or contexts).",
        "Smart append: check if impl file already exists in the test mapping's implMappings array. If exists, update the line numbers for that file. If doesn't exist, append as new impl mapping. Display whether updated or added. This allows one test to cover multiple impl files while preventing duplicate entries.",
        "Separate command for removal. link-coverage only adds/updates mappings. Display helpful message after linking showing how to remove: 'To remove this mapping: fspec unlink-coverage <feature> --scenario ... --test-file ...'. Removal command (unlink-coverage) is separate work unit, follows fspec pattern of separate add/remove commands."
      ],
      "examples": [
        "User runs 'fspec link-coverage user-login --scenario \"Login with valid credentials\" --test-file src/__tests__/auth.test.ts --test-lines 45-62', creates test mapping, displays success and helpful message",
        "User runs 'fspec link-coverage user-login --scenario \"Login with valid credentials\" --test-file src/__tests__/auth.test.ts --impl-file src/auth/login.ts --impl-lines 10,11,12', adds impl mapping to existing test",
        "User runs command with both test and impl flags at once, creates test mapping with impl mapping in one operation",
        "Test file doesn't exist, validation fails with error and suggestion to use --skip-validation",
        "User provides --skip-validation flag with non-existent file, command succeeds with warning message",
        "Impl lines '10-15' (range format) expands to array [10,11,12,13,14,15] in coverage file",
        "Adding impl file that already exists in test mapping updates line numbers instead of creating duplicate entry",
        "Adding test mapping with same test file but different lines appends as second mapping"
      ],
      "userStory": {
        "role": "developer tracking test coverage",
        "action": "link scenarios to test files and implementation files",
        "benefit": "I can track which code covers which acceptance criteria"
      }
    },
    "COV-004": {
      "id": "COV-004",
      "title": "Show Coverage Statistics",
      "status": "done",
      "createdAt": "2025-10-13T10:04:53.307Z",
      "updatedAt": "2025-10-13T11:01:35.541Z",
      "description": "Implement 'fspec show-coverage' command to display coverage statistics including percentage, test files, implementation files, and line counts",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-002"
      ],
      "parent": "COV-001",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T10:35:18.928Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T10:58:41.331Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T10:59:49.378Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T11:01:24.285Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T11:01:35.542Z"
        }
      ],
      "questions": [
        {
          "text": "@human: What output format(s) should show-coverage support? (text/json/markdown, with --format flag?)",
          "selected": true,
          "answer": "Markdown and JSON output formats. Default to markdown. Use --format flag (--format=json for JSON output, --format=markdown or no flag for markdown)"
        },
        {
          "text": "@human: For text output, what level of detail by default? (summary only, full breakdown, or configurable with --verbose?)",
          "selected": true,
          "answer": "Full breakdown always shown by default in markdown. Include summary stats + scenario-by-scenario coverage details (test files, implementation files, line numbers). Show which scenarios are covered and uncovered."
        },
        {
          "text": "@human: Should uncovered scenarios be highlighted in red and/or listed separately?",
          "selected": true,
          "answer": "Use both visual symbols (✅ for covered, ❌ for uncovered) throughout scenario list AND create a separate 'Coverage Gaps' section at the end listing all uncovered scenarios with action items"
        },
        {
          "text": "@human: Should show-coverage work on single file, all files, or both? (Usage: fspec show-coverage [file])",
          "selected": true,
          "answer": "Support both modes: show all files when no argument provided, show specific file when file path is provided. File path can be relative (user-login.feature) or full path (spec/features/user-login.feature)"
        },
        {
          "text": "@human: If showing all files, display aggregated stats, per-feature breakdown, or both?",
          "selected": true,
          "answer": "Both: show aggregated project summary at top (overall coverage, total features/scenarios, features overview table), then full per-feature breakdowns with scenario details for each feature file"
        },
        {
          "text": "@human: How to calculate covered scenarios? (has test mapping, or test + impl mappings?)",
          "selected": true,
          "answer": "Three-tier coverage system: 'Fully Covered' (has test mapping AND implementation mappings), 'Partially Covered' (has test mapping but empty implMappings), 'Uncovered' (no test mappings). Statistics should count fully covered + partially covered as total covered scenarios."
        },
        {
          "text": "@human: For line counts, count impl lines only, or test + impl lines separately?",
          "selected": true,
          "answer": "Separate counts for test lines and implementation lines. Display 'Test Lines', 'Implementation Lines', and 'Total Lines' in statistics. Parse line ranges (e.g., '45-62' = 18 lines) and count individual lines in arrays."
        },
        {
          "text": "@human: Should we validate that mapped files/lines still exist? (always, never, or --validate flag?)",
          "selected": true,
          "answer": "Always validate file paths exist when displaying coverage. Check that test files and implementation files exist on disk. Display warnings for missing files but still show the coverage data. This ensures users are immediately aware of stale mappings."
        },
        {
          "text": "@human: What happens if .coverage file doesn't exist? (error, show 0% with message, or suggest creating?)",
          "selected": true,
          "answer": "Error and exit with code 1 when .coverage file doesn't exist. Display clear error message with suggestion to create coverage file using appropriate command (fspec create-feature or manually). This ensures explicit coverage tracking setup."
        },
        {
          "text": "@human: What happens if .coverage file has invalid JSON? (error, warning, or try to parse?)",
          "selected": true,
          "answer": "Error and exit with code 1 when .coverage file has invalid JSON. Display parse error details (line number, error message) and suggest validating/recreating the file. Keep error message focused on the parse failure."
        }
      ],
      "rules": [
        "Markdown and JSON output formats. Default to markdown. Use --format flag (--format=json for JSON output, --format=markdown or no flag for markdown)",
        "Full breakdown always shown by default in markdown. Include summary stats + scenario-by-scenario coverage details (test files, implementation files, line numbers). Show which scenarios are covered and uncovered.",
        "Use both visual symbols (✅ for covered, ❌ for uncovered) throughout scenario list AND create a separate 'Coverage Gaps' section at the end listing all uncovered scenarios with action items",
        "Support both modes: show all files when no argument provided, show specific file when file path is provided. File path can be relative (user-login.feature) or full path (spec/features/user-login.feature)",
        "Both: show aggregated project summary at top (overall coverage, total features/scenarios, features overview table), then full per-feature breakdowns with scenario details for each feature file",
        "Three-tier coverage system: 'Fully Covered' (has test mapping AND implementation mappings), 'Partially Covered' (has test mapping but empty implMappings), 'Uncovered' (no test mappings). Statistics should count fully covered + partially covered as total covered scenarios.",
        "Separate counts for test lines and implementation lines. Display 'Test Lines', 'Implementation Lines', and 'Total Lines' in statistics. Parse line ranges (e.g., '45-62' = 18 lines) and count individual lines in arrays.",
        "Always validate file paths exist when displaying coverage. Check that test files and implementation files exist on disk. Display warnings for missing files but still show the coverage data. This ensures users are immediately aware of stale mappings.",
        "Error and exit with code 1 when .coverage file doesn't exist. Display clear error message with suggestion to create coverage file using appropriate command (fspec create-feature or manually). This ensures explicit coverage tracking setup.",
        "Error and exit with code 1 when .coverage file has invalid JSON. Display parse error details (line number, error message) and suggest validating/recreating the file. Keep error message focused on the parse failure."
      ],
      "examples": [
        "User runs 'fspec show-coverage user-login.feature', displays markdown report with 80% coverage (4/5 scenarios), full breakdown with symbols, and Coverage Gaps section",
        "User runs 'fspec show-coverage user-login.feature --format=json', outputs JSON with scenarios array, stats object, three-tier coverage status",
        "User runs 'fspec show-coverage' (no args), displays project summary with aggregated stats + per-feature breakdown for all .coverage files",
        "Scenario has test mapping with empty implMappings array, displayed as '⚠️ PARTIALLY COVERED' with warning icon",
        "Test file path doesn't exist on disk, display '⚠️ File not found: src/__tests__/deleted.test.ts' warning but still show coverage",
        "Line range '45-62' counts as 18 test lines, array [10,11,12,15,20] counts as 5 impl lines, displayed separately in stats",
        "User runs 'fspec show-coverage missing.feature', .coverage file doesn't exist, error with exit code 1 and suggestion message",
        ".coverage file has invalid JSON, command fails with parse error showing line number and suggestion to recreate"
      ],
      "userStory": {
        "role": "developer tracking test coverage",
        "action": "view coverage statistics for feature files",
        "benefit": "I can identify gaps in test coverage and track testing progress"
      }
    },
    "COV-005": {
      "id": "COV-005",
      "title": "Audit Coverage Command",
      "status": "done",
      "createdAt": "2025-10-13T10:04:55.178Z",
      "updatedAt": "2025-10-13T12:13:39.422Z",
      "description": "Implement 'fspec audit-coverage' command with interactive AI loop to verify and update line number mappings when code changes",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-002"
      ],
      "parent": "COV-001",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T11:58:47.194Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:09:52.214Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:10:30.001Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:12:54.205Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:13:39.422Z"
        }
      ],
      "userStory": {
        "role": "developer maintaining coverage tracking",
        "action": "audit and update line number mappings when code changes",
        "benefit": "I keep coverage data accurate as code evolves"
      },
      "questions": [
        {
          "text": "@human: Should audit-coverage automatically update line numbers if it detects they've shifted, or prompt AI to manually verify?",
          "selected": true,
          "answer": "Prompt AI to change (but unclear how to detect line shifts automatically)"
        },
        {
          "text": "@human: Should audit-coverage check that test files and implementation files still exist?",
          "selected": true,
          "answer": "Yes, verify that test files and implementation files exist"
        },
        {
          "text": "@human: Should audit-coverage be interactive or just display a report?",
          "selected": true,
          "answer": "Display good information on what to do next if something's not right (report with actionable recommendations)"
        }
      ],
      "assumptions": [
        "Prompt AI to change (but unclear how to detect line shifts automatically)"
      ],
      "rules": [
        "Yes, verify that test files and implementation files exist",
        "Display good information on what to do next if something's not right (report with actionable recommendations)",
        "Audit command must validate that all test files referenced in coverage exist on disk",
        "Audit command must validate that all implementation files referenced in coverage exist on disk",
        "Report must show missing files with clear actionable recommendations (remove stale mappings or restore deleted files)",
        "Command accepts feature file name as argument (e.g., 'fspec audit-coverage user-login')",
        "Output format: markdown report with sections for each scenario's mappings and issues found"
      ],
      "examples": [
        "Run 'fspec audit-coverage user-login', checks all files exist, displays report showing 3/3 files found, all mappings valid",
        "Audit finds test file missing, displays '❌ Test file not found: src/__tests__/deleted.test.ts' with recommendation to remove mapping",
        "Audit finds impl file missing, displays '❌ Implementation file not found: src/auth/deleted.ts' with recommendation"
      ]
    },
    "COV-006": {
      "id": "COV-006",
      "title": "ACDD Workflow Integration",
      "status": "done",
      "createdAt": "2025-10-13T10:04:57.016Z",
      "updatedAt": "2025-10-13T12:24:09.837Z",
      "description": "Integrate coverage tracking with ACDD workflow: block work unit progression to 'done' if coverage incomplete, emit system-reminders for uncovered scenarios",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-003",
        "COV-004",
        "COV-005"
      ],
      "parent": "COV-001",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T12:15:18.461Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:18:09.260Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:19:26.284Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:22:37.057Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:24:09.838Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec with ACDD workflow",
        "action": "ensure work units cannot be marked done when coverage is incomplete",
        "benefit": "I maintain quality standards and prevent incomplete work from being considered complete"
      },
      "rules": [
        "Block work unit status update to 'done' if linked feature file has uncovered scenarios (scenarios with empty testMappings array)",
        "Emit system-reminder when work unit cannot advance to done due to incomplete coverage, showing which scenarios lack coverage",
        "System-reminder must include specific commands to add coverage (e.g., 'fspec link-coverage <feature> --scenario ...')",
        "Check coverage completeness by reading .feature.coverage file and looking for scenarios with empty testMappings arrays",
        "Coverage checking is always enforced (no optional flag) to maintain consistent quality standards",
        "If .coverage file doesn't exist, allow status update with warning. If .coverage file exists, enforce coverage completeness.",
        "Only check coverage when moving to 'done' status, not when moving to 'validating'"
      ],
      "examples": [
        "Work unit AUTH-001 linked to user-login.feature with all 5 scenarios covered (all have testMappings), status update to 'done' succeeds",
        "Work unit AUTH-001 linked to user-login.feature with 2/5 scenarios uncovered (empty testMappings), status update to 'done' fails with error message and system-reminder",
        "System-reminder displays: '❌ Cannot mark work unit done: 2 scenarios uncovered in user-login.feature' with list of uncovered scenario names"
      ],
      "questions": [
        {
          "text": "@human: Should this blocking behavior be optional (via flag) or always enforced?",
          "selected": true,
          "answer": "Always enforced - this maintains quality standards consistently"
        },
        {
          "text": "@human: What happens if the .coverage file doesn't exist for a linked feature - should that block the status update?",
          "selected": true,
          "answer": "If .coverage file doesn't exist, allow the status update with a warning (coverage tracking is optional). But if .coverage file exists, enforce coverage completeness."
        },
        {
          "text": "@human: Should we only check coverage when moving to 'done' status, or also when moving to 'validating'?",
          "selected": true,
          "answer": "Only check coverage when moving to 'done' status - validating is still part of the development process"
        }
      ]
    },
    "BUG-005": {
      "id": "BUG-005",
      "title": "Remove work unit ID tags from generate-scenarios",
      "status": "done",
      "createdAt": "2025-10-13T11:30:51.399Z",
      "updatedAt": "2025-10-13T11:55:59.660Z",
      "description": "Fixed generate-scenarios to add work unit IDs as FEATURE-LEVEL tags only (not scenario-level). Modified check.ts to use proper validateTags function. Removed scenario-level work unit ID tags from all feature files. This implements the optimal two-tier linking system: feature-level tags for coarse-grained work unit → feature association, with coverage files providing fine-grained scenario traceability.",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T11:31:08.692Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T11:55:24.402Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T11:55:30.552Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T11:55:36.124Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T11:55:59.661Z"
        }
      ],
      "userStory": {
        "role": "developer maintaining fspec",
        "action": "verify that generate-scenarios adds work unit ID tags only at feature level",
        "benefit": "I ensure the two-tier linking system (feature-level tags + coverage files) works correctly"
      },
      "rules": [
        "Work unit ID tags must appear at feature level only, not scenario level",
        "generate-scenarios command must add work unit ID as feature-level tag",
        "Existing feature files must not have scenario-level work unit ID tags",
        "check.ts validation must use proper validateTags function",
        "Yes, add automated tests to verify generate-scenarios adds work unit ID at feature level only (check if tests already exist first)",
        "Yes, create validation rule to reject scenario-level work unit ID tags. However, many existing features already have work unit IDs, so the script (Q3) must fix them first before validation can be enforced",
        "Write a script to scan all feature files and move scenario-level work unit ID tags to feature level. This must run before validation enforcement"
      ],
      "examples": [
        "Run generate-scenarios for a work unit, verify the generated feature file has work unit ID as feature-level tag (e.g., @BUG-005 at top)",
        "Run generate-scenarios for a work unit, verify generated scenarios do NOT have work unit ID tags at scenario level",
        "Check existing feature files to verify no scenario-level work unit ID tags remain (like @COV-001 on individual scenarios)",
        "Verify check.ts uses validateTags() function instead of inline validation logic",
        "Write script that scans spec/features/*.feature files, finds scenario-level work unit ID tags (like @COV-001 on scenarios), moves them to feature-level tags",
        "After script runs, validate-tags command should reject any feature file with scenario-level work unit ID tags (pattern: @[A-Z]+-[0-9]+)"
      ],
      "questions": [
        {
          "text": "@human: Should we add automated tests to verify generate-scenarios adds work unit ID at feature level only?",
          "selected": true,
          "answer": "Yes, add automated tests to verify generate-scenarios adds work unit ID at feature level only (check if tests already exist first)"
        },
        {
          "text": "@human: Should we create a validation rule in check.ts or validate-tags to reject scenario-level work unit ID tags?",
          "selected": true,
          "answer": "Yes, create validation rule to reject scenario-level work unit ID tags. However, many existing features already have work unit IDs, so the script (Q3) must fix them first before validation can be enforced"
        },
        {
          "text": "@human: Is manual verification of existing feature files sufficient, or should we write a script to scan all feature files?",
          "selected": true,
          "answer": "Write a script to scan all feature files and move scenario-level work unit ID tags to feature level. This must run before validation enforcement"
        }
      ]
    },
    "BUG-006": {
      "id": "BUG-006",
      "title": "Parent work units shouldn't require scenarios",
      "status": "done",
      "createdAt": "2025-10-13T12:26:15.841Z",
      "updatedAt": "2025-10-13T12:30:03.560Z",
      "description": "Parent work units without linkedFeatures should only require all children to be done, not require scenarios to exist when moving to testing status",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T12:26:21.933Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:29:49.558Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:29:49.849Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:29:50.141Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:30:03.561Z"
        }
      ],
      "userStory": {
        "role": "developer working on parent work units",
        "action": "move parent work units through workflow without requiring scenarios",
        "benefit": "parent work units are containers that don't need their own feature files"
      },
      "rules": [
        "Parent work units (work units with children array) should skip scenario validation when moving to testing",
        "checkScenariosExist function should return true immediately if work unit has children",
        "Only leaf work units (no children) need to have scenarios tagged with @WORK-UNIT-ID",
        "Parent work units can only move to done when ALL children are done (existing validation)"
      ],
      "examples": [
        "COV-001 (parent with 5 children all done) can move from specifying -> testing -> implementing -> validating -> done without scenario validation",
        "COV-002 (leaf work unit, no children) requires @COV-002 tag in feature file to move to testing",
        "Parent work unit with incomplete children (COV-001 with COV-006 still in implementing) cannot move to done"
      ]
    },
    "COV-007": {
      "id": "COV-007",
      "title": "Generate Coverage Files for Existing Features",
      "status": "done",
      "createdAt": "2025-10-13T22:05:01.056Z",
      "updatedAt": "2025-10-13T22:14:08.318Z",
      "description": "Add a command to generate .feature.coverage files for existing feature files that don't have coverage tracking yet",
      "epic": "coverage-tracking",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T22:05:07.139Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T22:10:05.598Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T22:11:20.482Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T22:13:34.764Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T22:14:08.318Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for coverage tracking",
        "action": "generate coverage files for existing feature files that lack them",
        "benefit": "I can start tracking test coverage for features created before coverage tracking was implemented"
      },
      "rules": [
        "Command must scan spec/features/ directory for .feature files",
        "For each .feature file without a corresponding .feature.coverage file, generate one",
        "Skip files that already have valid .feature.coverage files (preserve existing coverage data)",
        "Overwrite .feature.coverage files that have invalid JSON (corrupted files)",
        "Generated coverage files must have same JSON schema as auto-created coverage files from create-feature",
        "Display summary: X files created, Y files skipped, Z files recreated (invalid JSON)",
        "Support --dry-run flag to preview what would be generated without creating files"
      ],
      "examples": [
        "Project has 66 .feature files, 0 .coverage files → command creates 66 .coverage files",
        "Project has 50 .feature files, 30 valid .coverage files → command creates 20 new .coverage files, skips 30",
        "Project has user-login.feature with 5 scenarios → generates user-login.feature.coverage with 5 entries in scenarios array, all with empty testMappings",
        "Run with --dry-run flag → displays what would be created but doesn't create any files",
        "Corrupted .coverage file with invalid JSON → overwrites with valid empty coverage file, displays 'Recreated'"
      ]
    },
    "COV-008": {
      "id": "COV-008",
      "title": "Unlink Coverage Mappings",
      "status": "done",
      "createdAt": "2025-10-13T22:20:53.067Z",
      "updatedAt": "2025-10-13T22:29:19.706Z",
      "description": "Add unlink-coverage command to remove test and implementation mappings from scenarios",
      "epic": "coverage-tracking",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T22:22:54.879Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T22:25:51.670Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T22:26:42.302Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T22:28:53.095Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T22:29:19.707Z"
        }
      ],
      "userStory": {
        "role": "developer managing coverage tracking",
        "action": "remove incorrect or outdated test and implementation mappings from scenarios",
        "benefit": "I can correct mistakes and update coverage as code evolves without manual JSON editing"
      },
      "rules": [
        "Support --all flag to remove all mappings for a scenario (reset to uncovered)",
        "Support removing specific test mapping by test-file path",
        "Support removing only implementation mapping while keeping test mapping",
        "Removing test mapping must also remove all its implementation mappings",
        "Must recalculate stats after any removal operation",
        "Error if scenario not found in coverage file"
      ],
      "examples": [
        "Remove all mappings: unlink-coverage user-login --scenario 'Login' --all → scenario becomes uncovered, stats recalculated",
        "Remove test mapping: unlink-coverage user-login --scenario 'Login' --test-file src/__tests__/auth.test.ts → removes test and all its impl mappings",
        "Remove only impl: unlink-coverage user-login --scenario 'Login' --test-file src/__tests__/auth.test.ts --impl-file src/auth/old.ts → keeps test mapping",
        "Error if scenario not found → displays available scenarios"
      ]
    },
    "DOC-003": {
      "id": "DOC-003",
      "title": "Clarify backward movement in workflow documentation",
      "status": "done",
      "createdAt": "2025-10-14T01:57:04.564Z",
      "updatedAt": "2025-10-14T10:51:21.943Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-14T01:57:11.127Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-14T10:47:23.806Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-14T10:50:35.138Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-14T10:50:42.296Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-14T10:51:21.944Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec workflow",
        "action": "understand backward state transitions",
        "benefit": "I can confidently move work backward when fixing mistakes"
      },
      "rules": [
        "Cannot skip states forward (ACDD enforcement)",
        "CAN move backward from validating to implementing or specifying to fix issues",
        "CAN move backward from done to any previous state when mistakes discovered",
        "Cannot move back to backlog (use blocked state instead)",
        "Blocked state can transition back to any non-done state",
        "Just text - CLI help should be text-based for terminal readability"
      ],
      "examples": [
        "Move from testing to specifying when tests revealed incomplete acceptance criteria",
        "Move from implementing to testing when test cases need refactoring",
        "Move from validating to implementing when quality checks fail",
        "Move from done to implementing when bug discovered in completed feature",
        "Try to move from backlog to testing - blocked (must go through specifying)"
      ],
      "questions": [
        {
          "text": "@human: Should help include visual state diagram or just text describing backward transitions?",
          "selected": true,
          "answer": "Just text - CLI help should be text-based for terminal readability"
        }
      ],
      "estimate": 2
    },
    "COV-010": {
      "id": "COV-010",
      "title": "Test: Example mapping commands auto-create work-units.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:11.075Z",
      "updatedAt": "2025-10-15T00:24:35.178Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. Need to create tests and implementation for example mapping commands using ensure utilities.",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:17:47.933Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:24:28.002Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:24:34.500Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:24:34.830Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:24:35.179Z"
        }
      ],
      "estimate": 2,
      "epic": "test-coverage"
    },
    "COV-011": {
      "id": "COV-011",
      "title": "Test: Dependency commands auto-create work-units.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:12.810Z",
      "updatedAt": "2025-10-15T00:25:55.102Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Implementation exists in ensure-files.ts, need tests to verify dependency commands use it.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:25:53.922Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:25:54.220Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:25:54.512Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:25:54.805Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:25:55.102Z"
        }
      ]
    },
    "COV-012": {
      "id": "COV-012",
      "title": "Test: Ensure utilities validate JSON structure",
      "status": "done",
      "createdAt": "2025-10-15T00:10:14.369Z",
      "updatedAt": "2025-10-15T00:29:07.394Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No tests found for validation within ensure utilities. Tests verify creation but not schema validation.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:27:05.485Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:27:54.504Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:28:30.230Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:29:07.099Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:29:07.395Z"
        }
      ],
      "rules": [
        "Ensure utilities must detect corrupted JSON files",
        "Ensure utilities must provide helpful error messages indicating what went wrong"
      ],
      "examples": [
        "Corrupted JSON with trailing comma throws parse error with file path",
        "Invalid JSON with missing closing brace throws parse error with line number"
      ],
      "estimate": 3
    },
    "COV-013": {
      "id": "COV-013",
      "title": "Test: All 48+ commands use ensure utilities",
      "status": "done",
      "createdAt": "2025-10-15T00:10:16.274Z",
      "updatedAt": "2025-10-15T00:33:46.472Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Need integration tests to verify all commands use ensure utilities instead of direct file reads.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:31:57.735Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:32:52.803Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:33:40.011Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:33:46.175Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:33:46.473Z"
        }
      ],
      "estimate": 2
    },
    "COV-014": {
      "id": "COV-014",
      "title": "Test: List work units command auto-creates work-units.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:17.732Z",
      "updatedAt": "2025-10-15T00:34:01.759Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Implementation exists (ensureWorkUnitsFile), need test to verify list-work-units command uses it.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:32:40.879Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:00.881Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:01.174Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:01.467Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:01.760Z"
        }
      ],
      "estimate": 2
    },
    "COV-015": {
      "id": "COV-015",
      "title": "Test: Update work unit uses ensureWorkUnitsFile",
      "status": "done",
      "createdAt": "2025-10-15T00:10:19.515Z",
      "updatedAt": "2025-10-15T00:34:03.243Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Need to verify update-work-unit command implementation uses ensure utility.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:32:42.787Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:02.357Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:02.648Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:02.942Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:03.243Z"
        }
      ],
      "estimate": 2
    },
    "COV-016": {
      "id": "COV-016",
      "title": "Test: Register tag auto-creates tags.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:31.606Z",
      "updatedAt": "2025-10-15T00:34:04.720Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Implementation likely exists but no specific test for register-tag using ensure utilities.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:32:44.610Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:03.831Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:04.127Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:04.425Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:04.720Z"
        }
      ],
      "estimate": 2
    },
    "COV-017": {
      "id": "COV-017",
      "title": "Test: Update foundation auto-creates foundation.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:31.907Z",
      "updatedAt": "2025-10-15T00:34:38.486Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No ensure utility or test found for foundation.json auto-creation.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:35.262Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:37.605Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:37.899Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:38.193Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:38.486Z"
        }
      ]
    },
    "COV-018": {
      "id": "COV-018",
      "title": "Test: List tags auto-creates tags.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:32.205Z",
      "updatedAt": "2025-10-15T00:34:39.662Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No test found verifying list-tags auto-creates tags.json.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:35.845Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:38.783Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:39.078Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:39.371Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:39.662Z"
        }
      ]
    },
    "COV-019": {
      "id": "COV-019",
      "title": "Test: Show foundation auto-creates foundation.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:32.497Z",
      "updatedAt": "2025-10-15T00:34:40.844Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No test found verifying show-foundation auto-creates foundation.json.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:36.429Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:39.958Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:40.255Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:40.549Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:40.845Z"
        }
      ]
    },
    "COV-020": {
      "id": "COV-020",
      "title": "Test: Register example mapping commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:42.265Z",
      "updatedAt": "2025-10-15T00:40:47.452Z",
      "description": "Feature: cli-command-registration. Status: CREATE_BOTH. Test file only verifies 39 commands excluding example mapping. Need to add example mapping commands to registration test.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:59.479Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:40:24.923Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:40:46.567Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:40:46.863Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:40:47.453Z"
        }
      ],
      "rules": [
        "Example mapping commands must be registered in CLI"
      ],
      "examples": [
        "add-rule, add-example, add-question commands should be accessible via CLI"
      ]
    },
    "COV-021": {
      "id": "COV-021",
      "title": "Test: Register workflow automation commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:42.555Z",
      "updatedAt": "2025-10-15T00:43:06.614Z",
      "description": "Feature: cli-command-registration. Status: CREATE_BOTH. No tests found for workflow automation command registration.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:01.240Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:42:15.799Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:42:39.547Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:42:59.849Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:43:06.615Z"
        }
      ],
      "rules": [
        "Workflow commands must be registered: auto-advance, board, workflow-automation"
      ],
      "examples": [
        "Running 'fspec workflow-automation' should show workflow automation options"
      ]
    },
    "COV-022": {
      "id": "COV-022",
      "title": "Test: Register validation commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:42.849Z",
      "updatedAt": "2025-10-15T00:43:28.938Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. Validation commands likely registered but no specific test verifies registration.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:03.008Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:43:21.439Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:43:28.062Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:43:28.356Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:43:28.938Z"
        }
      ],
      "rules": [
        "Validation commands must be registered: validate-spec-alignment, validate-work-units, repair-work-units"
      ],
      "examples": [
        "Running 'fspec validate-work-units' should verify work unit data integrity"
      ]
    },
    "COV-023": {
      "id": "COV-023",
      "title": "Test: Register assumption management command",
      "status": "done",
      "createdAt": "2025-10-15T00:10:43.142Z",
      "updatedAt": "2025-10-15T00:43:46.185Z",
      "description": "Feature: cli-command-registration. Status: CREATE_BOTH. No tests found for assumption management command.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:04.770Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:43:45.014Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:43:45.311Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:43:45.603Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:43:46.185Z"
        }
      ],
      "rules": [
        "Assumption management command must be registered: add-assumption"
      ],
      "examples": [
        "Running 'fspec add-assumption feature-name \"assumption\"' should add assumption to feature file"
      ]
    },
    "COV-024": {
      "id": "COV-024",
      "title": "Test: Update help text for all command categories",
      "status": "done",
      "createdAt": "2025-10-15T00:10:53.824Z",
      "updatedAt": "2025-10-15T00:44:02.469Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. Need test to verify help text is complete for all categories.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:06.523Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:44:01.294Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:44:01.588Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:44:01.883Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:44:02.469Z"
        }
      ],
      "rules": [
        "Help text must include all commands in their respective categories"
      ],
      "examples": [
        "Running 'fspec help project' should show all work unit commands"
      ]
    },
    "COV-025": {
      "id": "COV-025",
      "title": "Test: Help system shows all commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:54.124Z",
      "updatedAt": "2025-10-15T00:44:19.832Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. No test verifies help output includes all commands.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:08.285Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:44:18.664Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:44:18.959Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:44:19.250Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:44:19.833Z"
        }
      ],
      "rules": [
        "Help output must list all available commands organized by category"
      ],
      "examples": [
        "Running 'fspec --help' should show commands for spec, tags, foundation, query, and project management"
      ]
    },
    "COV-026": {
      "id": "COV-026",
      "title": "Test: Build succeeds with no errors",
      "status": "done",
      "createdAt": "2025-10-15T00:10:54.426Z",
      "updatedAt": "2025-10-15T00:44:52.043Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. Integration test needed to verify build success.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:10.042Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:44:50.873Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:44:51.164Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:44:51.457Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:44:52.044Z"
        }
      ],
      "rules": [
        "Build must succeed with exit code 0 after command registration changes"
      ],
      "examples": [
        "Running 'npm run build' should create dist/index.js with no TypeScript errors"
      ]
    },
    "COV-027": {
      "id": "COV-027",
      "title": "Test: System-reminder after create-feature with prefill",
      "status": "done",
      "createdAt": "2025-10-15T00:10:54.737Z",
      "updatedAt": "2025-10-15T00:45:17.872Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_TEST_ONLY. Tests verify prefill detection but no integration test for create-feature command displaying the reminder.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:11.805Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:16.989Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:17.286Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:17.579Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:17.873Z"
        }
      ],
      "rules": [
        "System-reminder must appear when create-feature generates prefill"
      ],
      "examples": [
        "After creating feature, reminder suggests 'fspec set-user-story' for [role]/[action]/[benefit] placeholders"
      ]
    },
    "COV-028": {
      "id": "COV-028",
      "title": "Test: System-reminder after generate-scenarios with prefill",
      "status": "done",
      "createdAt": "2025-10-15T00:11:05.298Z",
      "updatedAt": "2025-10-15T00:45:28.016Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_TEST_ONLY. Need integration test for generate-scenarios command.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:13.572Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:27.132Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:27.426Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:27.723Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:28.017Z"
        }
      ],
      "rules": [
        "System-reminder must appear when generate-scenarios creates prefill steps"
      ],
      "examples": [
        "After generating scenarios, reminder suggests 'fspec add-step' for placeholder steps"
      ]
    },
    "COV-029": {
      "id": "COV-029",
      "title": "Test: User story from Example Mapping generates complete Background",
      "status": "done",
      "createdAt": "2025-10-15T00:11:05.606Z",
      "updatedAt": "2025-10-15T00:45:38.597Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_BOTH. No tests found for Example Mapping user story to Background conversion.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:15.340Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:37.713Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:38.009Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:38.302Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:38.598Z"
        }
      ],
      "rules": [
        "User story from Example Mapping must generate complete Background without placeholders"
      ],
      "examples": [
        "When work unit has role/action/benefit set, generated Background should contain full user story"
      ]
    },
    "COV-030": {
      "id": "COV-030",
      "title": "Test: Workflow blocking prevents status change with prefill",
      "status": "done",
      "createdAt": "2025-10-15T00:11:05.899Z",
      "updatedAt": "2025-10-15T00:45:48.589Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_BOTH. No tests found for workflow blocking based on prefill detection.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:17.102Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:47.707Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:48.003Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:48.298Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:48.590Z"
        }
      ],
      "rules": [
        "Workflow status change must be blocked when linked feature file has prefill"
      ],
      "examples": [
        "Trying to move work unit to testing status should fail with error if feature file has [role]/[action] placeholders"
      ]
    },
    "COV-031": {
      "id": "COV-031",
      "title": "Test: Support custom output path for generate-foundation-md",
      "status": "done",
      "createdAt": "2025-10-15T00:11:06.192Z",
      "updatedAt": "2025-10-19T13:17:25.558Z",
      "description": "Feature: generate-foundation-md. Status: CREATE_TEST_ONLY. No test found for custom output path option.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:18.861Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T05:19:25.404Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:19:33.637Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:20:18.071Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:20:19.824Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T13:13:06.763Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T13:17:25.285Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T13:17:25.559Z"
        }
      ],
      "rules": [
        "generate-foundation-md must support custom output path option"
      ],
      "examples": [
        "'fspec generate-foundation-md --output custom/path.md' should create file at custom path"
      ]
    },
    "COV-032": {
      "id": "COV-032",
      "title": "Test: Support custom output path for generate-tags-md",
      "status": "done",
      "createdAt": "2025-10-15T00:11:16.150Z",
      "updatedAt": "2025-10-15T00:46:36.449Z",
      "description": "Feature: generate-tags-md. Status: CREATE_TEST_ONLY. No test found for custom output path option.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:20.631Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:46:35.511Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:46:35.806Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:46:36.103Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:46:36.450Z"
        }
      ],
      "rules": [
        "generate-tags-md must support custom output path option"
      ],
      "examples": [
        "'fspec generate-tags-md --output custom/path.md' should create file at custom path"
      ]
    },
    "COV-033": {
      "id": "COV-033",
      "title": "Test: List all scenarios for multiple work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:16.442Z",
      "updatedAt": "2025-10-15T05:24:22.365Z",
      "description": "Feature: get-scenarios. Status: CREATE_TEST_ONLY. No test found for listing scenarios from multiple work units simultaneously.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:22.406Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T05:24:21.188Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:24:21.481Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:24:22.071Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:24:22.366Z"
        }
      ],
      "rules": [
        "get-scenarios must support listing scenarios from multiple work units"
      ],
      "examples": [
        "'fspec get-scenarios AUTH-001 AUTH-002' should list scenarios from both work units"
      ]
    },
    "COV-034": {
      "id": "COV-034",
      "title": "Test: Rollback if markdown generation fails",
      "status": "done",
      "createdAt": "2025-10-15T00:11:16.747Z",
      "updatedAt": "2025-10-15T00:47:53.359Z",
      "description": "Feature: register-tag-json-backed. Status: CREATE_TEST_ONLY. No test found for rollback behavior on TAGS.md generation failure.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:24.174Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:47:52.447Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:47:52.752Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:47:53.056Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:47:53.360Z"
        }
      ],
      "rules": [
        "Tag registration must rollback if TAGS.md generation fails"
      ],
      "examples": [
        "If TAGS.md generation errors, tags.json should revert to previous state"
      ]
    },
    "COV-035": {
      "id": "COV-035",
      "title": "Test: Update statistics after registering tag",
      "status": "done",
      "createdAt": "2025-10-15T00:11:17.039Z",
      "updatedAt": "2025-10-15T00:48:04.694Z",
      "description": "Feature: register-tag-json-backed. Status: CREATE_TEST_ONLY. No test verifies statistics section is updated when registering tags.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:25.928Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:48:03.784Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:48:04.090Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:48:04.395Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:48:04.694Z"
        }
      ],
      "rules": [
        "Statistics section must be updated when tag is registered"
      ],
      "examples": [
        "After registering new tag, TAGS.md statistics should show incremented tag count"
      ]
    },
    "COV-036": {
      "id": "COV-036",
      "title": "Test: List scenario tags with category information",
      "status": "done",
      "createdAt": "2025-10-15T00:11:27.483Z",
      "updatedAt": "2025-10-15T00:49:36.550Z",
      "description": "Feature: scenario-level-tag-management. Status: CREATE_TEST_ONLY. Test exists for listing tags but doesn't verify category information is shown.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:27.690Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:49:35.622Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:49:35.928Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:49:36.234Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:49:36.550Z"
        }
      ],
      "rules": [
        "Scenario tags must be listed with category information"
      ],
      "examples": [
        "Tag display should show category grouping"
      ]
    },
    "COV-037": {
      "id": "COV-037",
      "title": "Test: Show steps with proper indentation (text format)",
      "status": "done",
      "createdAt": "2025-10-15T00:11:27.777Z",
      "updatedAt": "2025-10-15T03:17:39.051Z",
      "description": "Feature: show-acceptance-criteria. Status: CREATE_TEST_ONLY. Tests exist for markdown format but no specific test for text format indentation.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:29.448Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:27.565Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:38.457Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:38.756Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:39.052Z"
        }
      ]
    },
    "COV-038": {
      "id": "COV-038",
      "title": "Test: Handle malformed JSON file",
      "status": "done",
      "createdAt": "2025-10-15T00:11:28.072Z",
      "updatedAt": "2025-10-15T05:26:37.315Z",
      "description": "Feature: validate-json-schema. Status: CREATE_TEST_ONLY. No test found for malformed/unparseable JSON files.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:31.213Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T05:26:12.060Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:26:36.715Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:26:37.018Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:26:37.315Z"
        }
      ]
    },
    "COV-039": {
      "id": "COV-039",
      "title": "Test: Show work unit with all dependencies",
      "status": "done",
      "createdAt": "2025-10-15T00:11:28.367Z",
      "updatedAt": "2025-10-15T03:17:41.481Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No dedicated show/display test for work unit with all dependency types visible.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:32.974Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:30.931Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:40.880Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:41.181Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:41.482Z"
        }
      ]
    },
    "COV-040": {
      "id": "COV-040",
      "title": "Test: Display dependency graph for single work unit",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.027Z",
      "updatedAt": "2025-10-15T03:17:44.118Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. Export dependency graph test exists but not display for single work unit.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:34.742Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:32.661Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:43.518Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:43.817Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:44.119Z"
        }
      ]
    },
    "COV-041": {
      "id": "COV-041",
      "title": "Test: Show all work units blocked by specific unit",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.336Z",
      "updatedAt": "2025-10-15T03:17:46.469Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No query test for finding all work units blocked by a specific unit.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:36.502Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.064Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:45.868Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:46.173Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:46.469Z"
        }
      ]
    },
    "COV-042": {
      "id": "COV-042",
      "title": "Test: Find all currently blocked work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.639Z",
      "updatedAt": "2025-10-15T03:17:48.816Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No test for querying all blocked work units.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:38.265Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.372Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:48.218Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:48.519Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:48.816Z"
        }
      ]
    },
    "COV-043": {
      "id": "COV-043",
      "title": "Test: Show impact analysis when completing work unit",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.944Z",
      "updatedAt": "2025-10-15T03:17:52.275Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No test for impact analysis feature.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:40.036Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.678Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:51.680Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:51.977Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:52.276Z"
        }
      ]
    },
    "COV-044": {
      "id": "COV-044",
      "title": "Test: Show dependency chain depth",
      "status": "done",
      "createdAt": "2025-10-15T00:11:48.157Z",
      "updatedAt": "2025-10-15T03:18:04.022Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No test for calculating/displaying dependency chain depth.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:41.799Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.978Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:03.423Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:03.725Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:04.023Z"
        }
      ]
    },
    "COV-045": {
      "id": "COV-045",
      "title": "Test: Calculate critical path",
      "status": "done",
      "createdAt": "2025-10-15T00:11:48.451Z",
      "updatedAt": "2025-10-15T03:18:06.429Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_BOTH. No tests or implementation found for critical path calculation.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:43.559Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:43.290Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:05.829Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:06.128Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:06.429Z"
        }
      ]
    },
    "COV-046": {
      "id": "COV-046",
      "title": "Test: Identify bottleneck work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:48.741Z",
      "updatedAt": "2025-10-15T04:54:36.576Z",
      "description": "COMPLETED: Tests written, implementation done, coverage linked. query-bottlenecks.ts working correctly.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:45.332Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T04:04:02.216Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T04:52:38.745Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T04:54:16.382Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T04:54:36.588Z"
        }
      ],
      "rules": [
        "A bottleneck is a work unit that blocks multiple other work units (directly or transitively)",
        "Only work units NOT in 'done' status are bottlenecks (completed work doesn't block)",
        "Bottleneck score = total work units blocked (direct blocks + transitive blocks)",
        "Rank bottlenecks by score (highest to lowest) to prioritize what to complete first",
        "Only blocks/blockedBy relationships. dependsOn is a soft dependency that doesn't prevent work from starting, so it shouldn't factor into bottleneck calculation.",
        "Include bottlenecks with score >= 2 (blocking 2+ work units). A work unit blocking only 1 other is not significant enough to be called a bottleneck.",
        "No. Work units in 'blocked' status cannot be progressed, so they should not be identified as bottlenecks to prioritize. Only consider work units in states that can be actively worked on (backlog, specifying, testing, implementing, validating)."
      ],
      "examples": [
        "AUTH-001 blocks API-001 and UI-001 directly → bottleneck score: 2 (blocks 2 work units)",
        "DB-001 blocks API-001, API-001 blocks UI-001 → DB-001 bottleneck score: 2 (1 direct + 1 transitive)",
        "AUTH-001 blocks API-001, API-002, API-003, and API-001 blocks UI-001 → AUTH-001 score: 4 (highest bottleneck)",
        "DEPLOY-001 status='done' and blocks UI-001 → NOT a bottleneck (already complete)",
        "UI-001 has no 'blocks' relationships → bottleneck score: 0 (not a bottleneck)"
      ],
      "questions": [
        {
          "text": "@human: Should bottleneck calculation include 'dependsOn' relationships or only 'blocks/blockedBy'?",
          "selected": true,
          "answer": "No. Work units in 'blocked' status cannot be progressed, so they should not be identified as bottlenecks to prioritize. Only consider work units in states that can be actively worked on (backlog, specifying, testing, implementing, validating)."
        },
        {
          "text": "@human: Should we consider work unit estimates when ranking bottlenecks (e.g., 8-point story blocks more value than 1-point)?",
          "selected": true,
          "answer": "Only blocks/blockedBy relationships. dependsOn is a soft dependency that doesn't prevent work from starting, so it shouldn't factor into bottleneck calculation."
        },
        {
          "text": "@human: What is the minimum bottleneck score to be included in output (1+, 2+, 3+)?",
          "selected": true,
          "answer": "No. For simplicity, rank bottlenecks by count of blocked work units only. Estimate weighting could be a future enhancement."
        },
        {
          "text": "@human: Should work units in 'blocked' status be considered bottlenecks even though they can't progress themselves?",
          "selected": true,
          "answer": "Include bottlenecks with score >= 2 (blocking 2+ work units). A work unit blocking only 1 other is not significant enough to be called a bottleneck."
        }
      ],
      "userStory": {
        "role": "project manager or AI agent",
        "action": "identify bottleneck work units blocking the most work",
        "benefit": "I can prioritize completing high-impact work to unblock the project"
      },
      "assumptions": [
        "No. For simplicity, rank bottlenecks by count of blocked work units only. Estimate weighting could be a future enhancement."
      ]
    },
    "COV-047": {
      "id": "COV-047",
      "title": "Test: Auto-suggest dependency relationships",
      "status": "done",
      "createdAt": "2025-10-15T00:11:49.033Z",
      "updatedAt": "2025-10-15T05:05:29.014Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_BOTH. No tests or implementation found for auto-suggesting dependencies.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:47.103Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T04:04:03.849Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:04:14.467Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:05:25.400Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:05:29.015Z"
        }
      ],
      "rules": [
        "Auto-suggest analyzes work unit metadata (title, description, epic, prefix) to recommend likely dependency relationships",
        "Sequential IDs in same prefix suggest dependency (AUTH-001 → AUTH-002 implies AUTH-002 depends on AUTH-001)",
        "Build/Test pairs suggest dependency (work with 'Test X' depends on 'Build X')",
        "Infrastructure before features (e.g., 'Setup Auth' should be suggested as blocker for 'Login Flow')",
        "Suggestions are recommendations only - user must confirm before creating dependency relationships"
      ],
      "examples": [
        "AUTH-001 'Setup OAuth' and AUTH-002 'Login Flow' → Suggest: AUTH-002 depends on AUTH-001 (sequential IDs)",
        "'Build User API' and 'Test User API' → Suggest: 'Test User API' depends on 'Build User API' (build/test pair)",
        "'Database Schema Migration' and 'Add User Data' → Suggest: 'Add User Data' depends on 'Database Schema Migration' (infrastructure first)",
        "Work units in same epic 'User Management' → Suggest: relatesTo relationships for context",
        "AUTH-003 with no semantic relationship to AUTH-001 or AUTH-002 → No suggestion (avoid false positives)"
      ],
      "questions": [
        {
          "text": "@human: Should auto-suggest use AI/LLM for semantic analysis or only rule-based heuristics?",
          "selected": true,
          "answer": "Start with rule-based heuristics only (simpler, faster, no external dependencies). AI/LLM integration could be a future enhancement."
        },
        {
          "text": "@human: What confidence threshold should be used for suggestions (e.g., only suggest if >70% confidence)?",
          "selected": true,
          "answer": "No confidence scoring initially. Suggest only when rules match clearly (e.g., exact sequential IDs, exact 'Build X'/'Test X' match). Avoid ambiguous suggestions."
        },
        {
          "text": "@human: Should suggestions be presented interactively or in batch for approval?",
          "selected": true,
          "answer": "Batch mode. Display all suggestions and let user review/approve them together. Interactive mode could be added later with --interactive flag."
        },
        {
          "text": "@human: Should the system learn from user acceptance/rejection of suggestions over time?",
          "selected": true,
          "answer": "No learning capability in v1. Keep it simple and deterministic. Machine learning could be considered for future versions."
        }
      ],
      "userStory": {
        "role": "AI agent or developer",
        "action": "receive automatic suggestions for dependency relationships between work units",
        "benefit": "I can quickly establish connections without manually analyzing all work units"
      },
      "assumptions": [
        "Start with rule-based heuristics only (simpler, faster, no external dependencies). AI/LLM integration could be a future enhancement.",
        "No confidence scoring initially. Suggest only when rules match clearly (e.g., exact sequential IDs, exact 'Build X'/'Test X' match). Avoid ambiguous suggestions.",
        "Batch mode. Display all suggestions and let user review/approve them together. Interactive mode could be added later with --interactive flag.",
        "No learning capability in v1. Keep it simple and deterministic. Machine learning could be considered for future versions."
      ]
    },
    "COV-048": {
      "id": "COV-048",
      "title": "Test: Detect orphaned work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:58.176Z",
      "updatedAt": "2025-10-15T05:15:43.344Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_BOTH. No tests or implementation found for orphan detection.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:48.863Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T04:04:05.720Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:15:23.827Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:15:41.265Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:15:43.345Z"
        }
      ],
      "rules": [
        "An orphaned work unit has NO dependency relationships (no blocks, blockedBy, dependsOn, or relatesTo)",
        "An orphaned work unit has NO epic assignment (epic field is null or empty)",
        "Orphaned work units are isolated from the project context and may indicate abandoned or misconfigured work",
        "Detecting orphans helps identify work that should be connected, reassigned, or deleted",
        "No. Prefix alone does not provide sufficient context. A work unit must have either an epic OR at least one relationship to not be considered orphaned.",
        "Yes. Show suggested actions: 'Assign to epic', 'Add relationship to related work', 'Delete if no longer needed'. Make it actionable, not just informational."
      ],
      "examples": [
        "UI-999 has no epic, no blocks, no blockedBy, no dependsOn, no relatesTo → ORPHANED (completely isolated)",
        "AUTH-001 has epic='user-management' but no relationships → NOT orphaned (has epic context)",
        "API-001 has no epic but dependsOn DB-001 → NOT orphaned (has dependency relationship)",
        "TEST-042 has no epic, no relationships, status='done' → ORPHANED (even done work can be orphaned)",
        "MISC-005 has relatesTo relationship to SEC-001 → NOT orphaned (any relationship counts)"
      ],
      "questions": [
        {
          "text": "@human: Should work units with only a prefix (but no epic or relationships) be considered orphaned?",
          "selected": true,
          "answer": "No. Prefix alone does not provide sufficient context. A work unit must have either an epic OR at least one relationship to not be considered orphaned."
        },
        {
          "text": "@human: Should orphan detection exclude work units in 'done' status (completed work may not need connections)?",
          "selected": true,
          "answer": "No. Include all work units regardless of status. Even 'done' work can be orphaned and may indicate cleanup needed. Use --exclude-done flag if user wants to filter them out."
        },
        {
          "text": "@human: Should the command suggest actions for orphaned work (e.g., 'assign epic', 'add dependency', 'delete')?",
          "selected": true,
          "answer": "Yes. Show suggested actions: 'Assign to epic', 'Add relationship to related work', 'Delete if no longer needed'. Make it actionable, not just informational."
        }
      ],
      "userStory": {
        "role": "project manager or AI agent",
        "action": "detect orphaned work units with no epic or dependency relationships",
        "benefit": "I can identify isolated work that needs to be connected, reassigned, or cleaned up"
      },
      "assumptions": [
        "No. Include all work units regardless of status. Even 'done' work can be orphaned and may indicate cleanup needed. Use --exclude-done flag if user wants to filter them out."
      ]
    },
    "COV-049": {
      "id": "COV-049",
      "title": "Test: Query by status and prefix",
      "status": "done",
      "createdAt": "2025-10-15T00:11:58.467Z",
      "updatedAt": "2025-10-15T03:18:09.151Z",
      "description": "Feature: work-unit-query-and-reporting. Status: CREATE_TEST_ONLY. Status query exists, epic query exists, but no prefix query test.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:50.614Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:45.037Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:08.555Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:08.852Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:09.152Z"
        }
      ]
    },
    "COV-050": {
      "id": "COV-050",
      "title": "Test: Query with sorting by updated date",
      "status": "done",
      "createdAt": "2025-10-15T00:11:58.760Z",
      "updatedAt": "2025-10-15T03:18:11.671Z",
      "description": "Feature: work-unit-query-and-reporting. Status: CREATE_TEST_ONLY. No test found for sorting functionality.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:52.377Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:45.345Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:11.075Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:11.374Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:11.672Z"
        }
      ]
    },
    "COV-051": {
      "id": "COV-051",
      "title": "Test: Export filtered results to CSV",
      "status": "done",
      "createdAt": "2025-10-15T00:11:59.052Z",
      "updatedAt": "2025-10-15T03:18:14.131Z",
      "description": "Feature: work-unit-query-and-reporting. Status: CREATE_TEST_ONLY. JSON export exists but no CSV export test.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:54.123Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:45.650Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:13.529Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:13.832Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:14.132Z"
        }
      ]
    },
    "BUG-007": {
      "id": "BUG-007",
      "title": "generate-coverage does not detect new scenarios in existing feature files",
      "status": "done",
      "createdAt": "2025-10-15T04:09:40.314Z",
      "updatedAt": "2025-10-15T14:28:00.000Z",
      "description": "When new scenarios are added to an existing feature file, the generate-coverage command does not update the .coverage file to include them. This blocks the link-coverage workflow in ACDD.",
      "epic": "test-coverage",
      "children": [],
      "userStory": {
        "role": "developer following ACDD workflow",
        "action": "have generate-coverage detect and add new scenarios to existing .coverage files",
        "benefit": "I can link test coverage for new scenarios without manual JSON editing"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T04:10:11.653Z"
        }
      ],
      "rules": [
        "generate-coverage should compare feature file scenarios against coverage file scenarios",
        "If feature file has MORE scenarios than coverage file, add missing scenarios with empty testMappings array",
        "If coverage file has scenarios NOT in feature file, remove them (cleanup orphaned entries)",
        "Preserve existing test/impl mappings for unchanged scenarios (don't overwrite)",
        "Update stats section to reflect new scenario count and coverage percentage",
        "Yes. generate-coverage must be idempotent - safe to run multiple times. It should UPDATE existing coverage files, not overwrite them."
      ],
      "examples": [
        "REPRODUCTION: work-unit-dependency-management.feature has 42 scenarios, but .coverage file only has 39 scenario entries",
        "MISSING: Scenario 'Identify bottleneck work units blocking the most work' (line 501-518) NOT in coverage file",
        "MISSING: Scenario 'Auto-suggest dependency relationships based on work unit metadata' (line 520-536) NOT in coverage file",
        "MISSING: Scenario 'Detect orphaned work units with no epic or dependencies' (line 538-553) NOT in coverage file",
        "COMMAND RESULT: 'fspec generate-coverage' runs without error but does NOT add missing scenarios",
        "ERROR WHEN LINKING: 'fspec link-coverage work-unit-dependency-management --scenario \"Identify bottleneck...\"' fails with 'Scenario not found'",
        "FILE: spec/features/work-unit-dependency-management.feature - grep shows 42 scenarios: 'grep -c \"^  Scenario:\" spec/features/work-unit-dependency-management.feature' returns 42",
        "FILE: spec/features/work-unit-dependency-management.feature.coverage - only has 39 entries in scenarios array (verified by reading JSON)",
        "EXACT LINE: Feature file line 501: '@COV-046' tag, Scenario: 'Identify bottleneck work units blocking the most work' - MISSING from coverage",
        "EXACT LINE: Feature file line 520: '@COV-047' tag, Scenario: 'Auto-suggest dependency relationships based on work unit metadata' - MISSING from coverage",
        "EXACT LINE: Feature file line 538: '@COV-048' tag, Scenario: 'Detect orphaned work units with no epic or dependencies' - MISSING from coverage",
        "COMMAND TO REPRODUCE: 1) Add new scenario to existing .feature file 2) Run 'fspec generate-coverage' 3) Check .coverage file - new scenario NOT added 4) Try 'fspec link-coverage <feature> --scenario <name>' - ERROR: Scenario not found"
      ],
      "questions": [
        {
          "text": "@human: Should generate-coverage be idempotent (safe to run multiple times without data loss)?",
          "selected": true,
          "answer": "Yes. generate-coverage must be idempotent - safe to run multiple times. It should UPDATE existing coverage files, not overwrite them."
        },
        {
          "text": "@human: Should generate-coverage create backup of .coverage file before modifying?",
          "selected": true,
          "answer": "No backup needed. Since it's idempotent and git tracks changes, users can revert if needed."
        },
        {
          "text": "@human: Should there be a --force flag to overwrite coverage files vs update-only mode?",
          "selected": true,
          "answer": "No. Default behavior should be update mode (merge new scenarios). Keep it simple."
        }
      ],
      "estimate": 3,
      "assumptions": [
        "No backup needed. Since it's idempotent and git tracks changes, users can revert if needed.",
        "No. Default behavior should be update mode (merge new scenarios). Keep it simple."
      ]
    },
    "BUG-008": {
      "id": "BUG-008",
      "title": "generate-scenarios produces malformed Gherkin steps from example titles",
      "status": "done",
      "createdAt": "2025-10-15T04:16:17.565Z",
      "updatedAt": "2025-10-15T14:24:00.000Z",
      "description": "The generate-scenarios command is creating scenarios with malformed Given/When/Then steps that include the entire example title text instead of proper Gherkin syntax. This results in invalid scenarios with prefill placeholders and prevents moving work units through the workflow.",
      "children": [],
      "userStory": {
        "role": "developer using fspec with Example Mapping",
        "action": "have generate-scenarios create proper Gherkin Given/When/Then steps from example titles",
        "benefit": "generated scenarios are valid and don't block workflow progression with prefill errors"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T04:16:39.895Z"
        }
      ],
      "rules": [
        "Example titles that start with keywords like 'REPRODUCTION:', 'MISSING:', 'ERROR WHEN:', 'COMMAND RESULT:' should be parsed to extract the actual scenario content, not used verbatim as Given steps",
        "Generated scenarios must follow proper Gherkin structure: Given [precondition] / When [action] / Then [expected outcome]",
        "Steps should never include the full example title - they should be semantically meaningful Given/When/Then statements",
        "Scenario titles must be cleaned by removing common prefixes (REPRODUCTION, MISSING, ERROR WHEN, COMMAND RESULT, FILE, EXACT LINE, COMMAND TO REPRODUCE) to create readable scenario names",
        "Original example text must be preserved as a comment (# Example: ...) above each scenario to maintain traceability to Example Mapping"
      ],
      "examples": [
        "CURRENT: Example 'REPRODUCTION: work-unit-dependency-management.feature has 42 scenarios' → Scenario with 'Given REPRODUCTION: work-unit-dependency-management.feature has 42 scenarios, but .coverage file only has 39 scenario entries' | EXPECTED: → Scenario with 'Given a feature file exists with 42 scenarios / When I check the coverage file / Then it should have 42 scenario entries'",
        "CURRENT: Example 'MISSING: Scenario X (line 501-518) NOT in coverage file' → Generates 'Given [precondition] / When [action] / Then [expected outcome]' (placeholders\\!) | EXPECTED: → 'Given a scenario exists in feature file at lines 501-518 / When I run generate-coverage / Then the scenario should be added to the coverage file'",
        "CURRENT: Example 'ERROR WHEN LINKING: fspec link-coverage fails with Scenario not found' → Generates 'Given I have an invalid condition / When I execute ERROR WHEN LINKING...' (malformed\\!) | EXPECTED: → 'Given a scenario is missing from coverage file / When I run fspec link-coverage with that scenario name / Then it should fail with error Scenario not found'",
        "CURRENT: Example 'COMMAND RESULT: fspec generate-coverage runs without error but does NOT add missing scenarios' → 'Given I am COMMAND RESULT: fspec generate-coverage / When I runs without error...' (grammatically broken\\!) | EXPECTED: → 'Given I have a feature file with new scenarios / When I run fspec generate-coverage / Then it should run without error / And it should NOT add missing scenarios to existing coverage files' (documents the bug behavior)",
        "CURRENT: Example 'FILE: spec/features/work-unit.feature - grep shows 42 scenarios' → 'Given I am FILE: spec/features... / When I shows 42 scenarios...' (nonsensical grammar\\!) | EXPECTED: → 'Given a feature file spec/features/work-unit.feature exists / When I count scenarios using grep / Then it should return 42 scenarios'",
        "CURRENT: Example 'COMMAND TO REPRODUCE: 1) Add scenario 2) Run command 3) Check file 4) Try link' → 'Given I am COMMAND TO REPRODUCE: 1) / When I Add new scenario...' (truncated and malformed\\!) | EXPECTED: → 'Given I add a new scenario to an existing feature file / When I run fspec generate-coverage / And I check the coverage file / Then the new scenario should NOT be added / When I try to link coverage for the scenario / Then it should fail with Scenario not found'"
      ],
      "questions": [
        {
          "text": "Should generate-scenarios attempt to parse example titles to extract semantic meaning, or should users write proper Given/When/Then examples in the first place?",
          "selected": true,
          "answer": "Clean scenario titles by removing prefixes like 'REPRODUCTION:', 'MISSING:', etc. Keep full example as comment. Use existing extractStepsFromExample() for parsing."
        },
        {
          "text": "If examples contain complex reproduction steps (multiple actions), should generate-scenarios create multiple Given/When/Then steps or a single scenario outline?",
          "selected": true,
          "answer": "Use existing extractStepsFromExample() which already generates multiple Given/When/Then steps based on pattern matching. No changes needed - current system handles this."
        },
        {
          "text": "What should happen if an example title doesn't fit the Given/When/Then structure at all (e.g., purely descriptive)?",
          "selected": true,
          "answer": "Fall back to [placeholders] which triggers prefill detection. This is already implemented in extractStepsFromExample(). No changes needed."
        }
      ],
      "estimate": 2
    },
    "FEAT-006": {
      "id": "FEAT-006",
      "title": "Work unit type system - Core foundation",
      "status": "done",
      "createdAt": "2025-10-15T05:44:47.532Z",
      "updatedAt": "2025-10-25T19:37:42.828Z",
      "description": "Add support for different work unit types (story, task, bug) similar to JIRA, allowing better categorization of work units based on their nature (user-facing features vs operational work vs defects)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T05:54:25.542Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T06:06:59.919Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T06:09:03.428Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-15T06:15:05.862Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T06:25:53.799Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T06:26:03.435Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T06:26:09.298Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T06:39:12.885Z",
          "reason": "All child work units complete (FEAT-007, 008, 009, 010 all done)"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T06:39:15.377Z",
          "reason": "All child work units done, full test suite passes (1002/1002), build succeeds"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T12:34:02.868Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-25T19:37:42.829Z"
        }
      ],
      "userStory": {
        "role": "AI agent managing project work with fspec",
        "action": "categorize work units by type (story, task, bug)",
        "benefit": "I can track meta-work and housekeeping through Kanban without violating ACDD discipline for user-facing features"
      },
      "rules": [
        "Work units must have a type field: 'story', 'task', or 'bug'",
        "Default type is 'story' for backward compatibility with existing work units",
        "Stories require full ACDD workflow: backlog → specifying → testing → implementing → validating → done",
        "Tasks use simplified workflow: backlog → in-progress → done (+ blocked)",
        "Bugs use same ACDD workflow as stories but may skip Example Mapping in favor of reproduction scenarios",
        "Stories must have linked feature file before moving to testing state",
        "Tasks do not require feature files or tests",
        "Bugs must have reproduction scenario in feature file before moving to testing state",
        "Yes, existing work units without type field automatically get type='story' (backward compatible). New work units default to 'story' unless --type specified.",
        "Tasks CANNOT have feature files. Feature files represent user stories with acceptance criteria, which makes them stories by definition. Tasks are for operational work without user-facing behavior.",
        "Bugs MUST link to an existing feature file. If no feature file exists for the buggy behavior, it's a story, not a bug. Bugs fix/update existing documented features. Validation error should explain: 'Bugs must link to existing feature file. If feature has no spec, create a story instead.'",
        "Tasks support Example Mapping fields (rules, examples, questions) but they are OPTIONAL and only for clarity about what needs to be done. Unlike stories, tasks don't require these fields to be filled before progressing.",
        "Treat all estimates the same way (combined velocity), but reporting commands should have ability to break down metrics by type (--type=story, --type=task, --type=bug) or show combined.",
        "Type is immutable once set. If wrong, work unit must be deleted and recreated with correct type. This prevents confusion about workflow rules changing mid-flight.",
        "All work unit types can use 'in-progress' state. Stories map: specifying/testing/implementing/validating → all represent 'in-progress'. Tasks use 'in-progress' explicitly. Bugs follow story states. This provides consistency across types.",
        "Tasks use workflow: backlog → specifying → implementing → validating → done (+ blocked). They skip 'testing' state since no tests are required.",
        "Tasks in specifying state do NOT require feature files (unlike stories). Specifying is for internal clarity only - can use description, rules, examples fields.",
        "Yes, remove old rule #4. The corrected workflow is: backlog → specifying → implementing → validating → done. Tasks need 'specifying' for clarity but skip 'testing' since no tests required."
      ],
      "examples": [
        "Create story work unit: 'fspec create-story AUTH \"User Login\"' creates AUTH-XXX with type='story'",
        "Create task work unit: 'fspec create-task CLEAN \"Audit coverage files\"' creates CLEAN-XXX with type='task'",
        "Create bug work unit: 'fspec create-bug BUG \"Login fails with @ symbol\"' creates BUG-XXX with type='bug'",
        "Default type: 'fspec create-story AUTH \"Feature\"' creates work unit with type='story' (backward compatible)",
        "Filter by type: 'fspec list-work-units --type=task' shows only task work units",
        "Task workflow: CLEAN-001 moves backlog → in-progress → done (skipping specifying/testing/implementing/validating)",
        "Story validation: Moving AUTH-001 (type=story) to testing without feature file shows error 'Cannot move to testing: no feature file linked'",
        "Task flexibility: CLEAN-001 (type=task) can move from backlog directly to done without any validation errors",
        "Board visualization: 'fspec board' shows three sections: STORIES (full workflow), TASKS (simplified), BUGS (full workflow)",
        "Task workflow detail: CLEAN-001 (type=task) moves backlog → specifying (clarify what to do) → implementing (do the work) → validating (verify done) → done",
        "Task specifying phase: CLEAN-001 in specifying state can use optional Example Mapping (rules, examples) to clarify work scope before implementing"
      ],
      "questions": [
        {
          "text": "@human: Should existing work units without a type field automatically get type='story', or should we require manual migration?",
          "selected": true,
          "answer": "Yes, existing work units without type field automatically get type='story' (backward compatible). New work units default to 'story' unless --type specified."
        },
        {
          "text": "@human: Can a task optionally have a feature file linked for documentation purposes, or should tasks be completely prohibited from having feature files?",
          "selected": true,
          "answer": "Tasks CANNOT have feature files. Feature files represent user stories with acceptance criteria, which makes them stories by definition. Tasks are for operational work without user-facing behavior."
        },
        {
          "text": "@human: Should the board command show all three types together, or should it have separate views/sections for each type?",
          "selected": true,
          "answer": "No changes to board visualization. All types shown in same board view with their respective workflow states."
        },
        {
          "text": "@human: For bugs, should we enforce that they must link to an existing feature file (the one with the bug), or should they create a separate bug-fix feature file?",
          "selected": true,
          "answer": "Bugs MUST link to an existing feature file. If no feature file exists for the buggy behavior, it's a story, not a bug. Bugs fix/update existing documented features. Validation error should explain: 'Bugs must link to existing feature file. If feature has no spec, create a story instead.'"
        },
        {
          "text": "@human: Should tasks support Example Mapping fields (rules, examples, questions), or should those be story/bug-only features?",
          "selected": true,
          "answer": "Tasks support Example Mapping fields (rules, examples, questions) but they are OPTIONAL and only for clarity about what needs to be done. Unlike stories, tasks don't require these fields to be filled before progressing."
        },
        {
          "text": "@human: Should we track different velocity metrics for stories vs tasks vs bugs, or treat all estimates the same way?",
          "selected": true,
          "answer": "Treat all estimates the same way (combined velocity), but reporting commands should have ability to break down metrics by type (--type=story, --type=task, --type=bug) or show combined."
        },
        {
          "text": "@human: Can a work unit's type be changed after creation, or is it immutable once set?",
          "selected": true,
          "answer": "Type is immutable once set. If wrong, work unit must be deleted and recreated with correct type. This prevents confusion about workflow rules changing mid-flight."
        },
        {
          "text": "@human: Should 'in-progress' state be available for ALL work unit types, or should it remain task-only?",
          "selected": true,
          "answer": "All work unit types can use 'in-progress' state. Stories map: specifying/testing/implementing/validating → all represent 'in-progress'. Tasks use 'in-progress' explicitly. Bugs follow story states. This provides consistency across types."
        },
        {
          "text": "@human: Should I remove the old rule #4 that says 'Tasks use simplified workflow: backlog → in-progress → done' since it's been superseded by the corrected workflow?",
          "selected": true,
          "answer": "Yes, remove old rule #4. The corrected workflow is: backlog → specifying → implementing → validating → done. Tasks need 'specifying' for clarity but skip 'testing' since no tests required."
        }
      ],
      "assumptions": [
        "No changes to board visualization. All types shown in same board view with their respective workflow states."
      ],
      "estimate": 5,
      "epic": "work-item-types"
    },
    "FEAT-011": {
      "id": "FEAT-011",
      "title": "Prevent retroactive state walking - enforce temporal ordering",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T06:49:06.299Z",
      "updatedAt": "2025-10-15T07:07:46.452Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T06:49:30.983Z",
          "reason": "Need to add Example Mapping rules"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T07:06:20.805Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T07:06:36.424Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T07:06:42.872Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T07:07:46.453Z"
        }
      ],
      "rules": [
        "System must prevent AI agents from doing all work first, then retroactively walking through states as theater",
        "When moving to testing state: system must verify tests were created AFTER entering testing state, not before",
        "When moving to implementing state: system must verify tests currently FAIL (red phase). Tests failing proves they actually test something.",
        "When moving to validating state: system must verify tests now PASS (green phase) and implementation was modified AFTER entering implementing",
        "If work unit has artifacts (specs/tests/code) all timestamped BEFORE entering testing state, then: either delete the work unit if it has no unique value OR move it back to backlog and require proper ACDD workflow"
      ],
      "examples": [
        "FEAT-007, FEAT-008, FEAT-009, FEAT-010: All work (specs, tests, code) completed in previous session. Current session: AI moved each through specifying→testing→implementing→validating→done in 5 seconds each. System allowed it because @WORK-UNIT-ID tags existed in feature file and tests passed. Result: ACDD completely bypassed.",
        "work-item-types-for-stories-tasks-and-bugs.feature: Created before any child work units. Tests written before testing state. Implementation completed before implementing state. Feature file tagged with @FEAT-007 @FEAT-008 @FEAT-009 @FEAT-010 retroactively. checkScenariosExist() found tags and allowed testing state entry.",
        "System checks: (1) Does @WORK-UNIT-ID exist? YES. (2) Is state transition valid? YES. (3) Are children done? YES. Missing checks: (1) When was feature file created? (2) When were tests written? (3) Did tests fail first? (4) Was implementation written after tests?",
        "AI behavior enabled by current system: (1) Write all code in one session. (2) Tag feature file with work unit IDs. (3) Run tests to ensure they pass. (4) Walk through states as formality. (5) System approves everything. This is the opposite of ACDD.",
        "Correct ACDD sequence: (1) Enter specifying: write feature file. (2) Enter testing: write FAILING tests. (3) Run tests: verify they fail. (4) Enter implementing: write minimal code. (5) Run tests: verify they pass. (6) Enter validating: run full suite. System must enforce this temporal ordering."
      ],
      "userStory": {
        "role": "AI agent using fspec for ACDD workflow",
        "action": "ensure work is done in the correct temporal order",
        "benefit": "ACDD methodology is actually enforced, not just theatrical state walking"
      }
    },
    "DOC-004": {
      "id": "DOC-004",
      "title": "Validate Mermaid diagrams during foundation.json regeneration",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T07:36:09.439Z",
      "updatedAt": "2025-10-15T07:54:01.712Z",
      "description": "The generate-foundation-md command should validate all Mermaid diagrams in foundation.json before regenerating FOUNDATION.md. If any diagram has invalid syntax, the command should fail with detailed error information including the position in the JSON file and the specific Mermaid validation error, guiding the AI to fix and regenerate.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T07:36:16.916Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T07:45:13.894Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T07:47:31.554Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T07:51:32.720Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T07:54:01.712Z"
        }
      ],
      "userStory": {
        "role": "developer maintaining foundation.json documentation",
        "action": "validate all Mermaid diagrams when regenerating FOUNDATION.md",
        "benefit": "I catch syntax errors immediately with precise error locations and can fix them before the markdown file is written"
      },
      "rules": [
        "All Mermaid diagrams in foundation.json MUST be validated before writing FOUNDATION.md",
        "Validation errors MUST include the JSON position (architectureDiagrams array index) of the failing diagram",
        "Validation errors MUST include the diagram title for easy identification",
        "Validation errors MUST include the detailed Mermaid error message from mermaid.parse()",
        "The command MUST exit with code 1 if any diagram validation fails",
        "Error output MUST guide the AI to fix the diagram in foundation.json and regenerate",
        "Diagram validation MUST use the existing validateMermaidSyntax() function from add-diagram.ts",
        "After JSON schema validation - validate diagrams after the schema check passes",
        "Validate all diagrams at once and show all errors together - don't fail fast",
        "Yes, extract validateMermaidSyntax to src/utils/mermaid-validation.ts for reuse"
      ],
      "examples": [
        "Running 'fspec generate-foundation-md' with valid diagrams completes successfully and generates FOUNDATION.md",
        "Running 'fspec generate-foundation-md' with an invalid diagram at architectureDiagrams[2] shows: 'Error at architectureDiagrams[2] (title: \"Data Flow\"): Invalid Mermaid syntax: unexpected token' and exits with code 1",
        "Running 'fspec generate-foundation-md' with multiple invalid diagrams shows all failures with their positions, titles, and error messages",
        "Error message includes guidance: 'Fix the diagram(s) in spec/foundation.json and run fspec generate-foundation-md again'",
        "After fixing invalid diagrams in foundation.json and running 'fspec generate-foundation-md' again, the command succeeds and generates FOUNDATION.md"
      ],
      "questions": [
        {
          "text": "@human: Should validation happen BEFORE or AFTER JSON schema validation?",
          "selected": true,
          "answer": "After JSON schema validation - validate diagrams after the schema check passes"
        },
        {
          "text": "@human: Should we stop at the first invalid diagram or validate all diagrams and show all errors at once?",
          "selected": true,
          "answer": "Validate all diagrams at once and show all errors together - don't fail fast"
        },
        {
          "text": "@human: Should the validateMermaidSyntax function be extracted to a shared utility file for reuse?",
          "selected": true,
          "answer": "Yes, extract validateMermaidSyntax to src/utils/mermaid-validation.ts for reuse"
        }
      ],
      "estimate": 3
    },
    "BUG-010": {
      "id": "BUG-010",
      "title": "fspec init performs unnecessary string replacements on generic slash command template",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-15T08:07:58.029Z",
      "updatedAt": "2025-10-15T08:13:07.810Z",
      "description": "The init command replaces fspec-specific examples (user-authentication.feature, CLI-003, etc.) with generic placeholders (example-feature.feature, EXAMPLE-001). These replacements are unnecessary because the slash command file contains illustrative examples that work for any project. The replacements also cause issues when running init from fspec's own directory, overwriting the original examples. Solution: Remove all string replacement logic from generateTemplate() function.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T08:08:12.311Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T08:11:59.282Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T08:12:08.189Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T08:12:08.484Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T08:13:07.810Z"
        }
      ],
      "rules": [
        "The slash command file is generic guidance that works for any project",
        "Examples in the file are illustrative only - showing patterns not specific project details",
        "String replacements provide no value and cause issues when run from fspec directory"
      ],
      "examples": [
        "Running init from fspec dir overwrites original examples with generic ones",
        "External projects see user-authentication.feature in examples which works fine as illustration"
      ]
    },
    "EXMAP-002": {
      "id": "EXMAP-002",
      "title": "Preserve example mapping context as comments in generated feature files",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T08:34:45.292Z",
      "updatedAt": "2025-10-15T09:00:08.967Z",
      "description": "When generate-scenarios runs, embed full example mapping data (rules, examples, questions, assumptions) as comment blocks that persist through format cycles. This provides permanent context for AI and humans writing scenarios.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T08:34:53.790Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T08:39:15.384Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T08:44:19.099Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T08:57:40.553Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T09:00:08.967Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec for ACDD workflow",
        "action": "see full example mapping context when writing scenarios",
        "benefit": "I can write meaningful Given/When/Then steps based on business rules and concrete examples"
      },
      "rules": [
        "Comments in Gherkin AST MUST be preserved through format cycles",
        "Example mapping context embedded as comments MUST NOT conflict with add-architecture doc strings",
        "Generated feature files MUST contain zero scenarios initially (context-only)",
        "System-reminder MUST guide AI to write scenarios based on embedded examples",
        "Comment blocks MUST be visually distinct and easy to locate",
        "All example mapping data (rules, examples, questions, assumptions) MUST be embedded"
      ],
      "examples": [
        "FORMATTER PRESERVES COMMENTS: AI runs generate-scenarios, gets file with # comments, runs fspec format, comments are still present in file",
        "COMMENTS DON'T CONFLICT WITH ARCHITECTURE: File has # example mapping comments AND \"\"\" architecture notes doc string, both coexist without overwriting",
        "CONTEXT-ONLY GENERATION: generate-scenarios produces file with # comments + Background but ZERO scenarios, AI writes scenarios using Edit tool",
        "USER STORY IN TWO PLACES: User story appears in # comments AND in Background section, both updated when set-user-story runs",
        "SYSTEM-REMINDER GUIDES AI: After generate-scenarios, system-reminder tells AI 'write scenarios based on # EXAMPLES section', AI sees reminder and writes proper scenarios",
        "RULES IN COMMENTS INFORM SCENARIOS: # BUSINESS RULES says 'password 8+ chars', AI writes scenario with Given step checking password length",
        "ANSWERED QUESTIONS PRESERVED: # QUESTIONS section shows 'Q: OAuth support? A: Phase 2', developer reading file understands deferred decisions",
        "ASSUMPTIONS DOCUMENTED: # ASSUMPTIONS says 'email verification external', AI doesn't write scenarios for email verification",
        "VISUAL SEPARATION WITH BORDERS: Comment block has # === borders at top/bottom, easy to spot when scrolling through file",
        "MULTIPLE EXAMPLES TO SCENARIOS: # EXAMPLES has 3 items, AI writes 3 separate scenarios OR combines related ones into single scenario",
        "ADD-SCENARIO DOESN'T TOUCH COMMENTS: File has # example mapping comments, user runs add-scenario, comments remain untouched at top",
        "ADD-BACKGROUND DOESN'T TOUCH COMMENTS: File has # comments before Background, user runs add-background to update user story, comments persist",
        "PARSER PRESERVES COMMENTS IN AST: Gherkin parser reads file with # comments, ast.comments array contains comment objects with line numbers and text",
        "FORMATTER OUTPUTS COMMENTS FROM AST: formatGherkinDocument receives AST with comments, inserts comment lines at correct positions in output",
        "EMPTY EXAMPLE MAP HANDLED: Work unit has no rules/examples, generate-scenarios creates minimal comment block saying 'No example mapping data captured'",
        "PREFILL DETECTION STILL WORKS: Generated Background has [role] placeholder, prefill detector emits system-reminder about using set-user-story",
        "GIT DIFF SHOWS CONTEXT: Developer reviews PR, sees # example mapping comments in diff, understands why scenarios were written",
        "EXISTING COMMENT HANDLING: Feature file already has some # comments, generate-scenarios appends its comment block without conflict",
        "NO SCENARIOS MEANS FILE INCOMPLETE: generate-scenarios creates file with # comments + Background + zero scenarios, system-reminder says 'now write scenarios'",
        "AI USES EDIT TOOL WITH CONTEXT: AI reads file, sees # EXAMPLES: '1. User logs in with valid creds', writes Scenario with proper Given/When/Then using Edit tool"
      ],
      "assumptions": [
        "Gherkin parser (@cucumber/gherkin) already captures comments in AST",
        "Current formatter (gherkin-formatter.ts) ignores ast.comments field",
        "Comments use # syntax (Gherkin standard)",
        "Doc strings use triple quotes (architecture notes)",
        "AI agents have Edit tool access to feature files"
      ],
      "estimate": 5
    },
    "EXMAP-003": {
      "id": "EXMAP-003",
      "title": "Add system-reminder to generate-coverage command",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T08:49:29.798Z",
      "updatedAt": "2025-10-15T13:26:45.264Z",
      "description": "When generate-coverage creates coverage files, emit a system-reminder explaining that the LLM must manually link coverage using link-coverage command",
      "epic": "coverage-tracking",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T09:06:38.009Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T09:09:37.200Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T09:10:49.274Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T09:13:24.474Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T09:13:36.457Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-15T09:22:46.765Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T13:24:08.180Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T13:24:50.326Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:24:55.615Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:26:45.266Z"
        }
      ],
      "rules": [
        "Coverage files must be populated manually using link-coverage",
        "System reminder must be displayed after generate-coverage command",
        "Reminder must explain that coverage files are empty until linked",
        "Reminder must show example link-coverage commands",
        "Yes, reminder should be shown for both modes with contextual examples",
        "Yes, should mention show-coverage as verification step",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them",
        "Yes, should mention show-coverage as verification step",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
      ],
      "examples": [
        "User runs generate-coverage with no arguments and sees reminder",
        "User runs generate-coverage --dry-run and sees reminder",
        "User runs generate-coverage feature-name and sees reminder with feature-specific examples",
        "Reminder includes link-coverage command syntax with test file example",
        "Reminder includes link-coverage command syntax with implementation file example",
        "Reminder explains three-step ACDD workflow: write specs → link tests → link implementation"
      ],
      "questions": [
        {
          "text": "Should the reminder be shown for both single-feature and all-features modes?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        },
        {
          "text": "Should the reminder include show-coverage command as next step?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        },
        {
          "text": "Should the reminder be suppressible with a --quiet flag?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        },
        {
          "text": "Should the reminder explain the difference between generate-coverage and link-coverage?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        }
      ],
      "assumptions": [
        "No, reminder should always be shown as it's critical for ACDD workflow",
        "No, reminder should always be shown as it's critical for ACDD workflow",
        "No, reminder should always be shown as it's critical for ACDD workflow"
      ],
      "userStory": {
        "role": "developer using fspec with ACDD workflow",
        "action": "be reminded to manually link coverage after running generate-coverage",
        "benefit": "I don't forget the critical step of linking tests and implementation to scenarios"
      }
    },
    "HOOK-001": {
      "id": "HOOK-001",
      "title": "Kanban Lifecycle Hooks System",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T10:55:43.651Z",
      "updatedAt": "2025-10-21T00:50:35.164Z",
      "description": "Implement a hooks system similar to Claude Code hooks that allows executing custom commands before/after Kanban state transitions. Hooks are configured in spec/fspec-hooks.json and scripts live in spec/hooks/ directory. Enables quality gates, test automation, notifications, and CI/CD integration at each ACDD workflow stage.",
      "children": [
        "HOOK-002",
        "HOOK-003",
        "HOOK-004",
        "HOOK-005",
        "HOOK-006",
        "HOOK-007",
        "HOOK-008",
        "HOOK-009"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T10:55:52.838Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T13:28:29.038Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T13:28:40.015Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:28:40.379Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:28:40.739Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-20T22:40:32.638Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T00:50:33.128Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T00:50:34.521Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T00:50:34.844Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T00:50:35.168Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "configure lifecycle hooks to run custom scripts at Kanban transition points",
        "benefit": "I can automate quality gates, testing, notifications, and CI/CD workflows throughout the ACDD process"
      },
      "rules": [
        "Hooks are configured in spec/fspec-hooks.json file",
        "Hook scripts live in spec/hooks/ directory",
        "Hooks trigger before and after Kanban state transitions (pre-* and post-*)",
        "Hooks can be blocking (prevent transition on failure) or non-blocking (run but don't block)",
        "Hooks receive work unit context as JSON via stdin",
        "Hooks can trigger on Example Mapping actions (add-rule, add-example, add-question, answer-question)",
        "Hooks can trigger on generation commands (generate-scenarios, generate-coverage, generate-foundation-md, generate-tags-md)",
        "Hooks can trigger on coverage operations (link-coverage, unlink-coverage, audit-coverage)",
        "Hooks can block create operations (prevent resource creation if conditions not met)",
        "Hooks can block delete operations (prevent accidental deletion of critical resources)",
        "Hooks can return structured system messages that fspec passes back to the AI agent",
        "Blocking hooks that fail will halt the command and return an error with the hook's system message",
        "Hook system messages can include instructions, warnings, suggestions, or error details for the AI to act upon",
        "Hooks can return structured feedback (JSON) that AI agents consume to improve ACDD workflow",
        "Hooks enforce ACDD ordering by blocking transitions when prerequisites are not met",
        "Hooks can spawn separate Claude Code sessions with specific personas (roles) for peer review and validation",
        "Multi-agent hooks enable AI pair programming with different expertise (reviewer, QA, security, BDD expert, product owner)",
        "fspec provides the hooks framework and execution engine, users write their own hook scripts",
        "Hook scripts can be in any language (bash, python, node, etc) as long as they are executable",
        "fspec passes work unit context to hooks via stdin (JSON) and environment variables",
        "Hook scripts return exit codes and optional JSON output to fspec for processing",
        "Hooks can trigger on program lifecycle events (startup and exit)",
        "Startup hooks run before command logic executes (for setup, validation, or blocking)",
        "Exit hooks receive command output and can intercept, modify, or augment the response before returning to user",
        "Sequential execution only. Hooks for the same event run one after another in the order defined in fspec-hooks.json. This provides predictable execution order, easier debugging, and allows later hooks to depend on earlier hooks' side effects.",
        "No skip mechanism. When a blocking hook fails, the command is blocked and the user must fix the issue. To bypass a hook, the user must edit spec/fspec-hooks.json to remove or disable it (more intentional than a flag). This maintains discipline and ensures hooks enforce their intended policies.",
        "Always run for all work units. No matcher system. This keeps the framework simple and predictable. If users need conditional execution, they can implement it inside their hook scripts by reading the work unit context and exiting early if conditions aren't met.",
        "Default timeout is 60 seconds (matching Claude Code). Hooks can override with 'timeout' field in fspec-hooks.json. Global default can be set in 'global.timeout'. When timeout is exceeded, the hook process is killed and an error is returned.",
        "Plain stdout/stderr only. Exit code determines success (0) or failure (non-zero). Hook output is displayed as-is to the user. If blocking hook fails (exit != 0), fspec shows stderr in a system-reminder block for AI agent consumption. This keeps hooks simple and works with any tool.",
        "No dry-run mode. Users can use 'fspec list-hooks' to see configured hooks and 'fspec validate-hooks' to validate configuration syntax. To test a hook, users can temporarily make it non-blocking or run it manually outside of fspec.",
        "CLI commands 'fspec add-hook' and 'fspec remove-hook' manage hooks in fspec-hooks.json programmatically",
        "No chaining. Each hook receives the same original work unit context via stdin. Hooks execute sequentially but independently. If users need chaining logic, they can implement it inside their hook scripts (e.g., read files left by previous hooks or use pipes within the script).",
        "No chaining for any hooks. All hooks (event hooks and exit hooks) receive the original context/output via stdin. Hooks execute sequentially but independently for side effects (validation, logging, notifications). The original command output is returned to the user unchanged by hooks.",
        "Hooks inherit the parent process environment naturally (as spawned child processes). fspec does NOT set custom FSPEC_* environment variables. Hooks receive all context via stdin as JSON. Hooks are independent programs that manage their own environment.",
        "Support optional conditions in hook configuration. Hooks can specify 'condition' object with fields like 'tags', 'prefix', 'epic', 'estimateMin', 'estimateMax'. If condition doesn't match, hook is skipped. If no condition specified, hook always runs. This allows context-aware hooks without requiring logic in every script.",
        "Support hooks for ANY fspec command using convention: 'pre-<command-name>' and 'post-<command-name>'. Examples: pre-create-work-unit, post-add-rule, pre-link-coverage, post-generate-scenarios. Plus special lifecycle hooks: pre-start (before any command) and pre-exit (before returning output). This makes the system extensible for current and future commands.",
        "Yes. When a blocking hook fails (exit code != 0), fspec wraps the stderr output in a <system-reminder> block for AI agent consumption. This allows hooks to provide guidance, suggestions, and instructions to AI through plain text stderr output. Non-blocking hooks just display output normally.",
        "No standard schema. Hooks output freeform text to stdout/stderr. AI agents read and interpret the text naturally. This maximizes flexibility for hook authors and keeps the framework simple. Documentation can provide examples of effective hook output patterns.",
        "No. fspec provides the hooks framework only. Users can implement multi-agent patterns (spawning multiple Claude sessions, parallel execution, etc.) in their hook scripts using standard shell tools. This keeps fspec focused and avoids framework bloat."
      ],
      "examples": [
        "Developer configures post-implementing hook to run ESLint before allowing transition to validating",
        "Developer configures post-testing hook to run Playwright tests to verify E2E scenarios work",
        "Developer configures post-done hook to send Slack notification that work unit is complete",
        "Developer configures pre-validating hook to check test coverage is above 80%",
        "Developer configures post-add-rule hook to check if rule needs clarification (AI analysis)",
        "Developer configures post-generate-scenarios hook to auto-format generated feature files",
        "Developer configures post-generate-coverage hook to run test suite with coverage reporter and extract actual line mappings",
        "Developer configures post-answer-question hook to automatically add answer as rule or assumption based on AI classification",
        "Developer configures pre-generate-scenarios hook to validate that all questions are answered before allowing scenario generation",
        "Developer configures post-link-coverage hook to verify linked files exist and line ranges are valid",
        "Developer configures pre-create-work-unit hook to block creation if work unit title contains placeholder text like TODO or TBD",
        "Developer configures pre-delete-work-unit hook to prevent deletion of work units with status 'implementing' or 'validating'",
        "Developer configures pre-unlink-coverage hook to confirm before removing coverage mappings (safety check)",
        "Developer configures pre-delete-scenario hook to block deletion if scenario has existing test coverage",
        "Code quality hook fails with message: 'BLOCKED: TypeScript errors in src/auth.ts:42. Fix type annotation for loginUser function before proceeding to validating state.'",
        "Coverage hook returns: 'WARNING: Test coverage is 65%, below 80% threshold. Consider adding tests for edge cases in src/validator.ts:23-45 before moving to validating.'",
        "Example mapping hook suggests: 'SUGGESTION: Question 0 contains implementation details. Consider rephrasing to focus on behavior: What should happen when... instead of How should we implement...'",
        "AI uses post-testing hook to analyze test failures and suggest missing scenarios or edge cases",
        "AI uses post-implementing hook to compare code against acceptance criteria and flag deviations",
        "AI uses post-generate-scenarios hook to review generated Gherkin and suggest improvements for clarity",
        "AI uses pre-implementing hook to verify all scenarios have corresponding test mappings before allowing code to be written",
        "AI uses post-add-example hook to detect duplicate or conflicting examples and suggest consolidation",
        "AI uses post-validating hook to analyze coverage gaps and suggest missing test scenarios",
        "Developer configures post-implementing hook to spawn a separate Claude Code session as a 'code reviewer' persona to review implementation before validating",
        "Developer configures post-generate-scenarios hook to spawn Claude Code as 'BDD expert' persona to critique Gherkin quality",
        "Developer configures post-testing hook to spawn Claude Code as 'QA engineer' persona to review test coverage and suggest edge cases",
        "Developer configures post-add-example hook to spawn Claude Code as 'product owner' persona to validate examples match business requirements",
        "Developer configures pre-done hook to spawn Claude Code as 'security auditor' persona to review code for security vulnerabilities",
        "User writes custom bash hook in spec/hooks/check-quality.sh that runs ESLint and returns JSON feedback",
        "User writes Python hook in spec/hooks/analyze-coverage.py that uses pytest-cov to generate coverage reports",
        "User writes Node.js hook in spec/hooks/validate-api.js that spawns separate Claude session for review",
        "User configures startup hook to validate project configuration and block fspec execution if settings are invalid",
        "User configures startup hook to initialize external services (database connection, API tokens) before fspec runs",
        "User configures exit hook to send fspec command results to external dashboard or logging service",
        "User configures exit hook to intercept validation errors and add project-specific troubleshooting guidance to AI agent",
        "User configures exit hook to format fspec output for different consumers (JSON for CI, markdown for humans, structured for AI)",
        "User runs 'fspec add-hook post-implementing code-quality spec/hooks/check-quality.sh --blocking' to add a new hook to configuration",
        "User runs 'fspec remove-hook post-implementing code-quality' to remove a hook from configuration"
      ],
      "questions": [
        {
          "text": "@human: Should hooks for the same event run in parallel (all at once) or sequentially (one after another)? Claude Code runs them in parallel.",
          "selected": true,
          "answer": "Sequential execution only. Hooks for the same event run one after another in the order defined in fspec-hooks.json. This provides predictable execution order, easier debugging, and allows later hooks to depend on earlier hooks' side effects."
        },
        {
          "text": "@human: When a blocking hook fails, should we provide a way for the user to override and force the transition anyway (like --skip-hooks flag)?",
          "selected": true,
          "answer": "No skip mechanism. When a blocking hook fails, the command is blocked and the user must fix the issue. To bypass a hook, the user must edit spec/fspec-hooks.json to remove or disable it (more intentional than a flag). This maintains discipline and ensures hooks enforce their intended policies."
        },
        {
          "text": "@human: Should hooks be able to match specific work units (e.g., only run for AUTH-* prefixes or specific epics)? Or always run for all work units?",
          "selected": true,
          "answer": "Always run for all work units. No matcher system. This keeps the framework simple and predictable. If users need conditional execution, they can implement it inside their hook scripts by reading the work unit context and exiting early if conditions aren't met."
        },
        {
          "text": "@human: What should the default timeout be? Claude Code uses 60 seconds. Should we allow per-hook timeout overrides?",
          "selected": true,
          "answer": "Default timeout is 60 seconds (matching Claude Code). Hooks can override with 'timeout' field in fspec-hooks.json. Global default can be set in 'global.timeout'. When timeout is exceeded, the hook process is killed and an error is returned."
        },
        {
          "text": "@human: Should hook scripts be able to return structured output (JSON) that fspec displays to the user, or just stdout/stderr?",
          "selected": true,
          "answer": "Plain stdout/stderr only. Exit code determines success (0) or failure (non-zero). Hook output is displayed as-is to the user. If blocking hook fails (exit != 0), fspec shows stderr in a system-reminder block for AI agent consumption. This keeps hooks simple and works with any tool."
        },
        {
          "text": "@human: Do you want a dry-run mode to test hooks without actually running them (just show what would execute)?",
          "selected": true,
          "answer": "No dry-run mode. Users can use 'fspec list-hooks' to see configured hooks and 'fspec validate-hooks' to validate configuration syntax. To test a hook, users can temporarily make it non-blocking or run it manually outside of fspec."
        },
        {
          "text": "@human: Should we support hook chaining where one hook's output becomes the next hook's input?",
          "selected": true,
          "answer": "No chaining for any hooks. All hooks (event hooks and exit hooks) receive the original context/output via stdin. Hooks execute sequentially but independently for side effects (validation, logging, notifications). The original command output is returned to the user unchanged by hooks."
        },
        {
          "text": "@human: What environment variables should be available to hooks? (e.g., FSPEC_WORK_UNIT_ID, FSPEC_STATUS, FSPEC_FEATURE_FILES, etc.)",
          "selected": true,
          "answer": "Hooks inherit the parent process environment naturally (as spawned child processes). fspec does NOT set custom FSPEC_* environment variables. Hooks receive all context via stdin as JSON. Hooks are independent programs that manage their own environment."
        },
        {
          "text": "@human: Should we support hook conditions (e.g., only run if estimate > 5 points, or only for @critical tagged features)?",
          "selected": true,
          "answer": "Support optional conditions in hook configuration. Hooks can specify 'condition' object with fields like 'tags', 'prefix', 'epic', 'estimateMin', 'estimateMax'. If condition doesn't match, hook is skipped. If no condition specified, hook always runs. This allows context-aware hooks without requiring logic in every script."
        },
        {
          "text": "@human: Do you want hooks for non-transition events like create-work-unit, add-dependency, or link-coverage?",
          "selected": true,
          "answer": "Support hooks for ANY fspec command using convention: 'pre-<command-name>' and 'post-<command-name>'. Examples: pre-create-work-unit, post-add-rule, pre-link-coverage, post-generate-scenarios. Plus special lifecycle hooks: pre-start (before any command) and pre-exit (before returning output). This makes the system extensible for current and future commands."
        },
        {
          "text": "@human: Should we have hooks that run on commands like create-work-unit, add-dependency, or prioritize-work-unit for workflow automation?",
          "selected": true,
          "answer": "Yes - already answered in Question 9. All fspec commands support pre/post hooks including create-work-unit, add-dependency, prioritize-work-unit, etc. This enables workflow automation like auto-prioritizing critical work units or validating dependencies."
        },
        {
          "text": "@human: Should hooks be able to provide AI-consumable feedback that influences the next steps (e.g., suggest missing scenarios, recommend refactoring)?",
          "selected": true,
          "answer": "Yes. When a blocking hook fails (exit code != 0), fspec wraps the stderr output in a <system-reminder> block for AI agent consumption. This allows hooks to provide guidance, suggestions, and instructions to AI through plain text stderr output. Non-blocking hooks just display output normally."
        },
        {
          "text": "@human: Should we provide a standard schema for hook output that includes 'suggestions', 'warnings', 'blockers', and 'insights' for AI consumption?",
          "selected": true,
          "answer": "No standard schema. Hooks output freeform text to stdout/stderr. AI agents read and interpret the text naturally. This maximizes flexibility for hook authors and keeps the framework simple. Documentation can provide examples of effective hook output patterns."
        },
        {
          "text": "@human: Should hooks support spawning multiple Claude Code sessions in parallel for multi-perspective review (e.g., security + performance + maintainability reviewers)?",
          "selected": true,
          "answer": "No. fspec provides the hooks framework only. Users can implement multi-agent patterns (spawning multiple Claude sessions, parallel execution, etc.) in their hook scripts using standard shell tools. This keeps fspec focused and avoids framework bloat."
        }
      ],
      "assumptions": [
        "Yes - already answered in Question 9. All fspec commands support pre/post hooks including create-work-unit, add-dependency, prioritize-work-unit, etc. This enables workflow automation like auto-prioritizing critical work units or validating dependencies."
      ],
      "estimate": 13,
      "epic": "hooks-system"
    },
    "HOOK-002": {
      "id": "HOOK-002",
      "title": "Hook configuration schema and validation",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:40.720Z",
      "updatedAt": "2025-10-19T13:17:31.592Z",
      "description": "Create JSON schema for spec/fspec-hooks.json. Implement configuration loading, validation, and error handling. Support hook definition with name, command, blocking flag, timeout, and conditions.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T11:50:26.414Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T11:53:06.432Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T11:55:57.393Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T11:56:34.878Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T11:57:55.781Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T13:13:13.128Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T13:17:31.318Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T13:17:31.593Z"
        }
      ],
      "userStory": {
        "role": "fspec developer",
        "action": "define hook configuration in spec/fspec-hooks.json",
        "benefit": "the hooks system knows which scripts to execute at which events"
      },
      "rules": [
        "Configuration file is spec/fspec-hooks.json in JSON format",
        "Each hook has: name (string), command (path to executable), blocking (boolean, default false), timeout (number in seconds, default 60)",
        "Hooks can have optional condition object with: tags (array), prefix (array), epic (string), estimateMin (number), estimateMax (number)",
        "Configuration must be valid JSON and conform to hooks schema",
        "Hook command paths must point to executable files",
        "Global defaults can be set in 'global' object: timeout, shell"
      ],
      "examples": [
        "Valid config with single hook: {hooks: {'post-implementing': [{name: 'lint', command: 'spec/hooks/lint.sh', blocking: true}]}}",
        "Hook with timeout override: {name: 'e2e-tests', command: 'test.sh', timeout: 300}",
        "Hook with conditions: {name: 'security', command: 'audit.sh', condition: {tags: ['@security'], prefix: ['AUTH']}}",
        "Invalid JSON causes validation error with helpful message",
        "Non-existent hook command path causes validation error",
        "Missing hook file returns clear error: 'Hook command not found: spec/hooks/missing.sh'"
      ]
    },
    "HOOK-003": {
      "id": "HOOK-003",
      "title": "Hook execution engine",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:44.580Z",
      "updatedAt": "2025-10-15T12:09:58.633Z",
      "description": "Implement core hook execution: spawn processes, pass context via stdin JSON, collect stdout/stderr, handle exit codes, implement 60s default timeout with override support, sequential execution of hooks.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:00:26.203Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:03:56.276Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:05:03.823Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:08:33.750Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:09:58.633Z"
        }
      ],
      "userStory": {
        "role": "fspec developer",
        "action": "execute hook scripts at lifecycle events",
        "benefit": "I can run custom automation, quality gates, and notifications during fspec commands"
      },
      "rules": [
        "Hook execution engine spawns child processes for each hook script",
        "Hook context is passed as JSON to stdin (workUnitId, event, timestamp, etc.)",
        "stdout and stderr are captured and displayed to user/AI agent",
        "Exit code 0 indicates success, non-zero indicates failure",
        "Hooks timeout after configured duration (default 60s)",
        "Blocking hooks halt command execution on failure (non-zero exit)",
        "Hooks execute sequentially in the order defined in config",
        "Hook processes inherit parent environment variables"
      ],
      "examples": [
        "Execute single non-blocking hook that succeeds (exit 0) - output shown, command continues",
        "Execute single non-blocking hook that fails (exit 1) - warning shown, command continues",
        "Execute blocking hook that fails - command halted, error returned to user/AI",
        "Hook times out after 60s - process killed, timeout error shown",
        "Hook receives context via stdin: {\"workUnitId\":\"AUTH-001\",\"event\":\"post-implementing\",\"timestamp\":\"2025-01-15T10:30:00Z\"}",
        "Multiple hooks execute sequentially - first runs to completion, then second starts",
        "Hook stdout/stderr captured and displayed: 'Running tests...' visible to user"
      ]
    },
    "HOOK-004": {
      "id": "HOOK-004",
      "title": "Hook discovery and event naming",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:48.300Z",
      "updatedAt": "2025-10-15T12:17:01.555Z",
      "description": "Implement hook discovery for any command using pre-/post- convention. Support special lifecycle hooks: pre-start and pre-exit. Build event name from command name dynamically.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:11:00.282Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:14:07.598Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:14:54.286Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:15:29.403Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:17:01.555Z"
        }
      ],
      "userStory": {
        "role": "fspec system",
        "action": "discover and execute hooks for lifecycle events",
        "benefit": "hooks can be triggered at the right moments during command execution"
      },
      "rules": [
        "Event names follow pre-/post- convention: pre-<command-name>, post-<command-name>",
        "Special lifecycle hooks: pre-start (before any command), pre-exit (before returning output)",
        "Hook discovery searches config.hooks for matching event name",
        "If no hooks match event name, return empty array (no error)",
        "Event names are case-sensitive (pre-implementing != pre-Implementing)",
        "Command name extraction: 'fspec update-work-unit-status' -> 'update-work-unit-status'"
      ],
      "examples": [
        "Discover hooks for 'post-implementing' event - returns array of matching hooks",
        "Discover hooks for 'pre-start' special lifecycle event - returns global pre-start hooks",
        "Discover hooks for non-existent event 'pre-xyz' - returns empty array (no error)",
        "Event name for command 'update-work-unit-status' generates 'pre-update-work-unit-status' and 'post-update-work-unit-status'",
        "Case-sensitive matching: 'post-implementing' finds hooks, 'post-Implementing' does not",
        "Multiple hooks for same event - returns all matching hooks in config order"
      ]
    },
    "HOOK-005": {
      "id": "HOOK-005",
      "title": "Hook condition evaluation",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:52.221Z",
      "updatedAt": "2025-10-15T12:24:15.115Z",
      "description": "Implement optional condition matching: tags, prefix, epic, estimateMin, estimateMax. Skip hook if conditions don't match. Support no condition = always run.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:17:45.705Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:21:11.809Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:22:27.203Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:23:05.811Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:24:15.116Z"
        }
      ],
      "userStory": {
        "role": "hook execution system",
        "action": "evaluate hook conditions to determine if a hook should run",
        "benefit": "hooks only execute when their conditions match the current context"
      },
      "rules": [
        "Hooks with no condition always match (condition is optional)",
        "Condition with tags: hook runs if work unit has ANY of the specified tags (OR logic)",
        "Condition with prefix: hook runs if work unit ID starts with ANY of the specified prefixes (OR logic)",
        "Condition with epic: hook runs if work unit belongs to specified epic",
        "Condition with estimateMin/estimateMax: hook runs if work unit estimate is within range",
        "Multiple condition fields use AND logic (all must match)",
        "If context has no workUnitId, only hooks without conditions run"
      ],
      "examples": [
        "Hook with no condition matches any context - always runs",
        "Hook with tags:[@security] matches work unit with @security tag",
        "Hook with prefix:[AUTH,SEC] matches AUTH-001 but not DASH-001",
        "Hook with epic:'user-management' matches work unit in that epic",
        "Hook with estimateMin:5, estimateMax:13 matches work unit with estimate 8",
        "Hook with tags:[@security] AND prefix:[AUTH] - both must match (AND logic)",
        "Context with no workUnitId - only unconditional hooks match"
      ]
    },
    "HOOK-006": {
      "id": "HOOK-006",
      "title": "System reminder formatting for AI",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:56.257Z",
      "updatedAt": "2025-10-15T12:32:11.238Z",
      "description": "When blocking hook fails, wrap stderr in <system-reminder> block for AI consumption. Display hook name, exit code, and error message. Include 'DO NOT mention this reminder to the user' footer.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:26:08.503Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:29:26.029Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:30:18.689Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:30:56.713Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:32:11.239Z"
        }
      ],
      "userStory": {
        "role": "fspec system",
        "action": "format blocking hook stderr as system-reminders for AI agents",
        "benefit": "AI agents receive actionable feedback when hooks fail"
      },
      "rules": [
        "Blocking hook stderr is wrapped in <system-reminder> tags",
        "Non-blocking hook stderr is displayed as-is (no wrapping)",
        "System-reminder content includes hook name, exit code, and stderr output",
        "Empty stderr produces no system-reminder (only if stderr has content)",
        "System-reminder is appended to command output (not replacing it)"
      ],
      "examples": [
        "Blocking hook fails with stderr 'Invalid config' - wrapped in system-reminder",
        "Non-blocking hook fails with stderr - displayed as-is, no wrapping",
        "Blocking hook succeeds - no system-reminder generated",
        "Blocking hook fails with empty stderr - no system-reminder",
        "System-reminder includes: hook name 'validate', exit code 1, stderr content"
      ]
    },
    "HOOK-007": {
      "id": "HOOK-007",
      "title": "Hook management CLI commands",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:45:00.480Z",
      "updatedAt": "2025-10-15T12:51:50.899Z",
      "description": "Implement: fspec list-hooks, fspec validate-hooks, fspec add-hook, fspec remove-hook. List shows all configured hooks. Validate checks config syntax. Add/remove modify fspec-hooks.json.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:42:06.760Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:47:49.741Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:48:36.967Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:49:21.484Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:51:50.899Z"
        }
      ],
      "userStory": {
        "role": "fspec user",
        "action": "manage hooks via CLI commands",
        "benefit": "I can list, validate, add, and remove hooks without manually editing JSON"
      },
      "rules": [
        "list-hooks command displays all configured hooks grouped by event",
        "validate-hooks command checks config syntax and verifies hook scripts exist",
        "add-hook command adds a hook to config and creates the event array if needed",
        "remove-hook command removes a hook by name and event",
        "Commands fail gracefully if spec/fspec-hooks.json does not exist",
        "add-hook command requires: name, event, command (path to script)"
      ],
      "examples": [
        "list-hooks displays: post-implementing: lint, test",
        "validate-hooks passes - all scripts exist, JSON valid",
        "validate-hooks fails - missing script spec/hooks/missing.sh",
        "add-hook --name lint --event post-implementing --command spec/hooks/lint.sh --blocking",
        "remove-hook --name lint --event post-implementing - hook removed from config",
        "list-hooks when no config file - displays friendly message"
      ]
    },
    "HOOK-008": {
      "id": "HOOK-008",
      "title": "Integrate hooks into all commands",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:45:04.467Z",
      "updatedAt": "2025-10-15T13:01:53.657Z",
      "description": "Add hook execution to every fspec command. Call runHooks() before/after command logic. Support pre-start lifecycle hook. Support pre-exit lifecycle hook. Pass appropriate context to each hook.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:56:41.998Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:58:43.162Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:59:55.073Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:00:34.477Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:01:53.657Z"
        }
      ],
      "userStory": {
        "role": "fspec CLI user",
        "action": "have hooks execute automatically with every command",
        "benefit": "I can enforce policies and automations without manually invoking hooks"
      },
      "rules": [
        "Commands execute pre- hooks before main logic and post- hooks after main logic",
        "Hook event names follow pattern: pre-{command} and post-{command}",
        "Hooks receive context with workUnitId (if applicable), event name, and timestamp",
        "Blocking hook failures prevent command execution (pre-hooks) or prevent exit with success (post-hooks)",
        "Non-blocking hook failures do not prevent command execution or success",
        "Hooks are filtered by conditions before execution (tags, prefix, epic, estimate)",
        "Hook output is displayed using formatHookOutput() with system-reminders for blocking failures"
      ],
      "examples": [
        "Command update-work-unit-status triggers pre-update-work-unit-status and post-update-work-unit-status hooks",
        "Pre-hook validates work unit has feature file before allowing status change to testing",
        "Post-hook runs tests after implementing status change",
        "Blocking pre-hook failure prevents command from executing",
        "Non-blocking post-hook failure allows command to succeed",
        "Hook with tag condition only runs for work units with matching tag",
        "Hook output formatted with system-reminder shows blocking hook failure details"
      ]
    },
    "HOOK-009": {
      "id": "HOOK-009",
      "title": "Hook system documentation and examples",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:45:08.399Z",
      "updatedAt": "2025-10-15T13:08:41.103Z",
      "description": "Write comprehensive documentation: configuration format, hook script examples (bash/python/node), best practices for output, example hooks for common use cases (linting, testing, notifications).",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T13:02:40.697Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T13:04:34.908Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T13:05:21.697Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:07:19.458Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:08:41.104Z"
        }
      ],
      "userStory": {
        "role": "fspec user writing hook scripts",
        "action": "have comprehensive documentation and working examples",
        "benefit": "I can quickly create custom hooks without trial and error"
      },
      "rules": [
        "Documentation explains hook configuration JSON schema with all fields",
        "Example hooks provided for bash, python, and node.js",
        "Documentation explains hook context JSON passed via stdin",
        "Best practices documented for stdout/stderr usage and exit codes",
        "Common use case examples: linting, testing, notifications, validation",
        "Documentation includes troubleshooting section for common errors"
      ],
      "examples": [
        "Configuration doc shows complete fspec-hooks.json with global defaults and multiple hooks",
        "Bash hook reads JSON context from stdin and validates work unit has feature file",
        "Python hook parses JSON stdin and runs pytest on work unit tests",
        "Node.js hook reads stdin and sends Slack notification about status change",
        "Lint hook example shows proper exit codes: 0 for success, 1 for lint errors",
        "Troubleshooting doc explains 'Hook command not found' error and solution"
      ]
    },
    "BUG-011": {
      "id": "BUG-011",
      "title": "generate-scenarios missing architecture docstring",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T22:51:07.833Z",
      "updatedAt": "2025-10-15T23:10:52.876Z",
      "description": "The generate-scenarios command creates feature files without architecture docstrings, violating CLAUDE.md requirements. Older files created with create-feature have docstrings, but newer files created with generate-scenarios are missing them.",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T22:51:16.440Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T22:53:06.162Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T22:53:45.139Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:09:40.344Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:10:52.876Z"
        }
      ],
      "userStory": {
        "role": "developer using generate-scenarios",
        "action": "have feature files with architecture docstrings",
        "benefit": "all feature files meet CLAUDE.md requirements and have consistent structure"
      },
      "rules": [
        "All feature files MUST have architecture docstrings (CLAUDE.md requirement)",
        "generate-scenarios output MUST match create-feature template structure",
        "Docstring MUST come before example mapping comments",
        "Docstring MUST include TODO placeholders for architecture notes"
      ],
      "examples": [
        "User runs generate-scenarios, file contains both docstring and example mapping comments",
        "Generated file matches structure: tags → feature → docstring → comments → background",
        "Existing tests pass with new docstring addition"
      ]
    },
    "FEAT-012": {
      "id": "FEAT-012",
      "title": "Capture architecture notes during Example Mapping",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T22:58:05.227Z",
      "updatedAt": "2025-10-15T23:23:02.738Z",
      "description": "Add ability to capture architecture notes and non-functional requirements during Example Mapping discovery phase, and populate feature file docstrings with this information during generate-scenarios.",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T22:58:14.705Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T23:15:36.150Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T23:16:21.173Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:21:08.805Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:23:02.739Z"
        }
      ],
      "userStory": {
        "role": "AI agent doing Example Mapping",
        "action": "capture architecture notes and non-functional requirements",
        "benefit": "generated feature files have complete technical context in docstrings"
      },
      "rules": [
        "Architecture notes must be stored in WorkUnit during Example Mapping",
        "Architecture notes must populate docstring in generate-scenarios output",
        "Must support adding/removing/viewing architecture notes via CLI",
        "Architecture notes should include: dependencies, performance reqs, security considerations, implementation constraints"
      ],
      "examples": [
        "User runs 'fspec add-architecture-note WORK-001 \"Uses @cucumber/gherkin parser\"' during Example Mapping",
        "User runs 'fspec generate-scenarios WORK-001' and docstring contains captured architecture notes instead of TODO placeholders",
        "User runs 'fspec show-work-unit WORK-001' and sees architecture notes section with all captured notes",
        "Generated docstring includes sections for dependencies, performance, security based on captured notes"
      ],
      "questions": [
        {
          "text": "@human: Should architectureNotes be a separate array field in WorkUnit, or reuse assumptions field?",
          "selected": true,
          "answer": "Separate architectureNotes array field in WorkUnit (clearer separation from assumptions)"
        },
        {
          "text": "@human: Should we ask about architecture notes as a separate Example Mapping step (purple cards), or integrate with existing steps?",
          "selected": true,
          "answer": "Integrate with existing steps - ask architecture questions during Step 3 (Ask Questions phase) for natural flow"
        },
        {
          "text": "@human: What specific NFR questions should AI ask during discovery? (performance, security, dependencies, scalability, etc.)",
          "selected": true,
          "answer": "Ask about: libraries/dependencies, code that should be refactored/shared, code quality considerations, UI/UX examples (websites/screenshots), implementation patterns to follow"
        },
        {
          "text": "@human: Should architecture notes have categories/types, or just be free-form strings?",
          "selected": true,
          "answer": "Free-form strings initially - users can prefix naturally (e.g., 'Dependency: ...', 'Refactoring: ...'). Add categorization later if needed."
        }
      ]
    },
    "FEAT-013": {
      "id": "FEAT-013",
      "title": "Attachment support for discovery process",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T23:42:01.192Z",
      "updatedAt": "2025-10-15T23:47:36.516Z",
      "description": "Add ability to attach files (diagrams, mockups, documents) to work units during Example Mapping to supplement architecture notes and NFRs",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T23:42:21.297Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T23:42:57.989Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T23:43:10.317Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:43:11.875Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:44:54.141Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-15T23:46:00.822Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T23:46:24.484Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T23:47:32.452Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:47:34.074Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:47:36.517Z"
        }
      ],
      "userStory": {
        "role": "AI agent or developer using fspec",
        "action": "attach files to work units during Example Mapping",
        "benefit": "I can supplement architecture notes and NFRs with diagrams, mockups, and documents"
      },
      "rules": [
        "Attachments must be stored in spec/attachments/<work-unit-id>/ directory",
        "Attachment paths must be stored as relative paths from project root",
        "Source file must exist before copying to attachments directory"
      ],
      "examples": [
        "User runs 'fspec add-attachment AUTH-001 diagrams/auth-flow.png', file is copied to spec/attachments/AUTH-001/ and tracked in work unit",
        "User runs 'fspec list-attachments AUTH-001', sees all attached files with sizes and modification dates",
        "User runs 'fspec remove-attachment AUTH-001 diagram.png', file is deleted and tracking entry removed"
      ],
      "architectureNotes": [
        "Attachments array added to WorkUnit interface in src/types/index.ts",
        "Three new commands: add-attachment, list-attachments, remove-attachment",
        "Uses fs/promises for file operations (copyFile, stat, unlink)"
      ]
    },
    "HOOK-010": {
      "id": "HOOK-010",
      "title": "Migrate hook execution to use execa library",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T00:49:47.693Z",
      "updatedAt": "2025-10-16T01:18:17.009Z",
      "description": "Replace Node.js child_process.spawn with execa library for hook execution, following the patterns used in the cage project for better process management and cross-platform compatibility",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T00:49:52.619Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T00:55:20.542Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T00:57:07.118Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T01:06:35.448Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T01:18:17.009Z"
        }
      ],
      "userStory": {
        "role": "fspec developer",
        "action": "use execa for hook execution instead of child_process.spawn",
        "benefit": "better process management, improved error handling, and cross-platform compatibility"
      },
      "rules": [
        "Hook execution must maintain timeout behavior (default 60s)",
        "Hook context must be passed to stdin as JSON",
        "stdout and stderr must be captured separately",
        "Hook execution results must include hookName, success, exitCode, stdout, stderr, timedOut, duration",
        "execa library must be installed as a dependency",
        "All existing hook tests must continue to pass",
        "Non-detached behavior - hooks run attached to fspec process",
        "Keep custom timeout implementation integrated with execa - use AbortController signal to cancel subprocess",
        "Use execa's input option for passing JSON context - it's the best practice and handles stream management automatically"
      ],
      "examples": [
        "Hook executes successfully and returns exitCode 0 with captured stdout/stderr",
        "Hook times out after configured timeout period and is killed",
        "Hook fails with non-zero exit code and error message in stderr",
        "Hook receives context via stdin as JSON string",
        "Multiple hooks execute sequentially in order"
      ],
      "architectureNotes": [
        "Use execa library (same as cage project) for better process management",
        "Modify src/hooks/executor.ts executeHook() function",
        "Install execa as dependency in package.json",
        "Reference cage's server.ts implementation for execa usage patterns"
      ],
      "questions": [
        {
          "text": "@human: Should we support detached processes like cage does for server.ts, or keep the current non-detached behavior?",
          "selected": true,
          "answer": "Non-detached behavior - hooks run attached to fspec process"
        },
        {
          "text": "@human: Should we use execa's built-in timeout option or keep the custom timeout implementation?",
          "selected": true,
          "answer": "Keep custom timeout implementation integrated with execa - use AbortController signal to cancel subprocess"
        },
        {
          "text": "@human: Should we use execa's input option for passing context or stick with stdin.write()?",
          "selected": true,
          "answer": "Use execa's input option for passing JSON context - it's the best practice and handles stream management automatically"
        }
      ],
      "estimate": 3
    },
    "TEST-004": {
      "id": "TEST-004",
      "title": "Write missing tests for partially covered features",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-16T01:54:24.619Z",
      "updatedAt": "2025-10-16T11:07:03.554Z",
      "description": "Complete test coverage for 3 features: architecture-notes-in-example-mapping (2 scenarios), generate-scenarios-include-architecture-docstring (1 scenario), and preserve-example-mapping-context-as-comments-in-generated-feature-files (11 scenarios). Total: 14 uncovered scenarios that need tests.",
      "children": [],
      "estimate": 8,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T10:32:36.675Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T10:40:42.515Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T10:50:27.809Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T10:50:43.392Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T10:57:29.589Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T11:07:03.243Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T11:07:03.554Z"
        }
      ],
      "questions": [
        {
          "text": "@human: For these uncovered scenarios, should I write (A) full test implementations (traditional forward ACDD) or (B) skeleton tests (reverse ACDD style - structure only with TODOs)?",
          "selected": true,
          "answer": "Forward ACDD where there's no implementation/tests, reverse ACDD where there's no tests/features"
        },
        {
          "text": "@human: Should I examine the implementation files (e.g., generate-scenarios.ts, show-work-unit.ts) to infer what the tests should validate for scenarios that have existing code?",
          "selected": true,
          "answer": "Yes, examine implementation files to infer what the tests should validate. Figure out what code the test is running by analyzing existing implementation."
        },
        {
          "text": "@human: Are there any specific testing patterns or conventions in this codebase I should follow when writing tests for the generate-scenarios and example mapping commands?",
          "selected": true,
          "answer": "Follow the ACDD process - no special testing patterns beyond what's defined in CLAUDE.md"
        },
        {
          "text": "@human: I see the third feature has 11 uncovered scenarios. Should I tackle all 14 scenarios (2 from architecture-notes + 1 from generate-scenarios-include-architecture + 11 from preserve-example-mapping) in this single work unit, or should I break this into smaller work units?",
          "selected": true,
          "answer": "Do all 14 scenarios in one work unit - don't break it up"
        }
      ],
      "rules": [
        "Forward ACDD where there's no implementation/tests, reverse ACDD where there's no tests/features",
        "Yes, examine implementation files to infer what the tests should validate. Figure out what code the test is running by analyzing existing implementation.",
        "Do all 14 scenarios in one work unit - don't break it up"
      ],
      "assumptions": [
        "Follow the ACDD process - no special testing patterns beyond what's defined in CLAUDE.md"
      ],
      "examples": [
        "For 'View architecture notes in work unit' scenario - check show-work-unit command displays architecture notes added during example mapping",
        "For scenarios in preserve-example-mapping feature - test that add-scenario and add-background commands don't remove existing example mapping comments"
      ]
    },
    "FOUND-001": {
      "id": "FOUND-001",
      "title": "Design Generic Foundation Schema",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:12:53.931Z",
      "updatedAt": "2025-10-17T00:05:44.115Z",
      "description": "Create new TypeScript types and JSON schema for generic PRD structure focusing on WHY and WHAT",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:13:02.563Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T23:23:00.347Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:00:17.011Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T00:05:04.272Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T00:05:44.116Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for any project type",
        "action": "create a generic foundation document that captures WHY and WHAT",
        "benefit": "I have clear product requirements without mixing in implementation details"
      },
      "questions": [],
      "assumptions": [
        "Unlimited personas allowed, but suggest 3-7 in documentation as best practice. No hard limits enforced by schema."
      ],
      "rules": [
        "Multiple problems supported. Complex products can have thousands of problems. Foundation.json can reference external sub-foundation documents for scalability (all built from single foundation.json). This creates a hierarchical PRD structure.",
        "Broad capabilities only (3-7 high-level abilities). Granular features belong in .feature files. Example: 'User Authentication' is a capability in foundation.json, 'Login with OAuth' is a feature in user-authentication.feature.",
        "REQUIRED: project identity, problem statement, solution overview. OPTIONAL: architecture diagrams, constraints, detailed personas. This ensures minimum viable PRD while allowing detailed documentation.",
        "Schema must focus ONLY on WHY (problem) and WHAT (solution), never HOW (implementation)",
        "Schema must work for ANY project type: web apps, CLI tools, libraries, services, mobile apps",
        "Mermaid diagram validation must be preserved from current implementation",
        "JSON Schema must use Ajv for validation with clear error messages"
      ],
      "examples": [
        "Web app foundation includes personas: 'End User', 'Admin', 'API Consumer'",
        "CLI tool foundation includes persona: 'Developer using CLI in terminal'",
        "Library foundation includes persona: 'Developer integrating library into their codebase'",
        "Problem space includes multiple problems with impact ratings (high/medium/low)",
        "Solution includes 3-7 high-level capabilities like 'User Authentication', 'Data Visualization', 'API Integration'",
        "Foundation.json can reference sub-foundations: { 'subFoundations': ['spec/foundations/auth-subsystem.foundation.json'] }"
      ],
      "architectureNotes": [
        "TypeScript interfaces must map exactly to JSON Schema definitions",
        "Use Ajv with ajv-formats for validation (uri, email, date-time formats)",
        "Hierarchical foundations: parent foundation.json can reference child foundations in subFoundations array",
        "Migration path needed: old schema → new schema with backward compatibility flag",
        "Mermaid validation must use mermaid.parse() with jsdom (existing pattern)"
      ]
    },
    "FOUND-002": {
      "id": "FOUND-002",
      "title": "Implement Automated Discovery - Code Analysis",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:35.741Z",
      "updatedAt": "2025-10-17T02:20:14.997Z",
      "description": "Scan existing codebase to infer project type, personas, and capabilities using reverse ACDD techniques",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 8,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T00:09:59.672Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T00:29:37.164Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:34:52.164Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T00:37:07.269Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T00:38:38.932Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T02:04:30.871Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T02:05:39.193Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-17T02:06:41.226Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T02:17:17.252Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T02:18:45.665Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T02:19:03.302Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T02:20:14.997Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec to document an existing codebase",
        "action": "automatically discover project structure and infer personas/capabilities",
        "benefit": "I can quickly bootstrap a foundation document without manual analysis"
      },
      "rules": [
        "Code analysis must detect project type (web app, CLI tool, library, service, mobile app, desktop app, API)",
        "Code analysis must infer personas from user-facing interactions (routes, commands, UI components, API endpoints)",
        "Code analysis must infer capabilities from code structure (high-level features, not implementation details)",
        "Analysis must be fast enough for interactive use (< 5 seconds for typical projects)",
        "fspec provides GUIDANCE to AI, not implementation - AI decides how to analyze code",
        "Discovery must infer: project type, personas, capabilities, AND problems/pain points",
        "Support monorepos - AI analyzes all packages that are part of the same project"
      ],
      "examples": [
        "CLI tool with commander.js commands → project type: cli-tool, persona: Developer using CLI",
        "Express.js with /api routes → project type: web-app, personas: API Consumer, End User",
        "Package with exports in package.json → project type: library, persona: Developer integrating library",
        "React components in src/ → capability: User Interface, not implementation detail like 'Uses React hooks'",
        "AI discovers React app → infers problem: 'Users need interactive web UI' not 'Code needs React'"
      ],
      "questions": [
        {
          "text": "@human: Should code analysis support monorepos with multiple package.json files, or just single-project repositories?",
          "selected": true,
          "answer": "Yes, support monorepos - analyze all package.json files that are part of the same project"
        },
        {
          "text": "@human: What file patterns should we analyze to detect project type? (package.json, tsconfig.json, Cargo.toml, go.mod, etc.)",
          "selected": true,
          "answer": "AI decides file patterns - fspec guides AI to discover project type using available clues, not prescriptive tool list"
        },
        {
          "text": "@human: Should we infer problems/pain points from code, or only project type and personas?",
          "selected": true,
          "answer": "Yes, infer everything: project type, personas, capabilities, AND problems/pain points - all critical for complete foundation"
        },
        {
          "text": "@human: How deep should directory traversal go? Should we limit to specific directories (src/, lib/, cmd/) or scan entire project?",
          "selected": true,
          "answer": "AI decides traversal depth - fspec guides AI to intelligently explore codebase, not prescriptive directory limits"
        }
      ]
    },
    "FOUND-003": {
      "id": "FOUND-003",
      "title": "Implement Interactive Questionnaire",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:36.482Z",
      "updatedAt": "2025-10-17T00:55:12.776Z",
      "description": "Build Ink-based CLI questionnaire to gather WHY/WHAT information from users",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:20:17.487Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T00:45:42.074Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:47:44.622Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T00:54:48.957Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T00:55:12.776Z"
        }
      ],
      "architectureNotes": [
        "Questionnaire must guide AI through structured discovery workflow with specific question templates",
        "Section 1: Vision Questions - 'What is the core purpose?', 'Who are the primary users?', 'What problem does this solve?'",
        "Section 2: Problem Space - 'What are the top 3-5 pain points?', 'What is the impact?', 'What is the frequency?'",
        "Section 3: Solution Space - 'What are the 3-7 key capabilities?', 'What makes this solution unique?', 'What is out of scope?'",
        "Section 4: Architecture - 'What is the tech stack?' (optional if detected), 'What are system boundaries?', 'What are external dependencies?'",
        "Section 5: Constraints - 'Business constraints?', 'Technical constraints?', 'Timeline/budget constraints?'",
        "Prefill mode: If code analysis detected values, show as defaults with [DETECTED] tag, allow AI to confirm/edit/skip",
        "AI guidance: Each question includes HELP text explaining WHY it's asked and EXAMPLES of good answers"
      ],
      "rules": [
        "Questions must be grouped by section with progress indicator (Question 3 of 15)",
        "Must support both prefilled mode (--from-discovery) and blank slate (--interactive)",
        "Must validate answers before accepting (e.g. non-empty strings, valid format)"
      ],
      "examples": [
        "Vision question with help: 'What is the core purpose? [HELP: One sentence elevator pitch. Example: fspec helps AI agents follow ACDD workflow]'",
        "Prefilled answer: 'Primary user: Developer using CLI [DETECTED from code analysis] - Keep/Edit/Skip?'"
      ],
      "userStory": {
        "role": "developer using fspec with AI to bootstrap foundation documents",
        "action": "gather WHY/WHAT information through structured questionnaire",
        "benefit": "I can create complete foundation.json without manual analysis"
      }
    },
    "FOUND-004": {
      "id": "FOUND-004",
      "title": "Implement discover-foundation Command",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:37.238Z",
      "updatedAt": "2025-10-17T02:15:18.183Z",
      "description": "Orchestrate code analysis + questionnaire to generate foundation.json with validation",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 8,
      "dependsOn": [
        "FOUND-001",
        "FOUND-002",
        "FOUND-003"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:20:49.620Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T00:58:37.167Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:59:52.936Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:01:33.811Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:01:53.733Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T02:04:31.237Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T02:05:39.561Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-17T02:06:41.599Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T02:08:36.356Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T02:11:49.901Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T02:13:55.861Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T02:15:18.183Z"
        }
      ],
      "architectureNotes": [
        "System-reminder integration: Wrap questionnaire output in <system-reminder> tags when running in AI context (detectable via environment)",
        "System-reminder triggers: (1) After code analysis completes - show detected personas/capabilities (2) During questionnaire - provide examples of good answers (3) After foundation.json generated - next steps guidance",
        "System-reminder content: 'Code analysis detected 3 personas [list]. Review and confirm during questionnaire. Focus on WHY/WHAT, not HOW. See CLAUDE.md for boundary guidance.'"
      ],
      "rules": [
        "Must emit system-reminders to guide AI through discovery process (persona review, WHY/WHAT boundary, next steps)",
        "The command should output all questions at once in a structured format. The AI (Claude) sees the questions, analyzes the codebase based on the guidance, and then the command collects answers through a partial foundation.json file that the AI edits.",
        "The command creates a partial foundation.json with prefilled [DETECTED] values and [QUESTION] placeholders. The AI edits this file directly using Write/Edit tools, filling in answers based on code analysis. Then running the command again validates and completes the foundation.",
        "Two-phase execution: (1) First run outputs questions and creates partial foundation.json with placeholders. AI edits the file. (2) Second run (or --finalize flag) validates the completed foundation.json and writes the final version."
      ],
      "examples": [
        "After code analysis: <system-reminder>Detected 3 user personas from routes: End User, Admin, API Consumer. Review in questionnaire. Use 'fspec show-work-unit FOUND-002' for details.</system-reminder>"
      ],
      "userStory": {
        "role": "developer using fspec with AI to bootstrap foundation documents",
        "action": "run discover-foundation command to orchestrate analysis and questionnaire",
        "benefit": "I get a complete validated foundation.json without manual work"
      },
      "questions": [
        {
          "text": "@human: How should the interactive questionnaire work? Does it output all questions at once and expect answers in a file, or does it prompt question-by-question?",
          "selected": true,
          "answer": "The command should output all questions at once in a structured format. The AI (Claude) sees the questions, analyzes the codebase based on the guidance, and then the command collects answers through a partial foundation.json file that the AI edits."
        },
        {
          "text": "@human: When the command outputs questions, how does the AI provide answers? Through command arguments, through editing a file, or through some other mechanism?",
          "selected": true,
          "answer": "The command creates a partial foundation.json with prefilled [DETECTED] values and [QUESTION] placeholders. The AI edits this file directly using Write/Edit tools, filling in answers based on code analysis. Then running the command again validates and completes the foundation."
        },
        {
          "text": "@human: Should the command run multiple times (once to output questions, again to collect answers), or should it be a single execution that somehow waits for input?",
          "selected": true,
          "answer": "Two-phase execution: (1) First run outputs questions and creates partial foundation.json with placeholders. AI edits the file. (2) Second run (or --finalize flag) validates the completed foundation.json and writes the final version."
        }
      ]
    },
    "FOUND-005": {
      "id": "FOUND-005",
      "title": "Migrate Existing foundation.json",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:38.001Z",
      "updatedAt": "2025-10-17T01:09:17.482Z",
      "description": "Extract WHY/WHAT from current fspec foundation.json, move HOW content elsewhere, automated migration",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 3,
      "dependsOn": [
        "FOUND-001"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T01:03:24.343Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T01:05:56.004Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:07:10.808Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:08:03.028Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:09:17.482Z"
        }
      ],
      "userStory": {
        "role": "developer migrating fspec to generic foundation schema",
        "action": "migrate existing foundation.json to v2.0.0 format",
        "benefit": "foundation document follows the new generic schema and supports all project types"
      },
      "rules": [
        "Must preserve all existing architecture diagrams in architectureDiagrams array",
        "WHY/WHAT content stays in foundation.json, HOW content moves to CLAUDE.md or other docs",
        "Migration must be automated via CLI command 'fspec migrate-foundation'",
        "Migrated foundation.json must pass generic foundation schema validation"
      ],
      "examples": [
        "Current 'whatWeAreBuilding.projectOverview' maps to 'project.vision'",
        "Current 'whyWeAreBuildingIt.problemDefinition.primary' maps to 'problemSpace.primaryProblem'",
        "Current 'architectureDiagrams' array preserved as-is (already compatible)",
        "HOW content like 'technicalRequirements.coreTechnologies' moves to CLAUDE.md"
      ]
    },
    "FOUND-006": {
      "id": "FOUND-006",
      "title": "Update Documentation and Help",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:38.837Z",
      "updatedAt": "2025-10-17T01:23:48.715Z",
      "description": "Update CLAUDE.md, help system, and create discovery guide with examples",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 3,
      "dependsOn": [
        "FOUND-004"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T01:09:42.788Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T01:11:37.151Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:12:53.339Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:12:53.748Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:14:09.494Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:16:23.508Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:23:09.031Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:23:48.716Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for foundation document discovery",
        "action": "have comprehensive documentation and help for discovery commands",
        "benefit": "I can effectively use discover-foundation, questionnaire, and code analysis features"
      },
      "rules": [
        "CLAUDE.md must document discover-foundation workflow with examples",
        "Help system must have comprehensive --help output for discover-foundation command",
        "Discovery guide must explain code analysis patterns (CLI tool, web app, library)",
        "Documentation must show integration with Example Mapping workflow"
      ],
      "examples": [
        "CLAUDE.md shows: 'Run discover-foundation to analyze codebase and generate foundation.json'",
        "Help output includes WHEN TO USE, WORKFLOW, and EXAMPLES sections",
        "Discovery guide explains CLI tool pattern: bin field in package.json, commander usage"
      ]
    },
    "BUG-012": {
      "id": "BUG-012",
      "title": "Fix show-epic command returning undefined",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-16T23:24:12.754Z",
      "updatedAt": "2025-10-16T23:28:27.652Z",
      "description": "The show-epic command accepts invalid epic IDs and returns 'undefined' for epic and title instead of showing proper error message or help text",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:25:18.576Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T23:25:51.736Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T23:26:50.136Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T23:27:29.673Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T23:28:27.652Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "see a clear error when querying non-existent epics",
        "benefit": "I understand what went wrong and how to fix it"
      },
      "rules": [
        "Command must validate epic ID exists before attempting to display",
        "Must show clear error message with epic ID when not found",
        "Must exit with non-zero code on error"
      ],
      "examples": [
        "Run 'fspec show-epic invalid-epic' shows error: Epic 'invalid-epic' not found",
        "Error message suggests 'fspec list-epics' to see available epics",
        "Valid epic ID works correctly: 'fspec show-epic user-management' displays epic details"
      ]
    },
    "BUG-013": {
      "id": "BUG-013",
      "title": "Prevent story point estimation before feature file completion",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:34:28.036Z",
      "updatedAt": "2025-10-16T23:44:51.565Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:34:32.599Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T23:36:34.521Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T23:37:23.155Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T23:44:34.790Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T23:44:51.565Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec",
        "action": "be prevented from estimating story points before feature file is complete",
        "benefit": "I follow ACDD properly and estimate based on actual acceptance criteria"
      },
      "rules": [
        "Story and Bug work units CANNOT be estimated until feature file exists and is complete (specifying phase finished)",
        "Task work units CAN be estimated at any stage (tasks don't require feature files)",
        "When AI attempts invalid estimation, emit system-reminder explaining ACDD estimation rules",
        "Estimation requires completed feature file to understand complexity from acceptance criteria"
      ],
      "examples": [
        "Story work unit AUTH-001 in 'backlog' state with no feature file → estimation BLOCKED with system-reminder",
        "Story work unit AUTH-001 in 'testing' state with completed feature file → estimation ALLOWED",
        "Task work unit TASK-001 in 'backlog' state with no feature file → estimation ALLOWED (tasks exempt)",
        "Bug work unit BUG-001 in 'specifying' state but feature file has placeholders → estimation BLOCKED until prefill removed"
      ],
      "architectureNotes": [
        "Check work unit type: if type='task', skip validation (tasks don't require feature files)",
        "For story/bug types: find linked feature file via work unit ID tag (e.g., @AUTH-001)",
        "If no feature file found OR file has prefill placeholders, block estimation and emit system-reminder",
        "System-reminder should explain: ACDD requires feature file completion before estimation, suggest completing specifying phase first",
        "Reuse existing prefill detection logic from temporal validation (similar pattern)"
      ],
      "estimate": 2
    },
    "FOUND-007": {
      "id": "FOUND-007",
      "title": "Foundation existence check in commands",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-17T01:22:59.515Z",
      "updatedAt": "2025-10-25T19:37:43.615Z",
      "description": "Add check for foundation.json existence in key commands (board, create-work-unit, etc.). Commands should exit with helpful message if foundation.json missing, directing user to run discover-foundation first. CRITICAL: System reminder must tell AI agent to return to the original task after completing discover-foundation command.",
      "epic": "foundation-document-redesign",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T01:25:10.420Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T01:30:47.830Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:32:38.194Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:38:39.487Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:38:58.984Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:43:25.715Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:49:24.427Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:49:42.199Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T12:34:11.337Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-25T19:37:43.615Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec",
        "action": "ensure foundation.json exists before running project management commands",
        "benefit": "I prevent work from proceeding without proper project foundation and can resume my original task after discovery"
      },
      "rules": [
        "Commands that manage work units MUST check for foundation.json existence before executing",
        "If foundation.json is missing, command MUST exit with error code 1 and display helpful message",
        "Error message MUST direct user to run 'fspec discover-foundation' command",
        "System reminder MUST tell AI agent to return to original task after discover-foundation completes",
        "Check applies to: fspec board, create-work-unit, update-work-unit-status, create-epic, and other PM commands",
        "Yes, include exact command arguments. System reminders in Claude Code are used for actionable guidance - including the original command makes it clear what to retry after discover-foundation completes.",
        "No, only create/modify commands need foundation.json. Read-only commands like show-foundation, list-features, validate can run without foundation.json.",
        "Check only spec/foundation.json - this is the canonical location used by show-foundation, update-foundation, and generate-foundation-md commands."
      ],
      "examples": [
        "AI runs 'fspec board' without foundation.json → Command exits with error, displays message with discover-foundation instructions, system reminder tells AI to run board again after discovery",
        "AI runs 'fspec create-story AUTH \"Login\"' without foundation.json → Command exits with error, system reminder includes original command to retry",
        "AI runs 'fspec board' with foundation.json present → Command executes normally, no check triggered",
        "AI runs 'fspec validate' (non-PM command) without foundation.json → Command executes normally, foundation check not required for spec-only commands"
      ],
      "questions": [
        {
          "text": "@human: Should the system reminder include the exact command arguments that were originally attempted?",
          "selected": true,
          "answer": "Yes, include exact command arguments. System reminders in Claude Code are used for actionable guidance - including the original command makes it clear what to retry after discover-foundation completes."
        },
        {
          "text": "@human: Should read-only commands like 'fspec show-foundation' also require foundation.json, or only commands that create/modify work units?",
          "selected": true,
          "answer": "No, only create/modify commands need foundation.json. Read-only commands like show-foundation, list-features, validate can run without foundation.json."
        },
        {
          "text": "@human: Should the check look for BOTH foundation.json AND spec/foundation.json paths, or just spec/foundation.json?",
          "selected": true,
          "answer": "Check only spec/foundation.json - this is the canonical location used by show-foundation, update-foundation, and generate-foundation-md commands."
        }
      ],
      "estimate": 3
    },
    "BUG-014": {
      "id": "BUG-014",
      "title": "validate-foundation-schema uses wrong schema for generic foundations",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T02:39:24.338Z",
      "updatedAt": "2025-10-17T02:43:30.783Z",
      "description": "The validate-foundation-schema command validates against fspec-specific schema instead of detecting schema version and using appropriate validator (generic v2.0.0 or fspec-specific)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T02:39:28.719Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T02:40:53.846Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T02:41:31.662Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T02:43:24.348Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T02:43:30.783Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "validate foundation.json files",
        "benefit": "I get correct validation regardless of schema version"
      },
      "rules": [
        "Command must detect schema version from foundation.json 'version' field",
        "Version 2.0.0 and above should use generic-foundation-validator",
        "Version 1.x should use fspec-specific validator for backward compatibility"
      ],
      "examples": [
        "Foundation with version: 2.0.0 validates using generic schema successfully",
        "Foundation with version: 1.0.0 validates using fspec-specific schema"
      ]
    },
    "TEST-005": {
      "id": "TEST-005",
      "title": "Update test fixtures to use generic foundation schema",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-17T02:53:51.917Z",
      "updatedAt": "2025-10-17T04:36:30.647Z",
      "description": "Update test fixtures in 9 test files that are currently using old fspec-specific schema format to use the new generic v2.0.0 schema format. This is cleanup work following BUG-014 where we simplified validate-foundation-schema to only use generic schema.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T04:36:22.446Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T04:36:30.071Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T04:36:30.360Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T04:36:30.647Z"
        }
      ]
    },
    "REFAC-001": {
      "id": "REFAC-001",
      "title": "Migrate old fspec-specific schema commands to generic schema",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-17T03:12:44.169Z",
      "updatedAt": "2025-10-17T04:25:47.145Z",
      "description": "Complete migration from old foundation.schema.json (fspec-specific) to generic-foundation.schema.json. Update all commands and tests that still reference whatWeAreBuilding/whyWeAreBuildingIt fields.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T03:13:09.841Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T03:13:10.534Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T04:18:34.350Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T04:25:47.145Z"
        }
      ]
    },
    "COV-052": {
      "id": "COV-052",
      "title": "Fix coverage gaps and align with foundation v2.0.0 migration",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-17T04:41:45.465Z",
      "updatedAt": "2025-10-17T04:50:39.148Z",
      "description": "Complete coverage mapping for all features, remove obsolete foundation-schema-guidance references, and ensure 100% coverage after REFAC-001 migration",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T04:41:57.147Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T04:41:57.435Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T04:44:59.582Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T04:46:21.862Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T04:50:39.148Z"
        }
      ]
    },
    "HELP-001": {
      "id": "HELP-001",
      "title": "Audit and sync all help files with command implementations",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-17T04:55:11.179Z",
      "updatedAt": "2025-10-17T05:24:40.447Z",
      "description": "Verify every command help file (src/commands/*-help.ts) accurately reflects the actual command arguments, options, and behavior registered with Commander.js. Ensure src/help.ts grouping is complete and accurate.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T04:55:17.079Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T04:55:17.370Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T05:24:40.157Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T05:24:40.447Z"
        }
      ]
    },
    "HELP-002": {
      "id": "HELP-002",
      "title": "Register 7 missing commands with Commander",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-17T05:37:10.832Z",
      "updatedAt": "2025-10-17T05:42:41.825Z",
      "description": "7 fully-implemented commands with help files are not registered with Commander.js: add-hook, list-hooks, remove-hook, validate-hooks, dependencies, workflow-automation, migrate-foundation. Also remove 2 duplicate legacy help files (delete-features-help.ts, delete-scenarios-help.ts).",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T05:37:22.320Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T05:37:27.623Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T05:42:41.537Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T05:42:41.825Z"
        }
      ]
    },
    "FOUND-009": {
      "id": "FOUND-009",
      "title": "Foundation missing error message is not imperative enough",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T05:57:24.673Z",
      "updatedAt": "2025-10-17T06:04:32.745Z",
      "description": "When foundation.json is missing, the error message in src/utils/foundation-check.ts is not imperative or detailed enough. It must: (1) FORBID manual JSON creation, (2) Explain the complete interactive workflow, (3) Emphasize foundation.json is a detailed PRD not a summary, (4) Show exact command sequence for draft->finalize workflow",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T05:57:49.057Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T05:59:37.205Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-17T06:01:14.358Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T06:02:04.914Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T06:02:43.048Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T06:03:26.554Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T06:04:32.745Z"
        }
      ],
      "userStory": {
        "role": "AI agent without foundation.json",
        "action": "receive imperative guidance on foundation discovery workflow",
        "benefit": "I follow the correct interactive workflow instead of manually creating JSON files"
      },
      "rules": [
        "Error message must FORBID manual creation of foundation.json files",
        "Error message must explain foundation.json is a detailed PRD, not a quick summary",
        "Error message must show exact command sequence: discover-foundation creates draft, AI fills placeholders, discover-foundation --finalize creates final file"
      ],
      "examples": [
        "AI tries to create work unit, gets error saying 'NEVER manually create foundation.json - use discover-foundation workflow'",
        "Error message shows: Step 1: fspec discover-foundation (creates draft), Step 2: Fill [QUESTION:] placeholders, Step 3: fspec discover-foundation --finalize"
      ],
      "estimate": 2
    },
    "FOUND-010": {
      "id": "FOUND-010",
      "title": "Project type detection incorrectly identifies CLI tools as web-apps",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T05:57:26.180Z",
      "updatedAt": "2025-10-17T06:27:34.821Z",
      "description": "The discover-foundation command should NOT have automated project type detection. It must be 100% interactive questionnaire where AI asks human about project type, personas, capabilities. Remove all automated detection code from src/guidance/automated-discovery-code-analysis.ts",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T06:05:33.155Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T06:06:27.667Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-17T06:07:40.429Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T06:08:47.536Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T06:09:16.927Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-17T06:17:17.434Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T06:20:43.565Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T06:24:08.400Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T06:26:18.558Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T06:27:34.821Z"
        }
      ],
      "userStory": {
        "role": "AI agent running discover-foundation",
        "action": "correctly detect CLI tool projects",
        "benefit": "foundation.json has accurate project type and personas"
      },
      "rules": [
        "foundation.json.draft IS the guidance file - it defines structure and what needs to be filled",
        "Draft contains [QUESTION: text] placeholders for fields requiring human/AI input",
        "Draft contains [DETECTED: value] for auto-detected fields that AI should verify with human",
        "discover-foundation reads draft and identifies unfilled/placeholder fields",
        "For each unfilled field, command emits system-reminder prompting AI to gather information",
        "AI must analyze codebase AND ask human to gather accurate information",
        "AI must use fspec update-foundation command to set values (NOT manual editing)",
        "After each field is set, command re-reads draft and chains to next unfilled field",
        "When all [QUESTION:] placeholders resolved, command validates against JSON schema",
        "Final step: command creates foundation.json and deletes draft"
      ],
      "examples": [
        "Draft has projectType:[QUESTION: What type?] → Command prompts AI → AI analyzes commander.js usage → AI asks human 'Is this cli-tool, web-app, or library?' → Human: 'cli-tool' → AI runs: fspec update-foundation --field project.projectType --value cli-tool → Command re-reads draft and moves to next field",
        "Draft has personas with [QUESTION: Describe persona] → Command prompts AI to gather persona info → AI analyzes CLI commands, no web UI → AI asks human 'Who uses this and their goals?' → Human: 'Developers in terminal managing specs' → AI runs: fspec update-foundation --field personas[0].description --value 'Developer using fspec to manage Gherkin specs' → Command chains to next field",
        "Draft has all [QUESTION:] resolved → Command validates against schema → If valid: creates foundation.json, deletes draft → If invalid: shows validation errors, prompts AI to fix",
        "AI tries to manually edit foundation.json.draft → Command detects file change outside fspec → Emits system-reminder: 'You must use fspec update-foundation commands, not manual editing'",
        "Draft has [DETECTED: web-app] for projectType → Command prompts AI to verify → AI asks human 'Detected web-app, is this correct?' → Human: 'No, it's cli-tool' → AI runs: fspec update-foundation --field project.projectType --value cli-tool"
      ],
      "estimate": 3
    },
    "DISC-001": {
      "id": "DISC-001",
      "title": "Implement draft-driven discovery workflow with AI chaining",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-17T06:32:17.502Z",
      "updatedAt": "2025-10-17T07:03:28.396Z",
      "description": "discover-foundation must read draft, identify next unfilled field, prompt AI with system-reminders, re-read after each fspec update-foundation command, chain to next field, validate when complete, and auto-regenerate FOUNDATION.md from foundation.json",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T06:32:29.265Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T06:49:02.418Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T06:51:45.257Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T06:57:04.523Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T06:57:23.540Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T06:58:27.988Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T07:03:05.753Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T07:03:28.396Z"
        }
      ],
      "userStory": {
        "role": "AI agent running discover-foundation",
        "action": "be guided step-by-step through filling foundation.json.draft",
        "benefit": "foundation.json is created accurately with all required fields and FOUNDATION.md is auto-generated"
      },
      "rules": [
        "discover-foundation creates foundation.json.draft with [QUESTION:] and [DETECTED:] placeholders",
        "After creating draft, command scans for FIRST unfilled [QUESTION:] field",
        "For each unfilled field, command emits system-reminder with: field path, guidance text, example values",
        "System-reminder instructs AI to: analyze codebase, ask human, use fspec update-foundation command",
        "After AI runs fspec update-foundation, command automatically re-runs to find NEXT unfilled field",
        "Command must NOT advance if AI tries to manually edit draft - emit system-reminder to use commands",
        "When all [QUESTION:] placeholders resolved, command validates draft against JSON schema",
        "If validation passes: create foundation.json, delete draft, auto-run fspec generate-foundation-md",
        "If validation fails: show errors, keep draft, prompt AI to fix and re-run",
        "[DETECTED:] fields must be verified with human before accepting",
        "Command tracks progress: shows N of M fields completed in each system-reminder",
        "System-reminders must be actionable: specific field, specific command to run, example value",
        "AI must NEVER skip fields - command enforces sequential field completion",
        "Final FOUNDATION.md generation happens automatically without AI intervention",
        "Command must detect if draft was manually edited between runs and reject with error"
      ],
      "examples": [
        "INITIAL RUN: Human runs 'fspec discover-foundation' → Command creates foundation.json.draft with structure → Draft has REQUIRED fields: project{name,vision,projectType}, problemSpace{primaryProblem{title,description,impact}}, solutionSpace{overview,capabilities[]}, personas[] → All fields contain [QUESTION: ...] or [DETECTED: ...] placeholders → Command emits system-reminder: 'Draft created. To complete foundation, you must ULTRATHINK the entire codebase. Analyze EVERYTHING: commands, routes, UI, tests, README, package.json. Understand HOW it works, then determine WHY it exists and WHAT users can do. I will guide you field-by-field. Field 1/9: project.name'",
        "FIELD 1 (project.name): Command reads draft → Finds [QUESTION: What is the project name?] → Emits: 'Field 1/9: project.name. Analyze package.json name field. Confirm with human. Run: fspec update-foundation --field project.name --value <name>' → AI reads package.json, sees 'fspec' → AI asks human 'Package name is fspec, correct?' → Human confirms → AI runs 'fspec update-foundation --field project.name --value fspec' → Command detects update, re-scans draft, finds next unfilled field",
        "FIELD 2 (project.vision): Command re-scans → Finds [QUESTION: What is the one-sentence vision?] → Emits: 'Field 2/9: project.vision (elevator pitch). ULTRATHINK: Read ALL code, understand the system deeply. What is the core PURPOSE? Focus on WHY this exists, not HOW it works. Ask human. Run: fspec update-foundation --field project.vision --value \"your vision\"' → AI reads README, analyzes commands (validate, format, list-features), understands it manages Gherkin specs → AI formulates: 'CLI tool for managing Gherkin specifications using ACDD' → AI asks human 'Is vision correct?' → Human confirms → AI updates field",
        "FIELD 3 (project.projectType): Command re-scans → Finds [DETECTED: cli-tool] → Emits: 'Field 3/9: project.projectType. Auto-detected cli-tool from commander.js usage and bin field. Verify with human. Options: cli-tool, web-app, library, sdk, mobile-app, desktop-app, service, api, other. Run: fspec update-foundation --field project.projectType --value cli-tool' → AI analyzes code: sees commander.js imports, .command() calls, bin field in package.json → AI confirms: yes, this is cli-tool → AI asks human 'Detected cli-tool, correct?' → Human confirms → AI updates field → Command chains to problemSpace",
        "FIELD 4 (problemSpace.primaryProblem): Command re-scans → Finds [QUESTION: What problem does this solve?] → Emits: 'Field 4/9: problemSpace.primaryProblem. CRITICAL: Think from USER perspective. WHO uses this (persona)? WHAT problem do THEY face? WHY do they need this solution? Analyze codebase to understand user pain, ask human. Required: title, description, impact (high/medium/low). Run: fspec update-foundation --field problemSpace.primaryProblem.title --value \"Problem Title\"' → AI analyzes: this is CLI for specs, users are developers, they need structured spec workflow → AI asks human 'Primary problem: Developers lack structured workflow for managing specifications?' → Human elaborates → AI updates title,description,impact",
        "FIELD 5 (solutionSpace.capabilities): Command re-scans → Finds [QUESTION: What can users DO?] → Emits: 'Field 5/9: solutionSpace.capabilities. List 3-7 HIGH-LEVEL abilities users have. Focus on WHAT not HOW. Example: \"Spec Validation\" (WHAT), not \"Uses Cucumber parser\" (HOW). Analyze commands/features to identify user-facing capabilities. Run: fspec update-foundation --field solutionSpace.capabilities[0].name --value \"Capability Name\"' → AI analyzes commands: validate, format, list, create → Groups into capabilities: Spec Management, Validation, Work Unit Tracking → AI asks human → Human confirms → AI adds each capability with description",
        "FIELD 6 (personas): Command re-scans → Finds [QUESTION: Who uses this?] → Emits: 'Field 6/9: personas. Identify ALL user types from interactions. CLI tools: who runs commands? Web apps: who uses UI + who calls API? Analyze ALL user-facing code. Ask human about goals and pain points. Run: fspec update-foundation --field personas[0].name --value \"Persona Name\"' → AI analyzes: CLI commands used by developers, no web UI, no API consumers → Identifies persona: \"Developer using CLI in terminal\" → AI asks human about goals: managing specs, following ACDD → AI asks about pain points: fragmented tools, no workflow → AI updates persona with name, description, goals, painPoints",
        "COMPLETION: AI fills last required field → Command re-scans → ALL required fields complete (no [QUESTION:] in required fields) → Command validates draft against JSON schema → Schema validation PASSES → Command creates spec/foundation.json from draft → Command deletes spec/foundation.json.draft → Command AUTOMATICALLY runs 'fspec generate-foundation-md' (no AI action needed) → Command emits: 'Discovery complete\\! Created: spec/foundation.json, spec/FOUNDATION.md. Foundation is ready. You can now run fspec commands that require foundation.' → AI can now proceed with other work",
        "ERROR: Manual Editing → AI uses Write tool to edit foundation.json.draft directly → Command detects: draft mtime changed without fspec command → Command compares last known state vs current → Command emits ERROR in system-reminder: 'CRITICAL: You manually edited foundation.json.draft. This violates the workflow. You MUST use: fspec update-foundation --field <path> --value <value>. Reverting your changes. Draft restored to last valid state. Try again with proper command.' → Draft is restored → AI must use fspec commands",
        "ERROR: Validation Failure → AI fills all fields → Command validates against schema → Validation FAILS: missing required field problemSpace.primaryProblem.description → Command emits: 'Schema validation failed. Missing required: problemSpace.primaryProblem.description. Draft NOT finalized. Fix by running: fspec update-foundation --field problemSpace.primaryProblem.description --value \"your description\". Then re-run discover-foundation to validate.' → Draft kept, foundation.json NOT created → AI fixes missing field and re-runs"
      ],
      "attachments": [
        "spec/attachments/DISC-001/discovery-feedback-loop.mmd"
      ]
    },
    "BUG-015": {
      "id": "BUG-015",
      "title": "Foundation discovery workflow cannot update nested fields (capabilities, personas)",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T07:18:39.226Z",
      "updatedAt": "2025-10-17T07:52:53.614Z",
      "description": "The discover-foundation workflow guides AI to use 'fspec update-foundation --field <path> --value <value>' syntax, but the actual update-foundation command uses '<section> <content>' syntax and cannot update nested array fields like capabilities[] and personas[]. This breaks the field-by-field discovery feedback loop.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T07:18:52.919Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T07:21:32.389Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T07:22:28.653Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T07:24:04.760Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T07:25:17.038Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T07:25:48.358Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T07:37:31.310Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T07:52:53.615Z"
        }
      ],
      "examples": [
        "AI runs 'fspec discover-foundation' → system-reminder says 'Run: fspec update-foundation --field project.name --value <name>' → AI tries command → Error: 'unknown option --field'",
        "AI checks help with 'fspec update-foundation --help' → discovers actual syntax is '<section> <content>' not '--field <path> --value <value>'",
        "AI successfully uses 'fspec update-foundation projectName \"fspec\"' for simple fields → works correctly",
        "AI encounters foundation.json.draft with capabilities[] array placeholder → no CLI command exists to update array fields → workflow breaks",
        "AI encounters personas[] array with nested structure → update-foundation command cannot handle nested JSON objects → must manually edit file (violates automation principle)"
      ],
      "rules": [
        "discover-foundation system-reminders MUST use syntax that matches actual update-foundation command implementation",
        "update-foundation command MUST support updating nested array fields (capabilities[], personas[]) through CLI without manual file editing",
        "Foundation discovery workflow MUST be fully automatable by AI without requiring manual JSON editing",
        "All fields in foundation.json.draft MUST have corresponding CLI commands to update them programmatically"
      ],
      "architectureNotes": [
        "Root Cause: src/commands/discover-foundation.ts emits system-reminders with '--field <path> --value <value>' syntax, but src/commands/update-foundation.ts implements '<section> <content>' syntax with no --field option",
        "Impact: Breaks field-by-field discovery feedback loop documented in CLAUDE.md 'Foundation Document Discovery' section. AI cannot complete foundation without manual file editing.",
        "Current Workaround: AI must manually edit foundation.json or foundation.json.draft using Write tool, which violates the automation principle and bypasses validation",
        "Affected Fields: capabilities[] (array of {name, description} objects), personas[] (array of {name, description, goals[]} objects), architectureDiagrams[] (array of Mermaid diagrams)",
        "Schema Reference: src/schemas/generic-foundation.schema.json defines required structure - capabilities[] requires minItems:1, personas[] is optional but must follow persona definition structure"
      ],
      "questions": [
        {
          "text": "@human: Should update-foundation support JSON path syntax (e.g., 'capabilities[0].name') or add separate commands (e.g., 'add-capability', 'add-persona')?",
          "selected": true,
          "answer": "Add separate commands for better UX: 'fspec add-capability <name> <description>' and 'fspec add-persona <name> <description> --goal <goal>'. This follows existing command patterns (add-scenario, add-step) and is more intuitive than JSON path syntax."
        },
        {
          "text": "@human: Should the fix update discover-foundation to emit correct syntax, or extend update-foundation to support --field flag?",
          "selected": true,
          "answer": "Create new commands (add-capability, add-persona) that update foundation.json programmatically. Update discover-foundation to emit system-reminders with correct command syntax. This is cleaner than retrofitting --field flag to update-foundation."
        },
        {
          "text": "@human: How should AI update array elements - append to array, or replace entire array?",
          "selected": true,
          "answer": "Append to arrays for add-capability and add-persona commands. This allows building up the foundation iteratively during discovery. Provide separate clear-capabilities and clear-personas commands if replacement is needed."
        }
      ],
      "assumptions": [
        "Add separate commands for better UX: 'fspec add-capability <name> <description>' and 'fspec add-persona <name> <description> --goal <goal>'. This follows existing command patterns (add-scenario, add-step) and is more intuitive than JSON path syntax.",
        "Create new commands (add-capability, add-persona) that update foundation.json programmatically. Update discover-foundation to emit system-reminders with correct command syntax. This is cleaner than retrofitting --field flag to update-foundation.",
        "Append to arrays for add-capability and add-persona commands. This allows building up the foundation iteratively during discovery. Provide separate clear-capabilities and clear-personas commands if replacement is needed."
      ],
      "userStory": {
        "role": "AI agent using fspec discover-foundation workflow",
        "action": "update nested array fields in foundation.json through CLI commands",
        "benefit": "I can complete foundation discovery without manual file editing"
      }
    },
    "BUG-016": {
      "id": "BUG-016",
      "title": "discover-foundation --finalize doesn't show validation errors",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T08:37:12.330Z",
      "updatedAt": "2025-10-17T08:43:45.249Z",
      "description": "When 'fspec discover-foundation --finalize' fails validation, it only shows '✗ Foundation validation failed' without showing WHAT validation errors occurred. The validationErrors field is populated in the code (lines 132-139 in discover-foundation.ts) but never printed to the user in the CLI action handler (lines 280-288). This leaves users/AI with no feedback on what needs to be fixed.",
      "epic": "foundation-document-redesign",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T08:37:55.679Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T08:39:33.216Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T08:40:43.274Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T08:41:42.645Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T08:43:20.424Z"
        }
      ],
      "userStory": {
        "role": "AI agent using draft-driven discovery workflow",
        "action": "see detailed validation errors when finalize fails",
        "benefit": "I know exactly what fields to fix without guessing"
      },
      "rules": [
        "When finalize fails validation, MUST show detailed error messages",
        "Error messages MUST list missing/invalid fields",
        "Error messages MUST show commands to fix each type of issue",
        "Error messages MUST be visible to both users and AI agents"
      ],
      "examples": [
        "User runs 'fspec discover-foundation --finalize' with empty personas array, sees error: 'Missing required: personas[0].name' with command to fix",
        "User runs finalize with placeholder persona data, sees error listing ALL missing fields in personas",
        "User runs finalize with empty capabilities array, sees error: 'Missing required: solutionSpace.capabilities' with example command"
      ],
      "estimate": 2
    },
    "BUG-017": {
      "id": "BUG-017",
      "title": "update-foundation doesn't chain to next field during discovery",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T08:52:34.641Z",
      "updatedAt": "2025-10-17T08:57:37.226Z",
      "description": "When AI runs 'fspec update-foundation' during draft-driven discovery, the command updates the draft but doesn't automatically scan for and emit the next field guidance. This breaks the automatic field-by-field chaining workflow, forcing AI to manually call discover-foundation again or guess what field comes next.",
      "epic": "foundation-document-redesign",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T08:52:50.903Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T08:54:25.470Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T08:55:56.939Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T08:57:04.254Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T08:57:36.662Z"
        }
      ],
      "userStory": {
        "role": "AI agent using draft-driven discovery",
        "action": "automatically see next field guidance after updating a field",
        "benefit": "I don't have to manually re-run discover-foundation or guess what comes next"
      },
      "rules": [
        "After updating draft field, MUST automatically scan draft for next field",
        "MUST emit system-reminder with guidance for next unfilled field",
        "If all fields complete, MUST tell AI to run finalize",
        "Chaining MUST be automatic, no manual intervention required"
      ],
      "examples": [
        "AI runs 'fspec update-foundation projectName \"MyProject\"', sees success message PLUS system-reminder for Field 2/8: project.vision",
        "AI runs 'fspec update-foundation projectVision \"My vision\"', sees success message PLUS system-reminder for Field 3/8: project.projectType",
        "AI fills last field, sees success message PLUS system-reminder saying 'All fields complete. Run: fspec discover-foundation --finalize'"
      ],
      "estimate": 3
    },
    "BUG-018": {
      "id": "BUG-018",
      "title": "add-persona and add-capability don't work with foundation.json.draft",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T09:08:55.578Z",
      "updatedAt": "2025-10-17T09:15:50.916Z",
      "description": "During draft-driven discovery workflow, add-persona and add-capability commands fail because they check for foundation.json instead of foundation.json.draft. This prevents AI from adding personas/capabilities during the discovery phase.",
      "epic": "foundation-document-redesign",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T09:09:00.995Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T09:11:14.730Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T09:12:19.941Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T09:13:32.198Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T09:15:50.917Z"
        }
      ],
      "userStory": {
        "role": "AI agent using draft-driven discovery",
        "action": "add personas and capabilities during discovery phase",
        "benefit": "I can complete all foundation fields without waiting for finalization"
      },
      "rules": [
        "add-persona MUST check for foundation.json.draft first, then foundation.json",
        "add-capability MUST check for foundation.json.draft first, then foundation.json",
        "Commands MUST prefer draft over final foundation.json (draft takes precedence)",
        "Error messages MUST be helpful when neither file exists"
      ],
      "examples": [
        "AI runs 'fspec add-persona' during discovery, draft exists, persona added to draft",
        "AI runs 'fspec add-capability' during discovery, draft exists, capability added to draft",
        "AI runs 'fspec add-persona', no draft but foundation.json exists, persona added to foundation.json (backward compatibility)",
        "AI runs 'fspec add-capability', neither file exists, shows helpful error with 'fspec discover-foundation' suggestion"
      ],
      "estimate": 3
    },
    "FEAT-014": {
      "id": "FEAT-014",
      "title": "Add remove-persona and remove-capability commands",
      "type": "feature",
      "status": "done",
      "createdAt": "2025-10-17T09:22:49.579Z",
      "updatedAt": "2025-10-17T09:30:23.946Z",
      "description": "Users need commands to remove personas and capabilities from foundation.json or foundation.json.draft. Currently they must manually edit JSON files to remove unwanted placeholder entries.",
      "epic": "foundation-document-redesign",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T09:22:55.289Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T09:25:00.500Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T09:29:24.677Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T09:29:24.949Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T09:30:23.946Z"
        }
      ],
      "userStory": {
        "role": "user managing foundation document",
        "action": "remove unwanted personas and capabilities",
        "benefit": "I can clean up placeholders without manually editing JSON"
      },
      "rules": [
        "remove-persona MUST work with both foundation.json and foundation.json.draft (same file priority as add-persona)",
        "remove-capability MUST work with both foundation.json and foundation.json.draft (same file priority as add-capability)",
        "Remove commands MUST match by exact name (case-sensitive)",
        "If persona/capability not found, show error with list of available names"
      ],
      "examples": [
        "User runs 'fspec remove-persona Developer', persona removed from draft",
        "User runs 'fspec remove-capability \"Mind Mapping\"', capability removed from foundation.json",
        "User runs 'fspec remove-persona NonExistent', shows error listing available personas"
      ],
      "estimate": 2
    },
    "FEAT-015": {
      "id": "FEAT-015",
      "title": "Validate Mermaid diagrams in attachments",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-17T10:13:18.110Z",
      "updatedAt": "2025-10-17T10:27:24.865Z",
      "description": "Add validation for Mermaid diagram attachments using the same validation logic as add-diagram command, providing detailed syntax error feedback when diagrams are invalid",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T10:13:25.228Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T10:20:44.838Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T10:23:28.000Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T10:25:36.448Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T10:27:24.865Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec with AI agents",
        "action": "attach Mermaid diagrams to work units with automatic validation",
        "benefit": "I catch diagram syntax errors immediately and get helpful feedback to fix them"
      },
      "rules": [
        "Mermaid diagram attachments must be validated using the same mermaid.parse() logic as add-diagram command",
        "Only files with .mmd or .mermaid extensions should trigger Mermaid validation",
        "Invalid Mermaid syntax must prevent attachment with detailed error message including line numbers",
        "Valid Mermaid diagrams should be attached successfully with confirmation message",
        "Use similar error format to add-diagram but adapted for attachment context (e.g., 'Failed to attach diagram.mmd' instead of 'Failed to add diagram')",
        "No --skip-validation flag - all Mermaid diagrams must pass validation before attachment",
        "Yes, validate .md files that contain mermaid code blocks (triple-backtick mermaid syntax)"
      ],
      "examples": [
        "User attaches valid flowchart.mmd with 'graph TD' syntax - attachment succeeds with confirmation",
        "User attaches sequence.mermaid with invalid syntax - attachment fails with detailed error message showing line number",
        "User attaches diagram.png - no Mermaid validation performed (not .mmd or .mermaid extension)",
        "User attaches erDiagram.mmd with valid ER diagram syntax - attachment succeeds"
      ],
      "questions": [
        {
          "text": "@human: Should we also validate .md files that contain mermaid code blocks?",
          "selected": true,
          "answer": "Yes, validate .md files that contain mermaid code blocks (triple-backtick mermaid syntax)"
        },
        {
          "text": "@human: Should the error message format match exactly with add-diagram errors for consistency?",
          "selected": true,
          "answer": "Use similar error format to add-diagram but adapted for attachment context (e.g., 'Failed to attach diagram.mmd' instead of 'Failed to add diagram')"
        },
        {
          "text": "@human: Should we add a --skip-validation flag to allow attaching invalid diagrams for drafts?",
          "selected": true,
          "answer": "No --skip-validation flag - all Mermaid diagrams must pass validation before attachment"
        }
      ],
      "estimate": 3
    },
    "BUG-019": {
      "id": "BUG-019",
      "title": "Dependencies command throws 'Invalid action' error",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-18T23:33:40.052Z",
      "updatedAt": "2025-10-18T23:38:21.107Z",
      "description": "The 'fspec dependencies <work-unit-id>' command throws 'Error: Invalid action: <work-unit-id>' when invoked. The command registration expects an action argument first, but users/AI expect to pass work-unit-id directly to query dependencies.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-18T23:33:40.419Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-18T23:35:11.478Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-18T23:36:33.004Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-18T23:38:08.835Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-18T23:38:21.108Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec CLI",
        "action": "query work unit dependencies with simple syntax",
        "benefit": "I can understand dependency relationships without parsing complex multi-action commands"
      },
      "rules": [
        "Command must accept work-unit-id as first positional argument",
        "Command must display all dependency types: blocks, blockedBy, dependsOn, relatesTo",
        "Command must provide AI-friendly error wrapped in system-reminder if work unit does not exist"
      ],
      "examples": [
        "AI runs 'fspec dependencies MCP-001' and sees 'Dependencies for MCP-001:' with empty lists (no dependencies)",
        "AI runs 'fspec dependencies MCP-004' and sees 'Depends on: MCP-001, MCP-002'",
        "AI runs 'fspec dependencies INVALID-999' and gets system-reminder with suggestions to run 'fspec list-work-units'"
      ],
      "architectureNotes": [
        "Root cause: registerDependenciesCommand() uses multi-action router pattern with .argument('<action>') expecting 'list', 'add', 'remove', etc. but help docs suggest direct work-unit-id usage",
        "Solution: Simplify to single-purpose command accepting .command('dependencies <work-unit-id>') and call showDependencies() directly with AI-friendly error handling",
        "Error handling: Wrap errors in system-reminder tags to make failures highly visible to AI agents in Claude Code"
      ]
    },
    "DOCS-001": {
      "id": "DOCS-001",
      "title": "Clarify estimation timing in documentation and system-reminders",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-19T12:10:39.283Z",
      "updatedAt": "2025-10-19T12:34:31.582Z",
      "description": "System-reminders and documentation don't make it clear enough that story point estimation happens AFTER Example Mapping during the specifying phase, not before. AI agents are suggesting to add estimates before moving work units to specifying state, which violates ACDD workflow.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-19T12:10:47.439Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-19T12:18:22.138Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T12:22:04.487Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T12:33:00.375Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T12:34:31.583Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec",
        "action": "understand when to estimate story points",
        "benefit": "I follow ACDD workflow correctly without suggesting premature estimation"
      },
      "rules": [
        "Story point estimation happens AFTER Example Mapping, during specifying state",
        "Cannot estimate accurately without understanding scope from Example Mapping",
        "System-reminders in backlog state must NOT suggest adding estimates",
        "System-reminders in specifying state SHOULD remind to estimate after Example Mapping",
        "System-reminders must align with ACDD violation enforcement (feature file required before estimation)"
      ],
      "examples": [
        "AI shows MCP epic with 5 work units in backlog, suggests adding estimates before moving to specifying (WRONG)",
        "AI moves work unit to specifying, does Example Mapping, THEN suggests estimate based on discovered complexity (CORRECT)",
        "AI reads show-work-unit output showing 'no estimate' reminder in backlog state, incorrectly offers to add estimate immediately (WRONG)",
        "AI completes Example Mapping, generates scenarios, THEN sees reminder 'After generating scenarios, estimate based on feature file complexity' (CORRECT)"
      ],
      "architectureNotes": [
        "Files to check: src/commands/show-work-unit.ts (system-reminder logic), src/commands/update-work-unit-status.ts (state transition reminders), CLAUDE.md (workflow documentation), .claude/commands/fspec.md (slash command docs)",
        "CRITICAL FIX: System-reminder in show-work-unit.ts currently says 'Use Example Mapping results to estimate story points' but should say 'After generating scenarios from Example Mapping, estimate story points based on feature file complexity' to match ACDD violation enforcement",
        "Also update .claude/commands/fspec.md Step 2.5 section to explicitly state: estimate AFTER generating scenarios from Example Mapping, not before"
      ],
      "questions": [
        {
          "text": "@human: Are there other places in the codebase besides system-reminders where estimation timing should be clarified?",
          "selected": true,
          "answer": "Yes - update help documentation for update-work-unit-estimate command, add workflow examples to README.md and spec/CLAUDE.md showing correct timing, and potentially add validation to prevent estimating work units not yet in specifying state"
        }
      ],
      "estimate": 3
    },
    "FEAT-016": {
      "id": "FEAT-016",
      "title": "Warn AI when estimate is > 13 points to break down work unit",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-19T12:40:51.573Z",
      "updatedAt": "2025-10-19T13:17:50.986Z",
      "description": "When AI estimates a work unit at more than 13 points (21+), emit system-reminder warnings to guide breaking down into smaller work units (1-13 points each)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-19T12:40:58.524Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-19T13:03:29.376Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T13:05:27.211Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T13:11:11.102Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T13:17:50.986Z"
        }
      ],
      "userStory": {
        "role": "AI agent estimating work units",
        "action": "receive clear warnings and guidance when estimate is too large",
        "benefit": "I break down large work into manageable chunks without getting lost in the process"
      },
      "rules": [
        "Warning must include SPECIFIC step-by-step commands (not generic advice) to break down the work unit",
        "Warning should guide AI to review feature file scenarios for natural split boundaries (not arbitrary splitting)",
        "Warning is non-blocking (allows estimate to be set) but strongly recommends breaking down",
        "Warning triggers IMMEDIATELY when estimate > 13 points (21 is too large, but 13 is acceptable)",
        "Warning ONLY applies to story and bug types, NOT task types (tasks can legitimately be large)",
        "Warning should suggest breaking into smaller stories (1-13 points each) for clear guidance",
        "Warning persists in show-work-unit while estimate > 13 AND status is not done",
        "Warning guidance adapts based on context: if feature file exists suggest reviewing it for natural boundaries, if no feature file exists suggest creating it first before breaking down"
      ],
      "examples": [
        "AI estimates BUG-005 at 21 points → warning shown → AI ignores and continues → runs show-work-unit BUG-005 → warning shown again in system-reminder section → AI finally breaks it down",
        "AI estimates INFRA-001 (type=task, infrastructure setup) at 21 points → NO warning (task type exempt) → estimate accepted",
        "AI sees warning → reads feature file → identifies natural scenario groupings → creates child work units for each group → estimates each child (all <= 13) → links with dependencies"
      ],
      "architectureNotes": [
        "TWO PLACEMENT POINTS: (1) update-work-unit-estimate.ts - immediate warning when estimate set, (2) show-work-unit.ts - persistent reminder via getLargeEstimateReminder() in system-reminder.ts",
        "SYSTEM-REMINDER MUST BE HIGHLY SPECIFIC: Include exact fspec commands (create-story/create-bug/create-task, add-dependency, create-epic), not generic advice like 'break this down'",
        "GUIDE FEATURE FILE ANALYSIS: Remind AI to 'Review feature file linked to this work unit. Look for scenario groupings that could be separate stories. Each group should deliver incremental value.'",
        "PERSISTENCE STRATEGY: Warning appears in TWO contexts (immediate + show-work-unit) creating 'sticky' reminder. AI will see it multiple times, increasing likelihood of following through.",
        "STEP-BY-STEP WORKFLOW IN WARNING: (1) Review feature file (or create if missing), (2) Identify boundaries, (3) Create child work units with fspec create-story/create-bug/create-task, (4) Link with fspec add-dependency --depends-on, (5) Optionally create epic to group, (6) Delete original work unit or convert to epic using fspec create-epic"
      ],
      "questions": [],
      "estimate": 5
    },
    "BUG-020": {
      "id": "BUG-020",
      "title": "remove-question command shows '[object Object]' instead of question text",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-19T12:58:26.949Z",
      "updatedAt": "2025-10-20T20:43:10.871Z",
      "description": "When running 'fspec remove-question <id> <index>', the success message displays 'Removed question: [object Object]' instead of showing the actual question text that was removed",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T20:37:44.322Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T20:39:47.790Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T20:41:22.510Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T20:42:02.948Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T20:43:10.871Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "see the actual question text when removing a question",
        "benefit": "I can confirm I'm removing the correct question"
      },
      "rules": [
        "Success message must display the actual question text, not '[object Object]'",
        "Message format should be 'Removed question: <question text>'"
      ],
      "examples": [
        "Remove question 'Should we support OAuth?' displays 'Removed question: Should we support OAuth?'",
        "Remove question with special characters '@human: What happens?' displays correctly"
      ],
      "estimate": 1
    },
    "REV-001": {
      "id": "REV-001",
      "title": "Interactive reverse ACDD strategy planning command",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-19T20:57:37.321Z",
      "updatedAt": "2025-10-26T01:00:29.839Z",
      "description": "Refactor reverse ACDD workflow from prescriptive /rspec command to interactive strategy planning session. Implement 'fspec reverse' command that analyzes project state, detects gaps (missing features, tests, coverage, work units), offers strategic options, and guides AI step-by-step through gap-filling process. This command is a planning/guidance tool only - it does NOT execute reverse ACDD work itself, but helps AI make informed decisions about the best approach based on project state. Similar to discover-foundation interactive session with system-reminders.",
      "epic": "reverse-acdd-refactor",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-19T20:57:42.682Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-19T21:06:32.964Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T21:09:44.583Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-19T21:18:12.503Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-19T21:39:19.514Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T21:39:29.035Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T21:50:29.445Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T21:51:43.661Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T00:52:19.474Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T00:58:15.173Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T01:00:29.839Z"
        }
      ],
      "userStory": {
        "role": "AI agent (Claude) working on legacy codebase",
        "action": "plan and execute reverse ACDD strategy to fill specification/test gaps",
        "benefit": "I can intelligently choose the right approach based on project state rather than following rigid instructions"
      },
      "rules": [
        "Command must be interactive like discover-foundation (session-based with system-reminders)",
        "Command analyzes project state but does NOT execute reverse ACDD itself - it only guides",
        "Must detect gaps: missing features, missing tests, missing coverage mappings, missing work units",
        "Must offer multiple strategies based on gap analysis (Spec Gap Filling, Test Gap Filling, Coverage Mapping, Full Reverse ACDD)",
        "Must emit step-by-step guidance via system-reminders (NOT execute the steps)",
        "Must replace /rspec command in .claude/commands/fspec.md and deprecate it",
        "Must update spec/CLAUDE.md section on Reverse ACDD with new workflow",
        "Session file must be deleted on completion (--complete) or reset (--reset)",
        "State machine phases: analyzing → gap-detection → strategy-planning → executing → complete",
        "Show summary with counts, paginate detailed gap list, suggest --strategy to narrow scope",
        "Yes - include story point estimates in strategy suggestions (helps AI prioritize)",
        "Yes - support --dry-run for preview analysis without creating session file",
        "Must detect existing session and prevent overwrite - show status and suggest options (--continue, --status, --reset, --complete)",
        "Must persist session state in OS temp directory (tmpdir) using project-specific hash for filename isolation - ephemeral, OS-managed cleanup",
        "Must support CLI flags: --continue, --strategy=X, --status, --reset, --complete, --dry-run"
      ],
      "examples": [
        "User runs 'fspec reverse' → command analyzes project → finds 3 test files without features → suggests Strategy A (Spec Gap Filling) via system-reminder",
        "AI runs 'fspec reverse --strategy=A' → emits system-reminder with step 1 guidance → AI reads test file, creates feature, links coverage → AI runs 'fspec reverse --continue' → emits step 2 guidance",
        "User runs 'fspec reverse --status' → shows current phase (executing), detected gaps (3 test files without features), chosen strategy (A), current step (2 of 3)",
        "User runs 'fspec reverse --reset' → deletes session file → outputs 'Session reset' → user can start fresh with 'fspec reverse'",
        "Project has features but no tests → analysis detects 2 feature files without tests → suggests Strategy B (Test Gap Filling) → guides AI through creating test skeletons with --skip-validation",
        "Project has both features and tests but unmapped → analysis detects 5 scenarios without coverage links → suggests Strategy C (Coverage Mapping) → guides AI through linking existing tests to scenarios",
        "Project has raw implementation code only (no features, no tests) → analysis detects 10 implementation files → suggests Strategy D (Full Reverse ACDD) → guides through creating features, tests, and work units from scratch",
        "AI completes all steps → runs 'fspec reverse --complete' → command validates work done → deletes session file → emits system-reminder with completion summary",
        "User runs 'fspec reverse' while session exists → command detects existing session → exits with error → shows current status → suggests --continue, --status, --reset, --complete → does NOT overwrite session"
      ],
      "questions": [
        {
          "text": "@human: Should the session file be human-readable JSON or optimized binary format?",
          "selected": true,
          "answer": "Human-readable JSON - easier to debug, inspect, and aligns with foundation.json pattern"
        },
        {
          "text": "@human: Should we support parallel strategies (e.g., Strategy A + Strategy C simultaneously)?",
          "selected": true,
          "answer": "No parallel strategies in MVP - keep it simple. AI chooses one strategy, completes it, then can run reverse again for other gaps"
        },
        {
          "text": "@human: How should we handle very large projects (100+ gaps detected)? Paginate output?",
          "selected": true,
          "answer": "Show summary with counts, paginate detailed gap list, suggest --strategy to narrow scope"
        },
        {
          "text": "@human: Should --strategy=custom trigger an interactive Q&A session with the user?",
          "selected": true,
          "answer": "Defer --strategy=custom to Phase 2 - start with four predefined strategies (A, B, C, D)"
        },
        {
          "text": "@human: Should we track time/effort estimates for each strategy in the guidance output?",
          "selected": true,
          "answer": "Yes - include story point estimates in strategy suggestions (helps AI prioritize)"
        },
        {
          "text": "@human: Should the command support --dry-run mode to preview analysis without creating session?",
          "selected": true,
          "answer": "Yes - support --dry-run for preview analysis without creating session file"
        }
      ],
      "architectureNotes": [
        "State machine phases: analyzing → gap-detection → strategy-planning → executing → complete (similar to discover-foundation feedback loop)",
        "System-reminders emitted at phase transitions and for step-by-step guidance (wrapped in <system-reminder> tags)",
        "Reuses existing analysis utilities: file scanners (Glob), Gherkin parser, test file pattern matching",
        "NO execution logic in command - all work done by AI using existing fspec commands (create-feature, link-coverage, etc.)",
        "Integration point 1: .claude/commands/fspec.md must mention 'fspec reverse' and deprecate /rspec command",
        "Integration point 2: spec/CLAUDE.md section 'Reverse ACDD for Existing Codebases' must be updated with new workflow",
        "Strategy templates: A=Spec Gap Filling, B=Test Gap Filling, C=Coverage Mapping, D=Full Reverse ACDD (each has predefined guidance steps)",
        "Session state stored in tmpdir()/fspec-reverse-{hash}.json where hash=sha256(projectRoot).substring(0,12) - ephemeral, OS-managed cleanup, zero project pollution"
      ],
      "attachments": [
        "spec/attachments/REV-001/reverse-session-state-machine.mmd",
        "spec/attachments/REV-001/strategy-decision-tree.mmd",
        "spec/attachments/REV-001/reverse-session-sequence.mmd"
      ],
      "assumptions": [
        "Human-readable JSON - easier to debug, inspect, and aligns with foundation.json pattern",
        "No parallel strategies in MVP - keep it simple. AI chooses one strategy, completes it, then can run reverse again for other gaps",
        "Defer --strategy=custom to Phase 2 - start with four predefined strategies (A, B, C, D)"
      ],
      "estimate": 13
    },
    "UX-001": {
      "id": "UX-001",
      "title": "System-reminder for missing scenarios in link-coverage",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-19T21:40:43.514Z",
      "updatedAt": "2025-10-19T22:00:01.065Z",
      "description": "When link-coverage fails because a scenario is not found in the coverage file but exists in the feature file, emit a system-reminder telling the AI to run generate-coverage first",
      "epic": "cli-ux-improvements",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-19T21:40:52.678Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-19T21:52:58.263Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T21:54:10.182Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T21:59:49.858Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T22:00:01.066Z"
        }
      ],
      "userStory": {
        "role": "AI agent (Claude) using fspec",
        "action": "receive helpful guidance when link-coverage fails due to missing scenarios",
        "benefit": "I can quickly fix the issue without trial and error"
      },
      "rules": [
        "When link-coverage fails with 'Scenario not found', check if scenario exists in feature file",
        "If scenario exists in feature file but not in coverage file, emit system-reminder suggesting generate-coverage",
        "System-reminder must be wrapped in <system-reminder> tags (visible to AI, invisible to user)",
        "If scenario doesn't exist in feature file either, show normal error without system-reminder"
      ],
      "examples": [
        "AI adds new scenario to feature file, runs link-coverage before generate-coverage → error with system-reminder: 'Run generate-coverage first'",
        "AI tries to link non-existent scenario (typo in scenario name) → error without system-reminder, just shows available scenarios",
        "Coverage file missing entirely → system-reminder suggests running generate-coverage to create it"
      ],
      "estimate": 3
    },
    "DOCS-002": {
      "id": "DOCS-002",
      "title": "Update all documentation to replace /rspec with fspec reverse",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-19T22:25:10.476Z",
      "updatedAt": "2025-10-22T00:19:11.595Z",
      "description": "REV-001 implementation is complete but documentation still references deprecated /rspec command. Update all docs to use 'fspec reverse' instead.",
      "epic": "reverse-acdd-refactor",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-19T22:25:15.775Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T22:26:02.269Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T22:45:25.166Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T22:51:53.017Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T00:00:13.282Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T00:18:57.973Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T00:19:11.595Z"
        }
      ],
      "rules": [
        "All references to /rspec command must be replaced with 'fspec reverse'",
        "File .claude/commands/rspec.md must be deleted as it is deprecated by fspec reverse",
        "Command fspec reverse must have comprehensive help file at src/commands/reverse-help.ts following CommandHelpConfig pattern",
        "File src/commands/help.ts must include reverse command in command list",
        "File spec/foundation.json must include Interactive Reverse ACDD capability with proper description",
        "After foundation.json changes, spec/FOUNDATION.md must be regenerated using fspec generate-foundation-md"
      ],
      "examples": [
        "Update .claude/commands/fspec.md: Replace '(see /rspec)' with '(see fspec reverse command)'",
        "Update spec/CLAUDE.md section 'Reverse ACDD for Existing Codebases': Replace 'via /rspec command' with 'via fspec reverse command'",
        "Update README.md: Replace '/rspec - For reverse engineering' with 'fspec reverse - Interactive strategy planning for reverse ACDD'",
        "Create src/commands/reverse-help.ts with sections: name, description, usage, whenToUse, options (--continue, --strategy, --status, --reset, --complete, --dry-run), examples, commonErrors, typicalWorkflow",
        "Add to foundation.json capabilities: {name: 'Interactive Reverse ACDD Strategy Planning', description: 'Analyzes project gaps and guides AI through reverse ACDD workflow with step-by-step system-reminders'}"
      ]
    },
    "BUG-021": {
      "id": "BUG-021",
      "title": "fspec --help displays hardcoded version 0.0.1 instead of package.json version",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-20T20:24:28.844Z",
      "updatedAt": "2025-10-20T20:35:39.022Z",
      "description": "The --help command shows 'Version 0.0.1' which appears to be hardcoded. It should dynamically read the version from package.json to stay in sync with releases.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T20:24:55.239Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T20:29:02.950Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T20:30:35.528Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T20:34:32.979Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T20:35:39.023Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "run fspec --help to check version",
        "benefit": "I see the current version from package.json, not a hardcoded value"
      },
      "rules": [
        "Version displayed in --help must match package.json version exactly",
        "Version should update automatically when package.json changes (no manual hardcoding)",
        "Build time - version embedded in dist bundle during build (typical for CLI tools)",
        "Don't display version string if unavailable"
      ],
      "examples": [
        "When package.json has version 0.2.1, running 'fspec --help' displays 'Version 0.2.1'",
        "After bumping package.json to version 0.3.0 and rebuilding, 'fspec --help' displays 'Version 0.3.0'",
        "Currently shows 'Version 0.0.1' regardless of package.json value (bug to fix)"
      ],
      "questions": [
        {
          "text": "@human: Should version be read at build time (embedded in dist bundle) or runtime (reading package.json when --help runs)? Build-time is typical for CLI tools.",
          "selected": true,
          "answer": "Build time - version embedded in dist bundle during build (typical for CLI tools)"
        },
        {
          "text": "@human: If we can't read the version (edge case), should we show 'unknown' or fallback to a default value?",
          "selected": true,
          "answer": "Don't display version string if unavailable"
        }
      ],
      "estimate": 2
    },
    "BUG-022": {
      "id": "BUG-022",
      "title": "Feature file naming for bug work units",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-20T20:47:04.871Z",
      "updatedAt": "2025-10-20T20:59:44.477Z",
      "description": "When creating a bug work unit and generating scenarios, fspec creates feature files named after the bug description (task-oriented) instead of the capability being tested (capability-oriented). It should also check if an existing feature file covers the capability and either update that file or create a properly-named new file.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T20:47:35.812Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T20:53:30.604Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T20:55:16.828Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T20:58:32.397Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T20:59:44.477Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec to fix bugs",
        "action": "create feature files with capability-oriented names",
        "benefit": "bug tests document capabilities, not problems"
      },
      "questions": [
        {
          "text": "@human: When generating feature files from bug work units, what rules should determine the capability name? Should we extract it from the bug description or ask the developer?",
          "selected": true,
          "answer": "AI should extract capability from bug context and search for existing feature files before creating new ones"
        },
        {
          "text": "@human: Should the system check for existing feature files covering the same capability before creating a new file? How should it determine if a match exists?",
          "selected": true,
          "answer": "AI agent should determine if an existing feature file is suitable for the bug scenario"
        },
        {
          "text": "@human: If an existing feature file is found that covers the capability, should we add a bug-fix scenario to that file or create a separate file?",
          "selected": true,
          "answer": "Add or update bug scenario in existing feature file (and update associated tests)"
        }
      ],
      "rules": [
        "AI should extract capability from bug context and search for existing feature files before creating new ones",
        "AI agent should determine if an existing feature file is suitable for the bug scenario",
        "Add or update bug scenario in existing feature file (and update associated tests)",
        "Feature file names must be capability-oriented (what the system CAN DO), not task-oriented (the bug description)",
        "AI should analyze existing feature descriptions, scenarios, and tags to determine capability match",
        "If no suitable existing feature file exists, create new file with capability-oriented name derived from bug context"
      ],
      "examples": [
        "Bug: 'fspec help displays hardcoded version 0.0.1' → AI searches features, finds 'help-command.feature' → Adds bug-fix scenario to existing file",
        "Bug: 'fspec help displays hardcoded version 0.0.1' → AI searches features, no match found → Creates 'cli-version-display.feature' (capability-oriented name)",
        "Bug: 'validate command crashes on empty file' → AI finds 'gherkin-validation.feature' → Adds edge-case scenario to existing file",
        "Bug: 'format removes valid doc strings' → AI finds 'gherkin-formatting.feature' → Updates existing scenario or adds new regression scenario"
      ],
      "architectureNotes": [
        "Fix should be in src/commands/generate-scenarios.ts - the command responsible for creating feature files from work units",
        "Need to add capability extraction logic - analyze bug description to identify underlying capability being tested",
        "Need to add existing feature search - use fspec list-features or directly scan spec/features/ directory with feature file parsing",
        "When adding to existing file, use fspec add-scenario command to properly insert scenario with correct formatting and tags"
      ],
      "estimate": 5
    },
    "SPEC-002": {
      "id": "SPEC-002",
      "title": "Scenario deduplication and refactoring detection during generation",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-20T21:05:14.096Z",
      "updatedAt": "2025-10-20T21:35:48.787Z",
      "description": "When generating scenarios from Example Mapping, detect if any scenarios are refactors of existing scenarios in other feature files. Update existing feature files for refactored scenarios, fix tests, regenerate coverage. Create new feature files only for truly new scenarios.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T21:05:19.135Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T21:19:22.664Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T21:21:14.009Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T21:34:35.856Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T21:35:48.788Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for ACDD workflow",
        "action": "detect and handle scenario refactoring during generation",
        "benefit": "I avoid duplicate scenarios across feature files and maintain proper test coverage"
      },
      "rules": [
        "When generating scenarios, check if any match existing scenarios in other feature files",
        "If a scenario is a refactor of an existing scenario, update the existing feature file instead of creating a duplicate",
        "When refactoring scenarios, update corresponding tests and regenerate coverage mappings",
        "Create new feature files only for truly new scenarios that don't match existing ones",
        "AI agent searches all feature files first, analyzes scenario titles and steps, takes hints from user's intent to determine if this is a refactor or genuinely new functionality",
        "Old scenario should be updated (changed into the new scenario) because it already has associated test, implementation, and coverage mappings that should be preserved",
        "System MUST automatically update tests and regenerate coverage when refactoring scenarios - this is enforced and non-negotiable",
        "Detection happens during 'fspec generate-scenarios' command as primary workflow. Before generating scenarios, search existing features for matches, prompt user to confirm if refactor, then update existing feature OR create new. Also provide 'fspec audit-scenarios' as standalone command for finding duplicates across all features for maintenance/cleanup.",
        "When generating scenarios, check if any match existing scenarios in other feature files",
        "If a scenario is a refactor of an existing scenario, update the existing feature file instead of creating a duplicate",
        "When refactoring scenarios, update corresponding tests and regenerate coverage mappings",
        "Create new feature files only for truly new scenarios that don't match existing ones",
        "AI agent searches all feature files first, analyzes scenario titles and steps, takes hints from user's intent to determine if this is a refactor or genuinely new functionality",
        "Old scenario should be updated (changed into the new scenario) because it already has associated test, implementation, and coverage mappings that should be preserved",
        "System MUST automatically update tests and regenerate coverage when refactoring scenarios - this is enforced and non-negotiable",
        "Detection happens during 'fspec generate-scenarios' command as primary workflow. Before generating scenarios, search existing features for matches, prompt user to confirm if refactor, then update existing feature OR create new. Also provide 'fspec audit-scenarios' as standalone command for finding duplicates across all features for maintenance/cleanup."
      ],
      "questions": [
        {
          "text": "@human: How should we detect if a scenario is a 'refactor' vs a 'new' scenario? Should we use semantic similarity, exact title matching, or analyze the Given-When-Then steps?",
          "selected": true,
          "answer": "AI agent searches all feature files first, analyzes scenario titles and steps, takes hints from user's intent to determine if this is a refactor or genuinely new functionality"
        },
        {
          "text": "@human: When we detect a refactored scenario, what should happen to the old scenario? Should it be marked as deprecated, deleted, or should we prompt the user to decide?",
          "selected": true,
          "answer": "Old scenario should be updated (changed into the new scenario) because it already has associated test, implementation, and coverage mappings that should be preserved"
        },
        {
          "text": "@human: Should the system automatically update tests when refactoring scenarios, or should it flag them for manual review? What about cases where tests might break?",
          "selected": true,
          "answer": "System MUST automatically update tests and regenerate coverage when refactoring scenarios - this is enforced and non-negotiable"
        },
        {
          "text": "@human: Should this detection happen during 'fspec generate-scenarios' command, or should it be a separate validation step that can be run independently?",
          "selected": true,
          "answer": "Detection happens during 'fspec generate-scenarios' command as primary workflow. Before generating scenarios, search existing features for matches, prompt user to confirm if refactor, then update existing feature OR create new. Also provide 'fspec audit-scenarios' as standalone command for finding duplicates across all features for maintenance/cleanup."
        },
        {
          "text": "@human: You mentioned 'similar to how the last bug story we fixed did' - which bug story are you referring to? Can you provide the work unit ID so I can review that approach?",
          "selected": true,
          "answer": "BUG-008: generate-scenarios produces malformed Gherkin steps from example titles. This bug fix improved how generate-scenarios parses example titles and creates proper Gherkin scenarios. The pattern we should follow is similar - analyzing example text and intelligently transforming it into proper scenarios."
        },
        {
          "text": "@human: How should we detect if a scenario is a 'refactor' vs a 'new' scenario? Should we use semantic similarity, exact title matching, or analyze the Given-When-Then steps?",
          "selected": true,
          "answer": "AI agent searches all feature files first, analyzes scenario titles and steps, takes hints from user's intent to determine if this is a refactor or genuinely new functionality"
        },
        {
          "text": "@human: When we detect a refactored scenario, what should happen to the old scenario? Should it be marked as deprecated, deleted, or should we prompt the user to decide?",
          "selected": true,
          "answer": "Old scenario should be updated (changed into the new scenario) because it already has associated test, implementation, and coverage mappings that should be preserved"
        },
        {
          "text": "@human: Should the system automatically update tests when refactoring scenarios, or should it flag them for manual review? What about cases where tests might break?",
          "selected": true,
          "answer": "System MUST automatically update tests and regenerate coverage when refactoring scenarios - this is enforced and non-negotiable"
        },
        {
          "text": "@human: Should this detection happen during 'fspec generate-scenarios' command, or should it be a separate validation step that can be run independently?",
          "selected": true,
          "answer": "Detection happens during 'fspec generate-scenarios' command as primary workflow. Before generating scenarios, search existing features for matches, prompt user to confirm if refactor, then update existing feature OR create new. Also provide 'fspec audit-scenarios' as standalone command for finding duplicates across all features for maintenance/cleanup."
        },
        {
          "text": "@human: You mentioned 'similar to how the last bug story we fixed did' - which bug story are you referring to? Can you provide the work unit ID so I can review that approach?",
          "selected": true,
          "answer": "BUG-022: Feature file naming for bug work units. AI searches existing feature files, extracts capability from bug context, and either updates existing feature file OR creates capability-oriented new file. This demonstrates the search-before-create pattern we need for scenario deduplication."
        }
      ],
      "assumptions": [
        "BUG-008: generate-scenarios produces malformed Gherkin steps from example titles. This bug fix improved how generate-scenarios parses example titles and creates proper Gherkin scenarios. The pattern we should follow is similar - analyzing example text and intelligently transforming it into proper scenarios.",
        "CORRECTION: Reference work unit is BUG-022 (not BUG-008). BUG-022 'Feature file naming for bug work units' - AI searches existing feature files, extracts capability from bug context, and either updates existing feature file OR creates capability-oriented new file. This demonstrates the exact pattern we need: search before create, intelligently match scenarios, update existing features instead of duplicating.",
        "BUG-022 demonstrates the pattern: AI searches existing feature files, determines if scenario matches existing capability, and updates existing feature files instead of creating duplicates."
      ],
      "examples": [
        "User runs 'fspec generate-scenarios AUTH-005' where examples describe login validation. System finds existing scenario 'Validate user credentials' in user-authentication.feature. System prompts: 'Scenario appears to refactor existing scenario in user-authentication.feature. Update existing? (y/n)'. User confirms 'y'. System updates existing scenario, updates test file header comment, regenerates coverage.",
        "User runs 'fspec generate-scenarios AUTH-006' where examples describe OAuth integration. System searches all feature files, finds no OAuth-related scenarios. System creates new feature file 'oauth-integration.feature' with new scenarios.",
        "User runs 'fspec generate-scenarios BUG-009' with 3 examples. System detects: Example 1 matches existing scenario in feature-validation.feature (refactor), Example 2 matches scenario in tag-management.feature (refactor), Example 3 is new. System prompts for each match, updates 2 existing features with refactored scenarios, creates new feature file for Example 3 only.",
        "User runs 'fspec audit-scenarios' after several months of development. System finds 5 duplicate scenarios across different feature files. System reports: 'Found 5 potential duplicates' with file names, scenario titles, and similarity scores. User can choose to merge duplicates interactively.",
        "User runs 'fspec generate-scenarios AUTH-005' where examples describe login validation. System finds existing scenario 'Validate user credentials' in user-authentication.feature. System prompts: 'Scenario appears to refactor existing scenario in user-authentication.feature. Update existing? (y/n)'. User confirms 'y'. System updates existing scenario, updates test file header comment, regenerates coverage.",
        "User runs 'fspec generate-scenarios AUTH-006' where examples describe OAuth integration. System searches all feature files, finds no OAuth-related scenarios. System creates new feature file 'oauth-integration.feature' with new scenarios.",
        "User runs 'fspec generate-scenarios BUG-009' with 3 examples. System detects: Example 1 matches existing scenario in feature-validation.feature (refactor), Example 2 matches scenario in tag-management.feature (refactor), Example 3 is new. System prompts for each match, updates 2 existing features with refactored scenarios, creates new feature file for Example 3 only.",
        "User runs 'fspec audit-scenarios' after several months of development. System finds 5 duplicate scenarios across different feature files. System reports: 'Found 5 potential duplicates' with file names, scenario titles, and similarity scores. User can choose to merge duplicates interactively."
      ],
      "architectureNotes": [],
      "estimate": 8
    },
    "SPEC-003": {
      "id": "SPEC-003",
      "title": "Improve scenario similarity matching accuracy",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-20T21:44:50.450Z",
      "updatedAt": "2025-10-20T22:24:22.484Z",
      "description": "Replace simple Levenshtein distance with hybrid algorithm combining Jaro-Winkler, Token Set Ratio, Gherkin Structural analysis, Trigrams, and Jaccard similarity. Fix 7 critical bugs and improve accuracy from 60% to 88%.",
      "epic": "example-driven-discovery",
      "children": [],
      "attachments": [
        "spec/attachments/SPEC-003/SIMILARITY_ANALYSIS.md",
        "spec/attachments/SPEC-003/ALGORITHM_ANALYSIS.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T21:48:29.525Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T22:02:09.310Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T22:17:20.053Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T22:22:54.783Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T22:24:22.484Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for scenario deduplication",
        "action": "have accurate scenario similarity matching that handles edge cases and different phrasings",
        "benefit": "I can confidently detect duplicate scenarios and refactoring opportunities without false positives or false negatives"
      },
      "rules": [
        "Similarity scoring must handle empty strings without division by zero crashes",
        "Gherkin keywords (Given/When/Then/And/But) must be stripped from steps before similarity comparison",
        "Keyword extraction must include numbers and special characters (OAuth2, SHA256, Base64, etc.)",
        "Division by zero must be prevented when comparing scenarios with empty keyword sets",
        "Step reordering must not penalize similarity (Given A, Given B should match Given B, Given A)",
        "Partial step matching must be supported (3/4 identical steps should score high)",
        "Short scenario titles (< 20 chars) must use stricter thresholds to prevent false positives",
        "Hybrid algorithm must combine at least 5 different similarity algorithms with weighted scoring",
        "Overall accuracy must reach 88% (improvement from current 60%)",
        "Algorithm must handle word reordering without penalty (Token Set Ratio approach)",
        "Algorithm must handle typos and minor character variations (trigram similarity)",
        "Algorithm must respect Gherkin structure (Given/When/Then sections analyzed separately)",
        "Use 20 characters as threshold for short string detection (as recommended in attachments). Apply stricter threshold of 0.85 for short titles to prevent false positives.",
        "Yes - weight 'Then' steps 1.5x higher than 'Given/When' in Gherkin Structural analysis. Outcomes (Then) are more critical for determining scenario equivalence than preconditions/actions."
      ],
      "examples": [
        "BUG-1: Comparing two scenarios with empty titles should return 1.0 (both empty = identical) without division by zero crash",
        "BUG-2: Steps 'Given user exists, When login, Then success' should have keywords stripped to 'user exists, login, success' before comparison",
        "BUG-5: Technical terms like 'OAuth2', 'SHA256', 'Base64' must be extracted as keywords (regex must include numbers)",
        "BUG-4: Comparing scenarios with no extractable keywords should return 0 similarity without division by zero crash",
        "ISSUE-1: 'Given user exists, Given database connected, When login' should match 100% with 'Given database connected, Given user exists, When login' (reordered steps)",
        "ISSUE-2: Scenario A with steps [X, Y, Z, W] should score 75% step similarity with Scenario B with steps [X, Y, Z, Q] (3/4 match)",
        "ISSUE-3: 'User login' vs 'User logout' should NOT score 83.3% (false positive due to short strings)",
        "Jaro-Winkler: 'User login validation' vs 'User login verification' should score ~0.92 (better than Levenshtein for prefix matching)",
        "Token Set Ratio: 'Given user exists and database connected' vs 'Given database connected and user exists' should score 1.0 (word order independence)",
        "Trigram: 'authenticate' vs 'authentcate' (typo) should score ~0.85 (typo tolerance)",
        "Gherkin Structural: Compare Given/When/Then sections separately with Jaccard similarity, weight Then steps higher (outcomes matter more)",
        "Hybrid: Weighted combination of 5 algorithms (Jaro-Winkler 30%, Token Set 25%, Gherkin Structural 20%, Trigram 15%, Jaccard 10%) achieves 88% accuracy"
      ],
      "questions": [
        {
          "text": "@human: Should algorithm weights (Jaro-Winkler 30%, Token Set 25%, etc.) be configurable via options, or hardcoded based on the analysis recommendations?",
          "selected": true,
          "answer": "Configurable via options/parameters - allows dynamic tuning if results aren't optimal"
        },
        {
          "text": "@human: Should we implement Phase 1 only (80% accuracy, simpler) or both Phase 1 + Phase 2 (88% accuracy, more complex) in this work unit?",
          "selected": true,
          "answer": "Yes - implement both Phase 1 + Phase 2 for 88% accuracy target"
        },
        {
          "text": "@human: Are we okay with zero external dependencies (Phase 1+2 recommendation), or should we consider Phase 3 with Sentence-BERT ML library for 92% accuracy?",
          "selected": true,
          "answer": "Investigate semantic-chunking (https://www.npmjs.com/package/semantic-chunking) and other npm packages for semantic similarity as potential enhancement"
        },
        {
          "text": "@human: Should the similarity threshold (currently 0.7) be configurable per use case, or should we optimize it based on testing?",
          "selected": true,
          "answer": "No - threshold optimized based on testing, not user-configurable"
        },
        {
          "text": "@human: For short string bias handling, what should be the character threshold (attachments propose < 20 chars)? Should this be configurable?",
          "selected": true,
          "answer": "Use 20 characters as threshold for short string detection (as recommended in attachments). Apply stricter threshold of 0.85 for short titles to prevent false positives."
        },
        {
          "text": "@human: Should 'Then' steps (outcomes) be weighted higher than 'Given/When' steps in Gherkin Structural analysis, as proposed in the attachments?",
          "selected": true,
          "answer": "Yes - weight 'Then' steps 1.5x higher than 'Given/When' in Gherkin Structural analysis. Outcomes (Then) are more critical for determining scenario equivalence than preconditions/actions."
        },
        {
          "text": "@human: Should we prioritize speed or accuracy if there's a trade-off? (e.g., caching, two-stage filtering for large codebases)",
          "selected": true,
          "answer": "Prioritize accuracy over speed for Phase 1+2. All algorithms (Jaro-Winkler, Token Set, Gherkin Structural, Trigram, Jaccard) are O(n*m) or better. For 100+ scenarios, implement two-stage filtering: (1) fast keyword filtering, (2) full similarity on candidates."
        },
        {
          "text": "@human: Should we keep the old Levenshtein algorithm available via a flag for backward compatibility and comparison testing?",
          "selected": true,
          "answer": "Yes - keep old Levenshtein algorithm behind a flag for backward compatibility and A/B testing. Allows users to compare old vs new algorithm results during transition period."
        }
      ],
      "architectureNotes": [
        "Current Implementation: src/utils/scenario-similarity.ts uses Levenshtein distance (character-level edit distance) with 70/30 weighted scoring (title vs steps). Has 7 critical bugs and achieves only 60% accuracy.",
        "Proposed Hybrid Algorithm: Combine 5 algorithms with weighted scoring - Jaro-Winkler (30% - title matching), Token Set Ratio (25% - word reordering), Gherkin Structural (20% - Given/When/Then awareness), Trigram Similarity (15% - fuzzy matching), Jaccard Similarity (10% - keyword overlap). Expected 88% accuracy.",
        "Bug Fixes Required: (1) Division by zero for empty strings/keywords, (2) Strip Gherkin keywords before comparison, (3) Include numbers in keyword regex for technical terms, (4) Fix keyword extraction for match objects, (5) Remove redundant lowercasing, (6) Handle step reordering, (7) Support partial step matching.",
        "Performance: All Phase 1+2 algorithms have no external dependencies and run in O(n*m) time or better. For large codebases (100+ scenarios), consider two-stage matching: (1) Fast keyword filtering, (2) Full similarity only on candidates.",
        "Test Coverage: Must cover empty strings, empty steps, empty keywords, special characters, numbers in terms (OAuth2/SHA256), short titles, reordered steps, partial matches, typos, and performance with 100+ scenarios. See src/commands/__tests__/scenario-deduplication.test.ts",
        "References: (1) spec/attachments/SPEC-003/SIMILARITY_ANALYSIS.md - Bug analysis and test gaps, (2) spec/attachments/SPEC-003/ALGORITHM_ANALYSIS.md - Algorithm comparison and implementation guide, (3) Jaro-Winkler, Token Set Ratio, Trigram algorithms ~200 lines total with no dependencies"
      ],
      "assumptions": [
        "Configurable via options/parameters - allows dynamic tuning if results aren't optimal",
        "Yes - implement both Phase 1 + Phase 2 for 88% accuracy target",
        "Investigate semantic-chunking (https://www.npmjs.com/package/semantic-chunking) and other npm packages for semantic similarity as potential enhancement",
        "No - threshold optimized based on testing, not user-configurable",
        "semantic-chunking provides semantic embeddings via ONNX models (all-MiniLM-L6-v2 at 23MB) and cosine similarity. Can be added as optional Phase 3 enhancement for semantic matching when higher accuracy needed beyond 88% target.",
        "Prioritize accuracy over speed for Phase 1+2. All algorithms (Jaro-Winkler, Token Set, Gherkin Structural, Trigram, Jaccard) are O(n*m) or better. For 100+ scenarios, implement two-stage filtering: (1) fast keyword filtering, (2) full similarity on candidates.",
        "Yes - keep old Levenshtein algorithm behind a flag for backward compatibility and A/B testing. Allows users to compare old vs new algorithm results during transition period."
      ],
      "estimate": 8
    },
    "HOOK-011": {
      "id": "HOOK-011",
      "title": "Work unit-scoped hooks for dynamic validation",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-20T22:40:29.609Z",
      "updatedAt": "2025-10-21T00:52:25.364Z",
      "description": "Enable AI agents to attach hooks to specific work units without modifying global hook configuration",
      "children": [],
      "userStory": {
        "role": "AI agent working on a specific work unit",
        "action": "attach validation hooks (like eslint) to this work unit dynamically",
        "benefit": "I can enforce quality checks for this story without modifying global hook configuration"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T22:41:29.303Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T23:11:34.037Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T23:14:41.456Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T23:18:21.442Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T23:23:22.138Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T23:23:59.562Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T23:35:46.088Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T23:35:58.490Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T23:36:45.753Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T23:51:10.746Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T23:51:29.247Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T23:57:49.686Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T00:48:39.048Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T00:48:55.509Z"
        }
      ],
      "questions": [
        {
          "text": "@human: Should work unit-scoped hooks be saved permanently (persisted in work-units.json) or ephemeral (exist only during the current session)?",
          "selected": true,
          "answer": "Ephemeral by default - hooks run once when requested without persisting. AI can offer to convert useful virtual hooks into permanent hooks (saved to spec/fspec-hooks.json) if the user wants to reuse them."
        },
        {
          "text": "@human: How should the AI discover what virtual hooks are available? Should we have predefined templates (like 'eslint', 'prettier', 'test-coverage') or allow arbitrary commands (like 'npm run custom-lint'), or both?",
          "selected": true,
          "answer": "Virtual hooks are created conversationally - AI proactively asks user 'Do you want me to run anything at specific stages?' User names tools (e.g., 'eslint', 'stylelint'). AI then: 1) Checks if tools exist/are installed, 2) Looks up how to use them (help commands, web search), 3) Creates virtual hooks dynamically. No predefined registry needed."
        },
        {
          "text": "@human: When should the AI ask 'Do you want me to run anything at specific stages?' - at the start of the story, at specific workflow stages (like before implementing), or any time during the story?",
          "selected": true,
          "answer": "At the end of specifying phase - after specifications are complete and before moving to testing. This is when AI has full context of what will be built and can meaningfully ask about quality checks."
        },
        {
          "text": "@human: When a virtual hook executes (e.g., eslint at post-validating), should it only run for THIS work unit or apply globally to all work units until removed?",
          "selected": true,
          "answer": "Scoped to current work unit only by default. After the virtual hook executes successfully, AI should ask: 'This [tool] hook worked well. Do you want to make it permanent so it runs for all work units at this stage?' If yes, AI saves it to spec/fspec-hooks.json using 'fspec add-hook' command."
        },
        {
          "text": "@human: If a virtual hook fails (e.g., eslint finds errors), should it be blocking (prevent workflow transition) or non-blocking (show output but allow transition)? Or should AI ask the user which behavior they want?",
          "selected": true,
          "answer": "AI asks user when setting up hook: 'Should I block transitions if [tool] fails?' If user says blocking: STRICT ENFORCEMENT with <system-reminder> wrapping the failure output, AI CANNOT proceed with workflow transition until issues are fixed. If non-blocking: show output but allow transition."
        },
        {
          "text": "@human: What happens to virtual hooks when the work unit reaches 'done' status? Should they automatically be removed, or persist for potential future edits to this work unit?",
          "selected": true,
          "answer": "When work unit reaches 'done' status, AI asks user: 'Do you want to keep these virtual hooks for future edits to this story, or remove them?' If keep: hooks remain attached to work unit. If remove: hooks are cleaned up."
        },
        {
          "text": "@human: Where should virtual hooks be stored temporarily? Should they be in work-units.json (in a 'virtualHooks' field), or in a separate temporary file, or in memory only during the AI session?",
          "selected": true,
          "answer": "Virtual hooks stored in work-units.json as a 'virtualHooks' array field on the work unit. This ties hooks to the story lifecycle, persists across sessions, visible in 'fspec show-work-unit', and can be cleaned up when story is done."
        },
        {
          "text": "@human: When AI creates a virtual hook to run a tool (like eslint), should it: 1) Execute the command directly (e.g., store 'eslint src/' as the command), or 2) Generate a temporary script file in spec/hooks/.virtual/ that wraps the command?",
          "selected": true,
          "answer": "AI decides based on complexity: simple commands use direct execution (e.g., 'eslint src/'), complex ones generate script files in spec/hooks/.virtual/. If hook fails to execute (command not found, script errors, permission issues), AI must: 1) Detect execution failure, 2) Show error to user with <system-reminder>, 3) Offer to fix or remove the broken hook, 4) Ask user if they want to try a different approach."
        },
        {
          "text": "@human: Can a user add multiple virtual hooks to different stages (e.g., eslint at post-implementing AND prettier at post-validating)? And can they add multiple hooks to the SAME stage (e.g., both eslint and stylelint at post-implementing)?",
          "selected": true,
          "answer": "Unlimited virtual hooks allowed. User can add multiple hooks to different stages (eslint at post-implementing, prettier at post-validating) AND multiple hooks to the same stage (eslint AND stylelint both at post-implementing). Hooks execute sequentially in the order they were added."
        },
        {
          "text": "@human: How should users view and manage their virtual hooks after they're created? Should there be commands like 'fspec list-virtual-hooks HOOK-011' or should they appear in 'fspec show-work-unit HOOK-011' output? And how should users remove unwanted virtual hooks?",
          "selected": true,
          "answer": "Both dedicated commands AND AI conversational management. Commands: 'fspec add-virtual-hook HOOK-011 <event> <command>', 'fspec list-virtual-hooks HOOK-011', 'fspec remove-virtual-hook HOOK-011 <hook-name>'. Virtual hooks also appear in 'fspec show-work-unit HOOK-011' output. AI uses these commands when user says 'add eslint hook' or 'remove the prettier hook'. Commands MUST have comprehensive --help documentation so AI can use them correctly."
        },
        {
          "text": "@human: If a work unit has a virtual hook AND there's a global hook configured for the same event (both at post-implementing), what order should they run? Virtual first then global, or global first then virtual?",
          "selected": true,
          "answer": "Virtual hooks run BEFORE global hooks. Execution order: 1) Virtual hooks (work unit-specific), 2) Global hooks (from spec/fspec-hooks.json). This allows work unit-specific validation to happen first before broader project-wide checks."
        },
        {
          "text": "@human: How should users copy virtual hooks from one work unit to another? Should there be a command like 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011', or should AI handle it conversationally ('use the same hooks as AUTH-001')? And should it copy all hooks or allow selecting specific ones?",
          "selected": true,
          "answer": "Both dedicated command AND AI conversational management. Command: 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011' (copies all hooks) or 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011 --hook-name eslint' (copies specific hook). AI can handle conversationally: 'use the same hooks as AUTH-001' (all) or 'copy the eslint hook from AUTH-001' (specific). Command must have comprehensive --help."
        }
      ],
      "rules": [
        "Ephemeral by default - hooks run once when requested without persisting. AI can offer to convert useful virtual hooks into permanent hooks (saved to spec/fspec-hooks.json) if the user wants to reuse them.",
        "Virtual hooks are created conversationally - AI proactively asks user 'Do you want me to run anything at specific stages?' User names tools (e.g., 'eslint', 'stylelint'). AI then: 1) Checks if tools exist/are installed, 2) Looks up how to use them (help commands, web search), 3) Creates virtual hooks dynamically. No predefined registry needed.",
        "When AI asks 'Do you want me to run anything at specific stages?', it MUST list the available hook events (post-implementing, post-testing, post-validating, pre-specifying, etc.) so the human knows their options",
        "At the end of specifying phase - after specifications are complete and before moving to testing. This is when AI has full context of what will be built and can meaningfully ask about quality checks.",
        "AI must phrase the question clearly with examples: 'Do you want me to run a command or program at any stage of this story? For example, I could run eslint after implementing, or run prettier before validating. Here are the available stages: [list stages]'",
        "Scoped to current work unit only by default. After the virtual hook executes successfully, AI should ask: 'This [tool] hook worked well. Do you want to make it permanent so it runs for all work units at this stage?' If yes, AI saves it to spec/fspec-hooks.json using 'fspec add-hook' command.",
        "AI asks user when setting up hook: 'Should I block transitions if [tool] fails?' If user says blocking: STRICT ENFORCEMENT with <system-reminder> wrapping the failure output, AI CANNOT proceed with workflow transition until issues are fixed. If non-blocking: show output but allow transition.",
        "When work unit reaches 'done' status, AI asks user: 'Do you want to keep these virtual hooks for future edits to this story, or remove them?' If keep: hooks remain attached to work unit. If remove: hooks are cleaned up.",
        "Virtual hooks stored in work-units.json as a 'virtualHooks' array field on the work unit. This ties hooks to the story lifecycle, persists across sessions, visible in 'fspec show-work-unit', and can be cleaned up when story is done.",
        "AI decides based on complexity: simple commands use direct execution (e.g., 'eslint src/'), complex ones generate script files in spec/hooks/.virtual/. If hook fails to execute (command not found, script errors, permission issues), AI must: 1) Detect execution failure, 2) Show error to user with <system-reminder>, 3) Offer to fix or remove the broken hook, 4) Ask user if they want to try a different approach.",
        "Unlimited virtual hooks allowed. User can add multiple hooks to different stages (eslint at post-implementing, prettier at post-validating) AND multiple hooks to the same stage (eslint AND stylelint both at post-implementing). Hooks execute sequentially in the order they were added.",
        "Both dedicated commands AND AI conversational management. Commands: 'fspec add-virtual-hook HOOK-011 <event> <command>', 'fspec list-virtual-hooks HOOK-011', 'fspec remove-virtual-hook HOOK-011 <hook-name>'. Virtual hooks also appear in 'fspec show-work-unit HOOK-011' output. AI uses these commands when user says 'add eslint hook' or 'remove the prettier hook'. Commands MUST have comprehensive --help documentation so AI can use them correctly.",
        "Virtual hooks run BEFORE global hooks. Execution order: 1) Virtual hooks (work unit-specific), 2) Global hooks (from spec/fspec-hooks.json). This allows work unit-specific validation to happen first before broader project-wide checks.",
        "Both dedicated command AND AI conversational management. Command: 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011' (copies all hooks) or 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011 --hook-name eslint' (copies specific hook). AI can handle conversationally: 'use the same hooks as AUTH-001' (all) or 'copy the eslint hook from AUTH-001' (specific). Command must have comprehensive --help.",
        "Virtual hooks can receive git context (staged/unstaged files) via hook context JSON. AI can create hooks that target specific changed files. For complex hooks needing git context, AI generates script files in spec/hooks/.virtual/ that process the file list.",
        "Git context is OPTIONAL. When setting up a virtual hook, AI asks: 'Do you want this hook to target only changed files (staged/unstaged)? For example, I can run eslint only on your modified .ts files.' If yes: AI generates script that uses git context. If no: command runs as-is without git context (e.g., 'eslint src/' runs against entire codebase)."
      ],
      "examples": [
        "User is working on AUTH-001. At end of specifying, AI asks: 'Do you want me to run a command or program at any stage? For example, eslint after implementing. Available stages: post-implementing, post-testing, post-validating.' User says: 'Yes, run eslint and prettier.' AI creates two virtual hooks, asks if blocking, stores in work-units.json.",
        "Virtual hook 'eslint' runs at post-implementing. Eslint finds 3 errors. Hook is blocking. AI shows errors wrapped in <system-reminder>, CANNOT proceed to validating until user fixes errors. User fixes errors, re-runs transition, eslint passes, transition succeeds.",
        "Virtual hook runs successfully. AI asks: 'The eslint hook worked well. Do you want to make it permanent for all work units?' User says yes. AI runs 'fspec add-hook post-implementing eslint spec/hooks/.virtual/eslint-HOOK-011.sh --blocking' to save to spec/fspec-hooks.json.",
        "Work unit reaches done status. AI asks: 'Do you want to keep these virtual hooks for future edits to this story, or remove them?' User says remove. AI cleans up virtualHooks array from work-units.json and deletes generated script files.",
        "User says 'use the same hooks as AUTH-001'. AI runs 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011', copies all virtual hooks (eslint, prettier) with their configurations (blocking status, event names) to current work unit.",
        "Virtual hook command 'eslint src/' fails to execute (command not found). AI detects execution failure, shows error in <system-reminder>: 'Hook failed to execute: eslint: command not found. Install eslint or check PATH.' AI offers to remove broken hook or try different command.",
        "User runs 'fspec show-work-unit HOOK-011'. Output includes 'Virtual Hooks' section showing: 'post-implementing: eslint (blocking), prettier (non-blocking)', 'post-validating: test-coverage (blocking)'. User can see all active hooks at a glance.",
        "User says 'run eslint only on changed files'. AI creates virtual hook with script in spec/hooks/.virtual/eslint-changed-files.sh. Hook context includes git info: {stagedFiles: ['src/auth.ts'], unstagedFiles: ['src/utils.ts']}. Script runs: eslint $STAGED_FILES. This is more efficient than linting entire codebase."
      ],
      "estimate": 8,
      "virtualHooks": [],
      "attachments": [
        "spec/attachments/HOOK-011/HOOK-011-issues-found.md"
      ]
    },
    "BUG-023": {
      "id": "BUG-023",
      "title": "commonPatterns displays [object Object] in help output",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-21T00:28:59.162Z",
      "updatedAt": "2025-10-21T01:38:22.549Z",
      "children": [],
      "description": "Detailed bug analysis in spec/bugs/BUG-023-commonpatterns-formatting.md\n\nThe COMMON PATTERNS section in command help displays '[object Object]' instead of formatted pattern information. \n\nRoot cause: Type mismatch between CommandHelpConfig interface (expects string[]) and help file implementations (use objects with pattern/example/description).\n\nAffects: All help files including add-hook-help.ts and all 5 new virtual-hook help files.\n\nSee attached markdown for full analysis, reproduction steps, and recommended solutions.",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T01:32:35.146Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T01:34:32.725Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T01:35:33.322Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T01:38:06.003Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T01:38:22.550Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec CLI",
        "action": "view properly formatted COMMON PATTERNS in help output",
        "benefit": "I can understand usage patterns without seeing [object Object]"
      },
      "rules": [
        "Help formatter must support both string[] and object[] formats for commonPatterns (backward compatibility)",
        "Object format commonPatterns must display pattern name, example command, and description",
        "Interface must accept both formats: string[] | Array<{pattern,example,description}>"
      ],
      "examples": [
        "Running 'fspec add-virtual-hook --help' displays formatted patterns with name, example, and description instead of [object Object]",
        "All 20+ affected help commands display COMMON PATTERNS section correctly after fix",
        "Help commands still using string[] format continue to work (backward compatibility)"
      ],
      "estimate": 2
    },
    "HELP-003": {
      "id": "HELP-003",
      "title": "Regenerate help output for 20+ commands after BUG-023 fix",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-21T01:32:08.102Z",
      "updatedAt": "2025-10-21T01:41:10.513Z",
      "description": "After fixing the commonPatterns formatting bug (BUG-023), regenerate and verify help output for all affected commands to ensure proper display of COMMON PATTERNS section",
      "children": [],
      "attachments": [
        "spec/attachments/HELP-003/affected-help-files.md",
        "spec/attachments/HELP-003/verification-report.md",
        "spec/attachments/HELP-003/verify-help-patterns.sh"
      ],
      "dependsOn": [
        "BUG-023"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T01:39:35.953Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T01:39:37.906Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T01:41:01.813Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T01:41:10.514Z"
        }
      ],
      "estimate": 1
    },
    "GIT-001": {
      "id": "GIT-001",
      "title": "Replace git CLI usage with isomorphic-git library",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T01:48:10.185Z",
      "updatedAt": "2025-10-21T02:21:42.908Z",
      "description": "Replace all external git command calls with isomorphic-git, a pure JavaScript git implementation that can be bundled into fspec without external dependencies",
      "children": [],
      "attachments": [
        "spec/attachments/GIT-001/isomorphic-git-research.md",
        "spec/attachments/GIT-001/testing-patterns.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T01:52:37.646Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T02:10:46.791Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T02:14:18.345Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T02:20:14.711Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T02:21:42.908Z"
        }
      ],
      "userStory": {
        "role": "developer maintaining fspec",
        "action": "replace git CLI calls with isomorphic-git library",
        "benefit": "fspec can be bundled as a single executable without external dependencies"
      },
      "rules": [
        "Must create comprehensive git abstraction layer in src/git/ with common operations (status, add, commit, log) following best practices patterns",
        "Git abstraction layer must be architected as core shared infrastructure for all git operations across fspec",
        "Keep execa dependency (used for lifecycle hooks execution) but replace all git CLI calls with isomorphic-git",
        "Git abstraction layer must support configurable strict mode - callers can choose whether errors are thrown or silently return empty results",
        "No barrel exports (index.ts) - consumers must import directly from specific modules like src/git/status.ts",
        "Use modular structure with separate files per operation area: status.ts, add.ts, commit.ts, log.ts in src/git/ directory",
        "Create semantic wrapper types that hide isomorphic-git implementation details - consumers should not depend on library-specific types like StatusRow",
        "Internal modules can use isomorphic-git types internally but must transform to semantic types (e.g., FileStatus) at module boundaries",
        "Use isomorphic-git testing patterns from official documentation - research and document mock filesystem approach for unit tests",
        "No performance benchmarking required - isomorphic-git performance is acceptable for fspec use case",
        "Complete replacement of git-context.ts implementation - no feature flags or parallel implementations",
        "Must update existing feature file, tests, and coverage mappings to align with new isomorphic-git implementation"
      ],
      "examples": [
        "Virtual hook with git-context flag needs to get list of staged and unstaged files to pass to hook script (e.g., eslint only on changed files)",
        "Checkpoint system (GIT-002 dependency) needs to detect all modified, staged, and untracked files before creating intelligent stash snapshot",
        "Empty repository (git init, no commits yet) - should handle gracefully, treat all files as untracked without crashing",
        "Repository with .gitignore - operations should respect .gitignore by default, exclude ignored files (node_modules, dist, etc.) from status results",
        "Clean repository (no changes) - returns empty arrays efficiently for staged, unstaged, and untracked files"
      ],
      "estimate": 8
    },
    "GIT-002": {
      "id": "GIT-002",
      "title": "Intelligent checkpoint system for workflow transitions",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T01:48:11.753Z",
      "updatedAt": "2025-10-21T03:59:02.614Z",
      "description": "Implement automatic git stash/restore checkpointing when work units move through Kanban states, capturing all file changes (including fspec-modified files) for rollback capability",
      "children": [],
      "dependsOn": [
        "GIT-001"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T03:07:42.421Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T03:27:39.806Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T03:30:42.709Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T03:57:36.338Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T03:59:02.614Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "automatically save my work at each workflow transition",
        "benefit": "I can safely experiment without losing progress and recover from mistakes"
      },
      "rules": [
        "Checkpoints are automatically created when work unit status changes (before leaving current state)",
        "Users can create named checkpoints manually at any time for experiments",
        "Checkpoints capture all file changes including untracked files (respecting .gitignore)",
        "Automatic checkpoints use pattern '{work-unit-id}-auto-{state}', manual use user-provided names",
        "Checkpoints persist until explicitly deleted (no automatic expiration)",
        "Checkpoints stored as git stashes with special message format for filtering",
        "When restoration causes conflicts, AI receives system-reminder to resolve using Read/Edit tools",
        "All tests must run and pass after checkpoint restoration with conflicts",
        "Show all checkpoints by default with clear visual indicators (emoji like 🤖 for auto, 📌 for manual) so users feel confident in the safety net",
        "Use 'fspec checkpoint' (short form) for AI efficiency - less verbose, faster to type in conversations",
        "Ask user interactively when dirty working directory detected - present options (commit first, stash and restore, force restore with merge) and explain risks of each approach"
      ],
      "examples": [
        "User runs 'fspec update-work-unit-status GIT-002 implementing', system creates checkpoint 'GIT-002-auto-testing' before transition",
        "User runs 'fspec create-checkpoint GIT-002 before-refactor', system creates named checkpoint for experimentation",
        "User creates checkpoint 'baseline', tries approach A (fails), restores 'baseline', tries approach B (succeeds)",
        "User restores checkpoint causing conflicts, AI receives system-reminder, reads conflicted files, resolves with Edit tool, tests run automatically, restoration completes when tests pass",
        "User runs 'fspec list-checkpoints GIT-002', sees both automatic and manual checkpoints with timestamps",
        "User runs 'fspec cleanup-checkpoints GIT-002 --keep-last 5', system deletes old checkpoints keeping 5 most recent"
      ],
      "architectureNotes": [
        "Git stash message format: fspec-checkpoint:{work-unit-id}:{checkpoint-name}:{timestamp}",
        "Use 'git stash push -u -m message' to include untracked files respecting .gitignore",
        "Use 'git stash apply stash@{N}' for restoration (preserves stash for re-restoration)",
        "Conflict detection: parse git output for CONFLICT markers and identify affected files",
        "AI conflict resolution: emit system-reminder with conflicted files, AI uses Read/Edit to resolve",
        "Test validation: automatically run 'npm test' after conflict resolution, block completion if tests fail",
        "Leverage existing isomorphic-git integration for git operations"
      ],
      "questions": [
        {
          "text": "@human: Should automatic checkpoints be hidden by default in 'fspec list-checkpoints GIT-002' (require --show-auto flag to display)?",
          "selected": true,
          "answer": "Show all checkpoints by default with clear visual indicators (emoji like 🤖 for auto, 📌 for manual) so users feel confident in the safety net"
        },
        {
          "text": "@human: Command naming preference: 'fspec checkpoint GIT-002 name' (short) or 'fspec create-checkpoint GIT-002 name' (explicit)?",
          "selected": true,
          "answer": "Use 'fspec checkpoint' (short form) for AI efficiency - less verbose, faster to type in conversations"
        },
        {
          "text": "@human: Should restoration fail if working directory is dirty (uncommitted changes) even without conflicts?",
          "selected": true,
          "answer": "Ask user interactively when dirty working directory detected - present options (commit first, stash and restore, force restore with merge) and explain risks of each approach"
        },
        {
          "text": "@human: Should test command be configurable (package.json 'test' script vs hardcoded 'npm test')?",
          "selected": true,
          "answer": "fspec does NOT run tests - it emits system-reminder to AI agent that tests must be run. AI chooses test command (npm test, vitest, etc). This is about the system-reminder message content only."
        }
      ],
      "assumptions": [
        "fspec does NOT run tests - it emits system-reminder to AI agent that tests must be run. AI chooses test command (npm test, vitest, etc). This is about the system-reminder message content only."
      ],
      "estimate": 8
    },
    "GIT-003": {
      "id": "GIT-003",
      "title": "Fix GIT-001 critical bugs and logic errors",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T02:35:34.991Z",
      "updatedAt": "2025-10-21T03:03:08.487Z",
      "description": "Fix blocker test failure, critical logic bugs in getUnstagedFiles(), type safety violations, and add comprehensive test coverage for edge cases identified in ULTRATHINK analysis",
      "epic": "example-driven-discovery",
      "children": [],
      "attachments": [
        "spec/attachments/GIT-003/git-001-critical-analysis.md"
      ],
      "dependsOn": [
        "GIT-001"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T02:36:12.870Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T02:41:19.861Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T03:02:35.465Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T03:02:43.916Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T03:03:08.488Z"
        }
      ],
      "rules": [
        "BLOCKER (S1): Fix failing test - getUnstagedFiles() returns empty array for modified files in memfs environment",
        "CRITICAL (S2): Fix logic bug - getUnstagedFiles() misses files that are staged then modified again (partial staging scenario)",
        "CRITICAL (S2): Fix FileStatus.modified semantic ambiguity - rename to hasUnstagedModifications or add separate hasUnstagedChanges field",
        "HIGH (S3): Replace fs parameter type 'any' with proper IFs interface type for type safety",
        "MEDIUM (S4): Add comprehensive test coverage for 14 missing scenarios including deleted files, nested directories, partial staging, and edge cases"
      ],
      "examples": [
        "Failing test: File modified after commit in memfs not detected by getUnstagedFiles() - returns [] instead of ['modified.txt']",
        "Partial staging miss: echo v2 > file.txt && git add file.txt && echo v3 >> file.txt results in file appearing in staged but NOT unstaged (should be in both)",
        "Type safety violation: Passing { someMethod: () => {} } as fs option causes runtime error instead of compile-time error"
      ],
      "userStory": {
        "role": "developer maintaining fspec",
        "action": "fix critical bugs and logic errors in GIT-001 isomorphic-git integration",
        "benefit": "virtual hooks and checkpoint system work correctly with all git scenarios"
      },
      "estimate": 8
    },
    "EST-002": {
      "id": "EST-002",
      "title": "AI token usage tracking",
      "type": "story",
      "status": "specifying",
      "createdAt": "2025-10-21T05:25:26.138Z",
      "updatedAt": "2025-10-24T06:46:25.398Z",
      "description": "Enable AI agents to record token usage cumulatively against work units throughout the development lifecycle, providing visibility into AI resource consumption per story from start to completion. Track input tokens, output tokens, and total cost across all iterations and state transitions.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-24T06:46:25.398Z"
        }
      ]
    },
    "TECH-001": {
      "id": "TECH-001",
      "title": "JSONL format investigation for work-units.json scalability",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-21T05:25:29.539Z",
      "updatedAt": "2025-10-21T05:25:29.539Z",
      "description": "Investigate migrating from JSON to JSONL (JSON Lines) format for work-units.json to address file size limitations as projects scale. Research: 1) performance comparison for large datasets (1000+ work units), 2) append-only operations vs full file rewrites, 3) streaming read/write capabilities, 4) git diff friendliness, 5) backward compatibility strategies, 6) migration path from JSON to JSONL. Deliver recommendation with proof-of-concept if beneficial.",
      "children": []
    },
    "BOARD-002": {
      "id": "BOARD-002",
      "title": "Interactive Kanban board CLI",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T05:25:48.725Z",
      "updatedAt": "2025-10-27T06:34:19.400Z",
      "description": "Create an interactive terminal interface for fspec board that allows keyboard navigation across columns and work units. Press Enter to view full work unit details including description, attachments, example mapping data, dependencies, metrics, and more. Support vim-style navigation (hjkl), arrow keys, tab to switch columns, and quick actions (e.g., 's' for status change, 'e' to edit, 'a' for attachments).",
      "epic": "interactive-cli",
      "children": [],
      "attachments": [
        "spec/attachments/BOARD-002/interactive-kanban-board-design.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T05:23:40.679Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T05:27:12.661Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T05:28:24.067Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T05:36:04.373Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T05:38:17.307Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T06:26:43.346Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T06:27:51.687Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T06:28:29.902Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T06:30:19.984Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T06:32:34.448Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T06:33:08.185Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T06:34:16.054Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T06:34:17.176Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T06:34:18.281Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T06:34:19.400Z"
        }
      ],
      "userStory": {
        "role": "developer managing work units",
        "action": "navigate and interact with Kanban board using keyboard shortcuts",
        "benefit": "I can efficiently view, update, and manage work units without leaving the terminal"
      },
      "rules": [
        "Board must display 7 Kanban columns: backlog, specifying, testing, implementing, validating, done, blocked",
        "Arrow keys (←→ or hjkl) navigate between columns, ↑↓ (or jk) navigate work units within column",
        "Enter key opens detailed view of selected work unit",
        "Work unit cards show: type icon (📖/🐛/⚙️), ID, estimate, priority indicator (🔴🟡🟢), truncated title",
        "Selected work unit highlighted with cyan background, focused column has cyan border",
        "Board loads work units from Zustand store (fspecStore.loadData() on mount)",
        "Empty columns display 'No work units' message",
        "Column headers show: status name, count, total story points",
        "ESC key returns to previous view or exits board",
        "Detail view must display: work unit ID, title, description, type, status, estimate, epic, rules, examples, questions, attachments, dependencies, and 'Press ESC to return' message"
      ],
      "examples": [
        "User presses → arrow - focus moves from BACKLOG to SPECIFYING column, first work unit in SPECIFYING is selected",
        "User presses ↓ arrow - selection moves from RES-003 to RES-004 within BACKLOG column",
        "User presses Enter on ITF-002 - opens detail view showing full description, Example Mapping data, attachments",
        "BACKLOG column header shows: 'BACKLOG (26) - 78pts'",
        "Work unit ITF-001 (story, 5pt estimate) displays as: 📖 ITF-001 5pt 🟡",
        "Empty TESTING column shows 'No work units' message centered in column",
        "Board loads on mount by calling fspecStore.loadData() and displaying work units grouped by status",
        "Footer displays: '← → Columns | ↑↓ jk Work Units | ↵ Details | ESC Back'",
        "User presses Enter on BOARD-002 (currently selected) → Detail view opens showing: 'BOARD-002', 'Interactive Kanban board CLI', full description, 9 rules, 8 examples, 3 questions (answered), 1 attachment, 'Press ESC to return'"
      ],
      "questions": [
        {
          "text": "Should column navigation wrap around (pressing → on BLOCKED goes to BACKLOG)?",
          "selected": true,
          "answer": "Yes - wrap around. Pressing → on BLOCKED wraps to BACKLOG, ← on BACKLOG wraps to BLOCKED. Same for work units: ↓ on last wraps to first, ↑ on first wraps to last."
        },
        {
          "text": "Should work unit navigation within column wrap around (pressing ↓ on last item goes to first)?",
          "selected": true,
          "answer": "Yes - wrap around for seamless navigation. Pressing → on BLOCKED wraps to BACKLOG, pressing ← on BACKLOG wraps to BLOCKED."
        },
        {
          "text": "What happens when navigating to an empty column - skip it or allow focus with no selection?",
          "selected": true,
          "answer": "Yes - work unit navigation wraps. Pressing ↓ on last work unit selects first work unit, pressing ↑ on first selects last."
        }
      ],
      "estimate": 8
    },
    "CLEAN-001": {
      "id": "CLEAN-001",
      "title": "Add ESLint and Prettier for code quality",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T05:53:29.407Z",
      "updatedAt": "2025-10-26T04:35:56.985Z",
      "description": "Set up ESLint and Prettier to enforce consistent code style and catch common errors. This includes configuration, fixing existing violations, and integrating with the development workflow.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-26T03:42:35.790Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T03:49:41.728Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T04:03:22.774Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T04:05:17.712Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T04:07:35.182Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T04:08:08.945Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T04:10:45.800Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T04:13:53.425Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T04:22:05.705Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T04:23:16.009Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T04:24:15.665Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T04:25:18.384Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T04:28:55.408Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T04:32:53.837Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T04:35:56.985Z"
        }
      ],
      "userStory": {
        "role": "developer contributing to fspec",
        "action": "have ESLint and Prettier configured and running",
        "benefit": "code quality is consistent and common errors are caught automatically"
      },
      "rules": [
        "ESLint configuration MUST align with TypeScript strict mode and existing CLAUDE.md coding standards",
        "Prettier MUST be configured to match existing code formatting (2-space indentation, single quotes, etc.)",
        "All existing code violations MUST be fixed before integration (no warnings/errors in CI)",
        "Integration MUST NOT break existing npm scripts (build, test, dev)",
        "ESLint and Prettier MUST work together without conflicts (use eslint-config-prettier)"
      ],
      "examples": [
        "Developer runs 'npm run lint' and all TypeScript files are checked with ESLint showing zero errors",
        "Developer runs 'npm run format' and all files are formatted consistently with Prettier",
        "Developer runs 'npm run build' and it completes successfully (lint doesn't break build)",
        "Developer commits code and pre-commit hook runs ESLint+Prettier automatically",
        "ESLint catches common TypeScript errors (unused vars, missing types, etc.) during development",
        "Prettier formats code on save in VSCode/IDE with consistent 2-space indentation and single quotes"
      ],
      "estimate": 5
    },
    "INIT-004": {
      "id": "INIT-004",
      "title": "Support multiple AI agents beyond Claude",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T05:58:37.972Z",
      "updatedAt": "2025-10-21T10:50:48.434Z",
      "description": "Support multiple AI agents beyond Claude by cloning other AI agent tools to understand their capabilities and configuration requirements. Research how agents like Cursor, Aider, and Continue.dev work to design fspec integration patterns.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T08:45:16.988Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T10:22:39.520Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T10:31:02.888Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T10:37:36.334Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T10:38:20.381Z"
        }
      ],
      "attachments": [
        "spec/attachments/INIT-004/ai-coding-agents-october-2025.md",
        "spec/attachments/INIT-004/multi-agent-implementation-research.md",
        "spec/attachments/INIT-004/interactive-agent-selector-implementation.md",
        "spec/attachments/INIT-004/agent-auto-loading-capabilities-research.md",
        "spec/attachments/INIT-004/agent-instruction-mechanisms-research.md"
      ],
      "rules": [
        "Each AI agent must have its own documentation template (e.g., CLAUDE.md, AIDER.md, CURSOR.md)",
        "System-reminder tags are Claude Code specific and must be abstracted or made optional for other agents",
        "fspec init command must support --agent flag to specify which AI agent to configure",
        "Slash command directory paths vary by agent (e.g., .claude/commands/ vs .continue/commands/)",
        "Documentation must avoid hardcoded references to 'Claude' or 'Claude Code' in agent-agnostic sections",
        "Yes, support multiple agents: Allow 'fspec init --agent=aider --agent=cursor' to install configurations for multiple agents simultaneously. Generate spec/AGENT.md for each and install slash commands to respective directories",
        "Agent-specific prompting vocabulary (like 'ultrathink' for Claude) must be translated or removed for each agent based on their capabilities",
        "fspec init must create slash commands for ALL major fspec CLI commands (validate, format, list-features, create-work-unit, etc.), not just documentation",
        "All agent templates must be bundled in fspec distribution using Vite copy plugin",
        "Template directory structure must support both flat (cursor) and nested (claude) slash command paths",
        "Generate on-the-fly using TemplateManager pattern: shared command body + agent-specific wrappers (frontmatter, path, argument placeholders). Avoids 360-540 template files, enables consistency across agents",
        "Remove meta-cognitive prompts for CLI-only agents (Aider, Gemini CLI, Qwen CLI). Keep for IDE/extension-based agents (Cline, Windsurf, Cursor). Agent registry should have 'supportsMetaCognition' flag to control this",
        "Support both: 'fspec init' (no flags) shows interactive selector by default. 'fspec init --agent=X' runs non-interactive mode for automation/scripts",
        "Yes, auto-detect installed agents by checking for directories (.claude/, .cursor/, etc.). Sort list with: 1) Detected agents at top (pre-selected), 2) Popular agents (Claude Code, Codex, Copilot), 3) Remaining agents alphabetically",
        "Support all 18 agents in v1. Use dynamic generation - ONE base template that gets transformed based on agent capabilities (system-reminder support, meta-cognition support, slash command format). No separate template files per agent.",
        "Install THREE files per agent: 1) Root stub (AGENTS.md or AGENT_NAME.md) for auto-loading, 2) Full doc (spec/AGENT_NAME.md) for comprehensive workflow, 3) Slash command (.agent/commands/fspec.md) for manual trigger. Most agents (Claude, Cursor, Cline, Windsurf, Copilot, etc.) auto-load root stubs; CLI-only tools need slash commands.",
        "fspec init is idempotent and supports agent switching. Running 'fspec init --agent=cursor' after 'fspec init --agent=claude' should remove Claude-specific files (CLAUDE.md, spec/CLAUDE.md, .claude/commands/) and install Cursor-specific files (CURSOR.md or AGENTS.md, spec/CURSOR.md, .cursor/commands/). All files are auto-generated, safe to replace.",
        "Interactive selector is SINGLE-SELECT: arrow keys to navigate/highlight, Enter to confirm the currently highlighted agent. No multi-select, no checkboxes. For multiple agents, user must run 'fspec init --agent=X --agent=Y' using CLI flags.",
        "Default highlighted agent should be the FIRST DETECTED agent (if any were auto-detected). If no agents detected, default to first agent in sorted list.",
        "No --no-interactive flag needed. Presence of --agent flags is sufficient to determine mode: if --agent present, use CLI mode; if no --agent, use interactive mode. A --no-interactive flag without --agent makes no sense.",
        "fspec init is NON-DESTRUCTIVE: if .cursor/commands/ already exists with custom files, create fspec.md alongside them. Never delete or overwrite user's custom files. Only manage fspec-specific files (AGENTS.md, spec/AGENT.md, .agent/commands/fspec.md).",
        "Validate agent IDs against registry before installation. Check file permissions before writing. Create directories recursively (mkdir -p). Handle missing templates gracefully with error messages. Wrap blocking hook failures in <system-reminder> tags for AI visibility.",
        "Generate ONE comprehensive fspec.md per agent (1010-line pattern like current .claude/commands/fspec.md). NOT multiple smaller files. This file contains complete ACDD workflow, Example Mapping process, coverage tracking, etc. Format varies by agent: Markdown with YAML frontmatter (Claude, Cursor, Cline, etc.) or TOML (Gemini CLI, Qwen Code).",
        "Invalid agent ID: Show error with list of valid agents, exit code 1. Missing templates: Check dist/spec/templates/ and fallback to spec/templates/. If both missing, show error explaining distribution may be corrupted. Suggest reinstalling fspec. Permission errors: Show clear message about directory permissions, suggest chmod/chown fixes.",
        "Research complete - see spec/attachments/INIT-004/agent-instruction-mechanisms-research.md. Finding: Claude Code's <system-reminder> tags are UNIQUE. All other agents use visible Markdown patterns: bold text (**IMPORTANT:**), headers (###), code blocks, blockquotes. Transformation required: <system-reminder> → **⚠️ IMPORTANT:** (IDE agents) or **IMPORTANT:** (CLI agents). No equivalent invisible mechanism exists for other agents."
      ],
      "examples": [
        "User runs 'fspec init --agent=aider' and gets Aider-specific documentation template copied to spec/AIDER.md",
        "User runs 'fspec init --agent=cursor' and slash command is installed to .cursor/commands/fspec.md",
        "User runs 'fspec init --agent=cline' and gets Cline-specific docs without system-reminder references",
        "User runs 'fspec init --agent=cursor' and gets 20+ slash commands created (.cursor/commands/fspec-validate.md, .cursor/commands/fspec-format.md, etc.) plus spec/CURSOR.md",
        "After 'npm install -g fspec', global installation contains bundled templates at node_modules/fspec/dist/spec/templates/cursor/CURSOR.md",
        "CLAUDE.md contains 'ultrathink your next steps' but AIDER.md (CLI-based) removes meta-cognitive prompts entirely"
      ],
      "questions": [
        {
          "text": "@human: Should fspec init auto-detect which AI agent is being used, or always require explicit --agent flag?",
          "selected": true,
          "answer": "Support both: 'fspec init' (no flags) shows interactive selector by default. 'fspec init --agent=X' runs non-interactive mode for automation/scripts"
        },
        {
          "text": "@human: For agents without system-reminder support, should we strip those tags or replace with agent-specific patterns?",
          "selected": true,
          "answer": "Yes, auto-detect installed agents by checking for directories (.claude/, .cursor/, etc.). Sort list with: 1) Detected agents at top (pre-selected), 2) Popular agents (Claude Code, Codex, Copilot), 3) Remaining agents alphabetically"
        },
        {
          "text": "@human: Should 'fspec init' support multiple agents simultaneously (e.g., team with mixed Cursor + Aider users)?",
          "selected": true,
          "answer": "Support all 18 agents in v1. Use dynamic generation - ONE base template that gets transformed based on agent capabilities (system-reminder support, meta-cognition support, slash command format). No separate template files per agent."
        },
        {
          "text": "@human: Should we bundle ALL 18 agents' templates (increasing package size significantly) or allow dynamic generation?",
          "selected": true,
          "answer": "Research which agents support auto-loading project context files (AGENT.md pattern) vs requiring slash commands. Install both for v1 to maximize compatibility."
        },
        {
          "text": "@human: Should slash command templates be generated on-the-fly from shared logic or pre-built and bundled?",
          "selected": true,
          "answer": "Install THREE files per agent: 1) Root stub (AGENTS.md or AGENT_NAME.md) for auto-loading, 2) Full doc (spec/AGENT_NAME.md) for comprehensive workflow, 3) Slash command (.agent/commands/fspec.md) for manual trigger. Most agents (Claude, Cursor, Cline, Windsurf, Copilot, etc.) auto-load root stubs; CLI-only tools need slash commands."
        },
        {
          "text": "@human: How do we handle agents that don't support meta-cognitive prompts like 'ultrathink' (e.g., CLI-only Aider)?",
          "selected": true,
          "answer": "fspec init is idempotent and supports agent switching. Running 'fspec init --agent=cursor' after 'fspec init --agent=claude' should remove Claude-specific files (CLAUDE.md, spec/CLAUDE.md, .claude/commands/) and install Cursor-specific files (CURSOR.md or AGENTS.md, spec/CURSOR.md, .cursor/commands/). All files are auto-generated, safe to replace."
        },
        {
          "text": "@human: Should fspec init use interactive mode by default, or require explicit flags?",
          "selected": true,
          "answer": "Interactive selector is SINGLE-SELECT: arrow keys to navigate/highlight, Enter to confirm the currently highlighted agent. No multi-select, no checkboxes. For multiple agents, user must run 'fspec init --agent=X --agent=Y' using CLI flags."
        },
        {
          "text": "@human: Should interactive selector auto-detect installed agents and how should the list be sorted?",
          "selected": true,
          "answer": "Default highlighted agent should be the FIRST DETECTED agent (if any were auto-detected). If no agents detected, default to first agent in sorted list."
        },
        {
          "text": "@human: Should we support all 18 agents in v1, or start with a smaller set? Should we use separate template files or dynamic generation?",
          "selected": true,
          "answer": "No --no-interactive flag needed. Presence of --agent flags is sufficient to determine mode: if --agent present, use CLI mode; if no --agent, use interactive mode. A --no-interactive flag without --agent makes no sense."
        },
        {
          "text": "@human: Should we install both AGENT.md (for auto-load on startup) AND a slash command (for manual trigger), or just one? Which agents support auto-loading project context files?",
          "selected": true,
          "answer": "fspec init is NON-DESTRUCTIVE: if .cursor/commands/ already exists with custom files, create fspec.md alongside them. Never delete or overwrite user's custom files. Only manage fspec-specific files (AGENTS.md, spec/AGENT.md, .agent/commands/fspec.md)."
        },
        {
          "text": "@human: Should fspec init be idempotent? If user runs 'fspec init --agent=cursor' after already running 'fspec init --agent=claude', what should happen?",
          "selected": true,
          "answer": "Single base template with dynamic transformations based on agent.supportsSystemReminders, agent.supportsMetaCognition, and agent.category flags. Use TemplateManager pattern: ONE base template transformed via regex replacement and formatting functions."
        },
        {
          "text": "@human: Is the interactive selector single-select (arrow to highlight, enter to confirm) or multi-select (space to toggle checkboxes, enter to confirm multiple)?",
          "selected": true,
          "answer": "System-reminders: <system-reminder> → **⚠️ IMPORTANT:** (IDE agents with emoji) or **IMPORTANT:** (CLI agents). Meta-cognitive prompts: 'ultrathink', 'deeply consider' → removed for CLI-only agents. Use regex patterns. Agent placeholders: {{AGENT_NAME}}, {{SLASH_COMMAND_PATH}}, {{AGENT_ID}} replaced via string.replace()."
        },
        {
          "text": "@human: In interactive selector, which agent should be highlighted by default when the UI opens?",
          "selected": true,
          "answer": "ONE comprehensive fspec.md file per agent (like current 1010-line pattern), NOT multiple smaller files. Different formats: Markdown with YAML frontmatter (Claude, Cursor, Cline) or TOML (Gemini CLI, Qwen Code). Generate using TemplateManager pattern: shared body + agent-specific wrapper."
        },
        {
          "text": "@human: Do we need a --no-interactive flag, or is presence of --agent flags sufficient to disable interactive mode?",
          "selected": true,
          "answer": "Validate agent IDs against registry before installation. Check file permissions before writing. Create directories recursively (mkdir -p). Handle missing templates gracefully with error messages. Wrap blocking hook failures in <system-reminder> tags for AI visibility."
        },
        {
          "text": "@human: If target directories already exist with user's custom files (e.g., .cursor/commands/my-command.md), should fspec init be destructive or non-destructive?",
          "selected": true,
          "answer": "Use viteStaticCopy plugin to copy base template files (spec/templates/base/*.md) into dist/ during build. Templates bundled into dist/spec/templates/base/. Component code bundled normally by Vite. Template resolver tries production path first, falls back to dev path."
        },
        {
          "text": "@human: How do we transform the base template for different agents? Single base template with dynamic transformations based on agent.supportsSystemReminders, agent.supportsMetaCognition flags? Or multiple template tiers?",
          "selected": true,
          "answer": "id: string, name: string, description: string, slashCommandPath: string, slashCommandFormat: 'markdown' | 'toml', supportsSystemReminders: boolean, supportsMetaCognition: boolean, docTemplate: string, rootStubFile: string, detectionPaths: string[], available: boolean, category: 'ide' | 'cli' | 'extension'"
        },
        {
          "text": "@human: What exact patterns need transformation? 'ultrathink' → 'carefully consider'? '<system-reminder>' → '<\\!-- IMPORTANT: -->'? Any others? Should we use regex, string replacement, or AST parsing?",
          "selected": true,
          "answer": "Transform 'ultrathink' → removed (CLI agents) or kept (IDE agents). System-reminder: '<system-reminder>' → '**⚠️ IMPORTANT:**' (IDE with emoji) or '**IMPORTANT:**' (CLI). Also transform: 'deeply consider', 'take a moment to reflect' → removed for CLI agents. Use regex replacement: /<system-reminder>([\\s\\S]*?)<\\/system-reminder>/g. Placeholders: {{AGENT_NAME}}, {{SLASH_COMMAND_PATH}} via string.replace()."
        },
        {
          "text": "@human: Current .claude/commands/fspec.md is 1010 lines (comprehensive workflow guide). Should we generate ONE comprehensive fspec.md per agent (same pattern), or MULTIPLE smaller commands (fspec-validate.md, fspec-format.md, etc.)?",
          "selected": true,
          "answer": "Generate ONE comprehensive fspec.md per agent (1010-line pattern like current .claude/commands/fspec.md). NOT multiple smaller files. This file contains complete ACDD workflow, Example Mapping process, coverage tracking, etc. Format varies by agent: Markdown with YAML frontmatter (Claude, Cursor, Cline, etc.) or TOML (Gemini CLI, Qwen Code)."
        },
        {
          "text": "@human: Error handling: What should happen if user runs 'fspec init --agent=invalid-id'? Show list of valid agents? Exit with error code? What if template files missing from dist/?",
          "selected": true,
          "answer": "Invalid agent ID: Show error with list of valid agents, exit code 1. Missing templates: Check dist/spec/templates/ and fallback to spec/templates/. If both missing, show error explaining distribution may be corrupted. Suggest reinstalling fspec. Permission errors: Show clear message about directory permissions, suggest chmod/chown fixes."
        },
        {
          "text": "@human: Vite bundling: Should we bundle base template files (spec/templates/base/AGENT.md) in dist/, or bundle transformation logic as compiled code? What's the dist/ structure after build?",
          "selected": true,
          "answer": "Bundle base template files using viteStaticCopy plugin. Structure: dist/spec/templates/base/AGENT.md (ONE base template with placeholders). Runtime: templateGenerator.ts reads from dist/spec/templates/base/, transforms based on agent config, outputs to spec/AGENT.md. Dev mode: reads from spec/templates/base/. Template resolver tries production path first, falls back to dev."
        },
        {
          "text": "@human: Agent registry structure: Confirm complete AgentConfig interface fields (id, name, description, category, rootStubFile, fullDocFile, slashCommandPath, slashCommandFormat, detectionPaths, supportsSystemReminders, supportsMetaCognition, popularity for sorting). Missing any fields?",
          "selected": true,
          "answer": "AgentConfig fields confirmed: id (string), name (string), description (string), slashCommandPath (string), slashCommandFormat ('markdown' | 'toml'), supportsSystemReminders (boolean), supportsMetaCognition (boolean), docTemplate (string, e.g. 'CLAUDE.md'), rootStubFile (string, e.g. 'CLAUDE.md' or 'AGENTS.md'), detectionPaths (string[], e.g. ['.claude/', '.claude/commands/']), available (boolean), category ('ide' | 'cli' | 'extension'). Optional: popularity (number) for sorting."
        },
        {
          "text": "@human: Claude Code uses <system-reminder> tags for invisible-to-user workflow guidance. What equivalent mechanisms do other agents have for getting attention and providing hidden instructions? Need research on all 18 agents' attention/instruction mechanisms.",
          "selected": true,
          "answer": "Research complete - see spec/attachments/INIT-004/agent-instruction-mechanisms-research.md. Finding: Claude Code's <system-reminder> tags are UNIQUE. All other agents use visible Markdown patterns: bold text (**IMPORTANT:**), headers (###), code blocks, blockquotes. Transformation required: <system-reminder> → **⚠️ IMPORTANT:** (IDE agents) or **IMPORTANT:** (CLI agents). No equivalent invisible mechanism exists for other agents."
        }
      ],
      "architectureNotes": [
        "Create agent registry in spec/agents.json mapping agent names to configuration (doc template, slash command path, system-reminder support, etc.)",
        "Refactor init command: add --agent flag, read agent config from registry, copy appropriate templates, generate agent-specific documentation",
        "Create template system: templates/{agent-name}/AGENT.md and templates/{agent-name}/slash-command.md with variable substitution",
        "Add agent detection: check for .claude/, .cursor/, .continue/ directories or environment variables to auto-detect active agent",
        "Update vite.config.ts to copy spec/templates/{agent}/**/*.md to dist/spec/templates/{agent}/ for bundled distribution",
        "Template matrix challenge: 20-30 fspec commands × 18 agents = 360-540 template files. Consider shared template body + agent-specific wrappers to reduce duplication",
        "Init command must locate templates from bundled distribution (handle both dev: spec/templates/ and production: dist/spec/templates/ paths)",
        "ink/react Integration Architecture: Refactor fspec to use ink/react for ALL interactive commands (not just init). Create shared component library in src/components/ (AgentSelector, Spinner, ErrorMessage, SuccessMessage, ConfirmPrompt, etc.) and shared hooks in src/hooks/ (useKeyboardNavigation, useSafeInput, useAgentSelection). Follow DRY principles - reuse cage patterns (MainMenu navigation, keyboard input handling, visual feedback). Commands like 'fspec reverse', 'fspec board', future interactive commands should all use shared ink/react components. Vite build handles React/JSX compilation."
      ],
      "userStory": {
        "role": "developer using any AI coding agent",
        "action": "initialize fspec in my project with agent-specific configuration",
        "benefit": "I get properly formatted documentation and setup tailored to my agent without manual editing"
      },
      "assumptions": [
        "Auto-detect with fallback to explicit flag: Check for agent directories (.claude/, .cursor/, .continue/) and environment variables first, but allow --agent flag to override. Default to Claude Code if no detection",
        "Strip system-reminder tags for non-Claude agents: Use agent registry to check 'supportsSystemReminders' flag. For agents without support, strip tags but preserve content as comments or agent-specific annotations",
        "Bundle ALL 18 agents in v1 for simplicity and feature completeness. Future optimization: lazy-download popular agents on first use to reduce package size",
        "Research which agents support auto-loading project context files (AGENT.md pattern) vs requiring slash commands. Install both for v1 to maximize compatibility.",
        "Single base template with dynamic transformations based on agent.supportsSystemReminders, agent.supportsMetaCognition, and agent.category flags. Use TemplateManager pattern: ONE base template transformed via regex replacement and formatting functions.",
        "System-reminders: <system-reminder> → **⚠️ IMPORTANT:** (IDE agents with emoji) or **IMPORTANT:** (CLI agents). Meta-cognitive prompts: 'ultrathink', 'deeply consider' → removed for CLI-only agents. Use regex patterns. Agent placeholders: {{AGENT_NAME}}, {{SLASH_COMMAND_PATH}}, {{AGENT_ID}} replaced via string.replace().",
        "ONE comprehensive fspec.md file per agent (like current 1010-line pattern), NOT multiple smaller files. Different formats: Markdown with YAML frontmatter (Claude, Cursor, Cline) or TOML (Gemini CLI, Qwen Code). Generate using TemplateManager pattern: shared body + agent-specific wrapper.",
        "Use viteStaticCopy plugin to copy base template files (spec/templates/base/*.md) into dist/ during build. Templates bundled into dist/spec/templates/base/. Component code bundled normally by Vite. Template resolver tries production path first, falls back to dev path.",
        "id: string, name: string, description: string, slashCommandPath: string, slashCommandFormat: 'markdown' | 'toml', supportsSystemReminders: boolean, supportsMetaCognition: boolean, docTemplate: string, rootStubFile: string, detectionPaths: string[], available: boolean, category: 'ide' | 'cli' | 'extension'",
        "Transform 'ultrathink' → removed (CLI agents) or kept (IDE agents). System-reminder: '<system-reminder>' → '**⚠️ IMPORTANT:**' (IDE with emoji) or '**IMPORTANT:**' (CLI). Also transform: 'deeply consider', 'take a moment to reflect' → removed for CLI agents. Use regex replacement: /<system-reminder>([\\s\\S]*?)<\\/system-reminder>/g. Placeholders: {{AGENT_NAME}}, {{SLASH_COMMAND_PATH}} via string.replace().",
        "Bundle base template files using viteStaticCopy plugin. Structure: dist/spec/templates/base/AGENT.md (ONE base template with placeholders). Runtime: templateGenerator.ts reads from dist/spec/templates/base/, transforms based on agent config, outputs to spec/AGENT.md. Dev mode: reads from spec/templates/base/. Template resolver tries production path first, falls back to dev.",
        "AgentConfig fields confirmed: id (string), name (string), description (string), slashCommandPath (string), slashCommandFormat ('markdown' | 'toml'), supportsSystemReminders (boolean), supportsMetaCognition (boolean), docTemplate (string, e.g. 'CLAUDE.md'), rootStubFile (string, e.g. 'CLAUDE.md' or 'AGENTS.md'), detectionPaths (string[], e.g. ['.claude/', '.claude/commands/']), available (boolean), category ('ide' | 'cli' | 'extension'). Optional: popularity (number) for sorting."
      ],
      "estimate": 8
    },
    "RES-001": {
      "id": "RES-001",
      "title": "Interactive research command with multiple backend support",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-21T07:32:19.749Z",
      "updatedAt": "2025-10-21T07:32:27.373Z",
      "description": "Implement 'fspec research' command that provides AI agents with interactive choice of registered research endpoints during specifying phase (example mapping, architecture planning). Support multiple backends: (1) Perplexity via MCP (https://github.com/jsonallen/perplexity-mcp) for web search, (2) Nanobrowser via MCP for browser automation and web scraping, (3) Mindstrike via CLI for AI-powered knowledge queries. Command should register available endpoints, present interactive selection to AI agent, execute research query, and return formatted results.",
      "epic": "example-driven-discovery",
      "children": [],
      "dependsOn": [
        "MCP-002"
      ]
    },
    "BUG-024": {
      "id": "BUG-024",
      "title": "Fix dependencies command error with work unit ID argument",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T07:33:29.645Z",
      "updatedAt": "2025-10-21T07:50:38.438Z",
      "description": "The 'fspec dependencies <id>' command throws 'Invalid action: <id>' error instead of showing dependency tree. Error occurs at dist/index.js:8359. Command should accept work unit ID as argument and display dependency relationships (dependsOn, blocks, blockedBy, relatesTo).",
      "children": [],
      "attachments": [
        "spec/attachments/BUG-024/bug-024-error-details.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T07:35:58.546Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T07:38:45.398Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T07:49:54.638Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T07:50:09.592Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T07:50:38.438Z"
        }
      ],
      "rules": [
        "Legacy dependencies() function must be removed to prevent CLI routing conflicts"
      ],
      "examples": [
        "User runs 'fspec dependencies RES-001' and receives dependency list instead of 'Invalid action' error",
        "Command shows 'Dependencies for RES-001:' followed by relationship lists (blocks, blockedBy, dependsOn, relatesTo)"
      ],
      "architectureNotes": [
        "Root Cause: Legacy dependencies() function (line 1017-1072 in src/commands/dependencies.ts) is still exported and callable. This function expects (action, workUnitId, options) but CLI passes (workUnitId, options) directly to it. Solution: Remove the legacy function since registerDependenciesCommand() now uses showDependencies() instead."
      ],
      "userStory": {
        "role": "AI agent using fspec for project management",
        "action": "view work unit dependencies using 'fspec dependencies <id>'",
        "benefit": "I can understand dependency relationships and plan work order"
      }
    },
    "INIT-005": {
      "id": "INIT-005",
      "title": "Fix multi-agent support critical issues",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T10:50:08.007Z",
      "updatedAt": "2025-10-21T11:03:45.953Z",
      "description": "Address 25 bugs and anti-patterns discovered during INIT-004 implementation code review. Includes 3 critical issues (destructive file deletion, path traversal vulnerability, duplicate agent directories), 4 high priority, 6 medium, and 12 low priority issues.",
      "children": [],
      "attachments": [
        "spec/attachments/INIT-005/post-implementation-issues.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T10:51:51.424Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T10:55:38.963Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T10:58:21.113Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T11:03:12.454Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T11:03:45.953Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec with multiple AI agents",
        "action": "have critical bugs and anti-patterns from INIT-004 implementation fixed",
        "benefit": "multi-agent support is production-ready, secure, and follows best practices"
      },
      "rules": [
        "Agent switching must ONLY delete fspec-specific files (AGENT.md, spec/AGENT.md, .agent/commands/fspec.md), never entire directories or user's custom files",
        "Agent registry slashCommandPath must be validated to prevent path traversal attacks (no ../, no absolute paths, must be relative to project root)",
        "Each agent must have unique slashCommandPath and rootStubFile to avoid conflicts (e.g., codex and codex-cli cannot both use .codex/commands/)",
        "System-reminder regex transformation must handle nested tags, multiline content, and edge cases without breaking content",
        "Meta-cognitive prompt removal must use word boundaries to avoid corrupting valid words containing 'think' (e.g., 'rethink', 'thinking')",
        "Invalid agent ID errors must include list of valid agent IDs to help users discover available options"
      ],
      "examples": [
        "Critical: User runs 'fspec init --agent=cursor' after 'fspec init --agent=claude', system deletes .claude/commands/fspec.md only (not entire .claude/commands/ directory with user's custom commands)",
        "Critical: Agent registry contains malicious slashCommandPath '../../../etc/passwd', validation rejects it before creating files",
        "Critical: codex and codex-cli agents both try to use .codex/commands/, installation detects conflict and shows clear error message",
        "High: Template contains nested system-reminders, transformation correctly handles both levels without breaking content structure",
        "High: Template contains 'rethinking' and 'thinking', meta-cognitive removal only strips 'ultrathink' and 'deeply consider', preserves valid words",
        "High: User runs 'fspec init --agent=invalid-agent', error message lists all 18 valid agent IDs with descriptions"
      ],
      "estimate": 5
    },
    "INIT-006": {
      "id": "INIT-006",
      "title": "Wire up multi-agent support to fspec init command",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T11:10:11.887Z",
      "updatedAt": "2025-10-21T13:14:07.492Z",
      "description": "Update registerInitCommand to use new multi-agent system (installAgents, agent registry, interactive selector). Deprecate and remove old single-agent code (init function, generateTemplate, copyClaudeTemplate). The new infrastructure exists but isn't being called - fspec init still defaults to Claude-only installation.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T11:10:26.993Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T11:13:42.750Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T11:14:27.089Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T11:17:31.868Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T11:39:48.433Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T11:49:45.027Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T11:50:30.315Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T12:01:28.869Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T12:04:45.819Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T12:05:34.971Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T12:07:20.322Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T12:13:16.564Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T12:16:35.634Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T12:19:06.529Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T12:21:12.211Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T12:31:51.329Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T12:34:59.166Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T12:36:46.905Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T12:45:27.354Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T12:45:47.085Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T12:47:53.774Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T12:49:29.009Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T12:49:35.452Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T12:52:10.515Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T12:52:18.545Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T13:09:33.571Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T13:10:54.118Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T13:12:16.851Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T13:12:24.992Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T13:14:07.492Z"
        }
      ],
      "rules": [
        "registerInitCommand must call installAgents() with interactive selector when no --agent flag provided",
        "Old init() function, generateTemplate(), and copyClaudeTemplate() must be removed after migration",
        "Command must accept --agent flag (can be repeated) for non-interactive mode",
        "Interactive selector must use agent auto-detection to pre-select detected agents",
        "fspec init must work after global npm install without requiring local files",
        "Generated files must be customized for each agent (agent-specific names, paths, features)",
        "Interactive selector uses single-select navigation (arrow keys + ENTER), NOT checkboxes",
        "Cursor highlights currently selected agent, ENTER key immediately installs that agent",
        "NO multi-select - user can only select ONE agent at a time in interactive mode"
      ],
      "examples": [
        "User runs 'fspec init' with no flags, sees interactive agent selector with auto-detected agents pre-selected",
        "User runs 'fspec init --agent=cursor', skips interactive selector and installs Cursor directly",
        "After migration, old init(), generateTemplate(), copyClaudeTemplate() functions are deleted from init.ts",
        "User installs fspec globally with 'npm install -g fspec', then runs 'fspec init' in new project - command works without errors",
        "After running 'fspec init --agent=cursor', generated files contain 'Cursor' not 'Claude Code' in agent names",
        "After completing migration, old code paths (reading from project's .claude/commands/fspec.md) are completely removed",
        "User runs 'fspec init', sees list with cursor on first agent, presses down arrow twice to move cursor to Cline, presses ENTER, Cline is selected and installation starts",
        "User runs 'fspec init' in a directory with .claude/ folder, cursor starts on Claude Code (auto-detected), user presses ENTER, Claude Code is installed"
      ],
      "userStory": {
        "role": "developer using any AI coding agent",
        "action": "run 'fspec init' and get an interactive agent selector",
        "benefit": "I can choose my agent and get proper setup without needing to know the --agent flag syntax"
      },
      "estimate": 3
    },
    "BUG-025": {
      "id": "BUG-025",
      "title": "Intermittent test failure: command-help-system main help test",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-21T11:38:00.009Z",
      "updatedAt": "2025-10-22T01:46:07.007Z",
      "description": "The test 'Feature: Command Help System > Scenario: Main help mentions individual command help availability' fails intermittently in the full test suite with exit code 1, but passes when run individually. This suggests a test isolation or timing issue. The test has been temporarily skipped in src/commands/__tests__/command-help-system.test.ts:198.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T01:38:08.404Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T01:42:10.310Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T01:42:20.544Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T01:45:20.920Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T01:45:54.840Z"
        }
      ],
      "rules": [
        "Tests must not rebuild dist/index.js during execution as it causes race conditions"
      ],
      "examples": [
        "version-display.test.ts runs 'npm run build' while command-help-system.test.ts executes node dist/index.js --help, causing exit code 1 or undefined",
        "Test passes when run in isolation but fails when run with full suite due to dist/index.js being rebuilt by version-display.test.ts"
      ],
      "architectureNotes": [
        "Root cause: version-display.test.ts rebuilds dist/index.js during test execution, causing race condition with command-help-system.test.ts",
        "Solution: Mark version-display.test.ts with test.sequential() to prevent parallel execution with other CLI tests"
      ],
      "userStory": {
        "role": "developer running fspec test suite",
        "action": "run all tests concurrently without race conditions",
        "benefit": "tests are reliable and pass consistently"
      },
      "estimate": 2
    },
    "BUG-026": {
      "id": "BUG-026",
      "title": "Flaky tests: command-help-system and foundation-existence-check fail in full suite but pass individually",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-21T13:01:16.689Z",
      "updatedAt": "2025-10-22T01:54:20.584Z",
      "description": "Two test files pass when run individually but fail in full suite - indicates test isolation issues.\n\nCOMMAND HELP TEST:\n- File: src/commands/__tests__/command-help-system.test.ts:223\n- Scenario: Display help for Example Mapping command with patterns\n- Expected: exitCode 0, Actual: exitCode 1 (full suite) | exitCode 0 (isolated)\n- Command: node dist/index.js add-question --help\n\nFOUNDATION EXISTENCE CHECK TEST:\n- File: src/commands/__tests__/foundation-existence-check.test.ts:172\n- Scenario: Run validate command without foundation.json (read-only exempt)\n- Expected: exitCode 0, Actual: exitCode undefined (full suite) | exitCode 0 (isolated)\n- Command: fspec validate (using execa)\n\nROOT CAUSE HYPOTHESIS:\n- Global state pollution from earlier tests\n- Async cleanup issues (tests completing out of order)\n- File system state not properly isolated\n- CLI process state leaking between tests\n\nNEXT STEPS:\n1. Add beforeEach/afterEach hooks for clean state\n2. Check for process.exit() calls affecting exit codes\n3. Investigate test execution order to find polluting tests\n4. Use vitest --sequence.shuffle to identify order dependencies",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T01:47:09.811Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T01:54:05.760Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T01:54:07.340Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T01:54:09.258Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T01:54:09.990Z"
        }
      ],
      "rules": [
        "Tests that execute dist/index.js must not run in parallel with tests that rebuild it"
      ],
      "examples": [
        "command-help-system.test.ts executes 'node dist/index.js add-question --help' and gets exit code 1 when version-display.test.ts rebuilds dist/index.js in parallel",
        "foundation-existence-check.test.ts executes 'fspec validate' and gets exit code undefined when version-display.test.ts rebuilds dist/index.js in parallel",
        "After fixing BUG-025 (marking version-display.test.ts as sequential), both tests pass consistently in full suite"
      ],
      "architectureNotes": [
        "Root cause: Same as BUG-025 - version-display.test.ts rebuilding dist/index.js created race conditions with ALL CLI tests",
        "Solution: Fixed by BUG-025 solution - marking version-display.test.ts with describe.sequential() prevents parallel execution",
        "Impact: Both command-help-system.test.ts:223 and foundation-existence-check.test.ts:172 now pass consistently in full suite (verified across multiple runs)"
      ],
      "userStory": {
        "role": "developer running full test suite",
        "action": "have all CLI tests pass reliably",
        "benefit": "I can trust test results without intermittent failures"
      },
      "estimate": 1
    },
    "INIT-008": {
      "id": "INIT-008",
      "title": "Agent runtime detection for context-aware CLI output",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T13:28:51.970Z",
      "updatedAt": "2025-10-22T08:46:47.154Z",
      "description": "WHAT ALREADY EXISTS:\n1. Template generation time transformations (during 'fspec init'):\n   - removeMetaCognitivePrompts() strips 'ultrathink', 'deeply consider' for CLI agents\n   - stripSystemReminders() transforms <system-reminder> tags to bold text for non-Claude\n   - Agent registry has supportsMetaCognition and supportsSystemReminders flags\n   - This works great for generated files (AGENT.md, slash commands)\n\n2. Environment variable:\n   - FSPEC_DISABLE_REMINDERS=1 disables system-reminders entirely\n\nWHAT'S MISSING (THE ACTUAL PROBLEM):\n1. Runtime detection: fspec commands don't know which agent is running them\n   - 'fspec validate' emits <system-reminder> for ALL agents (only Claude understands)\n   - 'fspec update-work-unit-status' uses system-reminders regardless of agent\n   - Error messages don't adapt (all use <system-reminder> tags)\n   - Help commands don't tailor output based on agent\n\n2. CLI output adaptation:\n   - Commands should emit <system-reminder> for Claude Code\n   - Commands should emit **⚠️ IMPORTANT:** for Cursor/Cline/IDE agents  \n   - Commands should emit **IMPORTANT:** for CLI-only agents (Aider, Gemini)\n   - Currently everything uses <system-reminder> by default\n\n3. No detection mechanism:\n   - Can't tell if it's Claude vs Cursor vs Aider running the command\n   - No FSPEC_AGENT environment variable\n   - No config file (~/.fspec/config.json)\n   - No auto-detection from project files (.claude/, .cursor/)\n\nDetection strategies to implement:\n1. Environment variable: FSPEC_AGENT=claude (highest priority)\n2. Config file: ~/.fspec/config.json with {\"defaultAgent\": \"claude\"}\n3. Auto-detect from project: Check for .claude/, .cursor/, etc. in cwd\n4. Fallback: Safe default (plain text, no system-reminders)\n\nAcceptance Criteria:\n- Runtime agent detection using priority chain (env > config > auto-detect > default)\n- All CLI commands adapt output based on detected agent\n- System-reminders only emitted for Claude Code at runtime\n- Other agents get transformed output (bold text + emoji or plain)\n- Detection works across all 18 supported agents\n- Fallback to safe defaults if detection fails\n- Documentation for FSPEC_AGENT env var and ~/.fspec/config.json",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T08:28:46.801Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T08:41:15.717Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T08:44:03.360Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T08:45:18.471Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T08:46:47.154Z"
        }
      ],
      "rules": [
        "Detection must use priority chain: FSPEC_AGENT env var > config file > auto-detect from project files > safe default",
        "System-reminders only emitted for Claude Code at runtime",
        "Cursor/Cline/IDE agents receive **⚠️ IMPORTANT:** with bold text and emoji",
        "CLI-only agents (Aider, Gemini) receive **IMPORTANT:** plain text without emoji",
        "Must support all 18 agents defined in existing agent registry",
        "Must fallback to safe default (plain text, no system-reminders) if detection fails",
        "Per-project config file at spec/fspec-config.json (consistent with other fspec config files like spec/fspec-hooks.json)",
        "No runtime auto-detection needed. Agent is detected during 'fspec init' (using existing detection logic) and written to spec/fspec-config.json. All subsequent commands read from config file.",
        "Agent registry already exists with all needed metadata. 'fspec init' detects agent and writes to config. Runtime commands read config to determine output format (system-reminder for Claude, bold+emoji for IDE agents, plain for CLI agents)."
      ],
      "examples": [
        "User sets FSPEC_AGENT=claude, runs 'fspec validate', output contains <system-reminder> tags",
        "Cursor user (no env var) runs 'fspec validate' in project with .cursor/ directory, output contains **⚠️ IMPORTANT:** with emoji",
        "Aider user runs 'fspec validate' with no env var or config, auto-detects CLI-only agent, output contains **IMPORTANT:** plain text",
        "User has ~/.fspec/config.json with defaultAgent=cursor but FSPEC_AGENT=claude is set, Claude is used (env var takes priority)",
        "Unknown environment with no detection clues, system falls back to safe default (plain text output, no system-reminders)"
      ],
      "questions": [
        {
          "text": "@human: Should config file be global (~/.fspec/config.json) or per-project (.fspec/config.json) or both with priority?",
          "selected": true,
          "answer": "Per-project config file at spec/fspec-config.json (consistent with other fspec config files like spec/fspec-hooks.json)"
        },
        {
          "text": "@human: What are the exact directory/file patterns for auto-detection (e.g., .claude/, .cursor/, .aider/config)?",
          "selected": true,
          "answer": "No runtime auto-detection needed. Agent is detected during 'fspec init' (using existing detection logic) and written to spec/fspec-config.json. All subsequent commands read from config file."
        },
        {
          "text": "@human: Should the agent registry be extended with output format preferences (system-reminder vs bold vs plain)?",
          "selected": true,
          "answer": "Agent registry already exists with all needed metadata. 'fspec init' detects agent and writes to config. Runtime commands read config to determine output format (system-reminder for Claude, bold+emoji for IDE agents, plain for CLI agents)."
        }
      ],
      "userStory": {
        "role": "AI agent (Claude Code, Cursor, Aider, etc.) running fspec commands",
        "action": "have CLI output adapted to my capabilities (system-reminders, bold text, plain text)",
        "benefit": "I can understand and act on fspec guidance effectively without confusion or unsupported syntax"
      },
      "estimate": 5
    },
    "TECH-002": {
      "id": "TECH-002",
      "title": "Audit AI agent files for .gitignore exclusions",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-21T13:50:11.071Z",
      "updatedAt": "2025-10-22T06:55:51.180Z",
      "description": "Review all supported AI agents/tools and identify which files should be excluded from version control via .gitignore. Agents to investigate: Claude Code, Cursor, Windsurf, Copilot, and any other AI coding assistants we support. Look for: 1) Agent-specific configuration files, 2) Temporary files, 3) Cache directories, 4) Session state files, 5) Any generated files that shouldn't be committed. Create comprehensive .gitignore entries to prevent these files from being tracked.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T06:52:28.874Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T06:52:35.525Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T06:55:49.589Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T06:55:51.180Z"
        }
      ]
    },
    "BUG-027": {
      "id": "BUG-027",
      "title": "Stash system not adding files before creating stash",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-21T13:51:56.223Z",
      "updatedAt": "2025-10-22T01:07:49.222Z",
      "description": "The stash/restore checkpoint system appears to not be stashing any files. Investigation suggests that files are not being added to git before creating the stash, resulting in empty stashes. Need to verify: 1) Are files being staged with 'git add' before 'git stash'? 2) Are untracked files being included? 3) Are there any error messages being suppressed? 4) Test with actual file modifications to confirm stash behavior.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T00:27:04.797Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T00:52:31.871Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T00:54:13.903Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T01:07:08.885Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T01:07:49.222Z"
        }
      ],
      "questions": [
        {
          "text": "@human: What is the stash system currently doing wrong? When I create a checkpoint, what files should be saved and what actually gets saved?",
          "selected": true,
          "answer": "The stash system is using isomorphic-git which doesn't support git stash. It tries to simulate stashing with git.commit() but never stages files first with git.add(), resulting in empty commits that capture nothing. Files should be stashed using real 'git stash push -u -m message' command via execa (which the project already uses elsewhere)."
        },
        {
          "text": "@human: Should the checkpoint system stash both tracked modified files AND untracked new files? Or only tracked files?",
          "selected": true,
          "answer": "Yes, both tracked modified files AND untracked new files should be included using 'git stash push -u' where -u flag includes untracked files while respecting .gitignore. This matches the feature specification line 11."
        },
        {
          "text": "@human: Should we update the feature specification (intelligent-checkpoint-system-for-workflow-transitions.feature line 11) to document that files must be staged before stashing, not using native git -u flag?",
          "selected": true,
          "answer": "Yes, update the feature spec to document that isomorphic-git requires staging untracked files with git.add() before git.stash({ op: 'create' }) can capture them. This is a limitation of isomorphic-git, not native git."
        },
        {
          "text": "@human: For checkpoint restoration, should we attempt to detect and handle merge conflicts (if user modified files since checkpoint), or simply overwrite with checkpoint contents?",
          "selected": true,
          "answer": "Detect and handle conflicts. Compare file contents byte-by-byte. If conflicts detected, emit system-reminder with conflicted files and recommend creating new checkpoint first. Do NOT overwrite without user awareness."
        },
        {
          "text": "@human: Should checkpoint restoration preserve file permissions and timestamps, or just content?",
          "selected": true,
          "answer": "Just content. File permissions and timestamps are not critical for checkpoint use case (experimentation and rollback). Focus on content restoration only."
        }
      ],
      "rules": [
        "isomorphic-git HAS native git.stash() API with 'create' operation that creates stash commit without modifying working directory or refs",
        "isomorphic-git stash only handles TRACKED files - untracked files must be staged with git.add() BEFORE creating checkpoint for them to be captured",
        "Must reset index after checkpoint creation to avoid polluting user's staging area",
        "Store checkpoint refs in custom namespace (refs/fspec-checkpoints/{work-unit-id}/{checkpoint-name}) for organization and easy listing",
        "Checkpoints must capture both modified tracked files AND new untracked files (respecting .gitignore)",
        "Restoration reads checkpoint from custom ref (refs/fspec-checkpoints/{work-unit-id}/{checkpoint-name}) then manually restores files using git.readBlob() and fs.writeFile()",
        "Conflict detection compares working directory file contents vs checkpoint file contents byte-by-byte - if different, file is marked as conflicted",
        "If conflicts detected, emit system-reminder with conflicted files list and recommended actions (create new checkpoint first) - do NOT modify any files",
        "Files in checkpoint but not in working directory are restored (recreated) - files in working directory but not in checkpoint are ignored (left untouched)",
        "Cannot use git.stash({ op: 'apply' }) because our custom ref namespace (refs/fspec-checkpoints) is incompatible with isomorphic-git's reflog-based stash access",
        "Detect and handle conflicts. Compare file contents byte-by-byte. If conflicts detected, emit system-reminder with conflicted files and recommend creating new checkpoint first. Do NOT overwrite without user awareness."
      ],
      "examples": [
        "Current bug: git.commit() called without git.add(), creates empty commit that captures nothing",
        "User modifies tracked file README.md, runs checkpoint, file is staged then stashed with git.stash({ op: 'create' }), working directory unchanged",
        "User creates new untracked file auth.test.ts, runs checkpoint, file is staged with git.add() then captured by stash, working directory unchanged",
        "User modifies README.md and creates new.ts, runs checkpoint, both files staged and captured, index reset afterward, working directory unchanged",
        "User restores checkpoint, files from stash commit are read and written back to working directory, all files (tracked + previously-staged untracked) restored",
        "User creates checkpoint 'baseline', modifies files more, runs restore, all files read from checkpoint commit using git.readBlob() and written to working directory",
        "User creates checkpoint with file A (v1), modifies file A to v2, runs restore, conflict detected (contents differ), system-reminder emitted, file A NOT overwritten (stays v2)",
        "User creates checkpoint with file A, deletes file A from working directory, runs restore, file A is recreated from checkpoint (no conflict)",
        "User creates checkpoint, adds new file B (not in checkpoint), runs restore, file B is left untouched (ignored), only checkpoint files restored",
        "User tries to restore non-existent checkpoint name, git.resolveRef() throws error, restoration returns success=false with 'checkpoint not found' message"
      ],
      "attachments": [
        "spec/attachments/BUG-027/checkpoint-implementation-strategy.md",
        "spec/attachments/BUG-027/checkpoint-restoration-strategy.md"
      ],
      "assumptions": [
        "Yes, update the feature spec to document that isomorphic-git requires staging untracked files with git.add() before git.stash({ op: 'create' }) can capture them. This is a limitation of isomorphic-git, not native git.",
        "Just content. File permissions and timestamps are not critical for checkpoint use case (experimentation and rollback). Focus on content restoration only."
      ],
      "userStory": {
        "role": "developer using fspec checkpoints",
        "action": "create and restore checkpoints that actually capture all file changes",
        "benefit": "I can safely experiment and rollback without losing work"
      },
      "estimate": 5
    },
    "CLI-007": {
      "id": "CLI-007",
      "title": "Replace generic create-work-unit with type-specific commands",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T13:51:58.078Z",
      "updatedAt": "2025-10-25T07:29:27.515Z",
      "description": "Remove create-work-unit command entirely. Add 3 type-specific commands: create-story, create-bug, create-task. Each command emits intelligent system-reminders that guide AI agents to the appropriate discovery workflow: stories use Example Mapping, bugs use research commands (search-scenarios, search-implementation, show-coverage), tasks have minimal requirements. Breaking change (v2.0).",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-25T06:10:08.668Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-25T06:48:17.495Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-25T07:00:50.409Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-25T07:03:27.023Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-25T07:15:24.663Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-25T07:21:44.896Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T07:26:45.712Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-25T07:29:27.515Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec",
        "action": "create work units with appropriate guidance for each type",
        "benefit": "I follow the correct discovery workflow for stories, bugs, and tasks"
      },
      "rules": [
        "The generic create-work-unit command must be completely removed (breaking change)",
        "Each command must emit a type-specific system-reminder after creation guiding AI to the appropriate workflow",
        "create-bug must guide AI to research commands: search-scenarios, search-implementation, show-coverage",
        "create-story must guide AI to Example Mapping commands: add-rule, add-example, add-question, set-user-story",
        "create-task must indicate minimal requirements (optional feature file, optional tests)",
        "The generic create-work-unit command must be completely removed (breaking change)",
        "Each command must emit type-specific system-reminder after creation guiding AI to appropriate workflow",
        "create-story must guide AI to Example Mapping commands (add-rule, add-example, add-question, set-user-story)",
        "create-bug must guide AI to research commands (search-scenarios, search-implementation, show-coverage)",
        "create-task must indicate minimal requirements (optional feature file, optional tests)",
        "The group help in src/help.ts must be updated to reference create-story/bug/task instead of create-work-unit",
        "All command help files in src/commands/*-help.ts must be updated to remove create-work-unit references and add new command help files",
        "README.md must be updated to replace all create-work-unit examples with type-specific command examples",
        "spec/CLAUDE.md (auto-generated) must be regenerated to reflect new commands in all workflow examples",
        "All documentation files in docs/ directory must be searched and updated to replace create-work-unit with type-specific commands",
        "All system-reminders in source code must be found and updated to reference new commands (search for 'create-work-unit' in all .ts files)",
        "All test files must be updated to test new commands and verify old command is removed",
        "Commander.js registration in main CLI file must remove create-work-unit and register 3 new commands",
        "Complete example commands (Option A) - more helpful for AI agents because they provide concrete patterns, reduce cognitive load, and enable immediate action",
        "All options supported (Option A) - create-story/bug/task all support --epic, --description, --parent for consistency and because all types can legitimately have hierarchical relationships",
        "ALL mentions of 'work unit' terminology must be replaced with type-specific terminology (stories, bugs, tasks) throughout the ENTIRE codebase",
        "File names containing 'work-unit' must be evaluated for renaming to 'work-item' or type-specific names",
        "Hard breaking change (Option A) - v2.0.0 immediately removes create-work-unit and all work unit terminology. Clean break, no deprecation period.",
        "Variables named 'workUnit' must be renamed to contextually appropriate names (story, bug, task, or workUnit for generic cases)",
        "User-facing text saying 'work unit' must be replaced with 'story', 'bug', 'task', or collective term like 'work units'"
      ],
      "examples": [
        "AI runs 'fspec create-story AUTH \"User login\"' and sees system-reminder: 'Next steps - Example Mapping: 1. fspec add-rule AUTH-001 ..., 2. fspec add-example AUTH-001 ...'",
        "AI runs 'fspec create-bug BUG \"Login validation broken\"' and sees system-reminder: 'CRITICAL: Research existing code FIRST: 1. fspec search-scenarios --query=\"login\", 2. fspec search-implementation --function=\"validateLogin\"'",
        "AI runs 'fspec create-task TASK \"Setup CI/CD pipeline\"' and sees system-reminder: 'Task created. Tasks can skip feature files and tests for operational work.'",
        "AI runs 'fspec create-story AUTH \"User login\"' and sees system-reminder: 'Next steps - Example Mapping: 1. fspec add-rule AUTH-001 ..., 2. fspec add-example AUTH-001 ...'",
        "AI runs 'fspec create-bug BUG \"Login validation broken\"' and sees system-reminder: 'CRITICAL: Research existing code FIRST: 1. fspec search-scenarios --query=\"login\", 2. fspec search-implementation --function=\"validateLogin\"'",
        "AI runs 'fspec create-task TASK \"Setup CI/CD pipeline\"' and sees system-reminder: 'Task created. Tasks can skip feature files and tests for operational work.'",
        "In src/help.ts, replace 'fspec create-work-unit PREFIX \"Title\"' with 'fspec create-story PREFIX \"Title\"' in work management help",
        "Delete src/commands/create-work-unit-help.ts completely (breaking change)",
        "In README.md Quick Start section, replace 'fspec create-work-unit AUTH \"Login\"' with 'fspec create-story AUTH \"Login\"'",
        "Search all .ts files for 'create-work-unit' string and update to appropriate type-specific command based on context",
        "In spec/CLAUDE.md examples, replace all 'fspec create-work-unit' occurrences with context-appropriate create-story/bug/task",
        "Grep for system-reminder tags containing 'create-work-unit' and update each to reference new commands with type guidance",
        "Replace 'Work unit CLI-007' with 'Story CLI-007' in show-work-unit output",
        "Rename function updateWorkUnitStatus() to updateWorkUnitStatus() for generic cases, or updateStoryStatus() for type-specific",
        "In docs, change 'work unit management' to 'work unit management' or 'managing stories, bugs, and tasks'"
      ],
      "questions": [
        {
          "text": "@human: Should the system-reminders include complete example commands or just command templates?",
          "selected": true,
          "answer": "Complete example commands (Option A) - more helpful for AI agents because they provide concrete patterns, reduce cognitive load, and enable immediate action"
        },
        {
          "text": "@human: Should create-story/bug/refactor/task support all the same options as create-work-unit (--epic, --description, --parent)?",
          "selected": true,
          "answer": "All options supported (Option A) - create-story/bug/refactor/task all support --epic, --description, --parent for consistency and because all types can legitimately have hierarchical relationships"
        },
        {
          "text": "@human: When AI tries to use the old create-work-unit command, should it show a migration guide in the error message?",
          "selected": true,
          "answer": "No migration guide (Option B) - Command should simply not exist. AI will adapt by using available commands."
        },
        {
          "text": "@human: Should there be a deprecation period with warnings, or is this a hard breaking change (v2.0) that immediately removes create-work-unit?",
          "selected": true,
          "answer": "Hard breaking change (Option A) - v2.0.0 immediately removes create-work-unit and all work unit terminology. Clean break, no deprecation period."
        }
      ],
      "assumptions": [
        "No migration guide (Option B) - Command should simply not exist. AI will adapt by using available commands."
      ],
      "estimate": 5
    },
    "BUG-028": {
      "id": "BUG-028",
      "title": "spec/AGENT.md files contain stub instead of comprehensive workflow",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T21:09:20.138Z",
      "updatedAt": "2025-10-21T23:15:31.966Z",
      "description": "The spec/AGENT.md files (spec/CLAUDE.md, spec/CURSOR.md, etc.) currently contain only a 17-line stub that creates circular references. According to INIT-004 Rule 16, these files should contain the full ACDD workflow documentation (same 1019-line content as slash commands) with agent-specific transformations applied. Current implementation in templateGenerator.ts uses BASE_AGENT_TEMPLATE (17 lines) instead of getSlashCommandTemplate() content (1019 lines).",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T21:09:59.327Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T21:12:13.806Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T21:13:36.561Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T21:15:04.083Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T21:23:57.337Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T21:44:02.148Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T22:28:44.231Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T22:31:32.902Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T22:49:52.538Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T23:15:31.966Z"
        }
      ],
      "rules": [
        "spec/AGENT.md files must contain full Project Management Guidelines (2069 lines), not a 17-line stub",
        "generateAgentDoc() must use getProjectManagementTemplate() as base content, not BASE_AGENT_TEMPLATE",
        "Agent-specific transformations (stripSystemReminders, removeMetaCognitivePrompts, replacePlaceholders) must be applied to Project Management template",
        "Create projectManagementTemplate.ts following same pattern as slashCommandTemplate.ts with section files",
        "Keep BASE_AGENT_TEMPLATE only for root stub generation (CURSOR.md, AGENTS.md), use projectManagementTemplate for spec/AGENT.md",
        "Slash command generation (generateSlashCommandContent) is ALREADY CORRECT and should not be changed"
      ],
      "examples": [
        "Current spec/CLAUDE.md has 17 lines with circular reference: 'For using fspec commands and ACDD workflow: See spec/CLAUDE.md'",
        "Expected spec/CLAUDE.md should have ~2069 lines with full Project Management Guidelines including work unit management, ACDD workflow, coverage tracking, hooks, checkpoints",
        "Restored spec/CLAUDE.md (from GitHub) has 2069 lines titled 'Project Management and Specification Guidelines for fspec' - this content should be templated",
        "Slash command file .claude/commands/fspec.md has 1019 lines of ACDD workflow - this is DIFFERENT from spec/CLAUDE.md and should NOT be changed",
        "projectManagementTemplate.ts should follow same pattern as slashCommandTemplate.ts with section imports (getIntroSection, getProjectManagementSection, etc.)"
      ],
      "userStory": {
        "role": "AI agent (Cursor, Aider, etc.) reading spec/AGENT.md",
        "action": "read comprehensive ACDD workflow documentation",
        "benefit": "I understand the full fspec process without needing to read slash commands"
      },
      "architectureNotes": [
        "Create src/utils/projectManagementTemplate.ts following same pattern as slashCommandTemplate.ts",
        "Break spec/CLAUDE.md (2069 lines) into section files in src/utils/projectManagementSections/ directory",
        "Update generateAgentDoc() in src/utils/templateGenerator.ts to use getProjectManagementTemplate() instead of getSlashCommandTemplate()",
        "generateSlashCommandContent() is ALREADY CORRECT - it uses getSlashCommandTemplate() for .claude/commands/fspec.md (1019 lines)",
        "After fix, spec/CLAUDE.md should have ~2069 lines (Project Management Guidelines), .claude/commands/fspec.md should remain ~1019 lines (ACDD workflow)"
      ],
      "estimate": 2,
      "questions": [
        {
          "text": "@human: Should spec/CLAUDE.md contain the 'Project Management Guidelines' (current 139 lines) or the 'ACDD workflow from slash command' (1019 lines)? What is the actual bug we're fixing?",
          "selected": true,
          "answer": "spec/CLAUDE.md should contain 'Project Management and Specification Guidelines' (2069 lines), NOT the ACDD workflow from slash command (1019 lines). My original implementation was WRONG - I copied the slash command template instead of using the Project Management Guidelines template."
        }
      ],
      "attachments": [
        "spec/attachments/BUG-028/BUG-028-implementation-plan.md"
      ]
    },
    "BUG-029": {
      "id": "BUG-029",
      "title": "Fix failing tests after phase tag removal",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-22T06:13:05.750Z",
      "updatedAt": "2025-10-22T06:47:21.878Z",
      "description": "14 tests are failing after removing phase tags from the codebase. Tests in feature-level-tag-management.test.ts, get-scenarios.test.ts, register-tag.test.ts, retag.test.ts, show-acceptance-criteria.test.ts, and hooks tests need to be updated to reflect that phase tags no longer exist and are not required.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T06:13:31.902Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T06:31:30.323Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T06:31:44.751Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T06:44:27.847Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T06:47:21.878Z"
        }
      ],
      "rules": [
        "All test features must have both @component and @feature-group tags to pass validation",
        "Test expectations for TAGS.md must not check for Usage column (removed)",
        "Remove or update scenarios in feature files that test phase tag validation or usage metadata"
      ],
      "examples": [
        "feature-level-tag-management.test.ts expects result.success=true but gets false because validation fails",
        "generate-tags-md.test.ts and tags-md.test.ts check for Usage column in output but it no longer exists",
        "get-scenarios.test.ts expects 1 scenario but gets 3 because test features now have more tags after adding required @component/@feature-group",
        "retag.test.ts expects '@critical' in output but feature now has @cli @validation instead of @critical"
      ],
      "userStory": {
        "role": "developer maintaining test suite",
        "action": "fix failing tests after removing phase tags and usage metadata",
        "benefit": "all 1360 tests pass and the codebase is clean"
      },
      "estimate": 3
    },
    "BUG-030": {
      "id": "BUG-030",
      "title": "Agent-specific activation message not customized in fspec init success output",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T08:19:08.142Z",
      "updatedAt": "2025-10-22T08:54:43.782Z",
      "description": "The 'Run /fspec in your AI agent to activate' message appears in 2 places in the fspec init command output. This message is generic and doesn't provide agent-specific instructions. For example, Claude Code users see this message, but Gemini users would also see the same message, which may not be applicable. The message should be customized based on the detected AI agent (Claude Code, Gemini, Cursor, etc.) to provide relevant activation instructions. Related to INIT-008 (agent runtime detection).",
      "children": [],
      "dependsOn": [
        "INIT-008"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T08:49:32.630Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T08:51:50.634Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T08:52:50.210Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T08:53:24.438Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T08:54:43.782Z"
        }
      ],
      "rules": [
        "Activation message must be customized based on detected agent (from INIT-008 implementation)",
        "Message appears in 2 places in fspec init output and both must be updated",
        "Claude Code users should see: 'Run /fspec in Claude Code to activate'",
        "CLI agents (Aider, Gemini) should see agent-specific command format",
        "IDE agents (Cursor, Cline) should see instructions relevant to their IDE integration",
        "Default/unknown agents should see generic fallback message",
        "Two places: (1) src/commands/init.ts:234 in CLI success message (2) src/components/AgentSelector.tsx:56 in UI component"
      ],
      "examples": [
        "User runs 'fspec init' with Claude Code detected, sees 'Run /fspec in Claude Code to activate' in 2 places in output",
        "User runs 'fspec init' with Cursor detected, sees 'Open .cursor/commands/ in Cursor to activate' in output",
        "User runs 'fspec init' with Aider detected, sees 'Add .aider/ to your Aider configuration to activate' in output",
        "User runs 'fspec init' with unknown agent, sees generic fallback: 'Refer to your AI agent documentation to activate fspec'"
      ],
      "questions": [
        {
          "text": "@human: Where exactly are the 2 places in the init command output where this message appears?",
          "selected": true,
          "answer": "Two places: (1) src/commands/init.ts:234 in CLI success message (2) src/components/AgentSelector.tsx:56 in UI component"
        }
      ],
      "userStory": {
        "role": "developer running fspec init",
        "action": "see agent-specific activation instructions in the success message",
        "benefit": "I know exactly how to activate fspec in my specific AI agent"
      },
      "estimate": 2
    },
    "BUG-031": {
      "id": "BUG-031",
      "title": "No support for ULTRATHINK in discovery-driven feedback loop",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T08:19:09.971Z",
      "updatedAt": "2025-10-24T05:36:24.012Z",
      "description": "The discover-foundation command uses the term 'ULTRATHINK' in its guidance system-reminders to instruct AI agents to perform deep analysis. However, not all AI agents support extended thinking or use this terminology. Claude Code may understand 'ULTRATHINK', but Gemini, Cursor, and other agents do not. The discovery-driven feedback loop needs agent-specific language that adapts to the capabilities of the detected AI agent. For agents without extended thinking support, the term should be removed and replaced with standard instructions. This should integrate with INIT-008 (agent runtime detection) to provide appropriate guidance per agent.",
      "children": [],
      "dependsOn": [
        "INIT-008"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-24T05:17:04.908Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T05:24:00.191Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T05:25:56.326Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T05:31:49.250Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T05:36:24.012Z"
        }
      ],
      "attachments": [
        "spec/attachments/BUG-031/bug-031-investigation-findings.md"
      ],
      "userStory": {
        "role": "AI agent (non-Claude) using fspec discover-foundation",
        "action": "receive guidance in language my agent understands",
        "benefit": "I can successfully complete foundation discovery without confusion"
      },
      "rules": [
        "Claude Code is the only agent that supports 'ULTRATHINK' terminology (supportsMetaCognition flag)",
        "Non-Claude agents must receive generic 'analyze' or 'examine' language instead of ULTRATHINK",
        "Agent detection must use existing INIT-008 infrastructure (getAgentConfig from agentRuntimeConfig.ts)",
        "Output format must match agent type: system-reminder for Claude, bold+emoji for IDE agents, plain bold for CLI agents",
        "ULTRATHINK appears in exactly 2 locations: initial draft reminder and project.vision field guidance",
        "Focus only on locations with ULTRATHINK (initial draft + project.vision). Other fields don't have Claude-specific language. Keep scope minimal for quick fix (Option 1)."
      ],
      "examples": [
        "Claude Code agent runs discover-foundation, sees 'ULTRATHINK: Read ALL code, understand deeply' in system-reminder",
        "Cursor agent runs discover-foundation, sees 'Carefully analyze the entire codebase' with **⚠️ IMPORTANT:** format",
        "Aider CLI agent runs discover-foundation, sees 'Thoroughly examine the codebase' with **IMPORTANT:** plain text format",
        "Unknown/default agent runs discover-foundation, sees safe generic language without system-reminder tags",
        "discover-foundation initial draft creation uses agent.supportsMetaCognition to conditionally include ULTRATHINK",
        "project.vision field guidance checks agent capabilities before using ULTRATHINK terminology"
      ],
      "questions": [
        {
          "text": "@human: Should we add agent-specific variations for ALL field guidance prompts, or just focus on project.vision which currently has ULTRATHINK?",
          "selected": true,
          "answer": "Focus only on locations with ULTRATHINK (initial draft + project.vision). Other fields don't have Claude-specific language. Keep scope minimal for quick fix (Option 1)."
        },
        {
          "text": "@human: Should help documentation (discover-foundation-help.ts) also be updated to remove ULTRATHINK references, or can we keep it as an example of Claude-specific guidance?",
          "selected": true,
          "answer": "Update help docs to mention this is Claude-specific and explain agent-aware messaging. Add note: 'Non-Claude agents will see generic analysis language.' Documentation should reflect multi-agent reality."
        }
      ],
      "assumptions": [
        "Update help docs to mention this is Claude-specific and explain agent-aware messaging. Add note: 'Non-Claude agents will see generic analysis language.' Documentation should reflect multi-agent reality."
      ],
      "estimate": 3
    },
    "FEAT-017": {
      "id": "FEAT-017",
      "title": "Duplicate scenario detection in generate-scenarios command",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T08:26:22.211Z",
      "updatedAt": "2025-10-24T06:14:55.109Z",
      "description": "When 'fspec generate-scenarios' is run, it should check for existing scenarios across all feature files that might be duplicates. Existing code already exists to search for duplicate scenarios and provide results back to the LLM. This work unit refactors generate-scenarios to:\n\n1. Search for possible duplicate scenarios before generating new ones\n2. If duplicates reach a similarity threshold, display them with clear instructions\n3. Emit a system-reminder with:\n   - List of existing feature files that contain similar scenarios\n   - Guidance on what to investigate\n   - Instructions on how to ignore the warning if it's a false positive\n4. Add '--ignore-possible-duplicates' flag to bypass the check and continue generation\n5. Ensure the warning is actionable and prevents accidental duplication\n\nAcceptance Criteria:\n- Search existing feature files for similar scenarios during generate-scenarios\n- Display duplicate matches if similarity threshold is met\n- Emit system-reminder with clear next steps (investigate files, or use --ignore flag)\n- Add '--ignore-possible-duplicates' flag to skip duplicate check\n- Document the duplicate detection behavior in command help\n- Ensure existing duplicate search code is properly integrated",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T08:27:15.376Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T06:02:21.610Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T06:04:39.773Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T06:10:06.521Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T06:14:55.109Z"
        }
      ],
      "rules": [
        "Existing code already exists to search for duplicate scenarios and provide results to LLM",
        "System-reminder must provide CLEAR instructions on what to do next",
        "Must show which existing feature files to investigate when duplicates are detected",
        "Must provide instructions on how to ignore warning if it's not valid",
        "Command must accept --ignore-possible-duplicates flag to bypass duplicate check"
      ],
      "examples": [
        "User runs 'fspec generate-scenarios WORK-001', duplicate scenarios are found above threshold, system-reminder shows list of feature files to investigate with clear next steps",
        "User reviews system-reminder, investigates suggested feature files, determines it's a false positive, runs 'fspec generate-scenarios WORK-001 --ignore-possible-duplicates' to proceed",
        "User runs 'fspec generate-scenarios WORK-001', no duplicates found, scenarios are generated normally without any warnings"
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "detect duplicate scenarios before generating new ones",
        "benefit": "I avoid creating duplicate scenarios across feature files"
      },
      "estimate": 3
    },
    "BUG-032": {
      "id": "BUG-032",
      "title": "INIT-008 and BUG-030 implementation not integrated into actual codebase",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T09:02:16.255Z",
      "updatedAt": "2025-10-22T09:34:09.061Z",
      "description": "CRITICAL: The implementations for INIT-008 (agent runtime detection) and BUG-030 (agent-specific activation messages) exist as isolated utility functions with passing tests, but are NOT integrated into the actual codebase where they should be used.\n\nSYMPTOMS:\n1. BUG-030: getActivationMessage() function exists but init.ts:234 and AgentSelector.tsx:56 still show hardcoded generic message\n2. INIT-008: agentRuntimeConfig.ts functions (getAgentConfig, writeAgentConfig, formatAgentOutput) exist but are never called by any commands\n3. spec/fspec-config.json is never created during fspec init\n4. All commands still emit <system-reminder> tags unconditionally (formatAgentOutput not used)\n\nIMPACT:\n- Tests pass but user-facing functionality unchanged\n- Original bugs still exist in production code\n- 7 story points marked as 'done' but features not actually delivered\n- Integration gap between unit tests and real behavior\n\nROOT CAUSE:\n- TDD practiced at unit level only (isolated functions)\n- Missing integration/E2E tests showing actual command behavior\n- Work units marked 'done' without verifying end-to-end functionality\n- ACDD followed for isolated modules but not for system integration\n\nACCEPTANCE CRITERIA:\n- getActivationMessage() called from init.ts and AgentSelector.tsx\n- writeAgentConfig() called during fspec init (creates spec/fspec-config.json)\n- formatAgentOutput() used by all commands emitting system-reminders\n- Integration tests prove E2E functionality works\n- Manual testing confirms bugs are actually fixed\n\nRelated: INIT-008, BUG-030",
      "children": [],
      "attachments": [
        "spec/attachments/BUG-032/bug-032-integration-analysis.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T09:06:49.671Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T09:10:29.488Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T09:11:30.623Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T09:13:17.184Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T09:14:43.250Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T09:23:11.940Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T09:23:19.872Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T09:32:51.649Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T09:33:43.933Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T09:33:49.940Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T09:34:09.061Z"
        }
      ],
      "userStory": {
        "role": "developer who completed INIT-008 and BUG-030",
        "action": "have the utility functions actually integrated into the codebase",
        "benefit": "the features work for end users instead of just passing unit tests"
      },
      "rules": [
        "getActivationMessage() must be called from src/commands/init.ts:234 to show agent-specific activation instructions",
        "getActivationMessage() must be called from src/components/AgentSelector.tsx:56 to show agent-specific UI text",
        "writeAgentConfig() must be called during fspec init to create spec/fspec-config.json with detected agent",
        "Integration tests must verify end-to-end behavior, not just unit test isolation"
      ],
      "examples": [
        "Before: init.ts shows generic 'Run /fspec in your AI agent to activate'. After: init.ts calls getActivationMessage() and shows 'Run /fspec in Claude Code to activate' for Claude users",
        "Before: AgentSelector.tsx shows hardcoded text. After: AgentSelector calls getActivationMessage() and dynamically renders agent-specific text",
        "Before: fspec init completes but no spec/fspec-config.json created. After: init calls writeAgentConfig() and creates {'agent': 'claude'}"
      ],
      "estimate": 5
    },
    "INIT-009": {
      "id": "INIT-009",
      "title": "Remove initialization files",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T09:49:27.541Z",
      "updatedAt": "2025-10-22T10:15:04.951Z",
      "description": "Command to remove fspec init files from AI editors",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T09:49:34.506Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T10:10:31.908Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T10:11:52.764Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T10:13:14.706Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T10:15:04.951Z"
        }
      ],
      "userStory": {
        "role": "developer who wants to remove fspec files or switch agents",
        "action": "remove all fspec init files",
        "benefit": "my project is clean when I switch agents or remove fspec entirely"
      },
      "questions": [
        {
          "text": "@human: Should fspec remove-init-files remove spec/fspec-config.json, or only agent-specific files (spec/AGENT.md and slash command files)?",
          "selected": true,
          "answer": "Use an interactive prompt (similar to agent selector in fspec init) to ask user if they want to keep or remove spec/fspec-config.json"
        },
        {
          "text": "@human: Should fspec remove-init-files prompt for confirmation before deleting, or support a --force flag?",
          "selected": true,
          "answer": "No additional confirmation needed - the interactive prompt about keeping/removing config serves as the confirmation step. Delete immediately after user makes their choice."
        },
        {
          "text": "@human: Should fspec remove-init-files auto-detect installed agents (from spec/fspec-config.json or detection) and only remove those files, or remove all known agent files regardless?",
          "selected": true,
          "answer": "Auto-detect installed agents using spec/fspec-config.json or file detection, and only remove files for detected agents (not all known agents)"
        },
        {
          "text": "@human: If some init files don't exist (e.g., .claude/commands/fspec.md is missing), should the command fail with an error, or silently skip and report what was removed?",
          "selected": true,
          "answer": "Silently skip missing files and continue removing what exists. No error if files are already deleted."
        }
      ],
      "rules": [
        "Use an interactive prompt (similar to agent selector in fspec init) to ask user if they want to keep or remove spec/fspec-config.json",
        "No additional confirmation needed - the interactive prompt about keeping/removing config serves as the confirmation step. Delete immediately after user makes their choice.",
        "Auto-detect installed agents using spec/fspec-config.json or file detection, and only remove files for detected agents (not all known agents)",
        "Silently skip missing files and continue removing what exists. No error if files are already deleted."
      ],
      "examples": [
        "User runs 'fspec remove-init-files', interactive prompt asks 'Keep spec/fspec-config.json?', user selects 'No', all files removed including config",
        "User runs 'fspec remove-init-files', interactive prompt asks 'Keep spec/fspec-config.json?', user selects 'Yes', only agent files removed (spec/CLAUDE.md, .claude/commands/fspec.md), config preserved",
        "User runs 'fspec remove-init-files', spec/fspec-config.json contains 'claude' agent, only Claude files removed (not Cursor or other agents)",
        "User runs 'fspec remove-init-files', .claude/commands/fspec.md already missing, command silently skips and removes other files without error"
      ],
      "estimate": 3
    },
    "INIT-010": {
      "id": "INIT-010",
      "title": "Agent switching prompt in fspec init",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T09:53:36.556Z",
      "updatedAt": "2025-10-22T11:32:17.078Z",
      "description": "When fspec init detects existing agent files, prompt user to switch agents (replacing old files except spec/fspec-config.json)",
      "children": [],
      "dependsOn": [
        "INIT-009"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T10:19:28.647Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T11:26:40.105Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T11:30:20.262Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T11:31:55.506Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T11:32:17.079Z"
        }
      ],
      "userStory": {
        "role": "developer switching between AI coding agents",
        "action": "be prompted to switch agents when running fspec init with existing agent files",
        "benefit": "I can easily switch from one agent to another without manual cleanup"
      },
      "questions": [
        {
          "text": "@human: When should the agent switching prompt appear - always, or only when installing a different agent than currently installed?",
          "selected": true,
          "answer": "Detect current agent using BOTH spec/fspec-config.json AND file detection (like remove-init-files does), then prompt only if the new agent being installed is different from the detected agent"
        },
        {
          "text": "@human: What options should the agent switching prompt offer to the user?",
          "selected": true,
          "answer": "Two options: 'Switch to [NewAgent]' (removes old agent files, installs new agent) or 'Cancel' (keeps existing setup, aborts installation)"
        },
        {
          "text": "@human: Should spec/fspec-config.json be deleted, updated, or left unchanged when switching agents?",
          "selected": true,
          "answer": "Update spec/fspec-config.json to reflect the new agent ID (e.g., from {\"agent\": \"claude\"} to {\"agent\": \"cursor\"}) so runtime detection works correctly"
        },
        {
          "text": "@human: What happens in interactive mode when an existing agent is detected?",
          "selected": true,
          "answer": "Pre-select the detected agent in interactive selector. If user chooses the same agent, reinstall/refresh files (no prompt). If user chooses a different agent, show switch prompt ('Switch from Claude to Cursor?')"
        }
      ],
      "rules": [
        "Detect current agent using BOTH spec/fspec-config.json AND file detection (like remove-init-files does), then prompt only if the new agent being installed is different from the detected agent",
        "Two options: 'Switch to [NewAgent]' (removes old agent files, installs new agent) or 'Cancel' (keeps existing setup, aborts installation)",
        "Update spec/fspec-config.json to reflect the new agent ID (e.g., from {\"agent\": \"claude\"} to {\"agent\": \"cursor\"}) so runtime detection works correctly",
        "Pre-select the detected agent in interactive selector. If user chooses the same agent, reinstall/refresh files (no prompt). If user chooses a different agent, show switch prompt ('Switch from Claude to Cursor?')"
      ],
      "examples": [
        "User runs 'fspec init --agent=cursor', Claude files detected, prompt shows 'Switch from Claude to Cursor?', user selects 'Switch', Claude files removed, Cursor files installed, config updated to cursor",
        "User runs 'fspec init --agent=cursor', Claude files detected, prompt shows 'Switch from Claude to Cursor?', user selects 'Cancel', Claude files remain, Cursor not installed, exit code 0",
        "User runs 'fspec init' (interactive), Claude files detected and pre-selected, user selects Cursor instead, prompt shows 'Switch from Claude to Cursor?', user confirms, switch happens",
        "User runs 'fspec init' (interactive), Claude files detected and pre-selected, user presses Enter (keeps Claude), files reinstalled/refreshed without prompt",
        "User runs 'fspec init --agent=claude', Claude files already exist, no prompt shown (same agent), files reinstalled/refreshed (idempotent behavior)"
      ],
      "estimate": 5
    },
    "DOC-005": {
      "id": "DOC-005",
      "title": "Update documentation for remove-init-files and agent switching",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-22T10:21:21.357Z",
      "updatedAt": "2025-10-22T11:42:59.691Z",
      "description": "Update help files, README, and docs to document fspec remove-init-files command and agent switching prompt in fspec init. Files to update: src/commands/*-help.ts, src/help.ts, README.md, docs/*",
      "children": [],
      "dependsOn": [
        "INIT-009",
        "INIT-010"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T11:35:49.247Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T11:35:51.701Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-22T11:36:36.909Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T11:37:20.647Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T11:42:50.318Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T11:42:59.691Z"
        }
      ],
      "rules": [
        "Update src/help.ts to include remove-init-files in setup commands section",
        "Create src/commands/remove-init-files-help.ts with comprehensive help documentation",
        "Update init-help.ts to document agent switching behavior",
        "Update README.md with remove-init-files command and agent switching examples",
        "Update docs/getting-started.md and docs/user-guide.md with new commands"
      ],
      "examples": [
        "Help file follows same structure as other command help files (WHEN TO USE, PREREQUISITES, USAGE, EXAMPLES, etc.)",
        "README shows 'fspec remove-init-files' in CLI commands section with brief description",
        "init-help.ts includes note about agent switching prompt when different agent detected",
        "docs/getting-started.md shows how to remove fspec if user wants to uninstall"
      ],
      "estimate": 2
    },
    "BUG-033": {
      "id": "BUG-033",
      "title": "Incomplete implementation of INIT-009 and INIT-010 features",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T11:58:47.689Z",
      "updatedAt": "2025-10-22T13:00:23.524Z",
      "description": "Agent switching and remove-init-files features have passing tests but incomplete implementations. Interactive prompts missing, agent detection not integrated into action handlers, misleading help documentation.",
      "children": [],
      "attachments": [
        "spec/attachments/BUG-033/incomplete-implementation-analysis.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T11:59:56.902Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T12:08:47.604Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T12:14:46.380Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T12:59:13.127Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T13:00:23.524Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "have complete implementations of remove-init-files and init agent switching",
        "benefit": "the CLI actually works as documented and passes real user acceptance tests"
      },
      "rules": [
        "remove-init-files MUST prompt user with interactive Yes/No for keeping spec/fspec-config.json",
        "init command MUST detect existing agent before installation and compare with requested agent",
        "init command MUST prompt for agent switch confirmation when existing agent differs from requested agent",
        "Success messages MUST show detailed list of files removed/installed to match help documentation",
        "Agent config MUST be written only once (remove duplicate writeAgentConfig calls)",
        "Create a generic ConfirmPrompt.tsx component that can be reused for both cases (and future confirmations). Interface: ConfirmPrompt({ message, confirmLabel?, cancelLabel?, onSubmit }) returns boolean. This follows DRY principle and keeps components focused.",
        "Unit test the action handlers (not just internal functions). Mock ConfirmPrompt component responses. This is sufficient and provides faster feedback than E2E tests.",
        "Add --keep-config and --no-keep-config flags for explicit control in non-interactive environments. When flags are provided, skip the interactive prompt. When no flag provided, show interactive prompt (normal behavior). This is clear and unambiguous."
      ],
      "examples": [
        "User runs 'fspec remove-init-files', sees interactive prompt 'Keep spec/fspec-config.json?', selects 'Yes', config remains, agent files removed",
        "User runs 'fspec remove-init-files', sees interactive prompt, selects 'No', all files including config removed, detailed output shown",
        "User runs 'fspec init --agent=cursor' when Claude is installed, sees 'Switch from Claude to Cursor?' prompt, selects 'Switch', Claude files removed, Cursor installed",
        "User runs 'fspec init --agent=cursor' when Claude is installed, sees switch prompt, selects 'Cancel', Claude files remain, process exits cleanly",
        "User runs 'fspec init --agent=claude' when Claude is already installed, no prompt shown, files reinstalled idempotently"
      ],
      "questions": [
        {
          "text": "@human: Should we create new React/Ink components (KeepConfigPrompt.tsx, AgentSwitchPrompt.tsx) or integrate into existing AgentSelector component?",
          "selected": true,
          "answer": "Create a generic ConfirmPrompt.tsx component that can be reused for both cases (and future confirmations). Interface: ConfirmPrompt({ message, confirmLabel?, cancelLabel?, onSubmit }) returns boolean. This follows DRY principle and keeps components focused."
        },
        {
          "text": "@human: Should we add E2E tests that spawn actual CLI processes, or is unit testing the action handlers sufficient?",
          "selected": true,
          "answer": "Unit test the action handlers (not just internal functions). Mock ConfirmPrompt component responses. This is sufficient and provides faster feedback than E2E tests."
        },
        {
          "text": "@human: What should happen if user runs remove-init-files in non-interactive environment (CI/CD)? Should we have a --yes flag to skip prompts?",
          "selected": true,
          "answer": "Add --keep-config and --no-keep-config flags for explicit control in non-interactive environments. When flags are provided, skip the interactive prompt. When no flag provided, show interactive prompt (normal behavior). This is clear and unambiguous."
        }
      ],
      "architectureNotes": [
        "Implementation requires: 1) Create src/components/ConfirmPrompt.tsx (reusable Yes/No prompt), 2) Update remove-init-files action handler to use ConfirmPrompt, 3) Update init action handler to detect existing agent and show switch prompt, 4) Remove duplicate writeAgentConfig call in init.ts, 5) Update success messages to show detailed file lists",
        "Testing strategy: Unit test action handlers (not internal functions). Mock ConfirmPrompt component responses using vitest. Ensure tests call the actual action handler path that real users trigger.",
        "Files to modify: src/commands/remove-init-files.ts (action handler), src/commands/init.ts (action handler + remove duplicate), src/components/ConfirmPrompt.tsx (create new), src/commands/__tests__/remove-init-files.test.ts (fix tests), src/commands/__tests__/init-agent-switching.test.ts (fix tests)"
      ],
      "estimate": 5
    },
    "BUG-034": {
      "id": "BUG-034",
      "title": "Double prompt and missing success message in interactive init mode",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T13:08:50.031Z",
      "updatedAt": "2025-10-22T13:29:07.162Z",
      "description": "Interactive mode shows confusing double prompts (AgentSelector + switch confirmation) and no success message after installation. Users select agent, then must confirm again, then see no feedback about success.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T13:08:57.055Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T13:17:16.070Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T13:21:32.203Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T13:23:47.459Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T13:29:07.163Z"
        }
      ],
      "attachments": [
        "spec/attachments/BUG-034/bug-034-analysis.md"
      ],
      "userStory": {
        "role": "developer using fspec init",
        "action": "select an agent and see clear confirmation",
        "benefit": "I know the installation succeeded and what to do next"
      },
      "rules": [
        "Interactive mode MUST NOT show double prompts (AgentSelector selection IS user confirmation)",
        "Interactive mode MUST show success message with file list and activation instructions",
        "CLI mode (--agent flag) SHOULD still show agent switch confirmation prompt",
        "Both interactive and CLI modes MUST show identical success messages"
      ],
      "examples": [
        "User runs 'fspec init', selects Cursor from menu, sees NO second confirmation prompt, sees success message with file list",
        "User runs 'fspec init --agent=cursor' when Claude installed, sees 'Switch from Claude to Cursor?' prompt, confirms, sees success message",
        "User runs 'fspec init', selects same agent (Claude), sees NO prompt, sees success message showing reinstallation",
        "Success message shows: checkmark, agent name, indented file list, activation instructions - identical format for both modes"
      ],
      "architectureNotes": [
        "Fix 1: Pass promptAgentSwitch parameter to executeInit() in interactive mode that returns true (auto-confirm). This skips the second prompt while preserving CLI mode behavior.",
        "Fix 2: Change success message condition from 'if (options.agent.length > 0)' to 'if (result.success)' so both interactive and CLI modes show feedback.",
        "Files to modify: src/commands/init.ts (action handler lines 366 and 375). NO changes needed to executeInit(), installAgents(), or AgentSelector component."
      ],
      "estimate": 3
    },
    "GIT-004": {
      "id": "GIT-004",
      "title": "Interactive checkpoint viewer with diff and commit capabilities",
      "type": "story",
      "status": "specifying",
      "createdAt": "2025-10-22T13:35:44.893Z",
      "updatedAt": "2025-10-22T13:36:18.008Z",
      "description": "Add an interactive TUI for viewing checkpoints, examining file changes, seeing diffs, viewing staged/unstaged files, generating conventional commits, and performing git operations directly from the checkpoint view",
      "children": [],
      "dependsOn": [
        "GIT-002"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T13:36:02.558Z"
        }
      ],
      "questions": [
        {
          "text": "@human: How should users access the interactive checkpoint viewer? New command, integrated into kanban board, or integrated into show-work-unit?",
          "selected": false
        }
      ]
    },
    "BOARD-003": {
      "id": "BOARD-003",
      "title": "Real-time board updates with git stash and file inspection",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T13:42:12.487Z",
      "updatedAt": "2025-10-27T08:06:18.898Z",
      "description": "Add real-time board updates to the interactive Kanban CLI. Display git stashes and changed files (staged/unstaged) that users can click to inspect. Board should refresh automatically when work unit status changes. Support keyboard navigation to inspect stash details and file diffs.",
      "epic": "interactive-cli",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T05:38:39.225Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T05:41:53.905Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T05:43:07.455Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T05:44:53.992Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T05:46:34.390Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T05:58:46.491Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T05:59:52.547Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T06:00:33.304Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T06:02:39.451Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T06:07:24.261Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T06:07:53.144Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T06:08:56.316Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T06:09:00.977Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T06:09:15.768Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T06:09:25.356Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T07:57:49.474Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T08:06:05.321Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T08:06:18.898Z"
        }
      ],
      "userStory": {
        "role": "developer managing work units",
        "action": "see real-time status of work in progress",
        "benefit": "I can quickly inspect changes and stash state without leaving the terminal"
      },
      "rules": [
        "Board must display git stashes with timestamps and message previews",
        "Board must show changed files with staged/unstaged indicators (green/yellow)",
        "User can inspect stash details by selecting with Enter key",
        "User can view file diffs for changed files by selecting with Enter key",
        "Board refreshes automatically when work unit status changes",
        "Keyboard navigation: tab/shift-tab to switch between board/stash/files panels",
        "ESC key returns from detail view to board view",
        "CRITICAL: NEVER use git CLI commands (git status, git diff, git stash) - ONLY use isomorphic-git library",
        "Use existing utilities: getStagedFiles(), getUnstagedFiles() from src/git/status.ts",
        "Stash operations use git.log() with ref 'refs/stash' to list stashes via isomorphic-git",
        "File diffs generated using git.readBlob() and manual diff logic (NOT git diff CLI)"
      ],
      "examples": [
        "User opens board with 2 stashes: shows 'GIT-001-auto-testing (2 hours ago)' and 'baseline (3 days ago)'",
        "Board shows 3 staged files (green) and 2 unstaged files (yellow) in files panel",
        "User presses Enter on stash: detail view shows stash message, timestamp, and changed files",
        "User presses Enter on src/auth.ts: diff view shows +5 -2 lines with syntax highlighting",
        "Status changes from implementing to validating: board automatically refreshes and updates column",
        "User presses tab: focus switches from board to stash panel, border changes to cyan",
        "User presses ESC in diff view: returns to board view with previous focus restored",
        "Get staged files: import { getStagedFiles } from 'src/git/status'; const staged = await getStagedFiles(cwd); // ['src/auth.ts', 'README.md']",
        "Get unstaged files: import { getUnstagedFiles } from 'src/git/status'; const unstaged = await getUnstagedFiles(cwd); // ['src/utils.ts']",
        "List stashes: const logs = await git.log({ fs, dir: cwd, ref: 'refs/stash', depth: 10 }); // Returns stash commits",
        "Read file from stash: const { blob } = await git.readBlob({ fs, dir: cwd, oid: stashOid, filepath: 'src/auth.ts' }); // Get file content",
        "Generate diff: const headBlob = await git.readBlob({ fs, dir: cwd, oid: 'HEAD', filepath }); const workdirContent = await fs.readFile(filepath); const diff = computeDiff(headBlob, workdirContent);"
      ],
      "estimate": 8
    },
    "BUG-035": {
      "id": "BUG-035",
      "title": "Duplicate 'Next steps' message in fspec init output",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T13:52:15.040Z",
      "updatedAt": "2025-10-23T01:24:23.529Z",
      "description": "When running 'fspec init', the success message displays 'Next steps: Run /fspec in Claude Code to activate' twice - once after claude installation and once after Claude Code installation. Should only display once at the end.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-23T01:16:17.617Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-23T01:19:53.264Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-23T01:22:36.653Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-23T01:23:50.179Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-23T01:24:23.530Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec init interactively",
        "action": "complete the initialization process",
        "benefit": "I see clear next steps only once"
      },
      "rules": [
        "Next steps message should only appear once in init output",
        "AgentSelector component shows success message with Next steps in interactive mode",
        "Action handler also shows success message with Next steps for all modes",
        "CLI mode should not be affected by this fix"
      ],
      "examples": [
        "Developer runs 'fspec init' interactively, selects Claude, sees 'Next steps' message twice",
        "Developer runs 'fspec init --agent=claude' in CLI mode, sees 'Next steps' message once",
        "After fix: interactive mode should show success message only once with Next steps at the end"
      ],
      "architectureNotes": [
        "AgentSelector component (src/components/AgentSelector.tsx:58-61) displays success message with 'Next steps' when agent is selected",
        "Action handler in init.ts (line 394) also displays success message with 'Next steps' after executeInit completes",
        "Solution: Remove 'Next steps' section from AgentSelector component (lines 60-61), keep only in action handler"
      ],
      "estimate": 1
    },
    "AGENT-001": {
      "id": "AGENT-001",
      "title": "Test Cursor agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:09.683Z",
      "updatedAt": "2025-10-22T13:55:09.683Z",
      "description": "Verify fspec init --agent=cursor works correctly: creates .cursor/commands/fspec.md, creates spec/CURSOR.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-002": {
      "id": "AGENT-002",
      "title": "Test Cline agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:11.528Z",
      "updatedAt": "2025-10-22T13:55:11.528Z",
      "description": "Verify fspec init --agent=cline works correctly: creates .cline/commands/fspec.md, creates spec/CLINE.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-003": {
      "id": "AGENT-003",
      "title": "Test Aider agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:13.162Z",
      "updatedAt": "2025-10-22T13:55:13.162Z",
      "description": "Verify fspec init --agent=aider works correctly: creates .aider/ files, creates spec/AIDER.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-004": {
      "id": "AGENT-004",
      "title": "Test Windsurf agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:14.682Z",
      "updatedAt": "2025-10-22T13:55:14.682Z",
      "description": "Verify fspec init --agent=windsurf works correctly: creates .windsurf/workflows/fspec.md, creates spec/WINDSURF.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-005": {
      "id": "AGENT-005",
      "title": "Test GitHub Copilot agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:15.899Z",
      "updatedAt": "2025-10-22T13:55:15.899Z",
      "description": "Verify fspec init --agent=copilot works correctly: creates .github/prompts/fspec.md, creates spec/COPILOT.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-006": {
      "id": "AGENT-006",
      "title": "Test Gemini CLI agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:17.120Z",
      "updatedAt": "2025-10-22T13:55:17.120Z",
      "description": "Verify fspec init --agent=gemini works correctly: creates .gemini/commands/fspec.toml (TOML format), creates spec/GEMINI.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-007": {
      "id": "AGENT-007",
      "title": "Test Qwen Code agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:19.348Z",
      "updatedAt": "2025-10-22T13:55:19.348Z",
      "description": "Verify fspec init --agent=qwen works correctly: creates .qwen/commands/fspec.toml (TOML format), creates spec/QWEN.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-008": {
      "id": "AGENT-008",
      "title": "Test Kilo Code agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:20.666Z",
      "updatedAt": "2025-10-22T13:55:20.666Z",
      "description": "Verify fspec init --agent=kilocode works correctly: creates .kilocode/rules/fspec.md, creates spec/KILOCODE.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-009": {
      "id": "AGENT-009",
      "title": "Test Roo Code agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:22.053Z",
      "updatedAt": "2025-10-22T13:55:22.053Z",
      "description": "Verify fspec init --agent=roo works correctly: creates .roo/rules/fspec.md, creates spec/ROO.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-010": {
      "id": "AGENT-010",
      "title": "Test CodeBuddy agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:36.893Z",
      "updatedAt": "2025-10-22T13:55:36.893Z",
      "description": "Verify fspec init --agent=codebuddy works correctly: creates .codebuddy/commands/fspec.md, creates spec/CODEBUDDY.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-011": {
      "id": "AGENT-011",
      "title": "Test Amazon Q agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:38.297Z",
      "updatedAt": "2025-10-22T13:55:38.297Z",
      "description": "Verify fspec init --agent=amazonq works correctly: creates .amazonq/prompts/fspec.md, creates spec/AMAZONQ.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-012": {
      "id": "AGENT-012",
      "title": "Test Auggie agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:39.680Z",
      "updatedAt": "2025-10-22T13:55:39.680Z",
      "description": "Verify fspec init --agent=auggie works correctly: creates .auggie/ files, creates spec/AUGGIE.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-013": {
      "id": "AGENT-013",
      "title": "Test OpenCode agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:41.011Z",
      "updatedAt": "2025-10-22T13:55:41.011Z",
      "description": "Verify fspec init --agent=opencode works correctly: creates .opencode/command/fspec.md, creates spec/OPENCODE.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-014": {
      "id": "AGENT-014",
      "title": "Test Codex agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:42.525Z",
      "updatedAt": "2025-10-22T13:55:42.525Z",
      "description": "Verify fspec init --agent=codex works correctly: creates .codex/commands/fspec.md, creates spec/CODEX.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-015": {
      "id": "AGENT-015",
      "title": "Test Factory Droid agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:43.848Z",
      "updatedAt": "2025-10-22T13:55:43.848Z",
      "description": "Verify fspec init --agent=factory works correctly: creates .factory/commands/fspec.md, creates spec/FACTORY.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-016": {
      "id": "AGENT-016",
      "title": "Test Crush agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:45.836Z",
      "updatedAt": "2025-10-22T13:55:45.836Z",
      "description": "Verify fspec init --agent=crush works correctly: creates .crush/commands/fspec.md, creates spec/CRUSH.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "AGENT-017": {
      "id": "AGENT-017",
      "title": "Test Codex CLI agent compatibility",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T13:55:47.125Z",
      "updatedAt": "2025-10-22T13:55:47.125Z",
      "description": "Verify fspec init --agent=codex-cli works correctly: creates .codex/commands/fspec.md, creates spec/CODEX-CLI.md, shows correct activation instructions, and supports full ACDD workflow",
      "epic": "agent-testing",
      "children": []
    },
    "DEP-002": {
      "id": "DEP-002",
      "title": "Upgrade Vitest from 2.1.8 to 4.0.0",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-23T05:55:26.427Z",
      "updatedAt": "2025-10-23T06:02:38.051Z",
      "description": "Upgrade Vitest testing framework to version 4.0.0 (released October 22, 2025) which includes browser mode stabilization, visual regression testing support, and improved stability. This upgrade requires migration guide review, configuration updates, and comprehensive testing to ensure no breaking changes affect existing test suite.",
      "epic": "test-coverage",
      "children": [],
      "architectureNotes": [
        "Vitest 4.0 Release Notes (Oct 22, 2025):\n- Browser Mode stabilization (no longer experimental)\n- Visual regression testing with toMatchScreenshot assertion\n- Context import changed from @vitest/browser/context to vitest/browser\n- Pool default remains 'forks' (introduced in 2.0)\n- Migration guide: https://vitest.dev/blog/vitest-4"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-23T05:56:09.489Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-23T05:59:48.049Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-23T05:59:52.769Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-23T06:02:34.367Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-23T06:02:38.051Z"
        }
      ],
      "rules": [
        "All existing tests must pass after upgrade with no modifications",
        "Configuration changes must maintain safety settings (singleFork, fileParallelism: false)",
        "Must review official Vitest 4.0 migration guide before upgrading"
      ],
      "examples": [
        "Run npm install -D vitest@^4.0.0 to upgrade package",
        "Update vitest.config.ts if breaking changes affect configuration syntax",
        "Run full test suite with npm test to verify compatibility",
        "Check npm run build to ensure TypeScript compilation still works"
      ],
      "questions": [
        {
          "text": "@human: Should we explore browser mode features in Vitest 4.0 or keep using node environment only?",
          "selected": true,
          "answer": "Keep node environment only - fspec is a CLI tool with no browser requirements"
        },
        {
          "text": "@human: Do we want to adopt visual regression testing features or defer for future work?",
          "selected": true,
          "answer": "Defer visual regression testing - not applicable to CLI tools"
        }
      ],
      "userStory": {
        "role": "fspec developer",
        "action": "upgrade Vitest to version 4.0 for improved stability and latest features",
        "benefit": "I benefit from bug fixes, performance improvements, and maintain compatibility with the latest testing ecosystem"
      },
      "estimate": 2
    },
    "BUG-037": {
      "id": "BUG-037",
      "title": "Fix 2 failing test suites (version-display and cli-command-registration timeout)",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-23T06:29:08.901Z",
      "updatedAt": "2025-10-23T06:34:40.910Z",
      "description": "Test suite failures preventing npm test from passing: 1) version-display.test.ts has no active tests (all commented out), 2) cli-command-registration.test.ts times out after 30s because it executes 93+ CLI commands sequentially using execSync",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-23T06:29:24.460Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-23T06:31:23.142Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-23T06:31:49.455Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-23T06:32:39.053Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-23T06:34:40.910Z"
        }
      ],
      "userStory": {
        "role": "developer running npm test",
        "action": "have all tests pass successfully",
        "benefit": "I can verify code quality and ensure CI/CD pipeline succeeds"
      },
      "rules": [
        "All test files must contain at least one active test suite or be removed",
        "CLI command registration tests must complete within 30 seconds",
        "Tests that execute many CLI commands should use parallelization or mocking to reduce execution time"
      ],
      "examples": [
        "version-display.test.ts has all tests commented out, causing Vitest to report 'No test suite found in file'",
        "cli-command-registration.test.ts executes 93+ commands sequentially with execSync, taking over 30 seconds and timing out",
        "After fixing version-display.test.ts, running 'npm test' should not show 'No test suite found' error",
        "After optimizing cli-command-registration.test.ts, the test should complete in under 30 seconds"
      ],
      "estimate": 2
    },
    "BUG-038": {
      "id": "BUG-038",
      "title": "show-feature test failures - Work Units display assertions failing",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-23T06:49:57.837Z",
      "updatedAt": "2025-10-23T07:05:47.975Z",
      "description": "Three tests in show-feature.test.ts are failing with toContain assertions even though the expected content appears to be present in the output. Tests: 1) Display work units linked to feature (feature-level tags), 2) Display multiple work units from scenario-level tags, 3) Display work units when feature has no work unit tag. The content IS in the output but toContain is failing.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-23T06:50:51.336Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-23T06:59:18.606Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-23T07:03:12.372Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-23T07:03:48.010Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-23T07:05:47.975Z"
        }
      ],
      "userStory": {
        "role": "developer running tests",
        "action": "verify show-feature output contains expected work unit information",
        "benefit": "I can validate the command output without ANSI escape codes interfering with assertions"
      },
      "rules": [
        "Test assertions must work on plain text output without ANSI escape codes",
        "showFeature function must return content that can be tested with .toContain() assertions",
        "ANSI codes should only be present in stdout display, not in returned content for testing",
        "Option C: Remove chalk from showFeature() function. This is architecturally correct (separation of concerns), fixes the file-writing bug, makes tests pass without changes, and follows Single Responsibility Principle - the function generates data, the command handles display."
      ],
      "examples": [
        "Test checks for 'AUTH-001 (feature-level)' and it matches without ANSI codes",
        "Test checks for 'Work Units: None' and it matches exactly",
        "Running showFeature with format=text returns plain text in result.content"
      ],
      "questions": [
        {
          "text": "@human: Should we strip ANSI codes from result.content (option A), or return both raw and formatted content with a flag (option B)?",
          "selected": true,
          "answer": "Option C: Remove chalk from showFeature() function. This is architecturally correct (separation of concerns), fixes the file-writing bug, makes tests pass without changes, and follows Single Responsibility Principle - the function generates data, the command handles display."
        }
      ],
      "estimate": 1
    },
    "BUG-040": {
      "id": "BUG-040",
      "title": "Duplicate installation success message in fspec init",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-23T21:04:30.882Z",
      "updatedAt": "2025-10-23T21:39:37.842Z",
      "description": "fspec init displays two similar messages: '✓ Installed fspec for claude' and '✓ Installed fspec for Claude Code'. The last message is redundant and should be removed.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-23T21:04:35.481Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-23T21:33:27.411Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-23T21:36:15.622Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-23T21:36:51.749Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-23T21:39:37.842Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "see clear non-duplicate success messages after initialization",
        "benefit": "I understand installation status without confusion"
      },
      "rules": [
        "Only one success message should be displayed after installation completes",
        "The success message should include agent name, installed files, and next steps",
        "The duplicate final message (\"✓ Installed fspec for Claude Code\") should be removed"
      ],
      "examples": [
        "Running 'fspec init' for Claude Code shows: '✓ Installed fspec for claude' with file list and next steps, then '✓ Installed fspec for Claude Code' (CURRENT BEHAVIOR - duplicate)",
        "Running 'fspec init' for Claude Code should show: '✓ Installed fspec for claude' with file list and next steps, WITHOUT the final duplicate message (EXPECTED BEHAVIOR)",
        "Other agents (Cursor, Cline, Windsurf, etc.) should also show only one success message without duplicates"
      ],
      "estimate": 2
    },
    "RES-002": {
      "id": "RES-002",
      "title": "Research framework with custom script integration",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-23T21:16:17.909Z",
      "updatedAt": "2025-10-24T12:45:54.713Z",
      "description": "Create core research framework that allows users to select from available research endpoints (custom scripts like hooks) during Example Mapping. Should prompt users to research questions before/during Example Mapping sessions, display available tools, and execute selected research scripts.",
      "epic": "research-tools",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-23T21:16:48.878Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T12:41:20.597Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T12:42:53.619Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T12:43:43.757Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T12:45:54.713Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec during Example Mapping",
        "action": "research questions using external tools before defining acceptance criteria",
        "benefit": "I make informed decisions based on external knowledge sources"
      },
      "questions": [
        {
          "text": "@human: Should the research command be interactive (prompts user step-by-step) or CLI-based with flags (e.g., fspec research --tool=perplexity --query='question')?",
          "selected": true,
          "answer": "CLI-based with flags. Running 'fspec research' without flags displays instructional output for AI agents: lists available tools, their descriptions, and usage examples with --tool= flag. Example: 'fspec research --tool=perplexity --query=\"question\"'. The instructional output guides AI to use the correct tool and syntax."
        },
        {
          "text": "@human: How should research scripts be stored? Should we use a similar structure to hooks (e.g., spec/research-scripts/)?",
          "selected": true,
          "answer": "Yes, use similar structure to hooks. Research scripts stored in spec/research-scripts/ directory. Each tool is a script file (e.g., spec/research-scripts/perplexity.sh, spec/research-scripts/jira.sh, spec/research-scripts/confluence.sh)."
        },
        {
          "text": "@human: Should research results be automatically attached to work units, or should the user manually decide what to attach?",
          "selected": true,
          "answer": "Prompt user to attach research results. After research completes, ask: 'Attach research results to work unit RES-XXX? (y/n)'. If yes, save as attachment and optionally add to architecture notes/example mapping data. If no, display results only (user can refine query or run additional research)."
        },
        {
          "text": "@human: Should fspec prompt to research during Example Mapping automatically, or should it be manually invoked with 'fspec research'?",
          "selected": true,
          "answer": "Automatically prompt during Example Mapping. When user adds a question with 'fspec add-question', system asks: 'Would you like to research this question? (y/n)'. If yes, display available research tools and guide user to run 'fspec research --tool=<name> --query=\"question\"'. User can also manually invoke 'fspec research' anytime."
        },
        {
          "text": "@human: What should the research script interface look like? Should scripts receive JSON context via stdin (like hooks) and return JSON results via stdout?",
          "selected": true,
          "answer": "Research scripts are standalone CLI tools (like fspec). Each script defines its own interface, flags, and output format. When 'fspec research' lists tools, it shows how to get help (e.g., 'perplexity --help'). AI agents learn tool usage from tool's own documentation/help output. Tools return results in their chosen format (JSON, text, markdown, etc.), and AI interprets the response. No mandated stdin/stdout contract."
        },
        {
          "text": "@human: Should there be a registry of available research tools (similar to tags.json), or should tools be auto-discovered from the research-scripts directory?",
          "selected": true,
          "answer": "Auto-discover tools from spec/research-scripts/ directory. No registry file needed. fspec scans directory for executable scripts, lists them when running 'fspec research' without flags. Tool names derived from filenames (e.g., perplexity.sh → 'perplexity'). Discovery happens dynamically at runtime."
        }
      ],
      "rules": [
        "CLI-based with flags. Running 'fspec research' without flags displays instructional output for AI agents: lists available tools, their descriptions, and usage examples with --tool= flag. Example: 'fspec research --tool=perplexity --query=\"question\"'. The instructional output guides AI to use the correct tool and syntax.",
        "Yes, use similar structure to hooks. Research scripts stored in spec/research-scripts/ directory. Each tool is a script file (e.g., spec/research-scripts/perplexity.sh, spec/research-scripts/jira.sh, spec/research-scripts/confluence.sh).",
        "Yes, automatically attach research results to work units. Results saved as attachments and referenced in example mapping data. Architecture notes in feature files should reference research findings where appropriate. Example: 'Research via Perplexity on 2025-10-24: [summary]' in architecture notes section.",
        "Prompt user to attach research results. After research completes, ask: 'Attach research results to work unit RES-XXX? (y/n)'. If yes, save as attachment and optionally add to architecture notes/example mapping data. If no, display results only (user can refine query or run additional research).",
        "Automatically prompt during Example Mapping. When user adds a question with 'fspec add-question', system asks: 'Would you like to research this question? (y/n)'. If yes, display available research tools and guide user to run 'fspec research --tool=<name> --query=\"question\"'. User can also manually invoke 'fspec research' anytime.",
        "Research scripts are standalone CLI tools (like fspec). Each script defines its own interface, flags, and output format. When 'fspec research' lists tools, it shows how to get help (e.g., 'perplexity --help'). AI agents learn tool usage from tool's own documentation/help output. Tools return results in their chosen format (JSON, text, markdown, etc.), and AI interprets the response. No mandated stdin/stdout contract.",
        "Auto-discover tools from spec/research-scripts/ directory. No registry file needed. fspec scans directory for executable scripts, lists them when running 'fspec research' without flags. Tool names derived from filenames (e.g., perplexity.sh → 'perplexity'). Discovery happens dynamically at runtime.",
        "Auto-discover research tools by scanning spec/research-scripts/ for ANY executable files (not just .sh - could be .py, .js, compiled binaries, etc.). Check executable bit, not file extension."
      ],
      "examples": [
        "Developer runs 'fspec research' without flags, sees list of available tools: perplexity, jira, confluence, with descriptions and usage examples for each",
        "Developer runs 'fspec research --tool=perplexity --query=\"How does OAuth2 work?\"', tool executes and returns formatted results, system asks 'Attach research results to work unit? (y/n)'",
        "During Example Mapping, developer runs 'fspec add-question AUTH-001 \"@human: Should we support OAuth2?\"', system prompts 'Would you like to research this question? (y/n)'",
        "Developer chooses to attach results, research output saved to spec/attachments/AUTH-001/perplexity-oauth2-research-2025-10-24.md and referenced in work unit",
        "Research directory contains perplexity.py (Python), jira (compiled binary), confluence.js (Node). fspec auto-discovers all three by executable bit, derives names: 'perplexity', 'jira', 'confluence'."
      ],
      "estimate": 5
    },
    "RES-003": {
      "id": "RES-003",
      "title": "Perplexity research tool integration",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-23T21:16:30.953Z",
      "updatedAt": "2025-10-23T21:16:37.879Z",
      "description": "Create custom script for Perplexity API integration. Allows users to research questions using Perplexity during Example Mapping. Script should accept question input, call Perplexity API, and return formatted research results.",
      "epic": "research-tools",
      "children": [],
      "dependsOn": [
        "RES-002"
      ]
    },
    "RES-004": {
      "id": "RES-004",
      "title": "JIRA research tool integration",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-23T21:16:31.444Z",
      "updatedAt": "2025-10-23T21:16:38.364Z",
      "description": "Create custom script for JIRA API integration. Allows users to search JIRA issues, tickets, and documentation during Example Mapping. Script should support querying by project, labels, status, and return relevant issue details.",
      "epic": "research-tools",
      "children": [],
      "dependsOn": [
        "RES-002"
      ]
    },
    "RES-005": {
      "id": "RES-005",
      "title": "Confluence research tool integration",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-23T21:16:31.938Z",
      "updatedAt": "2025-10-23T21:16:38.846Z",
      "description": "Create custom script for Confluence API integration. Allows users to search Confluence pages and documentation during Example Mapping. Script should support full-text search and return page summaries with links.",
      "epic": "research-tools",
      "children": [],
      "dependsOn": [
        "RES-002"
      ]
    },
    "BOARD-004": {
      "id": "BOARD-004",
      "title": "Work unit ordering across all Kanban columns",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-23T22:15:34.560Z",
      "updatedAt": "2025-10-24T00:03:50.764Z",
      "description": "Enable prioritize-work-unit command to work on all Kanban columns (backlog, specifying, testing, implementing, validating, blocked) except done. Currently limited to backlog only.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-23T22:15:39.164Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-23T23:50:36.338Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-23T23:54:44.248Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T00:03:35.959Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T00:03:50.764Z"
        }
      ],
      "rules": [
        "Currently: prioritize-work-unit only works for backlog status, throws error for other statuses",
        "Change: Allow prioritize-work-unit to work on backlog, specifying, testing, implementing, validating, blocked statuses (NOT done)",
        "CRITICAL: prioritize-work-unit can ONLY reorder within the same column (same status). Cannot move work units between columns or reference work units in different columns.",
        "If --before or --after references a work unit in a different column, throw error with clear message",
        "If work unit is in done status, throw error AND emit system-reminder explaining done work units cannot be reordered",
        "Files requiring updates: src/commands/prioritize-work-unit.ts (lines 36-41, 91), src/commands/prioritize-work-unit-help.ts (lines 5, 8, 9, 25, 29, examples, commonErrors 66-67, typicalWorkflow 76, notes 96+100), src/help.ts (prioritize section), spec/features/kanban-workflow-state-management.feature (prioritize scenarios and validation)",
        "Update command description to: 'Reorder work units in any Kanban column except done'",
        "If work unit is the only item in its column, allow prioritization and succeed as no-op (idempotent operation)",
        "Update spec/features/kanban-workflow-state-management.feature: modify existing prioritize scenarios to test multi-column prioritization, remove validation scenario that tests 'Can only prioritize work units in backlog state' error (no longer valid)",
        "Update test files (src/commands/__tests__/kanban-workflow-state-management.test.ts and others): modify tests to cover multi-column prioritization, remove tests that specifically validate 'backlog-only' constraint (no longer valid)"
      ],
      "examples": [
        "User runs 'fspec prioritize-work-unit FEAT-017 --position top' where FEAT-017 is in specifying status. Command reorders FEAT-017 to top of specifying column (states.specifying array).",
        "User runs 'fspec prioritize-work-unit FEAT-017 --before AUTH-001' where FEAT-017 is in specifying and AUTH-001 is in testing. Command throws error: 'Cannot prioritize across columns. FEAT-017 (specifying) and AUTH-001 (testing) are in different columns.'",
        "User runs 'fspec prioritize-work-unit AUTH-001 --position top' where AUTH-001 is in done status. Command throws error and emits: '<system-reminder>Cannot prioritize work units in done column. Done items are ordered by completion time and cannot be manually reordered. Only backlog, specifying, testing, implementing, validating, blocked can be prioritized.</system-reminder>'",
        "Help text shows: 'fspec prioritize-work-unit - Reorder work units in any Kanban column except done'",
        "AUTH-001 is only item in implementing column. User runs 'fspec prioritize-work-unit AUTH-001 --position top'. Command succeeds with message: '✓ Work unit AUTH-001 prioritized successfully' (no error, no-op).",
        "Old scenario: 'Attempt to prioritize work not in backlog' tests error when implementing work unit is prioritized. REMOVE this scenario (no longer an error). Add new scenarios testing prioritization in specifying, testing, implementing, validating, blocked columns.",
        "Old test: 'should throw error when prioritizing work unit in implementing status' - REMOVE (no longer an error). Add new tests: 'should prioritize work unit in specifying column', 'should prioritize work unit in implementing column', etc."
      ],
      "userStory": {
        "role": "developer managing work priorities",
        "action": "reorder work units in any Kanban column except done",
        "benefit": "I can adjust priorities throughout the workflow, not just in backlog"
      }
    },
    "CLI-008": {
      "id": "CLI-008",
      "title": "Release command for reviewing changes and creating tagged releases",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-23T22:43:00.893Z",
      "updatedAt": "2025-10-24T00:50:36.088Z",
      "description": "Add /release slash command that: 1) Reviews all code changes since last git tag, 2) Creates commit with Roland Quast <rquast@rolandquast.com> details (not Claude's), 3) Tags the release, 4) Does NOT push (manual step). Command analyzes commit history and code changes for release notes.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-23T22:43:08.685Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T00:47:26.404Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T00:47:47.538Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T00:49:56.096Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T00:50:36.088Z"
        }
      ],
      "rules": [
        "Implement as slash command for Claude Code in .claude/commands/release.md (NOT an fspec CLI command)",
        "Commit author must be Roland Quast <rquast@rolandquast.com>, NOT Claude's default author",
        "Review all git commits since last tag using git log",
        "Analyze code changes in those commits for release notes",
        "Create git tag for the release version",
        "Do NOT push to remote (user must push manually)",
        "Use conventional commits to determine semver bump: BREAKING CHANGE = major, feat = minor, fix = patch",
        "Review ALL code changes line-by-line since last tag (not just commit messages)",
        "Combine conventional commit analysis with actual code diff review to generate comprehensive release notes",
        "Update package.json version field to match the new release version",
        "Release commit message format: 'chore(release): v{version}' with full release notes in commit body (breaking changes, features, fixes sections)",
        "If no previous git tag exists, use current package.json version as base for semver bump",
        "Before creating release: 1) Stage and commit all uncommitted changes with descriptive message, 2) Run npm test, 3) Run npm run build, 4) Abort release if tests or build fail",
        "When committing uncommitted changes before release: analyze changes and generate appropriate conventional commit message (not generic message)"
      ],
      "examples": [
        "Last tag is v0.3.0. Commits since: 'feat: add new command', 'fix: resolve bug'. Code diff shows 500 lines added. Claude reviews line-by-line, determines minor bump (feat), creates v0.3.1 tag with release notes combining commit analysis + code review.",
        "Last tag v0.3.0, new version v0.3.1 determined. Command updates package.json from 'version: 0.3.0' to 'version: 0.3.1', creates commit with updated package.json, then creates v0.3.1 tag.",
        "Commit message: 'chore(release): v0.3.1' with body containing '## Breaking Changes\\n(none)\\n\\n## Features\\n- Add new command\\n\\n## Fixes\\n- Resolve critical bug'",
        "No previous tag. package.json shows 'version: 0.3.0'. Commits contain 'feat: new feature'. Bump to v0.4.0 (minor bump from package.json version).",
        "User runs /release with uncommitted files. Command commits changes first, runs npm test (passes), runs npm run build (passes), then proceeds with release. If either fails, release is aborted with error message.",
        "Uncommitted changes include new test file and bug fix. Pre-release commit message: 'fix: resolve authentication bug and add test coverage' before proceeding with release commit."
      ],
      "userStory": {
        "role": "developer using Claude Code",
        "action": "create tagged releases with comprehensive release notes",
        "benefit": "I can automate version bumping and release documentation based on conventional commits"
      },
      "estimate": 5
    },
    "CLI-009": {
      "id": "CLI-009",
      "title": "Publish command for conditional npm publishing",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-23T22:43:01.389Z",
      "updatedAt": "2025-10-24T00:50:36.869Z",
      "description": "Add /publish slash command that: 1) Checks npm registry for @sengac/fspec current version, 2) Compares with local release tag, 3) Only publishes if version differs, 4) Prevents accidental duplicate publishing. Depends on release command being available.",
      "children": [],
      "dependsOn": [
        "CLI-008"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-23T22:50:47.930Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T00:47:27.186Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T00:47:48.316Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T00:49:56.870Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T00:50:36.869Z"
        }
      ],
      "rules": [
        "Implement as slash command for Claude Code in .claude/commands/publish.md (NOT an fspec CLI command)",
        "Verify git tag matches package.json version before comparing with npm registry (fail if mismatch)",
        "Compare package.json version with npm registry for @sengac/fspec - only publish if different",
        "If version already exists on npm registry, show message and exit successfully (not an error)",
        "No pre-publish testing or building - assume /release already validated. Only check version differences before publishing."
      ],
      "examples": [
        "Git tag: v0.3.1, package.json: 0.3.1, npm registry: 0.3.0. Versions match locally, differs from npm. Command proceeds with npm publish.",
        "Git tag: v0.3.1, package.json: 0.3.0, npm registry: 0.3.0. Mismatch detected. Command fails with error: 'Version mismatch: git tag (v0.3.1) does not match package.json (0.3.0). Run /release first.'",
        "Git tag: v0.3.0, package.json: 0.3.0, npm registry: 0.3.0. Command shows: 'Version 0.3.0 already published to npm. Skipping.' and exits successfully (exit code 0).",
        "User runs /publish after /release. Command checks: git tag (v0.3.1) matches package.json (0.3.1), differs from npm (0.3.0). Runs npm publish directly without tests/build."
      ],
      "userStory": {
        "role": "developer using Claude Code",
        "action": "publish releases to npm only if version differs from registry",
        "benefit": "I prevent accidental duplicate publishing"
      },
      "estimate": 3
    },
    "CLI-010": {
      "id": "CLI-010",
      "title": "Commit command with conventional commits and custom author",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-23T22:44:53.779Z",
      "updatedAt": "2025-10-24T00:50:37.643Z",
      "description": "Add /commit slash command that: 1) Analyzes all unstaged and staged files, 2) Stages all unstaged files, 3) Generates conventional commit message based on changes, 4) Creates commit with Roland Quast <rquast@rolandquast.com> author details (not Claude's), 5) Does NOT push (manual step).",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-23T22:53:59.997Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T00:47:27.962Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T00:47:49.117Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T00:49:57.642Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T00:50:37.643Z"
        }
      ],
      "rules": [
        "Implement as slash command for Claude Code in .claude/commands/commit.md (NOT an fspec CLI command)",
        "Commit author must be Roland Quast <rquast@rolandquast.com>, NOT Claude's default author",
        "Stage all unstaged files before committing (git add .)",
        "Generate conventional commit message by analyzing staged files and changes",
        "Do NOT push to remote (user must push manually)",
        "If no unstaged or staged files exist (clean working directory), show message and exit successfully (not an error)",
        "Follow strict conventional commits spec: type(scope): description. Include body with detailed changes and footer with BREAKING CHANGE if applicable."
      ],
      "examples": [
        "User runs /commit with clean working directory. Command shows: 'Nothing to commit, working directory clean.' and exits successfully.",
        "Unstaged files: src/commands/new-feature.ts (new file), src/types.ts (modified). Generated commit: 'feat(commands): add new feature command\\n\\nImplement new-feature command with TypeScript types and CLI integration.'"
      ],
      "userStory": {
        "role": "developer using Claude Code",
        "action": "create conventional commits with automated message generation",
        "benefit": "I maintain consistent commit history without manual message writing"
      },
      "estimate": 3
    },
    "RES-006": {
      "id": "RES-006",
      "title": "Stakeholder communication research script for unanswered questions",
      "type": "story",
      "status": "specifying",
      "createdAt": "2025-10-23T23:34:32.464Z",
      "updatedAt": "2025-10-23T23:43:29.518Z",
      "description": "Create research script that contacts stakeholders via chat platforms (Teams, Slack) when questions arise during Example Mapping that require human input. Integrates with fspec research framework to send questions and receive answers from project stakeholders.",
      "epic": "research-tools",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-23T23:34:38.818Z"
        }
      ],
      "rules": [
        "Use plugin architecture where communication platforms (Teams, Slack, etc.) can be added dynamically without modifying core script",
        "Main script stored in spec/research-scripts/stakeholder.sh, platform plugins stored in spec/research-scripts/plugins/ directory",
        "Script is one-way notification only: sends message to stakeholders and exits. Does NOT wait for response or handle callbacks.",
        "Message sender identity should be configurable (who the message appears to come from)",
        "Store platform credentials and settings in user-level config: ~/.fspec/fspec-config.json (NOT project-level spec/fspec-config.json)",
        "Message should include full context: question text, work unit ID, work unit title, epic (if any), existing rules, existing examples, and all questions/answers so far from Example Mapping",
        "AI asks human which platform(s) to use. If no preference specified, default to all configured platforms in ~/.fspec/fspec-config.json",
        "Auto-discover platform plugins by scanning spec/research-scripts/plugins/ directory for .sh files (no manifest/registry required)",
        "Auto-discover platform plugins by scanning spec/research-scripts/plugins/ directory for ANY executable files (not just .sh - could be .py, .js, compiled binaries, etc.)"
      ],
      "examples": [
        "User runs 'fspec research --tool=stakeholder --platform=teams --question=\"Should we support OAuth2?\"'. Main script loads spec/research-scripts/plugins/teams.sh and sends question via Teams API.",
        "AI runs 'fspec research --tool=stakeholder --platform=slack --question=\"OAuth support needed?\"'. Script sends message to configured Slack channel from configured user, then exits. Stakeholder sees notification and responds manually later in Claude Code session.",
        "User-level config at ~/.fspec/fspec-config.json contains Slack token and Teams webhook URL. Script reads from user config (not project config) to send stakeholder notifications.",
        "Message sent to Slack: 'Question for AUTH-001 (User Login, epic: user-management)\\n\\nQuestion: Should we support OAuth2?\\n\\nRules:\\n1. Password must be 8+ chars\\n\\nExamples:\\n1. Valid login with email/password\\n\\nPrevious Q&A:\\nQ: Support 2FA? A: Yes, in phase 2'",
        "AI asks: 'Send to Teams, Slack, or both?' Human says 'both'. Script sends to both platforms. If human doesn't specify, script checks config and sends to all configured platforms by default.",
        "Plugins directory contains teams.sh and slack.sh. Main script auto-discovers both platforms and can send to either/both based on config and user preference.",
        "Plugins directory contains teams.py (Python), slack (compiled Go binary), and discord.js (Node script). Main script auto-discovers all three by checking executable bit, not file extension."
      ],
      "dependsOn": [
        "CONFIG-001"
      ],
      "questions": [
        {
          "text": "@human: How should multiple stakeholders work? (A) Single destination per invocation, (B) Multiple destinations via repeated --platform flags, (C) Send to all configured platforms at once?",
          "selected": true,
          "answer": "AI asks human which platform(s) to use. If no preference specified, default to all configured platforms in ~/.fspec/fspec-config.json"
        }
      ]
    },
    "CONFIG-001": {
      "id": "CONFIG-001",
      "title": "Shared configuration management utilities for user and project config files",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-23T23:38:52.558Z",
      "updatedAt": "2025-10-24T13:10:08.190Z",
      "description": "Create shared code/functions to manage config files: user-level (~/.fspec/fspec-config.json) and project-level (spec/fspec-config.json). Utilities should handle reading, writing, merging, validating config across both scopes with proper precedence rules.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-24T12:51:18.003Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T13:06:27.440Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T13:08:19.621Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T13:08:20.311Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T13:10:08.190Z"
        }
      ],
      "questions": [
        {
          "text": "@human: What format should the config files use? Should both user-level and project-level use the same format?",
          "selected": true,
          "answer": "JSON format for both user-level (~/.fspec/fspec-config.json) and project-level (spec/fspec-config.json)"
        },
        {
          "text": "@human: When both user-level and project-level config files have the same setting, which takes precedence?",
          "selected": true,
          "answer": "Project-level config overrides user-level config (for project-specific overrides)"
        },
        {
          "text": "@human: How should nested config objects be merged? Deep merge (recursive) or shallow merge (replace entire objects)?",
          "selected": true,
          "answer": "Deep merge - merge nested objects recursively. This preserves user defaults while allowing project-specific overrides without duplication."
        },
        {
          "text": "@human: What types of settings should the config support? Specific schemas or generic JSON structure?",
          "selected": true,
          "answer": "Keep it generic - accept any JSON structure and let different features define their own config namespaces. No schema enforcement at the config utility level."
        },
        {
          "text": "@human: What should happen when config file doesn't exist, has invalid JSON, or is empty?",
          "selected": true,
          "answer": "File doesn't exist or is empty: return empty object {} (silent fallback). Invalid JSON syntax: throw error with helpful message (fail fast). Be lenient with absence, strict with mistakes."
        }
      ],
      "rules": [
        "JSON format for both user-level (~/.fspec/fspec-config.json) and project-level (spec/fspec-config.json)",
        "Project-level config overrides user-level config (for project-specific overrides)",
        "Deep merge - merge nested objects recursively. This preserves user defaults while allowing project-specific overrides without duplication.",
        "Keep it generic - accept any JSON structure and let different features define their own config namespaces. No schema enforcement at the config utility level.",
        "File doesn't exist or is empty: return empty object {} (silent fallback). Invalid JSON syntax: throw error with helpful message (fail fast). Be lenient with absence, strict with mistakes."
      ],
      "examples": [
        "User has no config files. Call loadConfig() returns empty object {}. No errors thrown.",
        "User has ~/.fspec/fspec-config.json with {\"timeout\": 60}. Project has no config. loadConfig() returns {\"timeout\": 60}.",
        "User has {\"research\": {\"timeout\": 60, \"tools\": [\"perplexity\"]}}. Project has {\"research\": {\"tools\": [\"jira\"]}}. loadConfig() returns {\"research\": {\"timeout\": 60, \"tools\": [\"jira\"]}} via deep merge.",
        "Project config has invalid JSON syntax (missing bracket). loadConfig() throws error with message: 'Invalid JSON in spec/fspec-config.json: Unexpected token...'.",
        "Developer calls writeConfig('user', {\"newSetting\": true}) and it writes to ~/.fspec/fspec-config.json with proper formatting."
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "manage configuration across user-level and project-level scopes",
        "benefit": "I can set personal defaults and project-specific overrides without duplication"
      },
      "estimate": 3
    },
    "BUG-041": {
      "id": "BUG-041",
      "title": "Data integrity validation missing in prioritize-work-unit",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-24T00:13:14.350Z",
      "updatedAt": "2025-10-24T00:23:53.471Z",
      "description": "prioritize-work-unit doesn't validate that work unit ID exists in the states array matching its status field, which could cause duplicates or silent failures if data is corrupted",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-24T00:13:42.487Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T00:16:25.424Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T00:17:51.849Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T00:23:51.839Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T00:23:53.471Z"
        }
      ],
      "userStory": {
        "role": "developer using prioritize-work-unit",
        "action": "detect data corruption early with clear error messages",
        "benefit": "I can fix corrupted data before it causes silent failures or duplicates"
      },
      "rules": [
        "Work unit status field MUST match which states array it's in (e.g., status='specifying' must be in states.specifying)",
        "If work unit status doesn't match its array location, throw error with repair suggestion",
        "Validate work unit's own status matches its array before prioritizing",
        "When using --before or --after, validate target work unit is in the same states array"
      ],
      "examples": [
        "AUTH-001 has status='specifying' but is in states.testing array. User runs 'fspec prioritize-work-unit AUTH-001 --position top'. Command throws: 'Data integrity error: Work unit AUTH-001 has status specifying but is not in states.specifying array. Run fspec repair-work-units'",
        "FEAT-017 is in specifying (correct). User runs 'fspec prioritize-work-unit FEAT-017 --before AUTH-001' where AUTH-001 status='specifying' but AUTH-001 is NOT in states.specifying. Command throws: 'Data integrity error: Work unit AUTH-001 has status specifying but is not in states.specifying array'",
        "Work unit AUTH-001 has status='implementing' and IS in states.implementing array. User runs 'fspec prioritize-work-unit AUTH-001 --position top'. Command succeeds (data is valid)"
      ]
    },
    "BUG-042": {
      "id": "BUG-042",
      "title": "1-based indexing not implemented in prioritize-work-unit",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-24T00:13:20.575Z",
      "updatedAt": "2025-10-24T00:23:54.289Z",
      "description": "Help text says numeric positions are 1-based (e.g., position 3 = third item) but code uses 0-based array indices, causing off-by-one errors",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-24T00:15:09.744Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T00:16:26.241Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T00:17:52.689Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T00:23:52.660Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T00:23:54.289Z"
        }
      ],
      "userStory": {
        "role": "user running prioritize-work-unit with numeric positions",
        "action": "use intuitive 1-based positions matching help text",
        "benefit": "position 3 means third item as documented, not fourth item"
      },
      "rules": [
        "Help text says numeric positions are 1-based (position 1 = first item, position 3 = third item)",
        "Code must convert 1-based user input to 0-based array indices (position - 1)",
        "Position must be >= 1 (reject position 0 or negative)"
      ],
      "examples": [
        "User runs 'fspec prioritize-work-unit AUTH-001 --position 1' expecting AUTH-001 to be first. AUTH-001 becomes first item (index 0).",
        "User runs 'fspec prioritize-work-unit AUTH-001 --position 3' expecting AUTH-001 to be third. AUTH-001 becomes third item (index 2).",
        "User runs 'fspec prioritize-work-unit AUTH-001 --position 0'. Command throws: 'Invalid position: 0. Position must be >= 1 (1-based index)'"
      ]
    },
    "REFAC-002": {
      "id": "REFAC-002",
      "title": "Remove unused rootStubFile property from AgentConfig",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-24T02:43:22.040Z",
      "updatedAt": "2025-10-24T02:50:36.405Z",
      "description": "The rootStubFile property in AgentConfig interface and all agent definitions is dead code. It was used by installRootStub() function which was removed in commit 9286b71 to fix the CLAUDE.md deletion bug. Property is defined but never used anywhere in the codebase.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-24T02:43:37.519Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T02:43:44.078Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T02:50:12.988Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T02:50:36.405Z"
        }
      ]
    },
    "GIT-005": {
      "id": "GIT-005",
      "title": "Wire up checkpoint CLI commands",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-24T06:28:46.772Z",
      "updatedAt": "2025-10-24T06:35:23.743Z",
      "description": "Checkpoint commands (checkpoint, list-checkpoints, restore-checkpoint, cleanup-checkpoints) exist but are not registered in src/index.ts, making them inaccessible from CLI",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-24T06:28:52.895Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T06:31:20.857Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T06:31:56.619Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T06:33:16.613Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T06:35:23.743Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "use checkpoint commands from the CLI",
        "benefit": "I can create, list, restore, and cleanup checkpoints for safe experimentation"
      },
      "rules": [
        "All checkpoint command files must export a registerXCommand function that takes a Commander program instance",
        "All checkpoint commands must be imported and registered in src/index.ts",
        "Command registration must follow existing patterns (checkpoint, list-checkpoints, restore-checkpoint, cleanup-checkpoints)"
      ],
      "examples": [
        "Running './dist/index.js checkpoint AUTH-001 baseline' creates a checkpoint named 'baseline' for work unit AUTH-001",
        "Running './dist/index.js list-checkpoints AUTH-001' shows all checkpoints for AUTH-001 with emoji indicators",
        "Running './dist/index.js restore-checkpoint AUTH-001 baseline' restores the baseline checkpoint for AUTH-001",
        "Running './dist/index.js cleanup-checkpoints AUTH-001 --keep-last 5' deletes old checkpoints, keeping only the 5 most recent"
      ],
      "estimate": 2
    },
    "BUG-043": {
      "id": "BUG-043",
      "title": "Auto-checkpoints not working - lazy import fails in bundled dist",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-24T06:47:47.525Z",
      "updatedAt": "2025-10-26T00:45:17.530Z",
      "description": "Automatic checkpoints are not being created during work unit status transitions. Root cause: Vite bundler incorrectly optimizes the conditional checkpoint logic, transforming 'const isDirty = await isWorkingDirectoryDirty(cwd); if (isDirty && currentStatus \\!== backlog)' into 'await Zn(t) && i \\!== backlog && (...)' which breaks execution flow. The checkpoint code never runs even when working directory is dirty.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-24T06:48:03.903Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T06:49:38.213Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T06:52:17.885Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T06:55:32.218Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T07:02:17.679Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T00:28:54.282Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T00:30:49.092Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T00:32:08.535Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T00:32:47.543Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T00:33:06.146Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T00:36:50.075Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T00:36:53.705Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T00:37:48.477Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T00:37:50.459Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T00:39:44.883Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T00:39:57.483Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T00:40:38.852Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T00:40:39.568Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T00:41:05.034Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T00:41:11.762Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T00:41:53.750Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T00:41:54.498Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T00:42:23.020Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T00:42:24.107Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T00:43:20.525Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T00:43:24.415Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T00:45:17.530Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec for ACDD workflow",
        "action": "have automatic checkpoints created reliably during work unit transitions",
        "benefit": "I can safely experiment and recover from mistakes without manual checkpoint creation"
      },
      "rules": [
        "Auto-checkpoints must be created before EVERY state transition (except from backlog)",
        "Lazy imports must work after Vite bundling into single dist/index.js file",
        "Auto-checkpoints must be created before EVERY state transition (except from backlog)",
        "Checkpoint creation logic must survive Vite bundler optimization without breaking execution flow",
        "Tests must validate BUNDLED distribution (dist/index.js), not just source code",
        "No dynamic imports (await import()) allowed in checkpoint-related code - ONLY static imports at top of file"
      ],
      "examples": [
        "User transitions from backlog to specifying with dirty working directory, sees '🤖 Auto-checkpoint created' message",
        "User transitions from specifying to testing with uncommitted changes, checkpoint saved before transition",
        "User has uncommitted changes, runs 'fspec update-work-unit-status TEST-001 implementing' (from testing state), sees '🤖 Auto-checkpoint: TEST-001-auto-testing created before transition' message",
        "User runs 'fspec list-checkpoints TEST-001' after transition, sees the auto-checkpoint in the list",
        "User has clean working directory, runs status transition, NO checkpoint created (expected behavior)",
        "User transitions FROM backlog state with uncommitted changes, NO checkpoint created (rule: except from backlog)",
        "Integration test runs 'npm run build' then executes './dist/index.js update-work-unit-status' and verifies checkpoint is actually created",
        "Static analysis test scans update-work-unit-status.ts for 'await import' and fails if found"
      ],
      "estimate": 3,
      "questions": [
        {
          "text": "@human: Should we fix this by refactoring the conditional logic (Option 1: if-else chain), using explicit boolean assignment (Option 2), or configuring Vite to disable optimization (Option 3)?",
          "selected": true,
          "answer": "Use Option 2: explicit boolean assignment - clearest intent, prevents optimizer issues, maintains readability"
        }
      ],
      "assumptions": [
        "Use Option 2: explicit boolean assignment - clearest intent, prevents optimizer issues, maintains readability"
      ]
    },
    "CLI-011": {
      "id": "CLI-011",
      "title": "Slash command for critical story review with ULTRATHINK",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-24T13:23:11.621Z",
      "updatedAt": "2025-10-24T22:55:40.235Z",
      "description": "Create /review slash command in .claude/commands that critically analyzes stories using ULTRATHINK to identify logical flaws, bugs, anti-patterns, and refactoring opportunities",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-24T13:23:18.623Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T22:37:39.740Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T22:40:01.575Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T22:41:43.753Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T22:55:40.235Z"
        }
      ],
      "userStory": {
        "role": "developer using Claude Code with fspec",
        "action": "critically review a story's acceptance criteria, tests, implementation, and coverage",
        "benefit": "I can identify logical flaws, bugs, anti-patterns, and refactoring opportunities before they become problems"
      },
      "rules": [
        "Command must prompt user to specify work unit ID if none provided as argument",
        "Must use ULTRATHINK mode for deep critical analysis of the story",
        "Must analyze all aspects: acceptance criteria (feature file), tests, implementation code, and coverage mappings",
        "Must identify: logical flaws, bugs introduced/created, anti-patterns, and refactoring opportunities",
        "Must check if existing architecture/utilities could be reused instead of new code",
        "Should read work unit metadata, linked feature file(s), test files from coverage, and implementation files from coverage",
        "Review output should be structured: Issues Found, Recommendations, Refactoring Opportunities, ACDD Compliance",
        "Yes, review should compare against similar completed stories using fspec query commands (get-scenarios, show-coverage, query-work-units) to identify inconsistencies in approach, naming conventions, and architectural patterns. If existing commands don't provide sufficient search capability, create a new story for enhanced search/comparison functionality as a dependency.",
        "Yes, review must validate consistency with CLAUDE.md coding standards (no 'any' types, ES modules, proper imports, etc.) and FOUNDATION.md project requirements (alignment with project goals, personas, capabilities)",
        "Yes, review must check if ACDD workflow was followed properly: verify temporal ordering (feature files created during specifying, tests before implementation), check for Example Mapping data (rules, examples, answered questions), validate state history timestamps align with file modification times",
        "Yes, review output must include specific actionable next steps for each issue: show the problem, suggest the fix, and provide concrete commands or actions to resolve it (e.g., 'Issue: Using any type in file.ts:42 → Fix: Replace with proper interface. Action: Edit file.ts line 42 to use UserInterface type')",
        "Yes, support reviewing multiple work units at once. Allow '/review CLI-001 CLI-002 CLI-003' syntax to review multiple stories in one go. Output should be structured per work unit with clear separators between reviews."
      ],
      "examples": [
        "User runs '/review CLI-011', command loads work unit, reads feature file, analyzes tests and implementation, outputs structured review with identified issues",
        "User runs '/review' without arguments, command asks 'Which work unit would you like me to review? Please provide the work unit ID (e.g., CLI-011)'",
        "Review finds test that doesn't actually test the scenario it claims to test, suggests rewriting test to properly validate acceptance criteria",
        "Review finds implementation using manual file operations when existing utility function in src/utils/ should be used instead, suggests refactoring",
        "Review finds feature file scenario that doesn't have corresponding test coverage, flags as gap in coverage mapping",
        "Review detects anti-pattern where code violates CLAUDE.md coding standards (using 'any' type instead of proper types), suggests specific fix"
      ],
      "questions": [
        {
          "text": "@human: Should the review compare against similar completed stories to identify inconsistencies or patterns?",
          "selected": true,
          "answer": "Yes, review should compare against similar completed stories using fspec query commands (get-scenarios, show-coverage, query-work-units) to identify inconsistencies in approach, naming conventions, and architectural patterns. If existing commands don't provide sufficient search capability, create a new story for enhanced search/comparison functionality as a dependency."
        },
        {
          "text": "@human: Should it validate consistency with CLAUDE.md coding standards and FOUNDATION.md project requirements?",
          "selected": true,
          "answer": "Yes, review must validate consistency with CLAUDE.md coding standards (no 'any' types, ES modules, proper imports, etc.) and FOUNDATION.md project requirements (alignment with project goals, personas, capabilities)"
        },
        {
          "text": "@human: Should it check if the ACDD workflow was followed properly (temporal ordering, Example Mapping before specs, tests before implementation)?",
          "selected": true,
          "answer": "Yes, review must check if ACDD workflow was followed properly: verify temporal ordering (feature files created during specifying, tests before implementation), check for Example Mapping data (rules, examples, answered questions), validate state history timestamps align with file modification times"
        },
        {
          "text": "@human: Should the review output include specific actionable next steps, or just identify issues for the developer to address?",
          "selected": true,
          "answer": "Yes, review output must include specific actionable next steps for each issue: show the problem, suggest the fix, and provide concrete commands or actions to resolve it (e.g., 'Issue: Using any type in file.ts:42 → Fix: Replace with proper interface. Action: Edit file.ts line 42 to use UserInterface type')"
        },
        {
          "text": "@human: Should it support reviewing multiple work units at once, or always single work unit reviews?",
          "selected": true,
          "answer": "Yes, support reviewing multiple work units at once. Allow '/review CLI-001 CLI-002 CLI-003' syntax to review multiple stories in one go. Output should be structured per work unit with clear separators between reviews."
        }
      ],
      "estimate": 8,
      "dependsOn": [
        "QRY-002"
      ]
    },
    "LANG-001": {
      "id": "LANG-001",
      "title": "Internationalization and localization support for multiple languages",
      "type": "story",
      "status": "specifying",
      "createdAt": "2025-10-24T22:27:50.151Z",
      "updatedAt": "2025-10-24T22:28:24.595Z",
      "description": "Add i18n framework to fspec to support multiple languages for all user-facing text including CLI output, error messages, help text, and system-reminders",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-24T22:27:54.064Z"
        }
      ],
      "userStory": {
        "role": "developer or AI agent using fspec in a non-English language environment",
        "action": "see all CLI output, error messages, and help text in my preferred language",
        "benefit": "I can use fspec effectively without language barriers"
      },
      "questions": [
        {
          "text": "@human: Which languages should be supported initially? (e.g., Spanish, French, German, Japanese, Chinese, etc.)",
          "selected": false
        },
        {
          "text": "@human: How should locale/language be configured? Environment variable (LANG), config file setting, CLI flag (--lang=es), or all three with precedence order?",
          "selected": false
        },
        {
          "text": "@human: Should Gherkin feature files remain in English (industry standard), or should they also be localizable?",
          "selected": false
        },
        {
          "text": "@human: Should system-reminders (for AI agents) be localized, or always remain in English since AI models typically understand English best?",
          "selected": false
        },
        {
          "text": "@human: What i18n library should be used? (e.g., i18next, FormatJS/react-intl for CLI, or custom solution)",
          "selected": false
        },
        {
          "text": "@human: Should translation files be JSON (easy to edit), YAML (human-readable), or .po/.pot files (professional translation tooling)?",
          "selected": false
        },
        {
          "text": "@human: Where should translation files be stored? Project-level (spec/i18n/), user-level (~/.fspec/i18n/), or both with merging?",
          "selected": false
        },
        {
          "text": "@human: Should date/time formatting, number formatting, and pluralization rules be supported (full i18n), or just text translation?",
          "selected": false
        },
        {
          "text": "@human: How should missing translations be handled? Fallback to English, show translation key, or throw error?",
          "selected": false
        },
        {
          "text": "@human: Should there be a command to extract translatable strings from source code (like 'fspec extract-translations')?",
          "selected": false
        }
      ]
    },
    "QRY-002": {
      "id": "QRY-002",
      "title": "Enhanced search and comparison commands for similar story analysis",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-24T22:53:07.974Z",
      "updatedAt": "2025-10-25T00:21:50.918Z",
      "description": "Create advanced query commands that allow /review to search for similar completed stories by analyzing patterns, naming conventions, architectural approaches, and implementation strategies to enable cross-story consistency checking",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-24T23:32:29.028Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-24T23:35:23.604Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-24T23:36:56.856Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-24T23:46:15.218Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-24T23:46:24.889Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-25T00:14:57.808Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T00:19:45.669Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-25T00:21:50.918Z"
        }
      ],
      "userStory": {
        "role": "developer using /review command",
        "action": "search for similar completed stories to compare patterns and approaches",
        "benefit": "I can identify inconsistencies and ensure architectural consistency across the codebase"
      },
      "rules": [
        "Search must support filtering by work unit type (story, bug, task)",
        "Search must support filtering by status (done, backlog, implementing, etc.)",
        "Search must support filtering by tags (single or multiple tags)",
        "Search must support filtering by feature group (e.g., all CLI features, all authentication features)",
        "Search results must show coverage information (test files and implementation files)",
        "Search must support text search across scenario names, feature descriptions, and work unit titles",
        "Search results must be sortable by date, story points, or work unit ID",
        "both - return work unit IDs for traceability and feature file paths for direct access to specs",
        "yes - side-by-side comparison helps identify pattern divergence and best practices",
        "table for human readability with --json flag option for programmatic use",
        "both - literal by default with --regex flag for advanced patterns",
        "yes - automatic highlighting of naming convention differences (camelCase vs snake_case, different prefixes, etc.)"
      ],
      "examples": [
        "Search for all completed CLI stories: fspec query-work-units --type=story --status=done --tag=@cli",
        "Find scenarios with 'validation' in the name across all features: fspec search-scenarios --query=validation",
        "Compare implementation approaches for authentication stories: fspec compare-implementations --tag=@authentication --show-coverage",
        "Find all work units using a specific utility function: fspec search-implementation --function=loadConfig --show-work-units",
        "List test patterns for high-priority features: fspec show-test-patterns --tag=@high --include-coverage"
      ],
      "questions": [
        {
          "text": "@human: Should search commands return work unit IDs, feature file paths, or both?",
          "selected": true,
          "answer": "both - return work unit IDs for traceability and feature file paths for direct access to specs"
        },
        {
          "text": "@human: Should comparison commands show side-by-side diffs of implementation approaches?",
          "selected": true,
          "answer": "yes - side-by-side comparison helps identify pattern divergence and best practices"
        },
        {
          "text": "@human: What output format should search results use (table, JSON, plain text)?",
          "selected": true,
          "answer": "table for human readability with --json flag option for programmatic use"
        },
        {
          "text": "@human: Should search support regex patterns or just literal string matching?",
          "selected": true,
          "answer": "both - literal by default with --regex flag for advanced patterns"
        },
        {
          "text": "@human: Should comparison commands highlight naming convention differences automatically?",
          "selected": true,
          "answer": "yes - automatic highlighting of naming convention differences (camelCase vs snake_case, different prefixes, etc.)"
        }
      ],
      "estimate": 13
    },
    "FEAT-018": {
      "id": "FEAT-018",
      "title": "Multi-Tool Bootstrap System",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-24T23:48:22.326Z",
      "updatedAt": "2025-10-24T23:48:22.326Z",
      "description": "Extend fspec init to bootstrap multiple tools (fspec, mindstrike CLI, future tools) for AI agents. Centralize agent detection logic (Claude Code, Cursor, Windsurf, etc.) and template management in fspec instead of duplicating per tool. Allow tools to register templates with fspec via tool registry. When running 'fspec init', detect agent and copy bootstrap files for ALL registered tools (fspec.md, mindstrike.md, etc.). This makes fspec the universal bootstrap manager for AI coding tools, eliminating duplicate agent detection logic across projects.",
      "children": []
    },
    "CLI-012": {
      "id": "CLI-012",
      "title": "Review command with done status integration",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-25T00:26:55.548Z",
      "updatedAt": "2025-10-25T00:47:19.259Z",
      "description": "Add 'fspec review' command that provides context for reviewing completed work units, and integrate system-reminder into done status transition to suggest reviews",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-25T00:27:02.445Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-25T00:35:37.381Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-25T00:43:30.816Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T00:43:31.567Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-25T00:47:19.259Z"
        }
      ],
      "userStory": {
        "role": "developer or AI agent completing work",
        "action": "review completed work units before finalizing them",
        "benefit": "I ensure quality and completeness before marking work as truly done"
      },
      "questions": [
        {
          "text": "@human: When exactly should the system-reminder to suggest review appear? (A) When transitioning TO done status, (B) When work unit IS IN done status and user runs another command, or (C) Both scenarios?",
          "selected": true,
          "answer": "A - When transitioning TO done status. Emit system-reminder suggesting 'fspec review <work-unit-id>' to review the work before finalizing."
        },
        {
          "text": "@human: What information should 'fspec review' provide? (A) Work unit summary, (B) Linked test/impl files from coverage, (C) Git diff for this work unit, (D) Validation checklist, (E) All of the above, or (F) Something else?",
          "selected": true,
          "answer": "E - All of the above. Use the same comprehensive review system from CLI-011's /review slash command, including work unit summary, coverage analysis, test/impl files, ACDD compliance, and coding standards validation."
        },
        {
          "text": "@human: Should review be (A) Informational only - just display data for manual review, (B) Interactive checklist - with items to mark complete, or (C) Automated - run validation commands and report results?",
          "selected": true,
          "answer": "A - Informational only. Display comprehensive review data using the same ULTRATHINK analysis from /review command, but let user manually assess. The review command provides context and guidance."
        },
        {
          "text": "@human: Should reviews be tracked/recorded? (A) Keep record that work unit was reviewed, (B) Require review confirmation before allowing done status, or (C) Optional review with reminder only (not mandatory)?",
          "selected": true,
          "answer": "C - Optional review with reminder only (not mandatory). System-reminder suggests using 'fspec review' when moving to done, but doesn't block the transition. Keeps workflow flexible."
        },
        {
          "text": "@human: What about work units already in done status? Should they support 'fspec review <work-unit-id>' for retrospective review? Can review be run multiple times?",
          "selected": true,
          "answer": "Yes - 'fspec review <work-unit-id>' should work for any work unit in any status (backlog, specifying, testing, implementing, validating, done, blocked). Can be run multiple times. Provides context-aware analysis based on current state."
        }
      ],
      "rules": [
        "Review command must be 'fspec review <work-unit-id>' CLI command, not just a slash command",
        "System-reminder must be emitted when transitioning to 'done' status in update-work-unit-status command",
        "Review command must use same analysis approach as CLI-011's /review slash command (ULTRATHINK, coverage, ACDD compliance)",
        "Review must work for work units in ANY status (not just done)",
        "System-reminder must include exact command: 'fspec review <work-unit-id>' with actual work unit ID"
      ],
      "examples": [
        "User runs 'fspec update-work-unit-status AUTH-001 done', system-reminder suggests 'Consider reviewing before finalizing: fspec review AUTH-001'",
        "User runs 'fspec review CLI-011', output shows: Issues Found (critical/warnings), ACDD Compliance, Coverage Analysis, Summary with priority actions",
        "User runs 'fspec review SPEC-001' (work unit in testing status), review shows current progress, missing test coverage, suggests next steps",
        "User runs 'fspec review BUG-007' (completed bug fix), review validates fix quality, checks regression test coverage, confirms coding standards"
      ],
      "estimate": 5
    },
    "TEST-006": {
      "id": "TEST-006",
      "title": "Docstring-based test-to-scenario linking system",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-25T00:26:56.043Z",
      "updatedAt": "2025-10-25T05:38:32.645Z",
      "description": "Create a docstring-based system for linking test scenarios/steps to Gherkin acceptance criteria, with tooling to sync and migrate existing unlinked tests",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-25T00:30:22.828Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-25T05:09:31.531Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-25T05:14:08.430Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-25T05:27:18.828Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-25T05:29:29.947Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T05:33:15.238Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-25T05:38:32.646Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for ACDD workflow",
        "action": "link test step comments to Gherkin feature file steps using @step prefix",
        "benefit": "I maintain Cucumber-style step-level traceability and get validation when steps don't match"
      },
      "questions": [
        {
          "text": "@human: What should the docstring format look like? Should it reference scenario names, Given/When/Then steps, or both? Should it include feature file paths?",
          "selected": true,
          "answer": "Coverage tracking uses scenario-level traceability in .feature.coverage files, NOT step-level @step docstrings. This system complements scenario-level coverage, not replaces it."
        },
        {
          "text": "@human: How should the tool detect existing tests without docstring links? Should it scan all test files in the project, or specific directories?",
          "selected": true,
          "answer": "Coverage files (.feature.coverage) are created automatically when create-feature command runs. Detection is implicit through show-coverage command which shows uncovered scenarios."
        },
        {
          "text": "@human: What should the migration tool do? (A) Interactive prompt for each unlinked test, (B) Batch analysis and suggested mappings, (C) Automatic linking based on test names, or (D) Something else?",
          "selected": true,
          "answer": "No migration tool exists. Coverage tracking is done manually via link-coverage command after writing tests and implementation. This is intentional - explicit linking ensures accuracy."
        },
        {
          "text": "@human: Should the sync tool validate that docstring references match actual scenarios in feature files? What happens if they're out of sync?",
          "selected": true,
          "answer": "Audit-coverage command validates file paths exist. Out-of-sync links can be detected (broken paths) and auto-fixed with --fix flag. Line number validation is NOT performed."
        },
        {
          "text": "@human: Should this integrate with existing .feature.coverage files, or be a separate system? Should it replace or complement coverage tracking?",
          "selected": true,
          "answer": "This IS the .feature.coverage system. Coverage files store scenario-to-test-to-implementation mappings. This complements feature files (acceptance criteria) with traceability data."
        }
      ],
      "rules": [
        "Every scenario must track which test file validates it and which implementation file implements it",
        "Coverage files (.feature.coverage) are auto-created by create-feature command and store scenario-to-test-to-implementation mappings",
        "Link coverage IMMEDIATELY after writing tests or code (do not batch)",
        "Coverage tracking uses line ranges for tests (e.g., 45-62) and specific line numbers for implementation (e.g., 10,11,12,23,24)",
        "Audit-coverage verifies file paths exist and can auto-fix broken links with --fix flag",
        "Coverage files (.feature.coverage) are created automatically when create-feature command runs. Detection is implicit through show-coverage command which shows uncovered scenarios.",
        "Audit-coverage command validates file paths exist. Out-of-sync links can be detected (broken paths) and auto-fixed with --fix flag. Line number validation is NOT performed.",
        "This IS the .feature.coverage system. Coverage files store scenario-to-test-to-implementation mappings. This complements feature files (acceptance criteria) with traceability data.",
        "Test files use comments (// Given, // When, // Then) that must match actual steps in feature file scenarios",
        "System validates that test comments match feature file steps exactly (Cucumber-style step matching)",
        "Step matching supports parameterized steps using hybrid similarity algorithm for fuzzy matching (e.g., '// Given I have 5 items' matches 'Given I have {int} items')",
        "Existing fspec coverage commands (link-coverage, show-coverage, audit-coverage) are enhanced to validate step comments match feature file steps",
        "Step comment validation is a HARD ERROR by default - command fails if test comments don't match feature steps",
        "Override flag --skip-step-validation allows linking even when step comments don't match (escape hatch for edge cases)",
        "When step validation fails, emit <system-reminder> showing: (1) which steps are missing/mismatched, (2) exact step text from feature file to copy, (3) how to override with --skip-step-validation flag",
        "Step comments use '@step' prefix for fast searching: '// @step Given I am on the login page'",
        "System is backward compatible - also recognizes plain step comments without @step prefix (e.g., '// Given I am on the login page')",
        "show-coverage displays step-level validation status showing which steps have matching comments (✓ matched) vs missing (✗ MISSING STEP COMMENT)",
        "Step matching uses existing hybrid similarity algorithm with adaptive thresholds: <10 chars=0.85, 10-20=0.80, 20-40=0.75, 40+=0.70"
      ],
      "examples": [
        "Developer writes test for 'Login with valid credentials' scenario at lines 45-62 in auth.test.ts, runs link-coverage command, coverage file updated with test mapping",
        "Developer implements login function at lines 10-24 in login.ts, runs link-coverage to add implementation mapping to existing test, coverage file shows full traceability",
        "Developer runs show-coverage for user-authentication feature, sees 50% coverage (1 of 2 scenarios covered), identifies uncovered scenario to work on next",
        "Developer refactors codebase and moves test files, runs audit-coverage, discovers broken file paths, runs audit-coverage --fix to remove stale mappings",
        "Developer runs show-coverage with no arguments, sees project-wide report showing 65% overall coverage across all features, identifies features needing attention",
        "Test has '// Given I have 5 items', feature has 'Given I have {int} items', hybrid similarity matches them with high confidence",
        "Running 'fspec link-coverage user-auth --scenario Login...' validates that test file contains matching step comments for all Given/When/Then steps in the scenario",
        "Test missing '// When I click login', link-coverage fails with system-reminder showing exact text to add: '// When I click the login button' and override option '--skip-step-validation'",
        "Test file with '// @step Given I am on the login page' matches feature step 'Given I am on the login page'",
        "Legacy test with '// Given I am logged in' (no @step prefix) still matches feature step 'Given I am logged in' for backward compatibility",
        "show-coverage output shows: 'Scenario: Login (FULLY COVERED)' with step breakdown '✓ Given I am on login page (matched)' and '✗ Then I should be logged in (MISSING STEP COMMENT)'",
        "Step '// @step Given I have 5 items' matches 'Given I have {int} items' using hybrid similarity with threshold 0.75 (medium length step)"
      ],
      "assumptions": [
        "Coverage tracking uses scenario-level traceability in .feature.coverage files, NOT step-level @step docstrings. This system complements scenario-level coverage, not replaces it.",
        "No migration tool exists. Coverage tracking is done manually via link-coverage command after writing tests and implementation. This is intentional - explicit linking ensures accuracy."
      ],
      "estimate": 5
    },
    "REV-002": {
      "id": "REV-002",
      "title": "Add agent-agnostic ultrathink to review command and update documentation",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-25T00:51:44.299Z",
      "updatedAt": "2025-10-25T01:30:13.576Z",
      "description": "Make review command use shared agent detection code (getAgentConfig) for agent-agnostic ultrathink support. Update all documentation (src/help.ts, command help files, CLAUDE.md autogenerator templates, README.md, docs/). Remove obsolete .claude/commands/review.md file.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-25T00:51:54.870Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-25T01:00:30.260Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-25T01:01:16.304Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T01:02:15.518Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-25T01:30:13.576Z"
        }
      ],
      "userStory": {
        "role": "AI agent (any type: Claude, Cursor, Aider, etc.)",
        "action": "use the review command with agent-specific metacognition formatting",
        "benefit": "I get properly formatted output that works with my capabilities"
      },
      "rules": [
        "Review command must use shared agent detection code (getAgentConfig) from src/utils/agentRuntimeConfig.ts",
        "Agent-specific formatting must use formatAgentOutput() for system-reminders (Claude) or bold text (other agents)",
        "Documentation must be updated in: src/help.ts, src/commands/review-help.ts (if exists), autogenerator templates, README.md, and docs/ directory",
        "Obsolete .claude/commands/review.md file must be removed (no longer used)",
        "Yes - Review command help should detect agent using getAgentConfig() and show agent-specific examples (e.g., <system-reminder> for Claude, **⚠️ IMPORTANT:** for Cursor). If no agent configured, show generic examples."
      ],
      "examples": [
        "Claude Code agent runs 'fspec review AUTH-001' and gets output with <system-reminder> tags for ULTRATHINK guidance",
        "Cursor agent runs 'fspec review API-005' and gets output with **⚠️ IMPORTANT:** bold text formatting",
        "Aider CLI agent runs 'fspec review DASH-003' and gets output with **IMPORTANT:** plain bold text",
        "Review command detects agent from FSPEC_AGENT env var or spec/fspec-config.json or defaults to safe plain text"
      ],
      "questions": [
        {
          "text": "@human: Should the review command help include examples for different agent types (Claude, Cursor, Aider)?",
          "selected": true,
          "answer": "Yes - Review command help should detect agent using getAgentConfig() and show agent-specific examples (e.g., <system-reminder> for Claude, **⚠️ IMPORTANT:** for Cursor). If no agent configured, show generic examples."
        }
      ],
      "estimate": 3
    },
    "REMIND-009": {
      "id": "REMIND-009",
      "title": "Context-aware system-reminders for workflow state transitions",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-25T11:29:04.049Z",
      "updatedAt": "2025-10-25T19:37:44.391Z",
      "description": "When work units transition to a new workflow state (backlog→specifying→testing→implementing→validating), emit a system-reminder showing the most commonly used commands for that state, helping AI agents discover the right commands without guessing. Each reminder should be concise, action-oriented, and include pointers to help documentation.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-25T11:29:23.862Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-25T11:41:40.734Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-25T11:42:57.867Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T11:46:23.443Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-25T11:46:40.414Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T12:34:19.526Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-25T19:37:44.391Z"
        }
      ],
      "userStory": {
        "role": "AI agent working on fspec project",
        "action": "see relevant commands when entering a new workflow state",
        "benefit": "I can discover and use the right commands without guessing or searching documentation"
      },
      "rules": [
        "System-reminders should appear when work unit status changes via update-work-unit-status command",
        "Each workflow state (backlog, specifying, testing, implementing, validating) has its own set of commonly used commands",
        "Reminders must be concise - show only 5-7 most common commands per state, not every possible command",
        "Each command should have brief syntax example showing arguments (e.g., 'fspec remove-rule <id> <index>' not just 'remove-rule')",
        "Include pointer to help documentation at end (e.g., 'For complete reference: fspec help discovery' or 'fspec <command> --help')",
        "Done and blocked states do not need command reminders (blocked needs issue resolution, done is complete)"
      ],
      "examples": [
        "When work unit moves to SPECIFYING, AI sees reminder: 'Common commands: fspec add-rule <id> \"rule\" | fspec remove-rule <id> <index> | fspec add-example <id> \"example\" | fspec remove-example <id> <index> | fspec add-question <id> \"@human: question?\" | fspec answer-question <id> <index> --answer \"...\" | fspec generate-scenarios <id>. For more: fspec help discovery'",
        "When work unit moves to TESTING, AI sees reminder: 'Common commands: fspec link-coverage <feature> --scenario \"...\" --test-file <path> --test-lines <range> | fspec show-coverage <feature> | fspec show-feature <name>. Write tests that map to Gherkin scenarios. For more: fspec link-coverage --help'",
        "When work unit moves to IMPLEMENTING, AI sees reminder: 'Common commands: fspec link-coverage <feature> --scenario \"...\" --impl-file <path> --impl-lines <lines> | fspec checkpoint <id> <name> | fspec restore-checkpoint <id> <name> | fspec list-checkpoints <id>. Write minimal code to pass tests. For more: fspec checkpoint --help'",
        "When work unit moves to VALIDATING, AI sees reminder: 'Common commands: fspec validate | fspec validate-tags | fspec check | fspec audit-coverage <feature> | npm test | npm run check. Run ALL tests to ensure nothing broke. For more: fspec check --help'",
        "When work unit moves to BACKLOG (deprioritization), no command reminder is shown since backlog is a waiting state with no active work"
      ],
      "questions": [
        {
          "text": "@human: Should the reminder show full command syntax with <placeholders> for arguments, or just command names with brief descriptions?",
          "selected": true,
          "answer": "Full command syntax with <placeholders> for arguments (e.g., 'fspec remove-rule <id> <index>') because it provides immediate usability and reduces ambiguity about argument order"
        },
        {
          "text": "@human: Should commands be shown one per line (vertical list) or separated by pipe | (horizontal compact)?",
          "selected": true,
          "answer": "One per line (vertical list) because it's easier to scan, maintains clean structure in system-reminders, and remains readable regardless of command count"
        },
        {
          "text": "@human: Should BACKLOG state show a reminder about prioritization commands (prioritize-work-unit, show-work-unit), or skip reminders entirely since it's a waiting state?",
          "selected": true,
          "answer": "Skip reminders entirely for BACKLOG state because it's a waiting state with no active work, and prioritization happens at board level rather than when transitioning individual work units"
        },
        {
          "text": "@human: Should VALIDATING state include non-fspec commands (npm test, npm run check) in the reminder, or only fspec commands?",
          "selected": true,
          "answer": "Only fspec commands - no external commands (npm test, npm run check, etc.) because fspec is platform and language agnostic"
        },
        {
          "text": "@human: Should the reminder appear every time status changes, or only the first time entering each state (cached per work unit)?",
          "selected": true,
          "answer": "Every time status changes because context switches between work units, backward movement in ACDD workflow, different conversation sessions, and low cost with high value for always having command context"
        }
      ],
      "estimate": 5
    },
    "FEAT-019": {
      "id": "FEAT-019",
      "title": "Reverse ACDD Strategy D Not Detecting Implementation Files",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-25T11:51:54.504Z",
      "updatedAt": "2025-10-25T12:29:06.438Z",
      "description": "When running 'fspec reverse' on a project with implementation files but no tests or features (like MusicPlayer.tsx, usePlaylistStore.ts), Strategy D (Full Reverse ACDD) is not detected. The tool only detects Strategy B (features without tests) based on unrelated feature files in the project. Expected: Strategy D should analyze implementation files in src/ and guide creation of feature files + tests. Actual: Strategy D not offered, manual specification fails with 'No active reverse session'.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-25T11:52:22.171Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-25T12:20:26.361Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-25T12:23:23.010Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T12:26:31.287Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-25T12:29:06.438Z"
        }
      ],
      "rules": [
        "Strategy D guides AI agents through outside-in BDD: Context → Personas → User Behavior → Example Maps → Features → Test Skeletons → Implementation Links",
        "Strategy D uses foundation.json personas to help AI understand WHO uses the system and WHAT they want to accomplish (not HOW it's implemented)",
        "AI provides implementation context as input, Strategy D helps transform it into user-centric feature specifications and example maps",
        "Strategy D should fill gaps backward from behavior to implementation: Example Maps → Features → Tests → Coverage Links to existing code",
        "Yes. Strategy D should actively prompt with persona-based questions using system-reminders to guide AI thinking. Example: 'WHO uses this? (Check foundation.json personas)' and 'WHAT does [persona] want to accomplish?'. This provides cognitive scaffolding to help AI shift from inside-out code-thinking to outside-in behavior-thinking. Prompts should be guiding (not blocking), conditional on foundation.json existence, and include examples of good persona-driven thinking.",
        "Foundation.json must exist (run 'fspec discover-foundation' if missing as one-time setup). During Strategy D, when persona is needed but missing, prompt AI to add it incrementally via 'fspec add-persona <name> <description> --goal <goal>'. For granular code (APIs, functions), guide AI to identify which human persona BENEFITS (not which system calls it) using system-reminders: 'Not who calls calculateDiscount() but who benefits from accurate discounts? Answer: Shopper'. Skip feature files for pure utilities (formatDate, parseJSON) - test-only coverage.",
        "Yes. Strategy D should provide transformation templates via system-reminders to help AI translate implementation → behavior. Templates: (1) UI Elements → User Actions (button → 'User clicks/taps [action]', input → 'User enters [data]'), (2) State → User Expectations (useState → 'User sees [state]', loading → 'User waits for [process]'), (3) API Endpoints → User Needs (POST /orders → 'User completes order'). Templates accelerate mental shift, ensure consistency, and reinforce outside-in thinking.",
        "Pause for review with guided prompts. After AI creates example map, Strategy D emits system-reminder with review checklist: 'Do rules cover examples?', 'Are examples concrete?', 'All questions answered?', 'Examples map to personas?'. Then offers explicit choice: (1) Generate features now: fspec generate-scenarios, (2) Add more examples/rules. AI explicitly chooses when to generate (not automatic). Example Mapping is a conversation requiring reflection, not a form-filling exercise. Quality gate prevents garbage-in-garbage-out.",
        "Semi-automatic with educational system-reminder. Strategy D auto-links coverage by default using 'fspec link-coverage --skip-validation' but emits system-reminder showing: (1) What was linked (scenario → test skeleton → implementation), (2) Exact command that was run (educational), (3) How to verify: 'fspec show-coverage', (4) How to fix if wrong: 'fspec unlink-coverage' then re-link manually. Balances low friction (automatic) with transparency (not a black box) and learning (AI sees the mechanism).",
        "Feature-scoped sessions (multiple related files allowed). Strategy D allows multiple implementation files in one session if they deliver the SAME user-facing feature. System-reminder guides AI: 'Do these files deliver same user behavior?' YES → One work unit, one example map, one feature file, multiple test files (one per implementation). NO → Separate sessions. BDD focuses on user behavior which often spans multiple files. Track all files in work unit metadata under 'reverseSession.implementationFiles[]'. Link all via coverage to same feature file."
      ],
      "examples": [
        "AI: 'I have MusicPlayer.tsx with play/pause/skip buttons' → Strategy D: 'Who uses this?' → AI sees foundation.json personas: Music Listener persona → Strategy D guides: 'What does Music Listener want?' → AI creates example map: 'Music Listener plays song', 'Music Listener pauses playback' → Generates feature file + test skeletons → Links coverage to MusicPlayer.tsx",
        "AI: 'I have usePlaylistStore.ts with addSong(), removeSong(), clearPlaylist()' → Strategy D: 'What user behavior does this support?' → AI identifies: Managing playlists → Creates example map with rules: 'User can add songs', 'User can remove songs' → Generates playlist-management.feature → Creates test skeleton → Links to usePlaylistStore.ts implementation",
        "Project has foundation.json with 'Mobile App User' persona (goal: Stream music on the go) → AI provides AudioPlayer.tsx context → Strategy D prompts: 'How does Mobile App User stream music?' → AI creates example map: 'User taps play', 'User adjusts volume', 'User sees album art' → Feature file generated with user-centric scenarios"
      ],
      "questions": [
        {
          "text": "@human: Should Strategy D scan src/ for files lacking feature files in spec/features?",
          "selected": true,
          "answer": "No. Strategy D should NOT scan src/ automatically. Instead, it should guide the AI agent through a context-driven discovery process: AI provides implementation context → Tool uses foundation.json personas → AI understands user behavior → Creates example maps → Generates features → Generates test skeletons → Links to implementation. This is outside-in BDD, not inside-out code scanning."
        },
        {
          "text": "@human: When AI provides implementation context (e.g., 'MusicPlayer.tsx has play/pause buttons'), should Strategy D prompt with persona-based questions like 'Which persona from foundation.json uses this feature?' or 'What does [persona] want to accomplish?'",
          "selected": true,
          "answer": "Yes. Strategy D should actively prompt with persona-based questions using system-reminders to guide AI thinking. Example: 'WHO uses this? (Check foundation.json personas)' and 'WHAT does [persona] want to accomplish?'. This provides cognitive scaffolding to help AI shift from inside-out code-thinking to outside-in behavior-thinking. Prompts should be guiding (not blocking), conditional on foundation.json existence, and include examples of good persona-driven thinking."
        },
        {
          "text": "@human: If foundation.json is missing or has no personas, should Strategy D guide AI through creating foundation first via 'fspec discover-foundation', or allow manual persona specification for this reverse session only?",
          "selected": true,
          "answer": "Foundation.json must exist (run 'fspec discover-foundation' if missing as one-time setup). During Strategy D, when persona is needed but missing, prompt AI to add it incrementally via 'fspec add-persona <name> <description> --goal <goal>'. For granular code (APIs, functions), guide AI to identify which human persona BENEFITS (not which system calls it) using system-reminders: 'Not who calls calculateDiscount() but who benefits from accurate discounts? Answer: Shopper'. Skip feature files for pure utilities (formatDate, parseJSON) - test-only coverage."
        },
        {
          "text": "@human: Should Strategy D provide templates or prompts to help AI transform implementation details (buttons, functions, state) into user behavior descriptions (plays song, pauses playback, manages playlist)?",
          "selected": true,
          "answer": "Yes. Strategy D should provide transformation templates via system-reminders to help AI translate implementation → behavior. Templates: (1) UI Elements → User Actions (button → 'User clicks/taps [action]', input → 'User enters [data]'), (2) State → User Expectations (useState → 'User sees [state]', loading → 'User waits for [process]'), (3) API Endpoints → User Needs (POST /orders → 'User completes order'). Templates accelerate mental shift, ensure consistency, and reinforce outside-in thinking."
        },
        {
          "text": "@human: After AI creates example maps (rules, examples, questions), should Strategy D automatically generate feature files and test skeletons, or should it prompt AI to review/refine the example map first?",
          "selected": true,
          "answer": "Pause for review with guided prompts. After AI creates example map, Strategy D emits system-reminder with review checklist: 'Do rules cover examples?', 'Are examples concrete?', 'All questions answered?', 'Examples map to personas?'. Then offers explicit choice: (1) Generate features now: fspec generate-scenarios, (2) Add more examples/rules. AI explicitly chooses when to generate (not automatic). Example Mapping is a conversation requiring reflection, not a form-filling exercise. Quality gate prevents garbage-in-garbage-out."
        },
        {
          "text": "@human: Should Strategy D guide AI to link test skeletons to existing implementation using 'fspec link-coverage --skip-validation' automatically, or require AI to manually create coverage links?",
          "selected": true,
          "answer": "Semi-automatic with educational system-reminder. Strategy D auto-links coverage by default using 'fspec link-coverage --skip-validation' but emits system-reminder showing: (1) What was linked (scenario → test skeleton → implementation), (2) Exact command that was run (educational), (3) How to verify: 'fspec show-coverage', (4) How to fix if wrong: 'fspec unlink-coverage' then re-link manually. Balances low friction (automatic) with transparency (not a black box) and learning (AI sees the mechanism)."
        },
        {
          "text": "@human: Should Strategy D track multiple implementation files in a single reverse session (e.g., MusicPlayer.tsx + usePlaylistStore.ts together), or require separate sessions per file?",
          "selected": true,
          "answer": "Feature-scoped sessions (multiple related files allowed). Strategy D allows multiple implementation files in one session if they deliver the SAME user-facing feature. System-reminder guides AI: 'Do these files deliver same user behavior?' YES → One work unit, one example map, one feature file, multiple test files (one per implementation). NO → Separate sessions. BDD focuses on user behavior which often spans multiple files. Track all files in work unit metadata under 'reverseSession.implementationFiles[]'. Link all via coverage to same feature file."
        }
      ],
      "userStory": {
        "role": "AI agent using fspec for reverse ACDD",
        "action": "be guided through outside-in BDD discovery when I have implementation files without features",
        "benefit": "I create user-centric specifications that trace behavior back to existing code, rather than just scanning files inside-out"
      },
      "estimate": 5
    },
    "REV-003": {
      "id": "REV-003",
      "title": "Strategy D processes existing feature files instead of scanning src/ for implementation files",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-25T12:34:33.055Z",
      "updatedAt": "2025-10-25T23:57:33.345Z",
      "description": "When 'fspec reverse --strategy=D' is run, it processes existing .feature files in spec/features/ directory rather than scanning src/ directory for implementation files (.tsx, .ts, .jsx, .js) that lack corresponding feature files. Expected: Strategy D should discover implementation files in src/ (like MusicPlayer.tsx, usePlaylistStore.ts) and guide creation of feature files for them. Actual: Strategy D iterates through existing feature files (e.g., cli-command-interface-for-ai-agent-control.feature) with guidance to 'Read test file... Then create feature file' which is confusing since the feature file already exists.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-25T12:34:33.733Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-25T23:35:11.086Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-25T23:39:25.827Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T23:44:24.297Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-25T23:48:46.955Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-25T23:52:57.267Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-25T23:57:33.345Z"
        }
      ],
      "rules": [
        "Strategy D should scan src/ directory recursively for .tsx, .ts, .jsx, .js files",
        "For each implementation file found, Strategy D should check if a corresponding feature file exists in spec/features/",
        "Strategy D should only process implementation files that have NO corresponding feature file",
        "Yes, use tinyglobby with pattern 'src/**/*.{ts,tsx,js,jsx}' to recursively find all implementation files, excluding test directories (__tests__, tests, test) and test files (*.test.ts, *.spec.ts)",
        "Use filename similarity with kebab-case conversion algorithm: deriveFeatureName() converts camelCase/PascalCase implementation filenames to kebab-case (e.g., MusicPlayer.tsx → music-player.feature, usePlaylistStore.ts → use-playlist-store.feature). Then check if spec/features/{kebab-name}.feature exists. This is simpler and more predictable than import/export analysis."
      ],
      "examples": [
        "MindStrike project has MusicPlayer.tsx (1532 lines) with no feature file. Strategy D should detect this and guide: 'Analyze MusicPlayer.tsx implementation → Create feature file → Create test file → Link coverage'",
        "Running 'fspec reverse --strategy=D' outputs: 'Step 1 of 7: Read test file: spec/features/cli-command-interface-for-ai-agent-control.feature. Then create feature file.' This is wrong - it's reading a feature file (not implementation), and the feature already exists."
      ],
      "questions": [
        {
          "text": "@human: Should Strategy D use glob patterns to find implementation files (e.g., src/**/*.{ts,tsx,js,jsx})?",
          "selected": true,
          "answer": "Yes, use tinyglobby with pattern 'src/**/*.{ts,tsx,js,jsx}' to recursively find all implementation files, excluding test directories (__tests__, tests, test) and test files (*.test.ts, *.spec.ts)"
        },
        {
          "text": "@human: How should Strategy D match implementation files to feature files? By filename similarity (MusicPlayer.tsx → music-player.feature) or by analyzing imports/exports?",
          "selected": true,
          "answer": "Use filename similarity with kebab-case conversion algorithm: deriveFeatureName() converts camelCase/PascalCase implementation filenames to kebab-case (e.g., MusicPlayer.tsx → music-player.feature, usePlaylistStore.ts → use-playlist-store.feature). Then check if spec/features/{kebab-name}.feature exists. This is simpler and more predictable than import/export analysis."
        }
      ],
      "userStory": {
        "role": "AI agent using fspec reverse for codebases without prior fspec usage",
        "action": "have Strategy D automatically discover implementation files in src/ and guide me through creating feature files for them",
        "benefit": "I can apply outside-in BDD to existing codebases without manually specifying which files need features"
      },
      "estimate": 8
    },
    "BUG-044": {
      "id": "BUG-044",
      "title": "AI agents skip docstring step validation by using --skip-step-validation flag",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-26T01:14:51.328Z",
      "updatedAt": "2025-10-26T01:29:52.666Z",
      "description": "AI agents frequently use the --skip-step-validation flag to bypass docstring step comment validation in link-coverage command, defeating the purpose of test-to-scenario traceability. The flag should ONLY be available for task work units (which don't require feature files). For story and bug work units, docstring validation must be MANDATORY with NO skip option. System must enforce this strictly and provide clear warnings that attempting to skip will result in having to go back and fix the docstrings when detected.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-26T01:14:56.087Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T01:18:43.166Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T01:21:17.987Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T01:25:08.566Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T01:29:52.666Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec with AI agents",
        "action": "enforce mandatory docstring step validation for test-to-scenario traceability",
        "benefit": "AI agents cannot skip critical validation and bypass the ACDD workflow discipline"
      },
      "rules": [
        "The --skip-step-validation flag must ONLY be available when linking coverage for task work units",
        "For story and bug work units, docstring step validation is MANDATORY with NO skip option",
        "If --skip-step-validation is used on a story/bug work unit, the command must fail with a strict error message",
        "Error message must clearly warn that skipping validation will be detected and require going back to fix docstrings",
        "All documentation referencing --skip-step-validation must be updated to explain the task-only restriction",
        "Step validation error system-reminders must be updated to remove mention of --skip-step-validation for story/bug work units"
      ],
      "examples": [
        "AI agent tries 'fspec link-coverage user-login --scenario Login --test-file auth.test.ts --test-lines 10-20 --skip-step-validation' on story work unit → command fails with error explaining skip is only for tasks",
        "AI agent links coverage for task work unit with 'fspec link-coverage infrastructure-setup --scenario Setup --test-file setup.test.ts --test-lines 5-15 --skip-step-validation' → command succeeds (tasks don't require feature files)",
        "AI agent links coverage for story without step comments in test file → receives system-reminder with exact steps to add, NO mention of skip flag",
        "Documentation shows --skip-step-validation with note: 'Only available for task work units. Story and bug work units require mandatory step validation.'"
      ],
      "architectureNotes": [
        "Must detect work unit type by looking up the feature file tag (e.g., @BUG-044) in work-units.json to determine if it's a story, bug, or task. If feature file doesn't exist or tag not found, assume story/bug (strictest validation)."
      ],
      "estimate": 5
    },
    "REV-004": {
      "id": "REV-004",
      "title": "AI-Driven Deep Code Review",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-26T01:45:50.383Z",
      "updatedAt": "2025-10-26T02:17:37.712Z",
      "description": "Enhance fspec review to use conversational AI-driven analysis for bug detection, architecture pattern validation, anti-pattern detection, refactoring suggestions, and FOUNDATION.md alignment checks",
      "epic": "cli-ux-improvements",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-26T01:45:55.459Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T01:51:45.416Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T01:54:09.558Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T02:00:06.864Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T02:01:43.060Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T02:01:48.739Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T02:08:44.259Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T02:17:37.712Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec for code quality",
        "action": "get deep analysis and actionable guidance on code quality issues",
        "benefit": "I can fix bugs, refactor code, and align with project architecture before marking work as done"
      },
      "rules": [
        "Review must use <system-reminder> tags for conversational AI-driven guidance (like fspec reverse)",
        "Review must instruct AI to read all implementation files linked to work unit coverage",
        "Review must instruct AI to analyze code for bugs, edge cases, race conditions, and logic errors",
        "Review must check code alignment with FOUNDATION.md goals and architectural principles",
        "Review must detect anti-patterns (duplicated code, God objects, tight coupling, etc.)",
        "Review must suggest refactoring opportunities for code sharing and DRY principle",
        "Review must preserve existing static checks (ACDD compliance, coverage, coding standards)",
        "Review system-reminder must be agent-aware (use getAgentConfig and formatAgentOutput)"
      ],
      "examples": [
        "AI runs 'fspec review AUTH-001' with implementation files in coverage → system-reminder appears after Summary section with implementation file paths listed",
        "Review work unit with 3 implementation files → system-reminder lists all 3 file paths from coverage data",
        "Review work unit with FOUNDATION.md present → system-reminder mentions FOUNDATION.md as reference document",
        "Review work unit with no implementation files in coverage → system-reminder still appears but without file list section",
        "Review preserves existing static checks → output contains both static issues section AND system-reminder section"
      ],
      "architectureNotes": [
        "Review output must include system-reminder with AI instructions for deep analysis. Pattern similar to fspec reverse: build systemReminder string, wrap with wrapSystemReminder(), include in result. AI instructions: 1) Read all implementation files from coverage data 2) Analyze code deeply for bugs/patterns 3) Check FOUNDATION.md alignment 4) Report findings conversationally. Preserve existing static analysis (lines 188-229 check for 'any', require, file extensions). Add new section after static checks for AI-driven deep analysis guidance."
      ],
      "estimate": 8
    },
    "REV-005": {
      "id": "REV-005",
      "title": "Conversational Review Prompt Before Done",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-26T01:48:22.493Z",
      "updatedAt": "2025-10-26T02:35:46.151Z",
      "description": "When AI moves work unit to 'done' status, emit system-reminder prompting AI to ask user if they want to run 'fspec review' for quality checks before marking complete",
      "epic": "cli-ux-improvements",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-26T01:48:27.129Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T02:22:27.444Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T02:30:30.399Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T02:33:13.196Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T02:35:46.151Z"
        }
      ],
      "userStory": {
        "role": "AI agent completing work units",
        "action": "proactively suggest running quality review before marking work as done",
        "benefit": "users catch quality issues early and maintain high code standards"
      },
      "rules": [
        "System-reminder must appear when moving work unit to 'done' status (pre-done trigger)",
        "System-reminder must prompt AI to ask user about running fspec review",
        "Prompt must be conversational and non-blocking (AI asks user, not hard requirement)",
        "System-reminder must suggest exact command: 'fspec review <work-unit-id>'",
        "Only trigger for story and bug work units (tasks don't need deep review)",
        "System-reminder must use agent-aware formatting (getAgentConfig, formatAgentOutput)"
      ],
      "examples": [
        "AI runs 'fspec update-work-unit-status AUTH-001 done' and receives system-reminder: 'Before marking complete, consider asking: Would you like me to run fspec review AUTH-001 to check for quality issues?'",
        "User says yes, AI runs 'fspec review AUTH-001', finds 2 issues, fixes them, then marks done",
        "User says no, AI proceeds to mark work unit as done without review",
        "AI moves task work unit TASK-001 to done, NO review prompt appears (tasks exempt)"
      ],
      "architectureNotes": [
        "Implementation location: src/commands/update-work-unit-status.ts. Add system-reminder emission when transitioning to 'done' status. Check workUnit.type: if story or bug, emit formatted system-reminder using formatAgentOutput(). Template: 'QUALITY CHECK OPPORTUNITY\\n\\nBefore marking {id} as done, consider running a quality review.\\n\\nSuggested action:\\n1. Ask user: Would you like me to run fspec review {id} to check for bugs, anti-patterns, and FOUNDATION.md alignment?\\n2. If yes: Run fspec review {id}, address findings, then mark done\\n3. If no: Proceed to mark done\\n\\nCommand: fspec review {id}'. Use existing getAgentConfig() for agent detection."
      ],
      "estimate": 3
    },
    "CONFIG-002": {
      "id": "CONFIG-002",
      "title": "Conversational Test and Quality Check Tool Detection",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-26T02:51:30.219Z",
      "updatedAt": "2025-10-26T12:28:53.072Z",
      "description": "Make fspec platform-agnostic by detecting test and quality check tools conversationally (like fspec review/reverse), replacing hardcoded npm references with AI-driven detection and setup via system-reminders",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-26T02:51:34.424Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T03:26:58.970Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T03:31:00.609Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T03:34:23.791Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T03:36:29.773Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T03:37:39.211Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T03:39:47.276Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T04:42:53.351Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T04:45:19.349Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T04:47:16.364Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T04:56:19.983Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T04:58:48.749Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T05:00:07.697Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T05:02:49.611Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T07:05:49.052Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T10:58:41.547Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T10:59:06.521Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T12:21:55.414Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T12:23:09.222Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T12:24:01.294Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T12:25:40.035Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T12:28:53.072Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec across different platforms",
        "action": "detect and configure test and quality check tools conversationally",
        "benefit": "fspec works on any platform (Node.js, Python, Rust, Go, etc.) without hardcoded assumptions"
      },
      "rules": [
        "fspec MUST NOT execute semantic code analysis - ALL detection done via system-reminders guiding AI",
        "Tool detection MUST be conversational like fspec review and fspec reverse",
        "Configuration MUST use same lookup system as system-reminder style detection",
        "AI MUST detect existing tools OR guide setup if none exist using current best practices",
        "All hardcoded npm test and npm check references MUST be replaced with platform-agnostic commands",
        "Store in spec/fspec-config.json with a 'tools' section (extend existing file that already stores agent config)",
        "One-time setup via explicit 'fspec configure-tools' command (like fspec init). Commands emit system-reminder if config missing, telling AI to run configure-tools. Detection happens once, used many times.",
        "Yes - 'fspec configure-tools' supports both initial setup AND reconfiguration. Includes --reconfigure flag for re-detection, manual override flags for explicit commands. Handles tool changes (switching frameworks, adding quality checks) conversationally.",
        "ALL documentation MUST be updated: src/help.ts, src/commands/*-help.ts, spec/CLAUDE.md, docs/, README.md for every aspect of tool configuration",
        "When AI detects multiple frameworks, chain them with && (e.g., '<framework1> && <framework2>'). All detected tools run sequentially.",
        "Include date-aware search queries in system-reminders (e.g., 'best <platform> testing tools 2025'). Platform placeholder filled by fspec based on project detection.",
        "Yes, ALL hardcoded npm commands in documentation and help files MUST be replaced with dynamic placeholders like <test-command> and <quality-check-commands> that system-reminders will fill in based on fspec configure-tools configuration. This is required by Rule #9.",
        "Placeholders like <test-command> and <quality-check-commands> in documentation MUST be dynamically replaced with actual configured commands when spec/CLAUDE.md is generated",
        "When spec/fspec-config.json has tools.test.command configured, all <test-command> placeholders in generated spec/CLAUDE.md should be replaced with the actual command",
        "When spec/fspec-config.json has tools.qualityCheck.commands configured, all <quality-check-commands> placeholders in generated spec/CLAUDE.md should be replaced with the chained command (joined with &&)",
        "configure-tools command MUST be registered in src/index.ts via registerConfigureToolsCommand() function",
        "Registration function MUST follow existing pattern: export async function registerConfigureToolsCommand(program: Command)",
        "Command MUST appear in --help output after registration"
      ],
      "examples": [
        "AI in validating phase, fspec checks spec/fspec-config.json for tools.test.command, finds none, emits system-reminder: 'No test command configured. Use Read/Glob to detect test framework, then run: fspec configure-tools --test-command <cmd>'",
        "AI receives system-reminder, uses Read/Glob tools to detect test framework, runs: fspec configure-tools --test-command '<detected-command>', fspec writes to spec/fspec-config.json",
        "Next validation, fspec reads spec/fspec-config.json, finds tools.test.command='<command>', emits system-reminder: 'Run tests: <command>'",
        "AI uses Read/Glob to detect multiple test frameworks, chains them: fspec configure-tools --test-command '<framework1> && <framework2>', fspec stores chained command",
        "No test tools detected: system-reminder includes date-aware search query 'best <platform> testing tools 2025', AI searches, configures result",
        "AI detects quality check tools via Glob, runs: fspec configure-tools --quality-commands '<tool1>' '<tool2>' '<tool3>', fspec stores as array",
        "AI runs 'fspec configure-tools --reconfigure', fspec re-emits system-reminder for detection, AI updates config with new tools",
        "AI reads slash command section with '<test-command>' placeholder, fspec generates spec/CLAUDE.md, replaces <test-command> with 'npm test' from fspec-config.json",
        "Python project with 'pytest' configured, <test-command> in documentation becomes 'pytest' in generated spec/CLAUDE.md",
        "Rust project with 'cargo test' configured, quality commands ['cargo clippy', 'cargo fmt --check'], <quality-check-commands> becomes 'cargo clippy && cargo fmt --check' in spec/CLAUDE.md",
        "User runs 'fspec configure-tools --help' and sees usage documentation with --test-command and --quality-commands options",
        "User runs 'fspec configure-tools --test-command \"npm test\"' and spec/fspec-config.json is updated with tools.test.command",
        "User runs 'fspec --help' and configure-tools appears in the command list alphabetically",
        "User runs 'fspec configure-tools --quality-commands \"npm run lint\" \"npm run typecheck\"' and spec/fspec-config.json has tools.qualityCheck.commands array"
      ],
      "questions": [
        {
          "text": "@human: Should fspec store detected tool configuration in spec/fspec-config.json or spec/.fspec/tools.json?",
          "selected": true,
          "answer": "Store in spec/fspec-config.json with a 'tools' section (extend existing file that already stores agent config)"
        },
        {
          "text": "@human: Should the conversational detection happen ONLY on first run, or re-detect on every command if config is missing?",
          "selected": true,
          "answer": "One-time setup via explicit 'fspec configure-tools' command (like fspec init). Commands emit system-reminder if config missing, telling AI to run configure-tools. Detection happens once, used many times."
        },
        {
          "text": "@human: Should there be an explicit 'fspec configure-tools' command for manual reconfiguration, or only automatic detection?",
          "selected": true,
          "answer": "Yes - 'fspec configure-tools' supports both initial setup AND reconfiguration. Includes --reconfigure flag for re-detection, manual override flags for explicit commands. Handles tool changes (switching frameworks, adding quality checks) conversationally."
        },
        {
          "text": "@human: When multiple test frameworks detected (e.g., both Vitest and Jest), should AI ask which to use, or use heuristics to pick?",
          "selected": true,
          "answer": "Conversational approach - emit system-reminder with analysis (test file counts, config freshness), provide data-driven recommendation, AI asks human to choose via AskUserQuestion. Prevents silent wrong choices, respects human context."
        },
        {
          "text": "@human: Should system-reminders include search queries for best practices (e.g., 'Search for best Rust testing tools 2025') or just guide AI to search?",
          "selected": true,
          "answer": "Include specific, actionable search queries in system-reminders with current year (e.g., 'Query: best Rust testing frameworks 2025'). Provides date-aware guidance, reduces AI guesswork, ensures current best practices discovered."
        },
        {
          "text": "@human: I found hardcoded 'npm test' and 'npm run' commands still in help files, slash command sections, project management sections, CLAUDE.md, and spec/CLAUDE.md. Should these ALL be replaced with dynamic placeholders like <test-command> that get filled in by system-reminders from fspec configure-tools?",
          "selected": true,
          "answer": "Yes, ALL hardcoded npm commands in documentation and help files MUST be replaced with dynamic placeholders like <test-command> and <quality-check-commands> that system-reminders will fill in based on fspec configure-tools configuration. This is required by Rule #9."
        }
      ],
      "estimate": 8
    },
    "INIT-011": {
      "id": "INIT-011",
      "title": "Automatic version check and update for slash command files",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-26T11:23:10.274Z",
      "updatedAt": "2025-10-27T02:52:57.441Z",
      "description": "Add version check to fspec.md slash command that automatically detects outdated files and replaces them with latest version",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-26T11:23:15.359Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T11:37:48.248Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T11:41:22.057Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T11:49:28.700Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T11:55:42.486Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T01:21:55.146Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T02:52:31.627Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T02:52:37.347Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T02:52:43.856Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T02:52:57.441Z"
        }
      ],
      "userStory": {
        "role": "developer who upgrades fspec to a new version",
        "action": "have slash command files automatically update to match the new version",
        "benefit": "I don't need to manually reinstall or update fspec configuration files"
      },
      "questions": [
        {
          "text": "@human: When the user runs /fspec, should version check happen BEFORE loading any help docs, or only when they try to execute fspec commands?",
          "selected": true,
          "answer": "Version check should happen as the FIRST command in fspec.md, before any help docs load. If version mismatch detected, it should STOP execution (exit 1) and tell the user to restart their AI agent."
        },
        {
          "text": "@human: Where should the version number be stored in fspec.md? At the very top as a comment, or in a specific section?",
          "selected": true,
          "answer": "Version should be embedded as the first argument to fspec --sync-version command at the top of fspec.md. Example: 'fspec --sync-version 0.6.0'. No HTML comments, just plain markdown command call."
        },
        {
          "text": "@human: Which files need version tracking and auto-replacement? Just .claude/commands/fspec.md, or also spec/CLAUDE.md, or both?",
          "selected": true,
          "answer": "Both files need tracking: .claude/commands/fspec.md (or equivalent for other agents) AND spec/CLAUDE.md. Both are updated when version mismatch detected."
        },
        {
          "text": "@human: Should the auto-update be silent, or should it notify the user that files were updated?",
          "selected": true,
          "answer": "Show agent-specific restart instructions. Use agent detection from spec/fspec-config.json and generate appropriate message using similar logic to getActivationMessage(). Claude Code: 'Exit and start new conversation', Cursor: 'Restart Cursor', etc."
        },
        {
          "text": "@human: What should happen if the version check command fails (network issue, file permissions, etc.)? Continue anyway or block execution?",
          "selected": true,
          "answer": "If version check fails (permissions, missing config, etc.), print warning but continue (exit 0). Only exit 1 for version mismatch. Include fallback: if can't detect agent, show generic 'Restart your AI agent' message."
        }
      ],
      "rules": [
        "Version check command must be the FIRST line executed in fspec.md before any help commands",
        "Version embedded in fspec.md must match package.json version for check to pass",
        "On version mismatch, command must update BOTH slash command file AND spec doc file",
        "Exit code 1 on version mismatch (stops workflow), exit code 0 on match (continues workflow)",
        "Restart instructions must be agent-specific using agent detection from fspec-config.json"
      ],
      "examples": [
        "User upgrades: npm install -g @sengac/fspec@0.7.0, runs /fspec in Claude Code, sees 'fspec --sync-version 0.6.0' execute, command detects mismatch, updates files, prints 'Updated to v0.7.0. Exit this conversation and start new one. Run /fspec again.', exits with code 1",
        "User with current version runs /fspec, 'fspec --sync-version 0.7.0' executes silently (versions match), exits 0, AI continues loading help commands normally",
        "Cursor user upgrades to v0.7.0, runs /fspec, version check detects mismatch, updates .cursor/commands/fspec.md and spec/CURSOR.md, prints 'Updated to v0.7.0. Restart Cursor and run /fspec again.'",
        "User deletes spec/fspec-config.json, version check can't detect agent, updates files anyway, shows generic message: 'Updated to v0.7.0. Restart your AI agent and run /fspec again.'",
        "fspec init command automatically embeds current package.json version into generated fspec.md: 'fspec --sync-version 0.7.0'"
      ],
      "estimate": 5
    },
    "CONFIG-003": {
      "id": "CONFIG-003",
      "title": "Tool detection check functions not integrated into workflow",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-26T16:13:38.381Z",
      "updatedAt": "2025-10-27T00:10:36.712Z",
      "description": "The checkTestCommand and checkQualityCommands functions exist and are tested but are never called during workflow transitions, preventing the conversational tool detection system from working as designed",
      "children": [],
      "attachments": [
        "spec/attachments/CONFIG-003/CONFIG-003-integration-gap-analysis.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-26T16:15:07.361Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T16:34:33.358Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T16:36:19.862Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T16:40:04.023Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T16:42:47.394Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T16:43:23.827Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T16:43:29.425Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T16:43:37.697Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T17:00:19.675Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T17:01:33.756Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T17:02:54.595Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T17:05:26.255Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T17:08:02.459Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T17:13:20.043Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T17:13:39.812Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T17:15:30.069Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T17:17:00.559Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-26T17:19:52.814Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-26T23:50:27.625Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-26T23:54:20.061Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-26T23:56:33.276Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-26T23:58:58.093Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T00:10:36.712Z"
        }
      ],
      "rules": [
        "Check functions MUST be called during status transitions to 'validating' state",
        "System-reminders MUST be emitted when config is missing to guide AI to run fspec configure-tools",
        "System-reminders MUST be emitted when config exists to tell AI what commands to run",
        "Integration MUST use existing checkTestCommand and checkQualityCommands functions without modification",
        "sync-version MUST fail (exit 1) when tool configuration is missing to prevent AI from continuing workflow without proper setup",
        "sync-version MUST fail (exit 1) when version is incorrect to prevent AI from continuing with wrong version",
        "sync-version MUST emit system-reminder about configure-tools when tool configuration is completely missing (file does not exist)",
        "configure-tools MUST regenerate agent templates (spec/CLAUDE.md, .claude/commands/fspec.md, etc.) after updating config to ensure templates reflect latest version",
        "configure-tools MUST regenerate templates silently (no output to user about template regeneration) to avoid cluttering the output with implementation details"
      ],
      "examples": [
        "AI runs 'fspec update-work-unit-status AUTH-001 validating' with no config, sees system-reminder: 'NO TEST COMMAND CONFIGURED'",
        "AI runs 'fspec update-work-unit-status AUTH-001 validating' with config present, sees system-reminder: 'Run tests: npm test'",
        "AI receives reminder, runs 'fspec configure-tools --test-command npm test', then validation emits actual command",
        "Integration test verifies checkTestCommand and checkQualityCommands are called during status transition",
        "AI runs 'fspec --sync-version 0.6.0' with no tool config, sees system-reminder, command exits with code 1, AI cannot continue until tools are configured",
        "AI runs 'fspec --sync-version 0.5.0' when actual version is 0.6.0, sees version mismatch error, command exits with code 1, AI cannot continue until correct version used",
        "AI runs 'fspec --sync-version 0.6.0' when spec/fspec-config.json does not exist, sees system-reminder to run configure-tools, command exits with code 1, AI runs configure-tools then re-runs sync-version",
        "AI runs 'fspec configure-tools --test-command npm test', command saves config AND regenerates spec/CLAUDE.md and .claude/commands/fspec.md with latest templates, ensuring AI has up-to-date documentation",
        "AI runs 'fspec configure-tools --test-command npm test', sees only '✓ Tool configuration saved to spec/fspec-config.json' output, templates regenerated silently in background without additional messages"
      ],
      "questions": [
        {
          "text": "@human: Should --sync-version also emit tool configuration checks to help onboard new AI agents?",
          "selected": true,
          "answer": "Yes - sync-version should emit tool config checks. This helps onboard new AI agents by guiding them to configure tools immediately after version update, ensuring they have complete workflow setup."
        }
      ],
      "assumptions": [
        "Yes - sync-version should emit tool config checks. This helps onboard new AI agents by guiding them to configure tools immediately after version update, ensuring they have complete workflow setup."
      ],
      "userStory": {
        "role": "AI agent using fspec for ACDD workflow",
        "action": "receive automatic guidance about tool configuration and version sync",
        "benefit": "I can complete proper workflow setup without manual intervention and avoid continuing with incorrect configuration"
      },
      "estimate": 2
    },
    "INIT-012": {
      "id": "INIT-012",
      "title": "Dynamic bootstrap command for slash command template",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T01:21:53.487Z",
      "updatedAt": "2025-10-27T03:11:29.158Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T01:22:04.407Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T01:46:45.501Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T01:56:24.108Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T01:56:28.682Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T01:59:15.192Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T02:06:07.106Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T02:06:46.604Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T02:07:31.010Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T02:08:41.504Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T02:09:25.151Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T02:11:45.377Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T02:15:08.725Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T02:18:30.120Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T02:20:59.216Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T02:21:38.797Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T02:23:58.730Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T02:24:46.688Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T02:26:53.055Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T02:27:27.561Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T02:27:32.491Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T02:34:11.257Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T02:37:03.622Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T02:40:19.361Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T02:41:58.310Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T02:42:37.378Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T02:43:15.910Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T02:45:24.124Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T02:59:07.597Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T03:01:51.903Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T03:02:42.242Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T03:04:05.920Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T03:11:29.158Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec",
        "action": "load documentation dynamically via bootstrap command",
        "benefit": "slash command template stays lightweight and content is always fresh"
      },
      "questions": [
        {
          "text": "@human: Should 'fspec bootstrap' output be identical to what's currently in the template after fspec --sync-version, or can we improve/reorganize it?",
          "selected": true,
          "answer": "'fspec bootstrap' command executes ALL section-generating functions internally (getHeaderSection(), getAcddConceptSection(), etc.) and outputs the combined template content. Uses existing slashCommandTemplate.ts functions. AI agent runs ONE Bash command (fspec bootstrap) instead of 8 separate help commands. See attachment: bootstrap-command-behavior.md"
        },
        {
          "text": "@human: Should 'fspec bootstrap' be mandatory (fail if not run), or optional (gracefully handle if skipped)?",
          "selected": true,
          "answer": "Bootstrap is ABSOLUTELY MANDATORY. If skipped, fspec commands MUST FAIL with clear error message instructing user to run 'fspec bootstrap' first. No fspec workflow commands should work until bootstrap completes successfully."
        },
        {
          "text": "@human: Should the bootstrap command check if documentation is already loaded (avoid duplicate loading in same session)?",
          "selected": true,
          "answer": "No need to track or prevent duplicate runs. If user runs 'fspec bootstrap' multiple times, it just outputs documentation again. No harm done."
        },
        {
          "text": "@human: What should happen to existing .claude/commands/fspec.md files when users upgrade? Auto-migrate to new format, or require manual deletion?",
          "selected": true,
          "answer": "No special migration logic needed. Existing --sync-version mechanism handles it automatically. When version mismatch detected, installAgentFiles() regenerates template with new 2-command format. Clean, simple, follows existing architectural pattern."
        },
        {
          "text": "@human: Should 'fspec bootstrap' accept arguments (like --skip-help or --minimal) to customize what gets loaded?",
          "selected": true,
          "answer": "NO customization allowed. 'fspec bootstrap' MUST output everything with NO options to skip sections. No --skip-help, no --minimal, no --skip-sections flags. Bootstrap outputs complete documentation ALWAYS."
        }
      ],
      "rules": [
        "The slash command template must contain ONLY two commands: 'fspec --sync-version X.X.X' and 'fspec bootstrap'",
        "All documentation content currently after 'fspec --sync-version' must be moved to dynamically generated output of 'fspec bootstrap'",
        "'fspec bootstrap' must execute the same help commands that are currently hardcoded (fspec --help, fspec help specs, etc.)",
        "Keep output identical to current template. Use existing template generation functions (with string replacement for <test-command> and <quality-check-commands> placeholders)",
        "Bootstrap is ABSOLUTELY MANDATORY. If skipped, fspec commands MUST FAIL with clear error message instructing user to run 'fspec bootstrap' first. No fspec workflow commands should work until bootstrap completes successfully.",
        "NO customization allowed. 'fspec bootstrap' MUST output everything with NO options to skip sections. No --skip-help, no --minimal, no --skip-sections flags. Bootstrap outputs complete documentation ALWAYS.",
        "Bootstrap command MUST internally execute these specific help commands that were removed from the template: 'fspec --help', 'fspec help specs', 'fspec help work', 'fspec help discovery', 'fspec help metrics', 'fspec help setup', 'fspec help hooks'",
        "Bootstrap output MUST be byte-for-byte identical to what previously appeared in the template after running all 7 help commands (fspec --help, fspec help specs, fspec help work, fspec help discovery, fspec help metrics, fspec help setup, fspec help hooks)",
        "The get*HelpContent() functions in src/help.ts MUST return the EXACT SAME content as their corresponding display*Help() functions, but as a string instead of console.log output",
        "getSpecsHelpContent() currently returns 6-line stub text, but MUST return the full 333 lines from displaySpecsHelp() function (lines 164-496 in help.ts)",
        "getWorkHelpContent() currently returns 6-line stub text, but MUST return the full 308 lines from displayWorkHelp() function (lines 498-805 in help.ts)",
        "getDiscoveryHelpContent(), getMetricsHelpContent(), getSetupHelpContent(), and getHooksHelpContent() all return stub text and MUST return their full display function content",
        "The display*Help() functions use console.log() and chalk for colored output - the get*HelpContent() functions MUST strip chalk formatting and return plain text strings",
        "The get*HelpContent() functions MUST NOT duplicate code - they should call the existing display*Help() functions, capture the console.log output, strip chalk formatting, and return the plain text string",
        "Use console interception or mock console.log to capture output from display*Help() functions, then strip ANSI escape codes (chalk formatting) using a utility function or regex",
        "BEFORE the help command outputs, bootstrap MUST display an explainer section that tells the AI agent: (1) what the following content is (output from fspec help commands), (2) WHY this information is critical (complete command reference for all fspec features), (3) HOW to access specific sections again (run individual help commands like 'fspec help specs', 'fspec help work', etc. - NOT 'fspec bootstrap')",
        "The explainer MUST appear immediately after the header sections (Step 1 and Step 1.5) and BEFORE the help command outputs (Step 2), so AI agents see it before reading the command documentation",
        "The slash command template file (.claude/commands/fspec.md) MUST contain ONLY the header instruction block (lines 1-10: title, IMMEDIATELY section with two commands, fspec CLI note, YOU MUST RUN warning). Everything after line 10 MUST BE REMOVED from the template because it is output by 'fspec bootstrap'",
        "The 'fspec bootstrap' command output MUST contain the complete workflow documentation starting from the persona/role description paragraph ('You are a master of project management...') through all ACDD workflow sections, Example Mapping, Kanban workflow, and complete help command outputs",
        "The template generation function getSlashCommandTemplate() in src/utils/slashCommandTemplate.ts MUST return ONLY the minimal header (title + IMMEDIATELY section + two commands). Remove all content after 'YOU MUST RUN THOSE COMMANDS...' - that content is now generated by bootstrap command"
      ],
      "attachments": [
        "spec/attachments/INIT-012/bootstrap-command-behavior.md"
      ],
      "examples": [
        "User runs 'fspec board' without running 'fspec bootstrap' first, command exits with error: 'ERROR: fspec bootstrap must be run first. Run: fspec bootstrap'",
        "User runs 'fspec --sync-version 0.6.0' then 'fspec bootstrap' successfully, then runs 'fspec board' - command executes normally",
        "AI runs 'fspec bootstrap', command internally calls getHeaderSection(), getAcddConceptSection(), etc., combines output, applies string replacement, prints to stdout",
        "AI runs 'fspec bootstrap' which internally executes: getHelpOutput(), getSpecsHelpOutput(), getWorkHelpOutput(), getDiscoveryHelpOutput(), getMetricsHelpOutput(), getSetupHelpOutput(), getHooksHelpOutput(), then combines and outputs all results",
        "When AI runs 'fspec bootstrap', the output MUST include complete 'fspec --help' content showing all command groups (specs, work, discovery, metrics, setup, hooks)",
        "When AI runs 'fspec bootstrap', the output MUST include complete 'fspec help specs' content with ALL commands: create-feature, add-scenario, add-step, validate, format, link-coverage, add-tag-to-feature, etc.",
        "When AI runs 'fspec bootstrap', the output MUST include complete 'fspec help work' content with ALL commands: create-story, create-bug, create-task, update-work-unit-status, board, checkpoint, restore-checkpoint, list-checkpoints, cleanup-checkpoints, etc.",
        "Currently 'fspec bootstrap' outputs stub text like 'Commands for creating and managing Gherkin feature files: create-feature, add-scenario, add-step, validate, format, and more.' This is WRONG - it must output the FULL command documentation",
        "getSpecsHelpContent() calls displaySpecsHelp() internally, captures all console.log output into a string array, joins it with newlines, strips chalk ANSI codes, returns plain text",
        "The explainer section should say something like: 'The following sections contain complete fspec command documentation. This is the output from running: fspec --help, fspec help specs, fspec help work, fspec help discovery, fspec help metrics, fspec help setup, fspec help hooks. You can run these commands individually at any time to refresh specific sections.'",
        "The .claude/commands/fspec.md file should contain ONLY these 10 lines: '# fspec Command - Kanban-Based Project Management\\n\\nIMMEDIATELY - run these commands...\\n\\n1. fspec --sync-version 0.6.0\\n2. fspec bootstrap\\n\\nfspec is a CLI program...\\n\\nYOU MUST RUN THOSE COMMANDS...' - Everything else (persona description, ACDD cycle, Example Mapping, etc.) is output by bootstrap command"
      ],
      "assumptions": [
        "No need to track or prevent duplicate runs. If user runs 'fspec bootstrap' multiple times, it just outputs documentation again. No harm done.",
        "No special migration logic needed. Existing --sync-version mechanism handles it automatically. When version mismatch detected, installAgentFiles() regenerates template with new 2-command format. Clean, simple, follows existing architectural pattern."
      ],
      "estimate": 5
    },
    "HELP-004": {
      "id": "HELP-004",
      "title": "Add comprehensive help documentation for bootstrap and configure-tools commands",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T03:16:30.302Z",
      "updatedAt": "2025-10-27T03:31:31.655Z",
      "description": "Add missing help documentation for fspec bootstrap and fspec configure-tools commands. This includes: creating help functions in src/help.ts and src/commands/*-help.ts, updating README.md with command documentation, updating template autogenerators that generate spec/CLAUDE.md and bootstrap output, and updating relevant documentation in the docs directory to ensure consistency across all documentation sources.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T03:17:14.097Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T03:21:12.976Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T03:22:27.036Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T03:25:26.871Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T03:31:31.655Z"
        }
      ],
      "userStory": {
        "role": "developer or AI agent using fspec",
        "action": "access comprehensive help documentation for bootstrap and configure-tools commands",
        "benefit": "I understand how to use these commands effectively without consulting source code"
      },
      "rules": [
        "Each command must have a comprehensive help file following the CommandHelpConfig pattern",
        "Help files must include whenToUse, prerequisites, typicalWorkflow, commonErrors, and relatedCommands sections",
        "Bootstrap command output must be auto-generated from help content functions",
        "README.md must document both commands with usage examples and options",
        "Documentation in docs directory must be synchronized with help content"
      ],
      "examples": [
        "Developer runs 'fspec bootstrap --help' and sees comprehensive help with whenToUse, prerequisites, typicalWorkflow sections",
        "Developer runs 'fspec configure-tools --help' and sees comprehensive help with platform-agnostic examples",
        "AI agent runs 'fspec bootstrap' and receives complete workflow documentation with all command help sections",
        "Developer searches README.md for configure-tools and finds complete documentation with all options and examples",
        "Documentation in docs/commands/bootstrap.md matches help content with no inconsistencies"
      ],
      "questions": [
        {
          "text": "@human: Should bootstrap command help be added to src/help.ts main help output, or only accessible via --help flag?",
          "selected": true,
          "answer": "Only accessible via --help flag, following existing pattern"
        },
        {
          "text": "@human: Do we need separate documentation files in docs/ directory, or should we rely on generated help from the help config files?",
          "selected": true,
          "answer": "Update existing docs files that reference these commands, use generated help from config files"
        },
        {
          "text": "@human: Should configure-tools help include specific examples for Node.js, Python, Rust, and Go, or keep it generic?",
          "selected": true,
          "answer": "Include specific examples for Node.js, Python, Rust, and Go to match existing platform-agnostic guidance"
        }
      ],
      "estimate": 5
    },
    "ITF-001": {
      "id": "ITF-001",
      "title": "Scaffold TUI infrastructure with Ink and cage components",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T04:16:56.752Z",
      "updatedAt": "2025-10-27T04:38:23.326Z",
      "description": "Install Ink, @inkjs/ui, Zustand dependencies. Copy cage's shared components (VirtualList, FullScreenLayout, InputContext, useSafeInput). Create ViewManager, App.tsx, fspecStore. Add TUI command. Make 'fspec' with no args launch TUI.",
      "epic": "interactive-tui-foundation",
      "children": [],
      "attachments": [
        "spec/attachments/ITF-001/tui-foundation-architecture.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T04:19:50.184Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T04:28:41.448Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T04:31:32.718Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T04:34:11.761Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T04:38:23.326Z"
        }
      ],
      "userStory": {
        "role": "developer building fspec's interactive TUI",
        "action": "scaffold core TUI infrastructure with Ink, Zustand, and reusable components from cage",
        "benefit": "I can build the interactive Kanban board and other TUI features on a solid, tested foundation"
      },
      "rules": [
        "TUI infrastructure must use Ink (React for CLIs) as the rendering engine",
        "State management must use Zustand with Immer for immutable updates",
        "Component library must include @inkjs/ui for pre-built UI primitives",
        "Components must be TypeScript with strict type safety (no 'any' types)",
        "All components must be tested with ink-testing-library",
        "Components must follow cage's architectural patterns (ViewManager, FullScreenLayout, modal input modes)"
      ],
      "examples": [
        "Developer imports FullScreenLayout from src/tui/layouts and wraps a simple Text component - renders with title bar and footer",
        "Developer uses ViewManager to navigate between two views - navigation works, back button returns to previous view",
        "Developer creates Zustand store with fspec work units data - updates trigger re-renders in Ink components",
        "Developer writes test with ink-testing-library's render() - can query rendered output and assert on text content",
        "Developer creates modal input mode component - switches between normal and insert modes with 'i' key"
      ],
      "questions": [
        {
          "text": "@human: Should we copy components directly from cage or create similar components inspired by cage's patterns?",
          "selected": true,
          "answer": "Create similar components inspired by cage's patterns (not direct copies). This ensures fspec has full control over the codebase, follows fspec's TypeScript standards, and avoids cage-specific dependencies. Adapt patterns but write fresh TypeScript code."
        },
        {
          "text": "@human: Do we need VirtualList component in Phase 1 scaffold or should it wait for ITF-002 (performance optimization)?",
          "selected": true,
          "answer": "VirtualList should be in Phase 1 scaffold. It's a foundational component needed for Kanban columns and work unit lists. Starting without it would require refactoring later. Include it in the initial scaffold."
        },
        {
          "text": "@human: Should the scaffold include basic keyboard navigation hooks or just the component structure?",
          "selected": true,
          "answer": "Include basic keyboard navigation hooks (useSafeInput, InputModeContext) in scaffold. These are foundational and needed for all interactive components. Without them, every component would need to reinvent input handling."
        }
      ],
      "estimate": 8
    },
    "ITF-002": {
      "id": "ITF-002",
      "title": "Zustand state management setup for fspec data",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T04:16:57.254Z",
      "updatedAt": "2025-10-27T05:10:30.340Z",
      "description": "Create fspecStore with work units, epics, features, tags state. Add actions: loadWorkUnits, updateWorkUnit, createWorkUnit, deleteWorkUnit. Integrate with existing JSON file operations. Handle real-time updates with file watchers or polling.",
      "epic": "interactive-tui-foundation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T04:58:56.621Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T05:01:58.555Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T05:03:46.531Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T05:08:22.056Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T05:10:30.340Z"
        }
      ],
      "userStory": {
        "role": "developer building interactive TUI",
        "action": "have Zustand store automatically load and sync all fspec data from JSON files",
        "benefit": "the TUI can display real work units, epics, and features without manual data loading"
      },
      "rules": [
        "Store must load data from spec/work-units.json, spec/epics.json, spec/features/ directory",
        "Store must use Zustand with Immer for immutable state updates",
        "Store actions must integrate with existing loadWorkUnits, loadEpics utility functions",
        "Store must provide selectors for filtering work units by status, epic, prefix",
        "Store initialization must be async to load JSON files from disk"
      ],
      "examples": [
        "Store initializes and loads 206 work units from work-units.json - workUnits array has 206 items",
        "Store loads 13 epics from epics.json - epics array has correct data structure with id, title, workUnits",
        "Component calls useWorkUnitsByStatus('backlog') - returns filtered array of work units in backlog status",
        "Component updates work unit status via store action - state updates immutably and component re-renders",
        "Store provides getWorkUnitsByEpic selector - returns work units filtered by epic ID"
      ],
      "questions": [
        {
          "text": "@human: Should the store poll for file changes or use file watchers for real-time updates?",
          "selected": true,
          "answer": "For ITF-002, keep it simple: no file watchers or polling yet. Just load once on initialization. Real-time updates will be handled in BOARD-003."
        },
        {
          "text": "@human: Should store initialization happen automatically on import or require explicit init() call?",
          "selected": true,
          "answer": "Require explicit init() call. This gives TUI control over when to load data and allows error handling during startup."
        },
        {
          "text": "@human: Should the store cache data in memory or reload from disk on every access?",
          "selected": true,
          "answer": "Cache in memory after loading. TUI needs fast access to data for rendering. BOARD-003 will handle refreshing when files change."
        }
      ],
      "estimate": 5
    },
    "ITF-003": {
      "id": "ITF-003",
      "title": "Launch interactive TUI when running fspec with no arguments",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T06:11:30.017Z",
      "updatedAt": "2025-10-27T06:23:02.545Z",
      "description": "Running 'fspec' with no arguments should launch the interactive Kanban board TUI instead of showing help text. This provides immediate visual feedback and makes the TUI the default interface.",
      "epic": "interactive-tui-foundation",
      "children": [],
      "userStory": {
        "role": "developer using fspec",
        "action": "see my work units visually when I run fspec",
        "benefit": "I get immediate visual feedback and can navigate my work interactively"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T06:11:45.400Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T06:13:52.454Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T06:14:51.816Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T06:19:05.928Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T06:21:27.950Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T06:21:52.480Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T06:22:59.197Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T06:23:00.321Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T06:23:01.434Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T06:23:02.545Z"
        }
      ],
      "rules": [
        "Running 'fspec' with no arguments MUST launch the interactive TUI (BoardView component)",
        "Running 'fspec --help' MUST still show help text (not launch TUI)",
        "Running 'fspec help' MUST still show help text (not launch TUI)",
        "TUI MUST be rendered using existing BoardView component (DRY - reuse BOARD-002 implementation)",
        "TUI MUST exit cleanly when user presses ESC or q key"
      ],
      "examples": [
        "Developer runs 'fspec' → BoardView TUI launches → Shows Kanban board with work units",
        "Developer runs 'fspec --help' → Help text displays → TUI does NOT launch",
        "Developer runs 'fspec validate' → Validation executes → TUI does NOT launch",
        "Developer in TUI presses ESC → TUI exits cleanly → Returns to shell prompt"
      ]
    },
    "ITF-004": {
      "id": "ITF-004",
      "title": "Fix TUI Kanban column layout to match table style",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T06:40:55.477Z",
      "updatedAt": "2025-10-27T07:56:53.007Z",
      "description": "Update interactive TUI Kanban columns to use table layout instead of boxed columns, matching the visual style of fspec board command",
      "epic": "interactive-tui-foundation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T06:41:00.684Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T06:51:25.894Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T06:53:34.347Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T07:01:49.813Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T07:06:36.436Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T07:10:44.985Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T07:13:11.960Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T07:14:34.345Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T07:15:49.906Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T07:19:38.141Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T07:21:15.684Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T07:24:45.644Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T07:25:29.339Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T07:26:07.700Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T07:28:26.199Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T07:28:36.178Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T07:30:54.143Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T07:31:53.126Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T07:31:54.238Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T07:54:01.324Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T07:56:53.007Z"
        }
      ],
      "userStory": {
        "role": "developer using the interactive TUI",
        "action": "view the Kanban board with a consistent table layout",
        "benefit": "the interface is clean, familiar, and matches the fspec board command style"
      },
      "rules": [
        "Columns must be part of a unified table with box-drawing characters (┌┬┐ ├┼┤ └┴┘), not individual bordered boxes",
        "Column headers must show: STATUS (count) - Xpts format",
        "Work units within columns must show: typeIcon ID Xpt priorityIcon",
        "The table layout must adapt to terminal width like fspec board does",
        "Focused column must be highlighted with cyan color",
        "Selected work unit within focused column must be highlighted",
        "All panels (Git Stashes, Changed Files, Kanban columns, footer) should be integrated into a single unified table layout to avoid duplicate borders",
        "Footer should be integrated into the unified table layout",
        "Support scrolling through ALL items with Page Up/Down. Show up arrow indicator above first visible item if scrolled past start. Show down arrow indicator below last visible item if more items exist beyond viewport. No artificial limit.",
        "Arrow up/down keys scroll one item at a time within focused column",
        "Page Up/Page Down keys scroll by full page (viewport height) of items at a time for faster navigation",
        "Component MUST register resize listener on stdout.on('resize', handler) to detect terminal dimension changes",
        "Terminal dimensions MUST be stored in React state to trigger re-renders when terminal resizes",
        "Component MUST cleanup resize listener with stdout.off('resize', handler) in useEffect cleanup to prevent memory leaks",
        "Column width calculation MUST be reactive using useMemo with terminal dimensions as dependency",
        "Layout MUST provide fallback dimensions (80 columns, 24 rows) when stdout dimensions unavailable",
        "MUST use useStdout directly and read stdout.columns (same pattern as BoardDisplay), NOT a custom useTerminalSize hook with state",
        "Column width calculation MUST be wrapped in useMemo with terminalWidth as dependency to recalculate on terminal changes",
        "Table row building MUST also be wrapped in useMemo with colWidth as dependency so entire table rebuilds on resize",
        "Focused column header MUST be highlighted in cyan color to show which column is active",
        "Selected work unit within focused column MUST be highlighted with cyan background to show which item is active",
        "Column headers and work unit rows MUST use Ink Text components with color/backgroundColor props, NOT plain strings, to support highlighting"
      ],
      "examples": [
        "User opens TUI, sees table with ┌┬┐ top border connecting all columns",
        "User navigates right with arrow key, sees focused column header turn cyan while others stay gray",
        "User navigates down within a column, sees selected work unit highlighted with cyan background",
        "User resizes terminal, table columns adjust width proportionally like fspec board",
        "Column shows AUTH-001 3pt 🟡 format with type icon and priority indicator",
        "User has 20 work units in backlog, presses Page Down, sees viewport scroll showing items 11-20 with up arrow indicator at top",
        "User scrolls to middle of long column, sees both up arrow at top and down arrow at bottom indicating more items in both directions",
        "User presses Page Up at top of column, nothing happens (already at start, no up arrow shown)",
        "Git Stashes panel integrated as table row above Kanban columns with proper ├┼┤ junction characters",
        "User presses arrow down, selected item moves down by 1 work unit",
        "User presses Page Down with 30 items and viewport showing 10 items, viewport jumps to show items 11-20",
        "User opens TUI at 120 columns wide, sees table with properly aligned borders. User resizes terminal to 80 columns, table instantly reflows with recalculated column widths and borders still properly aligned",
        "Component mounts, registers resize listener on stdout. Component unmounts, cleanup function removes resize listener to prevent memory leak",
        "Terminal resizes from 100 to 140 columns, column width recalculates from 12 chars to 18 chars, all work units and headers fit properly without truncation",
        "BoardDisplay uses: const { stdout } = useStdout(); const terminalWidth = stdout?.columns || 80; const colWidth = useMemo(() => calculateColumnWidth(terminalWidth), [terminalWidth]); - This pattern works perfectly",
        "UnifiedBoardLayout initially tried custom useTerminalSize hook with useState and resize listeners - This caused stale initial values and didn't match fspec board behavior",
        "User presses right arrow, BACKLOG header shows in gray, SPECIFYING header changes to cyan (focused). Work units in SPECIFYING column are visible, first one has cyan background (selected)",
        "User presses down arrow, first work unit in focused column loses cyan background, second work unit gets cyan background (selection moved)"
      ],
      "questions": [
        {
          "text": "@human: Should the Git Stashes and Changed Files panels also use table layout, or keep their current bordered box style?",
          "selected": true,
          "answer": "All panels (Git Stashes, Changed Files, Kanban columns, footer) should be integrated into a single unified table layout to avoid duplicate borders"
        },
        {
          "text": "@human: Should the footer with keyboard shortcuts also use table borders, or keep its current style?",
          "selected": true,
          "answer": "Footer should be integrated into the unified table layout"
        },
        {
          "text": "@human: Do you want the same column limit behavior (showing first 5 items + overflow count) as fspec board?",
          "selected": true,
          "answer": "Support scrolling through ALL items with Page Up/Down. Show up arrow indicator above first visible item if scrolled past start. Show down arrow indicator below last visible item if more items exist beyond viewport. No artificial limit."
        }
      ],
      "estimate": 5
    },
    "ITF-005": {
      "id": "ITF-005",
      "title": "Real-time file and git status watching in TUI",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T08:14:53.044Z",
      "updatedAt": "2025-10-27T08:34:33.724Z",
      "description": "Add fs.watch watchers for .git/refs/stash and .git/index to detect real-time changes to git stashes and file status (staged/unstaged). Update Zustand store reactively when changes are detected, similar to the existing work-units.json watcher. Reuse existing isomorphic-git functions and follow DRY principles.",
      "epic": "interactive-tui-foundation",
      "children": [],
      "userStory": {
        "role": "developer using fspec TUI",
        "action": "see real-time updates to git stashes and file status",
        "benefit": "the board reflects current state without manual refresh"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T08:15:22.144Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T08:18:48.076Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T08:20:07.365Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T08:28:13.409Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T08:34:33.724Z"
        }
      ],
      "rules": [
        "TUI must watch .git/refs/stash for real-time git stash changes",
        "TUI must watch .git/index for real-time file status changes (staged/unstaged)",
        "Watchers must update Zustand store state to trigger React re-renders",
        "MUST reuse existing isomorphic-git functions: getStagedFiles, getUnstagedFiles from src/git/status.ts",
        "MUST reuse existing git.log({ ref: 'refs/stash' }) pattern for loading stashes (DRY principle)",
        "Watchers must be cleaned up on component unmount to prevent memory leaks",
        "Store must provide actions: loadStashes(), loadFileStatus() to be called by watchers",
        "TUI must watch .git/HEAD for branch changes and commits on current branch"
      ],
      "examples": [
        "User opens TUI, creates git stash via terminal, TUI automatically updates stash panel without restart",
        "User stages a file with git add, TUI immediately shows file in staged section (green)",
        "User unstages a file with git reset, TUI moves file from staged to unstaged section (yellow)",
        "User creates checkpoint via fspec command, TUI stash panel updates showing new stash",
        "User modifies work-units.json AND stages a file, both panels update in real-time",
        "User exits TUI, watchers are cleaned up and don't leak memory"
      ],
      "questions": [
        {
          "text": "@human: Should watchers debounce rapid changes (e.g., multiple git add commands in quick succession)?",
          "selected": true,
          "answer": "No debouncing needed - let React handle re-render optimization naturally"
        },
        {
          "text": "@human: Should we also watch HEAD ref for branch changes or commits?",
          "selected": true,
          "answer": "Watch HEAD ref for current branch changes and commits"
        }
      ]
    },
    "BOARD-005": {
      "id": "BOARD-005",
      "title": "Test data leak: BOARD-TEST-001 appearing in real board",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-27T08:35:47.413Z",
      "updatedAt": "2025-10-27T08:44:09.956Z",
      "description": "Some test is creating BOARD-TEST-001 work unit without proper mocking, causing it to appear in the real board view. Tests should use isolated temporary directories or proper mocking to prevent test data from leaking into actual project data.",
      "epic": "interactive-tui-foundation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T08:36:17.521Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T08:40:04.483Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T08:40:12.336Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T08:43:42.872Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T08:44:09.956Z"
        }
      ],
      "userStory": {
        "role": "developer running tests",
        "action": "run tests without polluting real project data",
        "benefit": "I can trust that tests are isolated and won't affect my actual work units"
      },
      "rules": [
        "Tests MUST use temporary directories created with mkdtemp() to avoid polluting real project files",
        "Tests MUST clean up temporary directories in afterEach() hooks using rm(dir, { recursive: true, force: true })",
        "Tests that write to work-units.json MUST use testDir as cwd parameter, NOT process.cwd()",
        "BoardView-realtime-updates.test.tsx lines 209-223 are the problematic code that writes to real spec/work-units.json",
        "Tests MUST restore original file state if they absolutely must modify real files (use cleanup in try-finally blocks)"
      ],
      "examples": [
        "BoardView test creates BOARD-TEST-001 in real spec/work-units.json, causing it to appear in actual board view",
        "update-work-unit-ensure.test.ts correctly uses mkdtemp() to create isolated test directory in tmpdir()",
        "Test cleanup restores original work-units.json content at lines 260-262, but damage is already done",
        "Fix involves using mkdtemp() in beforeEach, passing testDir to loadData(), cleaning up in afterEach"
      ]
    },
    "BOARD-006": {
      "id": "BOARD-006",
      "title": "Incorrect column dividers in non-columnar TUI sections",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-27T08:48:01.553Z",
      "updatedAt": "2025-10-27T10:21:53.879Z",
      "description": "The TUI board displays column divider characters in separator lines that should only have them on one side or not at all. Need to distinguish between three separator types:\n\n1. NO COLUMNS (full-width sections):\n   - Line ABOVE Git Stashes: ├─────────┤ (no columns above or below)\n   - Line BETWEEN Git Stashes and Changed Files: ├─────────┤ (no columns above or below)\n   \n2. TRANSITION TO COLUMNS (from full-width to columnar):\n   - Line BETWEEN Changed Files and Kanban board: ├────┬────┬────┤ (no columns above, columns below)\n   \n3. COLUMNS (Kanban board section):\n   - Lines within Kanban board: ├────┼────┼────┤ (columns above and below)\n   \n4. TRANSITION FROM COLUMNS (from columnar to full-width):\n   - Line BETWEEN Kanban board and key mapping footer: ├────┴────┴────┤ (columns above, no columns below)\n   - Line BELOW key mapping footer: └────────────┘ (terminal edge)\n\nCurrent bug: All separators use column dividers (┼) regardless of context. Need to use ┬ (top junction), ┼ (cross junction), ┴ (bottom junction), or plain ─ (horizontal) based on what's above and below each line.",
      "epic": "interactive-tui-foundation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T08:50:13.394Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T08:52:50.126Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T08:53:04.322Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T09:00:59.508Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T09:01:27.183Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T09:46:06.139Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T09:48:02.287Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T09:48:08.530Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T09:50:58.482Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T09:51:05.396Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T10:05:35.951Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T10:06:39.027Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T10:06:44.833Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T10:09:34.435Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T10:09:40.651Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T10:10:15.806Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T10:10:55.206Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T10:10:56.274Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T10:13:23.836Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T10:13:25.497Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T10:14:26.919Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T10:15:05.810Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T10:15:06.875Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T10:21:48.954Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T10:21:53.879Z"
        }
      ],
      "userStory": {
        "role": "developer viewing TUI board",
        "action": "see correct box-drawing separators between sections",
        "benefit": "the interface looks visually correct and separators match their context"
      },
      "rules": [
        "Line 184 (after Git Stashes): Use ├──┤ with NO column dividers (no columns above or below)",
        "Line 202 (after Changed Files): Use ├──┬──┤ with TOP junctions (no columns above, columns start below)",
        "Line 252 (before key mapping footer): Use ├──┴──┤ with BOTTOM junctions (columns end above, no columns below)",
        "Lines 155 and 214: Keep ├──┼──┤ for actual Kanban board section (columns above and below)",
        "buildBorderRow helper must accept separator type parameter to distinguish between ─ (plain), ┬ (top), ┼ (cross), ┴ (bottom)",
        "Top border (┌─┐) should use plain horizontal separator (no columns above it)",
        "Bottom border (└─┘) should use plain horizontal separator (no columns below it)",
        "Footer row content should NOT have pipe characters separating command help text",
        "Footer help text should be centered horizontally within the total table width",
        "Footer help text should use diamond separator (◆) instead of pipe character (|) between command groups",
        "Column headers should display ONLY the state name in uppercase (e.g., BACKLOG, DONE, etc.) with no counts or story points"
      ],
      "examples": [
        "Line 184 currently shows ├──┼──┤ but should show ├────────┤ (no column dividers between Git Stashes and Changed Files)",
        "Line 202 currently shows ├──┼──┤ but should show ├──┬──┬──┤ (top junctions where Kanban columns start)",
        "Line 252 currently shows ├──┼──┤ but should show ├──┴──┴──┤ (bottom junctions where Kanban columns end)",
        "Lines 155 and 214 correctly use ├──┼──┤ for the Kanban board header separator",
        "Top border should show ┌────────┐ with NO column dividers (plain horizontal only)",
        "Bottom border should show └────────┘ with NO column dividers (plain horizontal only)",
        "Footer text '← → Columns | ↑↓ jk Work Units | ↵ Details | ESC Back' should have pipe characters as CONTENT, not column dividers",
        "Footer text '← → Columns | ↑↓ jk Work Units | ↵ Details | ESC Back' should have equal padding on left and right to center it",
        "Footer should display '← → Columns ◆ ↑↓ jk Work Units ◆ ↵ Details ◆ ESC Back' with diamond separators",
        "Headers should show 'BACKLOG', 'SPECIFYING', 'TESTING', 'IMPLEMENTING', 'VALIDATING', 'DONE', 'BLOCKED' without any additional text"
      ]
    },
    "BOARD-007": {
      "id": "BOARD-007",
      "title": "Consolidate Git info and add work unit details panel",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T10:26:36.107Z",
      "updatedAt": "2025-10-27T10:35:14.760Z",
      "description": "Merge Git Stashes and Changed Files into single panel, replace Changed Files section with work unit details panel showing type, title, description, dependencies for selected work unit",
      "epic": "interactive-tui-foundation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T10:26:40.856Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T10:29:02.609Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T10:29:58.305Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T10:35:07.683Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T10:35:14.760Z"
        }
      ],
      "userStory": {
        "role": "developer using TUI board",
        "action": "see git context and selected work unit details in one view",
        "benefit": "I can understand my current work context without switching views"
      },
      "rules": [
        "Git Stashes and Changed Files must be combined into single 'Git Context' panel",
        "Changed Files section must be replaced with Work Unit Details panel",
        "Work Unit Details panel shows type icon, title, description, dependencies, and other metadata",
        "Description must be truncated after few lines with indicator to press Enter for full details",
        "When no work unit selected, display user-friendly message like 'No work unit selected'"
      ],
      "examples": [
        "Git Context panel shows 'Git Stashes (2)' followed by stash list, then 'Changed Files (3 staged, 1 unstaged)' with file list",
        "Work unit BOARD-001 selected: shows 📖 story icon, title, truncated description, dependencies list",
        "No work unit selected in empty column: shows 'No work unit selected' message"
      ],
      "estimate": 5
    },
    "BOARD-008": {
      "id": "BOARD-008",
      "title": "Color-coded work units without shimmer or priority icons",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T10:41:03.150Z",
      "updatedAt": "2025-10-27T12:09:46.733Z",
      "description": "Display work units with color-coding by type. Story=white, Bug=red, Task=blue, Selected=green background (no shimmer). Story points format: [N] when >0, hidden when 0. No priority emoticons.",
      "epic": "interactive-tui-foundation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T10:41:09.156Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T10:43:46.573Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T10:44:54.050Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T11:04:50.427Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T11:05:05.468Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T11:28:43.485Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T11:57:25.619Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T12:04:39.836Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T12:06:10.449Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T12:06:52.396Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T12:07:10.279Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T12:09:46.733Z"
        }
      ],
      "userStory": {
        "role": "developer viewing TUI board",
        "action": "identify work unit types by color instead of emoji",
        "benefit": "I can quickly scan the board and distinguish stories, bugs, and tasks at a glance"
      },
      "rules": [
        "Story work units must display in white color",
        "Bug work units must display in red color",
        "Task work units must display in blue color",
        "Selected work unit must display with green background (overrides type color)",
        "Story points must be hidden when estimate is 0 or undefined",
        "Story points must display as [N] format when estimate > 0",
        "No priority emoticons must be displayed",
        "No shimmer animation on selected work units",
        "Story points must be hidden when estimate is 0 or undefined",
        "Story points must display as [N] format when estimate > 0",
        "No priority emoticons must be displayed",
        "No shimmer animation on selected work units"
      ],
      "examples": [
        "Story TECH-001 with 0 estimate displays as 'TECH-001' in white (no story points shown)",
        "Story FEAT-002 with 5 estimate displays as 'FEAT-002 [5]' in white",
        "Bug BUG-001 with 3 estimate displays as 'BUG-001 [3]' in red",
        "Task TASK-001 with no estimate displays as 'TASK-001' in blue",
        "Selected story displays with green background, no shimmer, no priority icons",
        "Story TECH-001 with 0 estimate displays as 'TECH-001' in white (no story points shown)",
        "Story FEAT-002 with 5 estimate displays as 'FEAT-002 [5]' in white",
        "Bug BUG-001 with 3 estimate displays as 'BUG-001 [3]' in red",
        "Task TASK-001 with no estimate displays as 'TASK-001' in blue",
        "Selected story displays with green background, no shimmer, no priority icons"
      ],
      "estimate": 5
    },
    "BOARD-009": {
      "id": "BOARD-009",
      "title": "Animated shimmer on last changed work unit",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T11:33:13.499Z",
      "updatedAt": "2025-10-27T13:22:11.715Z",
      "description": "Highlight the most recently modified work unit with green text color and animated left-to-right shimmer effect every 5 seconds",
      "epic": "interactive-tui-foundation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T11:33:18.483Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T11:47:08.680Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T11:50:59.702Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T11:53:28.774Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T11:56:01.740Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T11:58:23.414Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T11:59:20.940Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T11:59:50.434Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T12:00:15.328Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T12:03:13.711Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T12:51:51.932Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T12:54:54.129Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T12:56:23.041Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T12:57:20.561Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T13:00:51.119Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T13:08:42.196Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T13:09:02.580Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T13:13:46.293Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T13:17:04.125Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T13:18:38.247Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T13:21:53.297Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T13:22:11.715Z"
        }
      ],
      "userStory": {
        "role": "developer viewing TUI board",
        "action": "see which work unit was most recently changed",
        "benefit": "I can quickly identify where recent activity occurred"
      },
      "questions": [
        {
          "text": "@human: What constitutes a 'change' to a work unit?",
          "selected": true,
          "answer": "Compute last-changed work unit by finding max(updated) timestamp across all work units. Don't store separately in Zustand - use existing updated field. Track only shimmer animation toggle state in component state."
        },
        {
          "text": "@human: How should the shimmer animation work exactly?",
          "selected": true,
          "answer": "Alternate between shades of green (green → bright green → green), with pauses between 5-second cycles. No gradient sweep."
        },
        {
          "text": "@human: What happens if multiple work units changed columns at the same time?",
          "selected": true,
          "answer": "Pick the work unit with the most recent timestamp change (use work unit's updated field to determine recency)."
        },
        {
          "text": "@human: What happens when the last changed work unit is also the currently selected work unit?",
          "selected": true,
          "answer": "Shimmer the selector/background instead, from left to right in shades of green (bgGreen → bgGreenBright → bgGreen), with black text."
        },
        {
          "text": "@human: Should the shimmer override the work unit type color (white/red/blue) or shimmer the existing type color?",
          "selected": true,
          "answer": "Shimmer the existing type color. Story (white → whiteBright → white), Bug (red → redBright → red), Task (blue → blueBright → blue)."
        },
        {
          "text": "@human: When does the shimmer start and stop?",
          "selected": true,
          "answer": "On TUI startup, identify the work unit with the most recent 'updated' timestamp and start shimmering it immediately."
        },
        {
          "text": "@human: How should Zustand track status changes?",
          "selected": true,
          "answer": "Compute last-changed work unit by finding max(updated) timestamp across all work units. Don't store separately in Zustand - use existing updated field. Track only shimmer animation toggle state in component state."
        },
        {
          "text": "@human: Should we use the last stateHistory timestamp (only status changes) or add a dedicated lastStatusChange field to work units?",
          "selected": true,
          "answer": "Use the last stateHistory timestamp - this is the correct approach because it only tracks actual status/column changes (what users care about), not other field modifications like estimate changes. The stateHistory array is already part of the work unit data structure and is the source of truth for state transitions."
        }
      ],
      "rules": [
        "Last changed work unit is determined by status/column change, not other field updates",
        "Find last changed work unit by computing max(updated) timestamp across all work units",
        "When multiple work units have same timestamp, pick the one with most recent updated field",
        "Shimmer starts on TUI startup for the most recently changed work unit from history",
        "Shimmer continues indefinitely until another work unit changes status",
        "Zustand store WorkUnit interface must include updated and estimate fields to pass data from work-units.json to components",
        "At any given frame, one character is at peak brightness (whiteBright/redBright/blueBright), with darker gradient on both sides",
        "Gradient uses 3 brightness levels: dim (gray), base color (white/red/blue), bright (whiteBright/redBright/blueBright)",
        "Shimmer wave moves one character position per frame at smooth animation speed",
        "When shimmer reaches end of string, it loops back to the beginning continuously",
        "The Zustand store must transform updatedAt field from work-units.json to updated field when loading work units",
        "The lastChangedWorkUnit algorithm should use the most recent state transition timestamp from stateHistory array, not the updatedAt field which tracks any field modification",
        "Find last changed work unit by getting the most recent stateHistory timestamp across all work units",
        "Zustand store must include stateHistory array when loading work units so components can access state transition timestamps"
      ],
      "examples": [
        "Story TECH-001 with most recent timestamp displays with shimmering white text (white→whiteBright every 5s)",
        "Bug BUG-007 with most recent timestamp displays with shimmering red text (red→redBright every 5s)",
        "Task TASK-003 with most recent timestamp displays with shimmering blue text (blue→blueBright every 5s)",
        "Selected work unit AUTH-001 that is also last-changed displays with shimmering green background (bgGreen→bgGreenBright) and black text",
        "On TUI startup, BOARD-008 with updated='2025-10-27T21:30:00Z' is most recent, starts shimmering immediately",
        "User moves FEAT-002 from testing to implementing, shimmer stops on BOARD-008 and starts on FEAT-002",
        "Zustand store loads work unit with updated='2025-10-27T22:00:00Z' from work-units.json and passes it to UnifiedBoardLayout",
        "String 'FEAT-001' with shimmer at position 0: [F]EAT-001 where F is whiteBright, E is white, A is gray",
        "String 'FEAT-001' with shimmer at position 3: FEA[T]-001 where T is whiteBright, A and - are white, E and 0 are gray",
        "Bug work unit 'BUG-007' uses red gradient: gray → red → redBright → red → gray",
        "Task work unit 'TASK-003' uses blue gradient: gray → blue → blueBright → blue → gray",
        "Animation speed: shimmer moves 1 character position every 100ms for smooth visual wave effect",
        "For selected work unit that is also last-changed: apply shimmer gradient to background color (bgGreen → bgGreenBright → bgGreen) with black text",
        "Work unit BOARD-009 has stateHistory entry with timestamp 2025-10-27T13:13:46.292Z (most recent transition), should shimmer",
        "Work unit EXMAP-001 has updatedAt 2025-10-10T23:20:00.252Z but last stateHistory entry is older than BOARD-009, should NOT shimmer"
      ],
      "estimate": 5
    },
    "BUG-045": {
      "id": "BUG-045",
      "title": "Work items in columns don't scroll",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-27T12:13:55.515Z",
      "updatedAt": "2025-10-27T21:46:37.078Z",
      "description": "Work items in a column should scroll like the virtual lists in ~/projects/cage project, but currently they don't scroll at all. Need to implement scrollable list functionality similar to the cage project's virtual list implementation.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T12:14:59.940Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T12:20:01.437Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T12:21:58.025Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T12:23:05.935Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T12:25:14.138Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T12:27:25.459Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T12:29:50.004Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T12:30:44.993Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T12:31:48.192Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T12:31:56.470Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T12:36:07.963Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T12:38:34.207Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T12:40:09.876Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T12:41:07.048Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T12:44:23.419Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T21:43:55.395Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T21:44:23.525Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T21:46:27.634Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T21:46:34.888Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T21:46:35.998Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T21:46:37.078Z"
        }
      ],
      "userStory": {
        "role": "user navigating the fspec board TUI",
        "action": "scroll through work items using arrow keys",
        "benefit": "I can see all work items in a column without manually pressing Page Up/Down"
      },
      "rules": [
        "Arrow key navigation (up/down) should automatically scroll the viewport when selection moves beyond visible area",
        "Scrolling should follow the selected item, keeping it visible at all times",
        "Implementation should match VirtualList pattern from cage project (navigateTo helper function)",
        "Scroll indicators (↑ ↓) should show when there are items above/below visible viewport",
        "No, only arrow keys should trigger automatic scrolling. Do not use j/k vim-style navigation.",
        "Preserve scroll position per column. Each column maintains its own scroll offset state.",
        "Yes, wrap-around navigation should work (down on last item goes to first, up on first item goes to last).",
        "Scroll indicators (arrows) replace work items in viewport rows, reducing actual visible item count",
        "Visible work item count = VIEWPORT_HEIGHT - (number of arrows shown: 0, 1, or 2)",
        "Tests should verify rendering at different scroll positions. The component should calculate scroll offset based on selectedWorkUnitIndex prop and render accordingly. Tests pass selectedWorkUnitIndex and verify the correct items are visible.",
        "Tests should verify rendering logic. Component receives selectedWorkUnitIndex as prop and calculates scroll offset to keep that item visible. Tests pass different selectedWorkUnitIndex values and verify correct items are visible in output."
      ],
      "examples": [
        "User presses down arrow 11 times in a column with 20 items (viewport shows 10). Selection moves to item 11, viewport scrolls to show items 2-11 with selection visible.",
        "User at item 15 presses up arrow to item 5. Viewport scrolls up to show items 1-10 with item 5 selected.",
        "Column with 5 items and viewport height 10: no scroll indicators show, all items visible.",
        "Column with 20 items: ↓ indicator shows at bottom row when scrollOffset < (20 - 10), ↑ indicator shows at top row when scrollOffset > 0.",
        "Column with 15 items, scrollOffset=5, VIEWPORT_HEIGHT=10: Shows up arrow at row 0, items 6-14 in rows 1-9, down arrow at row 9 (only 8 items visible)",
        "Column with 25 items, scrollOffset=10, VIEWPORT_HEIGHT=10: Shows up arrow at row 0, items 11-19 in rows 1-9, but row 9 should show down arrow, so only items 11-18 visible (8 items total)"
      ],
      "questions": [
        {
          "text": "@human: Should vim-style navigation (j/k keys) also trigger automatic scrolling, matching the cage VirtualList pattern?",
          "selected": true,
          "answer": "Tests should verify rendering at different scroll positions. The component should calculate scroll offset based on selectedWorkUnitIndex prop and render accordingly. Tests pass selectedWorkUnitIndex and verify the correct items are visible."
        },
        {
          "text": "@human: When switching columns with left/right arrows, should we reset scroll offset to 0 for the new column, or preserve scroll position per column?",
          "selected": true,
          "answer": "Preserve scroll position per column. Each column maintains its own scroll offset state."
        },
        {
          "text": "@human: Should wrap-around navigation work (pressing down on last item goes to first item)?",
          "selected": true,
          "answer": "Yes, wrap-around navigation should work (down on last item goes to first, up on first item goes to last)."
        },
        {
          "text": "@human: The tests render with selectedWorkUnitIndex but don't simulate arrow key presses. Should tests actually press arrow keys to trigger scrolling, or just verify rendering at different scroll positions?",
          "selected": true,
          "answer": "Tests should verify rendering logic. Component receives selectedWorkUnitIndex as prop and calculates scroll offset to keep that item visible. Tests pass different selectedWorkUnitIndex values and verify correct items are visible in output."
        }
      ],
      "estimate": 5
    },
    "BOARD-010": {
      "id": "BOARD-010",
      "title": "Keyboard priority reordering with bracket keys",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T13:26:34.333Z",
      "updatedAt": "2025-10-28T00:50:41.136Z",
      "description": "Allow users to reorder work units within a column using [ and ] keys to move items up/down in priority",
      "epic": "interactive-tui-foundation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T13:26:34.982Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-28T00:01:07.899Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T00:03:35.764Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-28T00:20:50.787Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-28T00:22:23.137Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T00:23:47.930Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-28T00:23:49.101Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-28T00:35:42.604Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T00:37:09.629Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-28T00:37:17.345Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-28T00:40:31.237Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T00:41:35.209Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-28T00:41:40.893Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-28T00:45:08.520Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-28T00:50:41.136Z"
        }
      ],
      "userStory": {
        "role": "developer using TUI board",
        "action": "reorder work units within a column using bracket keys",
        "benefit": "I can quickly adjust priorities without leaving the keyboard"
      },
      "rules": [
        "Press [ key to move selected work unit up one position in the current column",
        "Press ] key to move selected work unit down one position in the current column",
        "Work unit order changes are persisted to work-units.json immediately",
        "Cannot move work unit up if it's already at the top of the column (first position)",
        "Cannot move work unit down if it's already at the bottom of the column (last position)",
        "Manual reordering with [ and ] keys is only allowed in backlog, specifying, testing, implementing, validating, and blocked columns (not done column)",
        "Work unit position is determined by its index in the states[columnName] array in work-units.json",
        "To move work unit up: swap its position with the previous work unit ID in the states array",
        "To move work unit down: swap its position with the next work unit ID in the states array",
        "Key bindings [ and ] must be displayed in help text at bottom of TUI board",
        "All keyboard input should be handled in a single unified location to prevent conflicts between multiple useInput hooks",
        "Bracket key handlers should be in UnifiedBoardLayout's useInput hook (where arrow keys and Enter are handled), NOT in BoardView's useInput hook",
        "UnifiedBoardLayout should call onMoveUp() and onMoveDown() callbacks (passed as props) when bracket keys are pressed",
        "loadData() in fspecStore MUST load work units by iterating states arrays (not Object.values(workUnits)) to preserve display order",
        "When moving work unit up or down, the selection cursor MUST follow the work unit to its new position"
      ],
      "examples": [
        "User selects BOARD-002 in backlog column (position 2), presses [, work unit moves to position 1",
        "User selects BOARD-001 in backlog column (position 1), presses [, nothing happens (already at top)",
        "User selects BOARD-003 in backlog column (position 2), presses ], work unit moves to position 3",
        "User selects last work unit in done column, presses ], nothing happens (already at bottom)",
        "After moving work unit, order persists when restarting TUI (loaded from work-units.json)",
        "User in done column presses [ or ], nothing happens (done column order is automatic by completion time)",
        "BoardView has useInput hook for ESC and Tab keys, UnifiedBoardLayout has useInput for arrow keys - bracket keys added to BoardView but not working, likely due to hook conflicts",
        "User selects BOARD-002 at position 2, presses [, BOARD-002 moves to position 1 AND selection cursor moves to position 1",
        "User selects BOARD-002 at position 2, presses ], BOARD-002 moves to position 3 AND selection cursor moves to position 3"
      ],
      "estimate": 5,
      "questions": [
        {
          "text": "@human: Where should the bracket key input handlers live - in BoardView or UnifiedBoardLayout? Currently we have useInput in BOTH components which might be causing conflicts.",
          "selected": true,
          "answer": "Bracket key handlers should live in UnifiedBoardLayout's useInput hook (where arrow keys and Enter are already handled). UnifiedBoardLayout will call onMoveUp/onMoveDown callbacks passed as props from BoardView."
        },
        {
          "text": "CRITICAL ARCHITECTURE: How should loadData() load work units to respect states array order? Currently loads Object.values(workUnits) which is unordered!",
          "selected": true,
          "answer": "loadData() MUST build workUnits array from states arrays! Algorithm: 1) Iterate each column in states object 2) For each ID in states[column], lookup workUnit from workUnits object 3) Push to result array IN ORDER. This ensures display order matches states array order."
        }
      ]
    },
    "BOARD-011": {
      "id": "BOARD-011",
      "title": "Order done column by completion time",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T13:28:41.647Z",
      "updatedAt": "2025-10-27T13:38:04.064Z",
      "description": "Display work units in the done column with most recently completed items at the top, ordered by when they were moved to done status",
      "epic": "interactive-tui-foundation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T13:28:42.315Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T13:30:21.761Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T13:33:16.619Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T13:37:45.870Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T13:38:04.064Z"
        }
      ],
      "userStory": {
        "role": "developer viewing the board",
        "action": "see completed work units ordered by completion time",
        "benefit": "I can quickly see what was finished most recently"
      },
      "rules": [
        "Done column displays work units with most recently completed at the top",
        "Completion time is determined by the timestamp when work unit was moved to done status (last stateHistory entry with state=done)",
        "Work units are sorted in descending order by completion timestamp (newest first)",
        "When a work unit is moved back to done from another state, it uses the new timestamp (appears at top again)",
        "Other columns (backlog, specifying, testing, implementing, validating, blocked) maintain existing order behavior"
      ],
      "examples": [
        "BOARD-005 completed at 10:00, BOARD-003 completed at 11:00, BOARD-007 completed at 09:00 → done column shows: BOARD-003, BOARD-005, BOARD-007",
        "BOARD-001 moved to done on Monday, BOARD-002 moved to done on Tuesday → BOARD-002 appears above BOARD-001",
        "BOARD-003 completed yesterday, user moves it back to implementing, then back to done today → BOARD-003 now appears at top of done column with today's timestamp",
        "On TUI startup, done column loads work units sorted by completion time from stateHistory timestamps"
      ],
      "estimate": 3
    },
    "BUG-046": {
      "id": "BUG-046",
      "title": "Fix failing BoardView TUI tests",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-27T14:39:22.122Z",
      "updatedAt": "2025-10-27T14:49:22.499Z",
      "description": "Fix multiple failing tests in BoardView components: done column filtering, work unit details display, and shimmer color handling",
      "epic": "interactive-tui-foundation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T14:39:29.608Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T14:42:31.674Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T14:42:39.259Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T14:48:50.171Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T14:49:22.499Z"
        }
      ],
      "rules": [
        "BoardView tests must use the test directory's work-units.json, not the project's work-units.json",
        "Tests create temporary directories with test data but components load from process.cwd()",
        "The fspecStore must accept an optional cwd parameter to support test isolation"
      ],
      "examples": [
        "Test creates BOARD-001 in temp dir, but component shows TECH-001 from project dir",
        "Test expects 'No work unit selected' but component shows TECH-001 details from project data",
        "BoardView accepts optional cwd prop, passes to store for test directory isolation"
      ],
      "userStory": {
        "role": "developer running TUI tests",
        "action": "test BoardView component in isolation",
        "benefit": "tests use test data not project data"
      },
      "estimate": 3
    },
    "BOARD-012": {
      "id": "BOARD-012",
      "title": "Column scrolling tests fail - tests don't trigger scrolling logic",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-27T21:46:45.776Z",
      "updatedAt": "2025-10-27T22:04:31.655Z",
      "description": "Tests in BoardView-column-scrolling.test.tsx don't actually simulate arrow key presses to trigger scrolling. They just render with selectedWorkUnitIndex but never call stdin.write() to press keys. Component needs to calculate scroll offset based on selectedWorkUnitIndex prop and auto-scroll viewport.",
      "epic": "interactive-tui-foundation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T21:46:51.477Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T21:50:03.890Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T21:50:11.238Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T22:04:03.943Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T22:04:31.655Z"
        }
      ],
      "userStory": {
        "role": "developer running tests",
        "action": "verify BoardView scrolling behavior",
        "benefit": "I can confirm viewport auto-scrolls to keep selected items visible"
      },
      "rules": [
        "Component must calculate scroll offset based on selectedWorkUnitIndex prop to keep selected item visible",
        "When selectedWorkUnitIndex is beyond visible viewport, viewport must scroll to show that item",
        "Scroll indicators (↑ ↓) show when there are items above/below visible viewport",
        "Scroll indicators consume viewport rows: visible items = VIEWPORT_HEIGHT - number_of_arrows",
        "Each column maintains its own scroll offset when switching between columns"
      ],
      "examples": [
        "Column has 20 items, viewport height 10, selectedWorkUnitIndex=10 (item 11): viewport scrolls to show items 2-11 with item 11 visible",
        "Column has 20 items, viewport height 10, selectedWorkUnitIndex=14 (item 15): viewport scrolls down, item 15 visible, items 1-5 scrolled out",
        "Column has 5 items, viewport height 10: no scroll indicators shown, all items visible",
        "Column has 20 items, selectedWorkUnitIndex=15: up arrow (↑) shown at top, down arrow (↓) shown at bottom",
        "Column has 15 items, viewport height 10, both arrows visible: only 8 items visible (10 - 2 arrows = 8)",
        "User at item 15 in column A, switches to column B, then back to column A: scroll position preserved, still at item 15"
      ],
      "estimate": 5
    },
    "BOARD-013": {
      "id": "BOARD-013",
      "title": "Full-Screen TUI Layout",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T22:17:54.321Z",
      "updatedAt": "2025-10-27T22:33:11.994Z",
      "description": "Make the Kanban board TUI fill the entire terminal screen like CAGE does, using responsive layout hooks and proper screen clearing",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T22:18:57.660Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T22:21:48.927Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T22:25:46.915Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T22:30:56.175Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T22:33:11.994Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec board",
        "action": "view the Kanban board in a full-screen TUI",
        "benefit": "I can see all work units clearly without wasted screen space"
      },
      "rules": [
        "Board must fill entire terminal width and height",
        "Board must respond to terminal resize events automatically",
        "Screen must be cleared before rendering to start from position (0,0)",
        "Layout must use Ink Box with width and height set to terminal dimensions",
        "No whitespace or padding should appear outside the board borders"
      ],
      "examples": [
        "User opens board in 80x24 terminal, board fills entire 80x24 space",
        "User opens board in 120x40 terminal, board fills entire 120x40 space",
        "User resizes terminal from 80x24 to 120x40 while board is open, board automatically resizes to 120x40",
        "Board renders with no extra whitespace above, below, left, or right of borders",
        "Board uses useStdout hook to detect terminal dimensions and updates on resize"
      ],
      "estimate": 5
    },
    "BOARD-014": {
      "id": "BOARD-014",
      "title": "Stretch board content to fill available viewport height",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T22:35:08.114Z",
      "updatedAt": "2025-10-28T02:55:49.519Z",
      "description": "Make the work unit table expand vertically to use all available space within FullScreenWrapper. Currently the table has a fixed height and doesn't stretch to fill the terminal.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T22:35:47.315Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T22:37:34.167Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T22:38:36.675Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T22:49:40.611Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T22:51:24.491Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T22:59:56.714Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T23:00:02.325Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T23:00:28.691Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T23:03:32.890Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T23:04:50.702Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T23:04:51.787Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T23:04:52.850Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T23:04:57.476Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T23:05:46.204Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-27T23:13:35.550Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T02:55:35.532Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-28T02:55:39.841Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-28T02:55:44.186Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-28T02:55:49.520Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec board",
        "action": "see the work unit table fill the entire terminal vertically",
        "benefit": "I can view more work units at once without wasted screen space"
      },
      "rules": [
        "Work unit table must expand to fill all available vertical space within FullScreenWrapper",
        "Column height must be calculated based on available viewport height minus headers and borders",
        "No empty space should appear between the work unit rows and the bottom border",
        "Table must respond to terminal resize by recalculating available height",
        "Work unit columns area must use Ink Box component with flexGrow=1 to automatically fill available vertical space",
        "Header panels (Git Stashes, Changed Files, Work Unit Details) must render separately from work unit table to minimize fixed height overhead"
      ],
      "examples": [
        "In 80x24 terminal with 3-row header and 1-row footer, columns should have 20 rows for work units",
        "In 120x40 terminal with same headers, columns should have 36 rows for work units",
        "When terminal resizes from 24 to 40 rows, column height increases from 20 to 36 rows"
      ],
      "questions": [
        {
          "text": "@human: Current unified table layout (ITF-004) uses 10 fixed rows for headers/footers, leaving only 13 work unit rows in a 24-row terminal. To achieve 20 work unit rows as specified, should we: A) Restructure to use Ink's Box/flexGrow for dynamic stretching with separate header panels, B) Simplify headers to use fewer rows while keeping unified table, or C) Adjust test expectations to match current layout?",
          "selected": true,
          "answer": "Option A: Restructure to use Ink's Box/flexGrow. Separate header panels (Git Stashes, Changed Files, Work Unit Details) from the work unit table. Use <Box flexGrow={1}> for the columns area to automatically fill available vertical space. This aligns with React/Ink best practices and eliminates manual row calculations."
        }
      ],
      "updated": "2025-10-28T02:55:49.519Z"
    },
    "BOARD-015": {
      "id": "BOARD-015",
      "title": "Fix work unit details panel to be static 4 lines high",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-27T23:13:42.715Z",
      "updatedAt": "2025-10-27T23:26:22.707Z",
      "description": "The work unit details panel was dynamically sized, causing the third line (metadata) to disappear. Make it static 4 lines: title, description, metadata, empty spacing.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-27T23:13:47.864Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-27T23:17:16.407Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-27T23:21:12.308Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-27T23:24:34.686Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-27T23:26:22.707Z"
        }
      ],
      "userStory": {
        "role": "developer viewing the TUI Kanban board",
        "action": "see work unit details in a consistent layout",
        "benefit": "the metadata line doesn't disappear when viewport calculations change"
      },
      "rules": [
        "Work Unit Details panel must always be exactly 4 content lines high (plus 1 header line)",
        "Line 1 must show: work unit ID and title",
        "Line 2 must show: first line of description (or empty if no description)",
        "Line 3 must show: metadata (Epic, Estimate, Status separated by |)",
        "Line 4 must be: empty spacing line",
        "Panel height must not change based on content - always 4 lines",
        "Viewport height calculation must account for the 5-line Work Unit Details section (1 header + 4 content)"
      ],
      "examples": [
        "Work unit TECH-001 with long description shows: Line 1: ID+title, Line 2: first desc line, Line 3: Status: backlog, Line 4: empty",
        "Work unit with no description shows: Line 1: ID+title, Line 2: empty, Line 3: Epic: x | Estimate: 5pts | Status: implementing, Line 4: empty",
        "No work unit selected shows: Line 1: 'No work unit selected' (centered), Lines 2-4: empty"
      ]
    },
    "LOG-001": {
      "id": "LOG-001",
      "title": "Add winston universal logger for fspec",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-28T00:29:38.433Z",
      "updatedAt": "2025-10-28T00:29:38.433Z",
      "description": "Add winston logging library as the universal logging solution for fspec. Configure winston with file transport (/tmp/fspec.log) and console transport. Support log levels (error, warn, info, debug). Replace all console.error calls with logger.error. Provide singleton logger instance importable throughout codebase.",
      "children": []
    },
    "BOARD-016": {
      "id": "BOARD-016",
      "title": "Work unit details panel shows incorrect work unit after reordering",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-28T01:27:18.527Z",
      "updatedAt": "2025-10-28T02:48:17.334Z",
      "description": "When using bracket keys to reorder work units, the Work Unit Details panel at the top of the board displays the wrong work unit. The selection cursor moves correctly, but the details panel doesn't update to show the newly selected work unit's information.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-28T01:27:53.427Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T01:28:34.324Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-28T01:28:40.250Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-28T01:29:40.013Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-28T01:43:50.612Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T01:49:11.783Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-28T01:55:52.760Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-28T02:03:26.775Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-28T02:06:16.024Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-28T02:09:27.574Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-28T02:09:33.745Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-28T02:10:31.576Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T02:12:46.156Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-28T02:13:30.750Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-28T02:21:43.109Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-28T02:26:14.882Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-28T02:36:05.973Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-28T02:36:17.431Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-28T02:37:36.529Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T02:38:42.857Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-28T02:39:42.279Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-28T02:40:35.699Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-28T02:40:40.356Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-28T02:44:41.136Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-28T02:44:46.378Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-28T02:46:10.033Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T02:46:44.961Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-28T02:47:25.221Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-28T02:48:16.575Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-28T02:48:17.336Z"
        }
      ],
      "rules": [
        "Done column work units are sorted by 'updated' timestamp in DESCENDING order (most recent first)",
        "groupedWorkUnits for done column MUST apply sort BEFORE passing units to UnifiedBoardLayout",
        "Work Unit Details panel selectedWorkUnit MUST match the visual position in the sorted done column display",
        "When moving work unit TO done status, insert work unit ID into states.done array at CORRECT sorted position (most recent 'updated' timestamp first)",
        "update-work-unit-status command MUST set 'updated' field to current ISO timestamp when transitioning TO done status",
        "Display order in TUI should match file order - NO runtime sorting in BoardView or UnifiedBoardLayout",
        "Use SHARED utility function for inserting/moving work units in states arrays (similar to moveWorkUnitUp/Down) - do NOT duplicate array manipulation logic",
        "REFACTOR moveWorkUnitUp/Down into shared utility function for array manipulation, then reuse for sorted insertion into done column",
        "When moving ANY work unit to done status, the ENTIRE states.done array MUST be sorted by 'updated' timestamp (most recent first), not just the newly inserted work unit",
        "Find and REMOVE any runtime sorting logic in TUI components (BoardView, UnifiedBoardLayout, groupedWorkUnits) - the file order IS the display order",
        "When sorting done array, use 'updated' field if present, otherwise fall back to 'createdAt' field for timestamp comparison"
      ],
      "examples": [
        "Done column has 3 work units: BOARD-001 (updated 10:00), BOARD-002 (updated 11:00), BOARD-003 (updated 09:00). Display order is BOARD-002, BOARD-001, BOARD-003. User selects position 0 (BOARD-002), details panel shows BOARD-002.",
        "BOARD-005 currently in implementing status (updated: 2025-10-28T10:00:00Z). User runs 'fspec update-work-unit-status BOARD-005 done'. States.done array has [BOARD-003, BOARD-001]. BOARD-003.updated=11:00, BOARD-001.updated=09:00. BOARD-005 inserted at position 1 (after BOARD-003, before BOARD-001). Final states.done: [BOARD-003, BOARD-005, BOARD-001].",
        "Done column states.done array: [BOARD-003, BOARD-005, BOARD-001]. TUI displays in exact file order: position 0=BOARD-003, position 1=BOARD-005, position 2=BOARD-001. User selects position 1, details panel shows BOARD-005 (NOT BOARD-001).",
        "Done array has [BOARD-003 (11:00), BOARD-001 (09:00), BOARD-005 (12:00)] in wrong order. When BOARD-007 (10:00) moves to done, ENTIRE array is sorted to [BOARD-005, BOARD-003, BOARD-007, BOARD-001]",
        "File has done array: [BOARD-005, BOARD-003, BOARD-001]. TUI displays in EXACT file order without any sorting. Position 0 shows BOARD-005, position 1 shows BOARD-003, position 2 shows BOARD-001.",
        "Work unit has updated='2025-10-28T12:00:00Z' and createdAt='2025-10-27T09:00:00Z'. Sorting uses updated (12:00) because it exists.",
        "Work unit has NO updated field but has createdAt='2025-10-27T10:00:00Z'. Sorting falls back to createdAt (10:00).",
        "Done array: [A (updated=12:00), B (no updated, createdAt=11:00), C (updated=10:00)]. After sorting: [A (12:00), B (11:00), C (10:00)] - all sorted by timestamp with fallback."
      ],
      "questions": [
        {
          "text": "@human: Should the sorting be applied in the groupedWorkUnits computation in BoardView.tsx, or somewhere else?",
          "selected": true,
          "answer": "Sort should be applied when WRITING to work-units.json states.done array, NOT at display time. When work unit moves to done, insert it in the correct position based on updated timestamp (most recent first)."
        },
        {
          "text": "@human: Are there any other columns besides 'done' that need special sorting, or is it only the done column?",
          "selected": true,
          "answer": "Only the done column needs special sorting. All other columns (backlog, specifying, testing, implementing, validating, blocked) maintain manual order from states arrays."
        },
        {
          "text": "@human: The 'updated' field is optional in the WorkUnit interface - should we handle work units without an 'updated' timestamp? If so, how should they be sorted?",
          "selected": true,
          "answer": "Work units MUST have 'updated' field set when moving to done. The update-work-unit-status command should set 'updated' field to current timestamp when transitioning to done."
        }
      ],
      "userStory": {
        "role": "developer using TUI board",
        "action": "see correct work unit details for selected item in done column",
        "benefit": "I can verify completed work matches what's displayed on screen"
      },
      "estimate": 5,
      "updated": "2025-10-28T02:48:17.335Z"
    },
    "LOCK-001": {
      "id": "LOCK-001",
      "title": "Implement file locking for concurrent access safety",
      "type": "story",
      "status": "testing",
      "createdAt": "2025-10-28T03:12:16.122Z",
      "updatedAt": "2025-10-28T05:16:06.302Z",
      "description": "Add three-layer file locking (proper-lockfile + readers-writer + atomic writes) to prevent JSON file corruption when multiple fspec instances run concurrently",
      "children": [],
      "userStory": {
        "role": "developer running multiple fspec instances concurrently",
        "action": "prevent JSON file corruption from race conditions",
        "benefit": "I can safely run multiple commands and TUI simultaneously without data loss"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-28T03:12:31.138Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T04:30:21.953Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-28T04:31:18.647Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-28T05:16:06.302Z"
        }
      ],
      "rules": [
        "File locking MUST use three-layer architecture: (1) proper-lockfile for inter-process coordination, (2) readers-writer pattern for in-process optimization, (3) atomic write-replace for safe writes",
        "Multiple readers can read the same file concurrently (readers-writer pattern allows parallel reads)",
        "Only ONE writer can modify a file at a time (exclusive write lock blocks all readers and other writers)",
        "All file writes MUST use atomic write-replace pattern (write to temp file + rename) to prevent partial writes",
        "proper-lockfile MUST use stale lock detection (10 second timeout) to prevent deadlocks from crashed processes",
        "Lock acquisition MUST use retry logic with exponential backoff (10 retries, 50-500ms timeout range)",
        "LockedFileManager MUST be a singleton to ensure in-process lock coordination across all file operations",
        "All JSON file operations (work-units.json, tags.json, foundation.json, etc.) MUST use LockedFileManager",
        "Read-modify-write operations MUST use transaction() method to ensure atomicity of the entire operation",
        "Lock release MUST happen in finally block to prevent lock leaks on errors",
        "YES - Support network filesystems. proper-lockfile's mkdir strategy is atomic on both local and network filesystems (NFS, SMB). No additional implementation cost, works in CI/CD and team environments.",
        "Throw error immediately after 10 retries with exponential backoff (50-500ms, ~5 seconds total). Simple, clean error message: 'Failed to acquire file lock. Check for stuck fspec processes.' Exit code 1.",
        "NEVER cache file contents. Always read from disk for consistency. Files are small (~200KB max), reads are fast (~3-5ms), caching adds complexity and risk of stale data across processes. Correctness > speed.",
        "Optional debug metrics via FSPEC_DEBUG_LOCKS environment variable. Logs lock acquisition time, wait time, retries, hold duration. Ties into LOG-001 logging infrastructure. Silent by default, verbose when debugging.",
        "All-at-once migration (NOT incremental). MUST work 100% perfectly the first time. Complete implementation: LockedFileManager + refactor utilities + refactor all ~50 commands + refactor TUI store + comprehensive tests. No partial states, no gradual rollout.",
        "ensure* functions use read-lock-first pattern: attempt read with READ lock, on ENOENT upgrade to WRITE lock with double-check before creating file",
        "READ locks released immediately after JSON.parse() completes - data is in memory, lock no longer needed, allows other operations to proceed",
        "transaction() method uses mutation-based API: callback receives data, mutates in place, returns void - fileManager writes mutated data automatically on completion",
        "transaction() errors cause rollback: if callback throws error, no write occurs and file remains unchanged - error propagates to caller for proper logging and exit codes",
        "Multi-file operations use sequential transactions (not atomic): each file gets separate transaction, if later transaction fails earlier transactions already committed - acceptable due to denormalized data, defensive querying, and repair utilities",
        "Debug metrics enabled via FSPEC_DEBUG_LOCKS environment variable: logs lock type, file path, wait time, hold duration, retry count - silent by default, verbose when debugging - ties into LOG-001 logging infrastructure when available"
      ],
      "examples": [
        "User runs 'fspec list-work-units' in terminal 1 AND 'fspec update-work-unit-status BOARD-001 done' in terminal 2 simultaneously - Both commands acquire proper-lockfile locks, list-work-units reads while update-work-unit-status waits for write lock, no corruption occurs",
        "TUI board is running (refreshing every 2 seconds) AND user runs 'fspec create-story PREFIX Title' - TUI's read lock and command's write lock coordinate via proper-lockfile, work-units.json is never corrupted, TUI sees new work unit after refresh",
        "Three fspec commands run concurrently: (1) list-work-units, (2) show-work-unit BOARD-001, (3) update-work-unit-status BOARD-002 done - Commands 1 and 2 read concurrently with in-process readers lock, command 3 waits for exclusive write lock, all succeed without corruption",
        "Process 1 acquires write lock on work-units.json and crashes mid-write - proper-lockfile's stale lock detection (10 second timeout) allows Process 2 to acquire lock after timeout, preventing permanent deadlock",
        "Command writes to work-units.json using atomic pattern: (1) writes to work-units.json.tmp.abc123, (2) renames to work-units.json - If crash occurs during step 1, original file is intact; if during step 2, rename is atomic",
        "Reader 1 and Reader 2 both call fileManager.readJSON('work-units.json') - Both acquire in-process read locks simultaneously (readers-writer pattern), both acquire proper-lockfile locks with retry, both read file concurrently",
        "Writer calls fileManager.writeJSON('work-units.json', data) while Reader is active - Writer waits for Reader's in-process read lock to release, then acquires exclusive write lock, prevents read-during-write corruption",
        "Command refactoring minimal change: Replace 'const data = await ensureWorkUnitsFile(cwd); ... await writeFile(file, JSON.stringify(data, 2))' with 'await fileManager.transaction(file, async (data) => { ... })' - same 400 lines of mutation logic unchanged",
        "Transaction rollback on error: 'await fileManager.transaction(file, async (data) => { if (\\!valid) throw new Error(\"bad\"); data.x = 1; })' - Error thrown, no write occurs, file unchanged, error propagates to command catch block",
        "Multi-file sequential transactions: 'await fileManager.transaction(workUnitsFile, async (data) => { data.workUnits[id] = newWorkUnit; }); await fileManager.transaction(epicsFile, async (data) => { data.epics[epicId].workUnits.push(id); });' - If second fails first committed, run fspec repair-work-units to fix",
        "Debug metrics output: 'FSPEC_DEBUG_LOCKS=1 fspec update-work-unit-status AUTH-001 done' logs '[LOCK] Acquired WRITE lock on work-units.json (waited 2ms, held 15ms, retries 0)' - helps diagnose performance issues and lock contention"
      ],
      "architectureNotes": [
        "Three-Layer Lock Architecture: Layer 1 (Inter-Process) = proper-lockfile with mkdir strategy for cross-process coordination; Layer 2 (In-Process) = Readers-writer pattern using promises and queues for concurrent reads; Layer 3 (Atomic Writes) = Temp file + rename for POSIX atomic write guarantees",
        "LockedFileManager Singleton Pattern: Single instance coordinates all in-process locks via Map<string, number> for read counts and Set<string> for write locks, with separate waiting queues (Array<() => void>) for blocked readers and writers",
        "proper-lockfile Configuration: stale=10000ms (10 second timeout for crashed processes), retries={retries:10, minTimeout:50ms, maxTimeout:500ms} for exponential backoff, realpath=false for symlink support and performance",
        "Affected Files: work-units.json (230+ work units, high contention), foundation.json, tags.json, prefixes.json, epics.json, example-map.json, fspec-hooks.json - ALL must use LockedFileManager",
        "Migration Strategy: (1) Create src/utils/file-manager.ts with LockedFileManager class, (2) Refactor ensure-files.ts to use fileManager singleton, (3) Update all commands to use fileManager.transaction() for read-modify-write, (4) Add comprehensive concurrency tests"
      ],
      "attachments": [
        "spec/attachments/LOCK-001/file-locking-architecture.md"
      ],
      "questions": [
        {
          "text": "@human: Should the file locking system handle network filesystems (NFS, SMB) or only local filesystems?",
          "selected": true,
          "answer": "All-at-once migration (NOT incremental). MUST work 100% perfectly the first time. Complete implementation: LockedFileManager + refactor utilities + refactor all ~50 commands + refactor TUI store + comprehensive tests. No partial states, no gradual rollout."
        },
        {
          "text": "@human: What should happen if lock acquisition fails after all retries - throw error immediately or offer user option to retry/abort?",
          "selected": true,
          "answer": "Throw error immediately with clear message. The retry logic (10 retries with exponential backoff) already provides sufficient resilience. After retries exhausted, command should fail fast with actionable error message suggesting user check for stuck processes."
        },
        {
          "text": "@human: Should LockedFileManager cache file contents to reduce disk I/O, or always read from disk for consistency?",
          "selected": true,
          "answer": "Always read from disk for consistency. Caching introduces cache invalidation complexity and potential stale reads in concurrent scenarios. File I/O performance is acceptable (3-5ms reads) and correctness is more important than speed."
        },
        {
          "text": "@human: Do we need metrics/logging for lock performance (acquisition time, wait time, contentions) or keep it simple?",
          "selected": true,
          "answer": "Keep it simple initially, add metrics later if needed. Start with basic error logging only. Can add FSPEC_DEBUG_LOCKS environment variable for verbose lock debugging in future iterations (Phase 2 enhancement)."
        },
        {
          "text": "@human: Should the migration happen in one phase (all-at-once) or incrementally (file by file, command by command)?",
          "selected": true,
          "answer": "Incremental migration is safer. Phase 1: Create LockedFileManager + refactor ensure-files.ts. Phase 2: Migrate high-risk commands (update-work-unit-status, create-story). Phase 3: Migrate remaining commands. Phase 4: TUI store. This allows testing at each phase."
        }
      ],
      "estimate": 8
    }
  },
  "states": {
    "backlog": [
      "LOG-001",
      "RES-003",
      "RES-004",
      "RES-001",
      "RES-005",
      "TECH-001",
      "AGENT-001",
      "AGENT-002",
      "AGENT-003",
      "AGENT-004",
      "AGENT-005",
      "AGENT-006",
      "AGENT-007",
      "AGENT-008",
      "AGENT-009",
      "AGENT-010",
      "AGENT-011",
      "AGENT-012",
      "AGENT-013",
      "AGENT-014",
      "AGENT-015",
      "AGENT-016",
      "AGENT-017",
      "FEAT-018"
    ],
    "specifying": [
      "GIT-004",
      "RES-006",
      "EST-002",
      "LANG-001"
    ],
    "testing": [
      "LOCK-001"
    ],
    "implementing": [],
    "validating": [],
    "done": [
      "BOARD-014",
      "BOARD-016",
      "BOARD-015",
      "BOARD-013",
      "BOARD-012",
      "BUG-046",
      "BOARD-011",
      "BOARD-010",
      "BUG-045",
      "BOARD-009",
      "BOARD-008",
      "BOARD-007",
      "BOARD-006",
      "BOARD-005",
      "ITF-005",
      "ITF-004",
      "ITF-003",
      "ITF-002",
      "ITF-001",
      "HELP-004",
      "INIT-012",
      "CONFIG-003",
      "INIT-011",
      "CONFIG-002",
      "REV-005",
      "REV-004",
      "BUG-044",
      "REV-003",
      "FEAT-019",
      "REMIND-009",
      "REV-002",
      "TEST-006",
      "CLI-012",
      "QRY-002",
      "CLI-011",
      "BUG-043",
      "GIT-005",
      "REFAC-002",
      "BUG-042",
      "BUG-041",
      "CONFIG-001",
      "CLI-010",
      "CLI-009",
      "CLI-008",
      "BOARD-004",
      "RES-002",
      "BUG-040",
      "BUG-038",
      "BUG-037",
      "DEP-002",
      "BUG-035",
      "BOARD-003",
      "BUG-034",
      "BUG-033",
      "DOC-005",
      "INIT-010",
      "INIT-009",
      "BUG-032",
      "FEAT-017",
      "BUG-031",
      "BUG-030",
      "BUG-029",
      "BUG-028",
      "CLI-007",
      "BUG-027",
      "TECH-002",
      "INIT-008",
      "BUG-026",
      "BUG-025",
      "INIT-006",
      "INIT-005",
      "BUG-024",
      "INIT-004",
      "CLEAN-001",
      "BOARD-002",
      "GIT-003",
      "GIT-002",
      "GIT-001",
      "HELP-003",
      "BUG-023",
      "HOOK-011",
      "SPEC-003",
      "SPEC-002",
      "BUG-022",
      "BUG-021",
      "DOCS-002",
      "UX-001",
      "REV-001",
      "BUG-020",
      "FEAT-016",
      "DOCS-001",
      "BUG-019",
      "FEAT-015",
      "FEAT-014",
      "BUG-018",
      "BUG-017",
      "BUG-016",
      "BUG-015",
      "DISC-001",
      "FOUND-010",
      "FOUND-009",
      "HELP-002",
      "HELP-001",
      "COV-052",
      "REFAC-001",
      "TEST-005",
      "BUG-014",
      "FOUND-007",
      "BUG-013",
      "BUG-012",
      "FOUND-006",
      "FOUND-005",
      "FOUND-004",
      "FOUND-003",
      "FOUND-002",
      "FOUND-001",
      "TEST-004",
      "HOOK-010",
      "FEAT-013",
      "FEAT-012",
      "BUG-011",
      "HOOK-009",
      "HOOK-008",
      "HOOK-007",
      "HOOK-006",
      "HOOK-005",
      "HOOK-004",
      "HOOK-003",
      "HOOK-002",
      "HOOK-001",
      "EXMAP-003",
      "EXMAP-002",
      "BUG-010",
      "DOC-004",
      "FEAT-011",
      "FEAT-006",
      "BUG-008",
      "BUG-007",
      "COV-051",
      "COV-050",
      "COV-049",
      "COV-048",
      "COV-047",
      "COV-046",
      "COV-045",
      "COV-044",
      "COV-043",
      "COV-042",
      "COV-041",
      "COV-040",
      "COV-039",
      "COV-038",
      "COV-037",
      "COV-036",
      "COV-035",
      "COV-034",
      "COV-033",
      "COV-032",
      "COV-031",
      "COV-030",
      "COV-029",
      "COV-028",
      "COV-027",
      "COV-026",
      "COV-025",
      "COV-024",
      "COV-023",
      "COV-022",
      "COV-021",
      "COV-020",
      "COV-019",
      "COV-018",
      "COV-017",
      "COV-016",
      "COV-015",
      "COV-014",
      "COV-013",
      "COV-012",
      "COV-011",
      "COV-010",
      "DOC-003",
      "COV-008",
      "COV-007",
      "BUG-006",
      "BUG-005",
      "COV-006",
      "COV-005",
      "COV-004",
      "COV-003",
      "COV-002",
      "COV-001",
      "REMIND-008",
      "REMIND-007",
      "REMIND-006",
      "REMIND-005",
      "REMIND-004",
      "REMIND-003",
      "REMIND-002",
      "BUG-004",
      "CLI-006",
      "CLI-005",
      "BUG-003",
      "RSPEC-001",
      "DOC-002",
      "INIT-003",
      "BUG-002",
      "BUG-001",
      "CLI-004",
      "SAFE-002",
      "TEST-003",
      "CLI-003",
      "TEST-002",
      "REMIND-001",
      "DOC-001",
      "CLI-002",
      "SAFE-001",
      "BOARD-001",
      "INIT-002",
      "FEAT-005",
      "FEAT-004",
      "FEAT-003",
      "FEAT-002",
      "FEAT-001",
      "TEST-001",
      "SPEC-001",
      "QRY-001",
      "EST-001",
      "DEP-001",
      "CLI-001",
      "INIT-001",
      "EXMAP-001"
    ],
    "blocked": []
  }
}