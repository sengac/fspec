{
  "meta": {
    "version": "1.0.0",
    "lastUpdated": "2025-10-22T10:19:43.042Z"
  },
  "workUnits": {
    "EXMAP-001": {
      "id": "EXMAP-001",
      "title": "Redesign Example Mapping to match BDD technique",
      "status": "done",
      "createdAt": "2025-10-10T22:58:36.526Z",
      "updatedAt": "2025-10-10T23:20:00.252Z",
      "description": "Current implementation is wrong - operates on work units instead of stories. Need to redesign to follow 4-card system (yellow story, blue rules, green examples, red questions) that happens BEFORE writing feature files. Example Mapping should help discover what scenarios to write, not modify existing ones.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T22:58:42.985Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:05:16.853Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:19:16.805Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:19:26.991Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:20:00.252Z"
        }
      ]
    },
    "INIT-001": {
      "id": "INIT-001",
      "title": "Add ensureWorkUnitsFile to ALL 48+ commands",
      "status": "done",
      "createdAt": "2025-10-10T23:23:00.738Z",
      "updatedAt": "2025-10-10T23:30:22.581Z",
      "description": "Following EXMAP-001 pattern, add ensureWorkUnitsFile/ensurePrefixesFile/ensureEpicsFile utilities to ALL commands that read JSON files. This prevents ENOENT errors and improves first-time user experience.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:23:13.046Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:24:25.195Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:30:08.298Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:30:09.868Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:30:22.581Z"
        }
      ],
      "rules": [
        "ALL commands that read spec/work-units.json MUST use ensureWorkUnitsFile",
        "ALL commands that read spec/prefixes.json MUST use ensurePrefixesFile",
        "ALL commands that read spec/epics.json MUST use ensureEpicsFile",
        "Ensure utilities MUST be idempotent - safe to call multiple times",
        "NO command should fail with ENOENT errors when JSON files missing"
      ],
      "examples": [
        "Create epic command auto-creates spec/epics.json when missing",
        "Create prefix command auto-creates spec/prefixes.json when missing",
        "List work units command auto-creates spec/work-units.json when missing",
        "Update work unit command uses ensureWorkUnitsFile instead of direct readFile",
        "Calling ensureWorkUnitsFile multiple times returns same data without overwriting"
      ],
      "questions": [],
      "assumptions": [
        "No - tags.json and foundation.json already auto-create via register-tag and add-diagram commands"
      ]
    },
    "CLI-001": {
      "id": "CLI-001",
      "title": "Verify all CLI commands and help system complete",
      "status": "done",
      "createdAt": "2025-10-10T23:34:14.426Z",
      "updatedAt": "2025-10-11T02:09:46.737Z",
      "description": "VERIFIED: 84 commands registered, help system comprehensive and accurate, all validation checks passing",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:09:01.564Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:09:45.913Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:09:46.189Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:09:46.463Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:09:46.737Z"
        }
      ],
      "rules": [
        "ALL 84 commands MUST be registered in src/index.ts with proper CLI bindings",
        "MUST have comprehensive help text for each command",
        "MUST pass all validation checks (build, validate, validate-tags)"
      ],
      "examples": [
        "All commands registered and accessible",
        "Help system shows all commands",
        "Build succeeds with no errors"
      ]
    },
    "DEP-001": {
      "id": "DEP-001",
      "title": "Work Unit Dependency Management",
      "status": "done",
      "createdAt": "2025-10-10T23:39:22.582Z",
      "updatedAt": "2025-10-10T23:47:00.473Z",
      "description": "Implement dependency tracking between work units including add-dependency, remove-dependency, and dependency validation",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:39:38.913Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:42:11.831Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:46:12.749Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:46:19.691Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:47:00.473Z"
        }
      ],
      "rules": [
        "MUST maintain bidirectional consistency (if A blocks B, then B blockedBy A)",
        "MUST detect circular dependencies before creating relationships",
        "MUST prevent deletion of work units that block other work",
        "MUST auto-transition to blocked state when blockedBy work exists",
        "Work units can have 4 relationship types: blocks, blockedBy, dependsOn, relatesTo"
      ],
      "examples": [
        "Add blocks relationship creates bidirectional link",
        "Remove dependency cleans up both sides of relationship",
        "Circular dependency detection prevents A→B→A loops",
        "Adding blockedBy dependency auto-sets work unit to blocked state",
        "Query dependency stats shows metrics across all work units"
      ]
    },
    "EST-001": {
      "id": "EST-001",
      "title": "Work Unit Estimation and Metrics",
      "status": "done",
      "createdAt": "2025-10-10T23:39:24.324Z",
      "updatedAt": "2025-10-10T23:51:10.655Z",
      "description": "Implement estimation and metrics tracking including assign estimates, record tokens, calculate cycle time",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:47:18.974Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:48:44.204Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:51:10.109Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:51:10.383Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:51:10.655Z"
        }
      ],
      "rules": [
        "MUST support Fibonacci story points (1,2,3,5,8,13,21) for estimation",
        "MUST track AI-specific metrics: actualTokens and iterations",
        "MUST calculate cycle time from stateHistory timestamps",
        "MUST compare estimate vs actual to provide accuracy feedback",
        "MUST provide pattern-based estimation recommendations"
      ],
      "examples": [
        "Update work unit with 5-point estimate",
        "Record 45k tokens consumed",
        "Increment iteration count",
        "Query estimate accuracy for work unit",
        "Get estimation guide with patterns"
      ]
    },
    "QRY-001": {
      "id": "QRY-001",
      "title": "Work Unit Query and Reporting",
      "status": "done",
      "createdAt": "2025-10-10T23:39:26.221Z",
      "updatedAt": "2025-10-10T23:52:11.901Z",
      "description": "Implement query and reporting features including compound queries, statistical reports, and data export",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-10T23:51:24.531Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-10T23:52:11.067Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-10T23:52:11.346Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-10T23:52:11.624Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-10T23:52:11.901Z"
        }
      ],
      "rules": [
        "MUST support compound queries combining multiple filters (status, prefix, epic, tags)",
        "MUST export query results to JSON, CSV, or Markdown formats",
        "MUST generate statistical summary reports across work units",
        "MUST support sorting and pagination for large result sets",
        "MUST provide machine-readable output for CI/CD integration"
      ],
      "examples": [
        "Query by status and prefix",
        "Export work units to JSON",
        "Generate summary report with statistics",
        "Query with sorting by updated date",
        "Export filtered results to CSV"
      ]
    },
    "SPEC-001": {
      "id": "SPEC-001",
      "title": "Complete placeholder scenarios with proper Given/When/Then",
      "status": "done",
      "createdAt": "2025-10-11T02:11:53.337Z",
      "updatedAt": "2025-10-11T02:18:27.489Z",
      "description": "Fill in 24 placeholder scenarios across 6 feature files with concrete Given/When/Then steps",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:12:07.366Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:13:37.952Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:18:26.932Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:18:27.212Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:18:27.489Z"
        }
      ],
      "rules": [
        "Each placeholder scenario MUST have concrete Given/When/Then steps",
        "Steps MUST be specific and testable (no vague descriptions)",
        "Scenarios MUST align with their example mapping source",
        "All scenarios MUST follow Gherkin best practices",
        "Completed scenarios MUST pass validation"
      ],
      "examples": [
        "Fill INIT-001 scenarios (5 scenarios)",
        "Fill DEP-001 scenarios (5 scenarios)",
        "Fill EST-001 scenarios (5 scenarios)",
        "Fill QRY-001 scenarios (5 scenarios)",
        "Fill CLI-001 scenarios (3 scenarios)",
        "Fill add-scenario scenarios (1 scenario)"
      ]
    },
    "TEST-001": {
      "id": "TEST-001",
      "title": "Implement comprehensive test coverage for all commands",
      "status": "done",
      "createdAt": "2025-10-11T02:25:37.571Z",
      "updatedAt": "2025-10-11T03:07:49.878Z",
      "description": "Write tests for remaining untested commands to achieve near-100% test coverage across the CLI",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T03:05:37.421Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T03:06:54.869Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T03:07:39.735Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T03:07:44.751Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T03:07:49.878Z"
        }
      ],
      "rules": [
        "MUST test all CLI commands with valid inputs",
        "MUST test error handling and edge cases",
        "MUST achieve 90%+ code coverage on critical commands",
        "MUST validate file operations (read, write, delete)",
        "MUST test integration points (parser, formatter, validator)"
      ],
      "examples": [
        "Test create-feature with all template variations",
        "Test validation with invalid Gherkin syntax",
        "Test format preserves content and fixes indentation",
        "Test file operations handle missing directories",
        "Test tag registry operations (add, update, delete)"
      ]
    },
    "FEAT-001": {
      "id": "FEAT-001",
      "title": "Implement add-scenario and add-step commands",
      "status": "done",
      "createdAt": "2025-10-11T02:26:06.358Z",
      "updatedAt": "2025-10-11T02:34:00.512Z",
      "description": "Complete implementation of add-scenario and add-step commands for modifying feature files programmatically (phase3)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:26:56.216Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:28:39.953Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:33:59.946Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:34:00.227Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:34:00.512Z"
        }
      ],
      "rules": [
        "MUST parse existing feature file without corrupting content",
        "MUST maintain proper Gherkin formatting and indentation",
        "MUST validate scenario/step syntax before adding",
        "MUST preserve existing tags and metadata",
        "MUST support adding to any position (append, prepend, after scenario)"
      ],
      "examples": [
        "Add scenario to feature file",
        "Add Given step to scenario",
        "Add When step to scenario",
        "Add Then step to scenario",
        "Add scenario with tags"
      ]
    },
    "FEAT-002": {
      "id": "FEAT-002",
      "title": "Implement delete-scenario command",
      "status": "done",
      "createdAt": "2025-10-11T02:37:12.464Z",
      "updatedAt": "2025-10-11T02:43:37.355Z",
      "description": "Complete implementation of delete-scenario command for removing scenarios from feature files (phase4)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:37:48.826Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:40:58.673Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:43:36.723Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:43:37.047Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:43:37.355Z"
        }
      ],
      "rules": [
        "MUST safely delete scenario without corrupting file",
        "MUST preserve other scenarios and structure",
        "MUST support deletion by scenario name or index",
        "MUST handle scenario tags properly during deletion",
        "MUST provide confirmation before deleting"
      ],
      "examples": [
        "Delete scenario by name",
        "Delete scenario by index",
        "Delete multiple scenarios by tag",
        "Confirm before deletion",
        "Preserve remaining scenarios intact"
      ]
    },
    "FEAT-003": {
      "id": "FEAT-003",
      "title": "Implement scenario querying and filtering",
      "status": "done",
      "createdAt": "2025-10-11T02:37:12.740Z",
      "updatedAt": "2025-10-11T02:47:04.736Z",
      "description": "Implement get-scenarios and show-acceptance-criteria commands for querying scenarios by tag (phase4)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:43:45.616Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:44:45.290Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:47:04.171Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:47:04.451Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:47:04.736Z"
        }
      ],
      "rules": [
        "MUST support querying scenarios by single or multiple tags",
        "MUST output scenario list with metadata (feature, tags, steps)",
        "MUST support JSON and plain text output formats",
        "MUST handle AND/OR logic for multiple tags",
        "MUST show acceptance criteria in readable format"
      ],
      "examples": [
        "Get scenarios by single tag",
        "Get scenarios by multiple tags (AND logic)",
        "Show acceptance criteria for tag",
        "Output scenarios as JSON",
        "Query with tag matching pattern"
      ]
    },
    "FEAT-004": {
      "id": "FEAT-004",
      "title": "Implement bulk operations (delete-by-tag, retag)",
      "status": "done",
      "createdAt": "2025-10-11T02:49:30.896Z",
      "updatedAt": "2025-10-11T02:57:58.944Z",
      "description": "Implement bulk delete features/scenarios by tag and bulk retag operations (phase5 high priority)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:50:54.242Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T02:52:40.455Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T02:57:58.367Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T02:57:58.656Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T02:57:58.944Z"
        }
      ],
      "rules": [
        "MUST support bulk deletion across multiple files",
        "MUST preview changes before executing bulk operations",
        "MUST handle tag renaming with bidirectional updates",
        "MUST preserve file structure during bulk operations",
        "MUST provide detailed summary of changes made"
      ],
      "examples": [
        "Delete all scenarios with @deprecated tag",
        "Delete feature files tagged @phase1",
        "Rename tag from @old-tag to @new-tag",
        "Preview bulk delete before confirmation",
        "Show summary of bulk changes"
      ]
    },
    "FEAT-005": {
      "id": "FEAT-005",
      "title": "Implement update operations (scenario, step)",
      "status": "done",
      "createdAt": "2025-10-11T02:49:31.178Z",
      "updatedAt": "2025-10-11T03:01:38.306Z",
      "description": "Implement update-scenario and update-step commands for modifying existing content (phase5)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T02:58:07.304Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T03:00:04.811Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T03:01:27.456Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T03:01:32.883Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T03:01:38.306Z"
        }
      ],
      "rules": [
        "MUST support updating scenario name/title",
        "MUST support updating step text",
        "MUST preserve tags and metadata during updates",
        "MUST validate new content before applying",
        "MUST maintain proper Gherkin syntax"
      ],
      "examples": [
        "Update scenario name",
        "Update Given step text",
        "Update When step text",
        "Update Then step text",
        "Update step preserving position"
      ]
    },
    "INIT-002": {
      "id": "INIT-002",
      "title": "Add ensureFoundationFile and ensureTagsFile with proper auto-initialization",
      "status": "done",
      "createdAt": "2025-10-11T03:55:06.491Z",
      "updatedAt": "2025-10-11T04:29:23.795Z",
      "description": "Add ensureFoundationFile() and ensureTagsFile() functions to src/utils/ensure-files.ts and update ALL commands that read foundation.json or tags.json to use these functions instead of manual file checks",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T03:55:27.686Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T04:00:53.724Z",
          "reason": "Feature file tagged with @INIT-002, ready to write tests"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T04:12:03.024Z",
          "reason": "Tests written, ready to implement ensureFoundationFile and ensureTagsFile"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T04:25:49.608Z",
          "reason": "All commands updated to use ensure functions, tests passing"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T04:29:23.795Z",
          "reason": "Implementation complete: ensureFoundationFile() and ensureTagsFile() added, all commands updated, all tests passing"
        }
      ]
    },
    "BOARD-001": {
      "id": "BOARD-001",
      "title": "Implement board command with Ink + React visualization",
      "status": "done",
      "createdAt": "2025-10-11T04:32:31.325Z",
      "updatedAt": "2025-10-11T05:18:44.997Z",
      "description": "Create a Kanban board visualization using Ink + React that displays all work units across 7 workflow states. The board command replaces the old display-board implementation with a responsive terminal UI following React patterns.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-11T04:32:38.196Z",
          "reason": "Analyzing feature file scenarios and current broken implementation"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-11T04:43:24.069Z",
          "reason": "Example mapping complete, design agreed: box-drawing columns, 3-item limit, BLOCKED highlighted, all columns shown"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-11T04:44:20.798Z",
          "reason": "Tests written and passing for data structure, now implementing visual output"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-11T05:11:08.352Z",
          "reason": "Implementation complete: BoardDisplay component using Ink + React, architecture docs updated, component follows React patterns with useStdout, ready for validation"
        },
        {
          "state": "done",
          "timestamp": "2025-10-11T05:13:08.776Z",
          "reason": "Implementation validated: board command displays Kanban board correctly using Ink + React, all tests pass, follows React patterns, architecture docs updated, no issues found"
        }
      ]
    },
    "SAFE-001": {
      "id": "SAFE-001",
      "title": "Prevent spec directory creation outside project root",
      "status": "done",
      "createdAt": "2025-10-12T03:27:57.082Z",
      "updatedAt": "2025-10-12T04:47:39.305Z",
      "description": "Add validation to check if current directory is within project root before creating spec directories",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T03:28:04.689Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T04:43:22.902Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T04:45:14.668Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T04:47:23.341Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T04:47:39.306Z"
        }
      ],
      "rules": [
        "Project root is determined by finding a spec/ directory, but search must stop at a project boundary marker (.git, package.json, etc.)",
        "Search algorithm walks upward from cwd, stopping at project boundary markers: .git, package.json, .gitignore, Cargo.toml, pyproject.toml",
        "If spec/ directory exists within project boundary, use that directory as project root",
        "If no spec/ directory found within project boundary, create spec/ at the project boundary location (not cwd)",
        "If no project boundary marker found after searching to filesystem root, create spec/ in current working directory",
        "Stop at first boundary marker found when searching upward (closest to cwd)",
        "All spec directory creation must go through a centralized utility function that performs project root detection",
        "Search upward with a maximum limit (e.g., 10 directories) to prevent excessive traversal",
        "On permission errors or filesystem issues, gracefully fall back to creating spec/ in current working directory",
        "Centralized utility should automatically create spec/ directory and return the spec path (not project root)",
        "Defer testing refactored callers until core utility is complete. Critical: Do not break existing functionality - ensure backward compatibility so all current tests continue passing. Architecture must support both old and new code paths during transition."
      ],
      "examples": [
        "User at /project/src/commands/, .git at /project/, no spec/ exists → create /project/spec/",
        "User at /project/src/commands/, .git at /project/, spec/ exists at /project/spec/ → use /project/spec/",
        "User at /tmp/random/, no boundary markers found → create /tmp/random/spec/",
        "Monorepo: /monorepo/.git and /monorepo/packages/app/package.json, user at /monorepo/packages/app/src/ → use /monorepo/packages/app/ as root",
        "User at /very/deep/nested/path/a/b/c/d/e/f/g/h/i/j/k/, no boundary within 10 dirs → create spec/ at cwd",
        "User at /project/src/, permission denied reading parent dirs → create spec/ at /project/src/"
      ],
      "questions": [],
      "assumptions": [
        "Need to verify existing ensure-files.ts functions work with new project root detection - may need to refactor callers to use returned spec path instead of manually constructing it"
      ]
    },
    "CLI-002": {
      "id": "CLI-002",
      "title": "Fix missing list-prefixes CLI command registration",
      "status": "done",
      "createdAt": "2025-10-12T03:48:03.694Z",
      "updatedAt": "2025-10-12T03:53:56.776Z",
      "description": "The list-prefixes command is documented in help but not registered in the CLI",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T03:48:12.204Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T03:50:18.426Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T03:51:37.431Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T03:52:38.137Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T03:53:56.776Z"
        }
      ],
      "questions": [],
      "rules": [
        "Yes, consistent with list-epics behavior",
        "Yes, output format should match list-epics for consistency",
        "Yes, return empty list with yellow message if no prefixes.json exists"
      ],
      "examples": [
        "User runs 'fspec list-prefixes' and sees all registered prefixes with their descriptions",
        "User runs 'fspec list-prefixes' and sees work unit counts for each prefix (e.g., 'SAFE: 1/1 (100%)')",
        "User runs 'fspec list-prefixes' when no prefixes.json exists, sees 'No prefixes found' in yellow"
      ]
    },
    "DOC-001": {
      "id": "DOC-001",
      "title": "Add story point estimation guidance",
      "status": "done",
      "createdAt": "2025-10-12T05:13:30.172Z",
      "updatedAt": "2025-10-12T06:58:58.773Z",
      "description": "Add story point estimation guidelines to /fspec command including Fibonacci scale, estimation prompts, and best practices",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T06:57:57.344Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:58:57.916Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:58:58.206Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:58:58.489Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:58:58.773Z"
        }
      ]
    },
    "REMIND-001": {
      "id": "REMIND-001",
      "title": "Implement system-reminder pattern",
      "status": "done",
      "createdAt": "2025-10-12T05:13:30.451Z",
      "updatedAt": "2025-10-12T05:29:04.618Z",
      "description": "Add system-reminder wrapper functions and trigger points to prevent AI drift during long conversations",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:17:36.967Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T05:20:47.043Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:21:53.587Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:23:54.695Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:24:11.995Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:24:29.001Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:25:59.299Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:26:23.102Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:26:44.204Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:27:04.588Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T05:27:37.721Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T05:27:52.779Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T05:29:04.618Z"
        }
      ],
      "rules": [
        "System reminders must be wrapped in <system-reminder> tags",
        "Reminders must be invisible to users but visible to Claude",
        "Reminders should only be injected after specific command executions",
        "Each reminder must be context-specific to the command executed",
        "Reminders must be conditional and context-aware - only show when relevant to the current situation",
        "Reminders should be appended AFTER main command output"
      ],
      "examples": [
        "After 'fspec update-work-unit-status UI-001 testing', output includes reminder: 'Write FAILING tests BEFORE any implementation code'",
        "After 'fspec update-work-unit-status UI-001 implementing', output includes reminder: 'Write ONLY enough code to make tests pass'",
        "After 'fspec update-work-unit-estimate UI-001' without an estimate value, output includes reminder: 'Use Fibonacci scale (1,2,3,5,8,13)'",
        "After 'fspec list-work-units --status=backlog' returns empty, output includes reminder: 'Consider creating new work units or checking priorities'"
      ],
      "questions": []
    },
    "TEST-002": {
      "id": "TEST-002",
      "title": "Test system reminders",
      "status": "done",
      "createdAt": "2025-10-12T05:24:45.522Z",
      "updatedAt": "2025-10-12T06:57:17.505Z",
      "description": "Testing if system reminders work correctly",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:24:53.211Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:56:43.819Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:56:44.107Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:56:44.393Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:57:17.505Z"
        }
      ]
    },
    "CLI-003": {
      "id": "CLI-003",
      "title": "Initialize fspec slash command in Claude Code project",
      "status": "done",
      "createdAt": "2025-10-12T05:41:20.177Z",
      "updatedAt": "2025-10-12T06:53:58.304Z",
      "description": "Add 'fspec init' command that installs the /fspec slash command into a Claude Code project by creating/using .claude/commands/ directory and copying fspec.md command file. Should be idempotent and safe to run multiple times.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:42:05.997Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T05:54:31.892Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:51:49.181Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:52:51.675Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:53:58.304Z"
        }
      ],
      "rules": [
        "Command must prompt user to choose: Claude Code or custom location",
        "If Claude Code selected, install to .claude/commands/fspec.md automatically",
        "If custom location selected, prompt for full file path where to save",
        "Template must be generic and reusable across any project (not fspec-specific examples)",
        "Success means file exists at specified location after command completes",
        "Create parent directories if they don't exist",
        "If target file exists, prompt for confirmation before overwriting",
        "Template references fspec commands but uses generic project placeholders (not fspec-specific examples)",
        "Use ink/react for interactive prompts (consistent with existing board UI)",
        "Command works from any directory, installs relative to current working directory",
        "Template uses same structure as .claude/commands/fspec.md but with generic project placeholders",
        "If user cancels overwrite, display 'Installation cancelled' and exit with success (0)",
        "Custom path must be relative to current directory (same or subdirectory, not parent or absolute)",
        "On success, display both confirmation message and next steps for usage",
        "On error (permission denied, disk full, etc), display error message and exit with non-zero code",
        "Use example-project style (lowercase example placeholders)",
        "Include all sections from current fspec.md (complete template with all ACDD workflow, example mapping, estimation, etc)",
        "Allow: ./file.md, file.md, subdir/file.md, subdir/nested/file.md. Reject: ../file.md, /absolute/path, ~/home/path"
      ],
      "examples": [
        "User runs 'fspec init' in project root, selects Claude Code, file created at ./claude/commands/fspec.md",
        "User runs 'fspec init', selects custom location, enters 'docs/ai/fspec.md', file created at ./docs/ai/fspec.md",
        "User runs 'fspec init' when .claude/commands/fspec.md exists, prompted to confirm overwrite, user confirms, file is overwritten",
        "User runs 'fspec init', selects custom location, enters 'some/deep/path/fspec.md', parent directories created automatically",
        "User runs 'fspec init', selects custom location, enters '../parent/fspec.md', validation fails with error about path being outside current directory",
        "User runs 'fspec init' when .claude/commands/fspec.md exists, declines overwrite, command exits with 'Installation cancelled'",
        "User runs 'fspec init', selects Claude Code, command succeeds, displays '✓ Installed /fspec command to .claude/commands/fspec.md' and 'Run /fspec in Claude Code to activate'"
      ],
      "questions": [],
      "estimate": 5
    },
    "TEST-003": {
      "id": "TEST-003",
      "title": "Test answer-question with multiple questions",
      "status": "done",
      "createdAt": "2025-10-12T05:57:24.220Z",
      "updatedAt": "2025-10-12T06:57:49.173Z",
      "description": "Testing that answering multiple questions works correctly with proper index handling",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T05:57:25.745Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:57:48.309Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:57:48.599Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:57:48.887Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:57:49.173Z"
        }
      ],
      "questions": [],
      "rules": [
        "Use option A for consistency",
        "Edge case X should return error code 400",
        "Not in phase 1, defer to backlog"
      ]
    },
    "SAFE-002": {
      "id": "SAFE-002",
      "title": "Fix race condition in answer-question when run concurrently",
      "status": "done",
      "createdAt": "2025-10-12T06:01:08.064Z",
      "updatedAt": "2025-10-12T06:33:27.231Z",
      "description": "Add file locking or transaction mechanism to prevent race conditions when multiple answer-question commands run in parallel. Currently parallel executions can overwrite each other's changes causing data loss.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T06:01:09.809Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T06:07:32.863Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T06:09:49.140Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T06:32:14.013Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T06:33:27.232Z"
        }
      ],
      "rules": [
        "Multiple concurrent writes to work-units.json must not corrupt data",
        "When multiple answer-question commands run in parallel, all answers must be saved",
        "Last write must not overwrite changes from earlier writes",
        "Solution must work across platforms (macOS, Linux, Windows)",
        "Question indices must remain stable even after questions are answered",
        "YES - Use stable indices with 'selected' flag. Change questions from string array to object array: [{text: 'question', selected: false}, ...]. When answered, mark as selected:true and add answer field. This eliminates race condition without needing file locks.",
        "Questions use 'selected' property to indicate if answered, not 'answered' property"
      ],
      "examples": [
        "User runs 3 answer-question commands in parallel, all 3 questions are answered and all 3 rules are added",
        "User runs answer-question while another command modifies work-units.json, both changes are preserved",
        "User adds 3 questions (indices 0,1,2), answers question 1, indices remain 0,1,2 but question 1 is marked as answered",
        "Question object structure: {text: '@human: Should we...?', selected: false} becomes {text: '@human: Should we...?', selected: true, answer: 'Yes because...'} when answered"
      ],
      "questions": [],
      "assumptions": [
        "Not needed - stable indices approach eliminates race condition without file locking",
        "Not needed - stable indices approach can be used for all commands, but answer-question is the priority",
        "Not applicable - no lock acquisition with stable indices approach"
      ],
      "estimate": 3
    },
    "CLI-004": {
      "id": "CLI-004",
      "title": "Wire up init command to CLI program",
      "status": "done",
      "createdAt": "2025-10-12T07:09:52.763Z",
      "updatedAt": "2025-10-12T07:21:43.421Z",
      "children": [],
      "description": "The init command implementation exists in src/commands/init.ts but is NOT registered in src/index.ts. This means users cannot run 'fspec init'. Need to: 1) Register command in CLI, 2) Add to help system, 3) Update feature files with complete acceptance criteria, 4) Ensure tests cover end-to-end CLI invocation (not just unit tests), 5) Validate command actually works via CLI before marking done.",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:10:05.831Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:12:12.711Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:20:18.251Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T07:20:25.581Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T07:21:20.272Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T07:21:43.421Z"
        }
      ],
      "rules": [
        "Command must be registered in src/index.ts with .command('init')",
        "Command must support interactive prompts using ink/react (option --type and --path flags)",
        "Command must appear in 'fspec --help' output and 'fspec help setup' section",
        "E2E tests must verify 'fspec init' actually works via CLI, not just unit tests of the function"
      ],
      "examples": [
        "Running 'fspec init' prompts for installation type (Claude Code or Custom)",
        "Running 'fspec init --type=claude-code' installs to .claude/commands/fspec.md",
        "Running 'fspec --help' shows init command in output"
      ]
    },
    "BUG-001": {
      "id": "BUG-001",
      "title": "Scenario-level tagging rejects work unit tags",
      "status": "done",
      "createdAt": "2025-10-12T07:13:53.468Z",
      "updatedAt": "2025-10-12T07:17:29.244Z",
      "description": "add-tag-to-scenario command rejects work unit tags like @CLI-004 even though add-tag-to-feature accepts them. The scenario tagging uses /^@[a-z0-9-#]+$/ regex while feature tagging uses isWorkUnitTag() helper. Need to make scenario tagging use the same work unit tag validation as feature tagging.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:13:56.954Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:14:51.941Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T07:15:26.562Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T07:15:58.002Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T07:17:29.245Z"
        }
      ],
      "rules": [
        "add-tag-to-scenario MUST use isWorkUnitTag() helper for validation, same as add-tag-to-feature",
        "Work unit tags (@PREFIX-NNN format) MUST be accepted at both feature and scenario level"
      ],
      "examples": [
        "Running 'fspec add-tag-to-scenario file.feature \"Scenario\" @CLI-004' should succeed",
        "Work unit tags like @AUTH-001, @BUG-001, @CLI-004 should be accepted"
      ]
    },
    "BUG-002": {
      "id": "BUG-002",
      "title": "generate-scenarios displays 'undefined' instead of count",
      "status": "done",
      "createdAt": "2025-10-12T07:14:42.738Z",
      "updatedAt": "2025-10-12T07:19:58.352Z",
      "description": "When running 'fspec generate-scenarios <work-unit-id>', the success message shows 'Generated undefined scenarios' instead of showing the actual count of scenarios generated. The command should display 'Generated N scenarios' where N is the number of scenarios created.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:18:37.948Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T07:18:52.782Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T07:19:19.951Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T07:19:35.465Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T07:19:58.353Z"
        }
      ],
      "rules": [
        "generate-scenarios command MUST return the count of scenarios generated",
        "Success message MUST display 'Generated N scenarios' where N is the actual count"
      ],
      "examples": [
        "Running 'fspec generate-scenarios WORK-001' should display 'Generated 3 scenarios' not 'Generated undefined scenarios'"
      ]
    },
    "INIT-003": {
      "id": "INIT-003",
      "title": "Copy CLAUDE.md template to new spec directory",
      "status": "done",
      "createdAt": "2025-10-12T07:58:21.443Z",
      "updatedAt": "2025-10-12T08:20:05.866Z",
      "description": "When fspec init creates a new spec/ directory, it should copy the spec/CLAUDE.md file (bundled with the package) to the target project. This ensures new projects have the complete specification guidelines and workflow documentation from the start. The file is bundled from spec/CLAUDE.md to dist/spec/CLAUDE.md during build - no separate templates/ directory needed.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T07:58:34.774Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T08:05:45.263Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T08:06:40.200Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T08:09:35.216Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T08:10:49.918Z"
        }
      ],
      "rules": [
        "CLAUDE.md template must be bundled with fspec package in a templates/ directory",
        "CLAUDE.md file must be identical across all projects (no customization)",
        "If spec/CLAUDE.md already exists, overwrite it with the latest template",
        "fspec init command must set up complete spec directory structure with CLAUDE.md and /fspec slash command",
        "Always overwrite - no version checking needed",
        "Show confirmation message in /fspec slash command output (fspec.md), no separate message from fspec init CLI",
        "Enhance existing 'fspec init' command to copy CLAUDE.md template"
      ],
      "examples": [
        "User runs 'fspec init' in empty directory, creates spec/ directory with CLAUDE.md and .claude/commands/fspec.md",
        "User runs 'fspec init' in directory with existing spec/CLAUDE.md, overwrites with latest template",
        "CLAUDE.md template is copied from fspec package's templates/CLAUDE.md to project's spec/CLAUDE.md",
        "fspec init copies templates/CLAUDE.md to spec/CLAUDE.md preserving all content exactly",
        "/fspec slash command shows 'Copied spec/CLAUDE.md specification guidelines' in output",
        "Running 'fspec init' twice overwrites spec/CLAUDE.md with latest template (no prompt, no backup)"
      ],
      "questions": [
        {
          "text": "@human: Should 'fspec init' also check if the CLAUDE.md template in the package is newer than the one in the project and offer to update it?",
          "selected": true,
          "answer": "Always overwrite - no version checking needed"
        },
        {
          "text": "@human: What should happen if the templates/ directory is missing from the fspec package installation?",
          "selected": true,
          "answer": "Templates directory is bundled with package build - if missing, it's a build error (should never happen in production)"
        },
        {
          "text": "@human: Should there be any output message confirming CLAUDE.md was copied/updated?",
          "selected": true,
          "answer": "Show confirmation message in /fspec slash command output (fspec.md), no separate message from fspec init CLI"
        },
        {
          "text": "@human: Looking at existing INIT-002 work unit, should this enhance the existing init command or be separate?",
          "selected": true,
          "answer": "Enhance existing 'fspec init' command to copy CLAUDE.md template"
        }
      ],
      "assumptions": [
        "Templates directory is bundled with package build - if missing, it's a build error (should never happen in production)"
      ],
      "estimate": 2
    },
    "DOC-002": {
      "id": "DOC-002",
      "title": "Provide schema information for foundation.json",
      "status": "done",
      "createdAt": "2025-10-12T11:46:03.860Z",
      "updatedAt": "2025-10-12T23:11:14.375Z",
      "description": "Add schema information to foundation.json to help AI agents draft foundation documents more easily. May require relaxing some schema constraints to make it more flexible for agents.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T11:46:21.581Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-12T22:56:07.240Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-12T22:59:39.116Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-12T23:11:14.091Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-12T23:11:14.376Z"
        }
      ],
      "rules": [
        "Schema must guide AI agents to write documentation in a specific format that preserves project meaning and prevents drift",
        "Schema must be provided as a separate JSON Schema file (foundation.schema.json)",
        "Schema file must be accessible via CLI command so AI agents can read it",
        "Field names should be flexible (e.g., accept both camelCase and snake_case) while maintaining similar overall structure",
        "Schema must include rich descriptions explaining the intent behind each section",
        "Schema must include examples of good vs. bad content for each field",
        "Schema must include validation rules (e.g., minimum array lengths, required fields)",
        "Schema must include format instructions for structured fields",
        "Must provide both 'fspec show-foundation-schema' to display schema and 'fspec validate-foundation-schema' to validate foundation.json",
        "No backward compatibility required - existing foundation.json files may need migration to new format",
        "Mermaid syntax validation should be handled by Mermaid library (mermaid.parse()), not by JSON Schema. Schema only validates that mermaidCode field exists and is a string.",
        "Schema should allow AI agents to add custom sections beyond the standard ones (project, whatWeAreBuilding, whyWeAreBuildingIt). Use additionalProperties: true for extensibility.",
        "Validation should check semantic content of descriptions. Schema descriptions should guide AI on what to write and what NOT to write (e.g., 'projectOverview should focus on WHAT/HOW, not WHY - business justification belongs in whyWeAreBuildingIt').",
        "Schema should allow additional properties (additionalProperties: true) for future extensibility. AI agents can add custom sections as needed."
      ],
      "examples": [
        "Schema for 'projectOverview' includes description: 'A comprehensive technical overview (2-4 sentences) describing: (1) what systems are being built, (2) who uses them (target users), (3) how the systems integrate. Focus on WHAT and HOW, not WHY. Example: A Kanban-based project management and specification tool for AI agents...'",
        "Schema for 'problemDefinition.primary' includes validation: must contain 'title', 'description', and 'coreProblems' array with minimum 3 items describing distinct problem categories",
        "Schema accepts both camelCase and snake_case for ALL field names. Examples: 'architectureDiagrams' OR 'architecture_diagrams', 'technicalRequirements' OR 'technical_requirements', 'projectOverview' OR 'project_overview'",
        "AI agent runs 'fspec show-foundation-schema' and receives JSON Schema with rich descriptions and examples. Agent uses this to understand how to structure foundation.json sections when running 'fspec update-foundation'",
        "AI agent runs 'fspec validate-foundation-schema' after updating foundation.json. Validation fails with message: 'Field problemDefinition.primary.coreProblems must have at least 3 items (found 2)'. Agent adds another problem and re-validates."
      ],
      "questions": [
        {
          "text": "@human: Should the schema validate Mermaid syntax in architectureDiagrams array, or just validate that mermaidCode field is a string?",
          "selected": true,
          "answer": "Mermaid syntax validation should be handled by Mermaid library (mermaid.parse()), not by JSON Schema. Schema only validates that mermaidCode field exists and is a string."
        },
        {
          "text": "@human: Should the schema enforce specific top-level section names (project, whatWeAreBuilding, whyWeAreBuildingIt) or allow AI agents to add custom sections?",
          "selected": true,
          "answer": "Schema should allow AI agents to add custom sections beyond the standard ones (project, whatWeAreBuilding, whyWeAreBuildingIt). Use additionalProperties: true for extensibility."
        },
        {
          "text": "@human: How detailed should validation be? Should it validate the semantic content of descriptions (e.g., 'projectOverview should not mention business justification') or just structural rules (required fields, types, array lengths)?",
          "selected": true,
          "answer": "Validation should check semantic content of descriptions. Schema descriptions should guide AI on what to write and what NOT to write (e.g., 'projectOverview should focus on WHAT/HOW, not WHY - business justification belongs in whyWeAreBuildingIt')."
        },
        {
          "text": "@human: Should we provide a migration command (e.g., 'fspec migrate-foundation') to convert existing foundation.json to the new flexible format, or should users manually update?",
          "selected": true,
          "answer": "No migration command needed. No backward compatibility - users must manually update foundation.json to new format when schema is introduced."
        },
        {
          "text": "@human: Should the schema allow additional properties beyond the defined ones (additionalProperties: true) to support future extensibility, or be strict (additionalProperties: false)?",
          "selected": true,
          "answer": "Schema should allow additional properties (additionalProperties: true) for future extensibility. AI agents can add custom sections as needed."
        }
      ],
      "assumptions": [
        "No migration command needed. No backward compatibility - users must manually update foundation.json to new format when schema is introduced."
      ],
      "estimate": 5
    },
    "RSPEC-001": {
      "id": "RSPEC-001",
      "title": "Add rspec command for reverse ACDD",
      "status": "done",
      "createdAt": "2025-10-12T11:46:05.565Z",
      "updatedAt": "2025-10-13T00:20:55.500Z",
      "description": "Create new 'rspec' command that performs reverse ACDD by decomposing/reverse engineering existing applications. The command discovers user stories, personas, and acceptance criteria from existing code. Extends the /fspec slash command to tell Claude to read fspec.md and continue with reverse engineering workflow.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-12T23:11:24.854Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T00:20:36.464Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T00:20:42.594Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T00:20:49.164Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T00:20:55.501Z"
        }
      ],
      "rules": [
        "Must identify user personas who interact with the system",
        "Must identify high-level activities or goals users achieve with the software",
        "Must break down high-level activities into smaller specific tasks or interactions that code supports",
        "Analysis involves: (1) analyzing functionality and mapping to user goals, (2) examining UI elements/features/workflows, (3) grouping related features into epics/journeys, (4) decomposing into individual user stories",
        "Must produce user story map organized visually along user journey (broad activities at top, detailed interactions underneath)",
        "User stories must be expressed as user-centric narratives (As a [persona], I want [goal], So that [benefit])",
        "fspec init must install rspec.md slash command (similar to how it installs fspec.md)",
        "rspec.md first line (after title) must say 'fully read fspec.md' with markdown link to exact fspec.md location",
        "Must create everything fspec can do: work units, epics, prefixes, example maps, features, foundation.json (particularly this, keep updating as it learns), diagrams, unit/integration tests (NOT implemented), test-to-feature links (header comments)",
        "Must create user story map in feature file docstrings or foundation.json (wherever closest to where it needs to be)",
        "Must ONLY create artifacts that use fspec or are tests - nothing else",
        "When encountering incomplete/ambiguous code: reverse engineer as much as possible, then ask human to complete via Example Mapping session",
        "foundation.json must be continuously updated as system learns more about the codebase",
        "Unit tests and integration tests created must NOT be implemented (skeleton only) - AI/human implements them later following ACDD",
        "/rspec is a Claude Code slash command (not CLI command) - user invokes it via /rspec in Claude Code",
        "User story map should be one or more Mermaid diagrams (preferably) plus any supporting artifacts that help visualize the map"
      ],
      "examples": [
        "Skeleton test file header includes: /** Feature: spec/features/[name].feature\\n * This test validates acceptance criteria. Tests map to Gherkin scenarios.\\n */",
        "User runs /rspec in Claude Code → AI reads .claude/commands/rspec.md → First line says 'fully read fspec.md' (with link) → AI follows fspec workflow while reverse engineering",
        "User story map created as Mermaid diagram in foundation.json architectureDiagrams array with section='User Story Map'",
        "Reverse engineered Express.js app: creates epic 'api-management', prefix 'API', work units API-001 'User authentication', API-002 'Data validation', feature files with inferred scenarios, skeleton tests with describe/it blocks (no implementation)"
      ]
    },
    "BUG-003": {
      "id": "BUG-003",
      "title": "Summary report shows 'undefined' instead of file path",
      "status": "done",
      "createdAt": "2025-10-13T05:18:30.471Z",
      "updatedAt": "2025-10-13T07:23:52.363Z",
      "description": "When running 'fspec generate-summary-report --format=markdown', the output shows 'Report generated: undefined' instead of the actual file path where the report was saved.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T05:18:44.355Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T05:22:07.396Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T05:22:44.125Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T05:24:48.456Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T05:25:46.597Z"
        }
      ],
      "rules": [
        "Command output must show the actual file path where the report was generated",
        "When --output option is provided, show that specific path",
        "When --output option is NOT provided, show the default generated path",
        "Function must return outputFile property containing the path where report was written",
        "Function must accept format (markdown, json, html) and output (file path) options",
        "Function must write report to file system in the specified format",
        "Default output path should be spec/summary-report.{format}"
      ],
      "examples": [
        "User runs 'fspec generate-summary-report --format=markdown', sees 'Report generated: spec/summary-report.md'",
        "User runs 'fspec generate-summary-report --format=markdown --output=custom.md', sees 'Report generated: custom.md'",
        "Currently shows 'Report generated: undefined' instead of actual path",
        "Function currently returns SummaryReport object without outputFile property",
        "CLI calls result.outputFile which is undefined",
        "Function signature currently missing format and output parameters"
      ],
      "estimate": 2
    },
    "CLI-005": {
      "id": "CLI-005",
      "title": "Add --help support to all fspec commands",
      "status": "done",
      "createdAt": "2025-10-13T05:32:26.029Z",
      "updatedAt": "2025-10-13T05:56:38.745Z",
      "description": "Currently commands like 'fspec create-epic --help' fail with 'unknown option --help'. Every fspec command should support --help flag that displays detailed usage information, options, arguments, and practical examples for that specific command. This includes all ~80+ commands across specs, work, discovery, metrics, and setup groups.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T05:32:33.248Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T05:44:40.837Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T05:46:16.843Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T05:55:36.370Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T05:56:38.746Z"
        }
      ],
      "rules": [
        "Help output must include: command description, all options with descriptions, required vs optional arguments, practical examples, and related commands",
        "Help formatting must use custom colored output matching 'fspec help specs' style, optimized for AI agent readability",
        "Number of examples should be contextually appropriate per command complexity",
        "Individual command help (--help) must be separate from group help (fspec help specs/work/etc)",
        "Main fspec --help output must mention that each command supports its own --help flag",
        "Must use custom help system, not Commander.js built-in help (insufficient quality)",
        "Help must include AI-optimized sections when applicable: WHEN TO USE, WHEN NOT TO USE, COMMON PATTERNS, TYPICAL WORKFLOW, PREREQUISITES, related workflow states",
        "Examples must show both command and expected output for clarity",
        "Help templates must vary by command complexity: Simple (1-2 examples), Medium (2-3 examples), Complex (4-5 examples showing different modes)",
        "Help must include COMMON ERRORS section with error messages and fixes",
        "Related commands section must only show highly related commands with whatever format makes sense (syntax/names/workflow context)",
        "No validation or schema enforcement needed - help text should be inline in command code",
        "Whatever is most elegant while retaining exact same functionality - ultrathink this",
        "Create help infrastructure first, then implement each command help individually",
        "Yes, refactor into shared help utilities module for consistency",
        "Infrastructure first: build help system, then implement per command",
        "Infrastructure first: build help system, then implement per command"
      ],
      "examples": [
        "User runs 'fspec create-epic --help' and sees: description, usage syntax, options (none), arguments (<name> <title>), 2 examples with output, related commands (list-epics, show-epic, create-work-unit)",
        "User runs 'fspec list-work-units --help' and sees: WHEN TO USE section, all options (--status, --prefix, --epic), 3 examples showing different filters with sample output, TYPICAL WORKFLOW mentioning backlog → specifying flow",
        "User runs 'fspec add-dependency --help' and sees: description explaining dependency types, 5 examples showing shorthand vs --blocks vs --blocked-by vs --depends-on vs --relates-to, COMMON ERRORS section for 'work unit not found', related commands (remove-dependency, dependencies, export-dependencies)",
        "User runs 'fspec update-work-unit-status --help' and sees: PREREQUISITES (work unit must exist), WHEN TO USE (moving through ACDD workflow), valid status values listed, TYPICAL WORKFLOW showing backlog→specifying→testing→implementing→validating→done, example with output showing status change",
        "User runs 'fspec --help' and sees updated main help with note: 'Get detailed help for any command with: fspec <command> --help'",
        "User runs 'fspec add-question --help' and sees: WHEN TO USE (during Example Mapping in specifying phase), COMMON PATTERNS (use @human: prefix for questions directed at human), example showing question with answer flow, related commands (answer-question, add-rule, add-example, generate-scenarios)"
      ],
      "questions": [
        {
          "text": "@human: How should we handle the --help flag given the custom help system that overrides Commander?",
          "selected": true,
          "answer": "Whatever works best - could be smoke tests, integration tests, or manual testing"
        },
        {
          "text": "@human: Should we refactor existing help command formatting utilities into shared module?",
          "selected": true,
          "answer": "Integration tests that verify help output contains required sections and examples"
        },
        {
          "text": "@human: Should we implement help for all 80+ commands at once or incrementally?",
          "selected": true,
          "answer": "Infrastructure first: build help system, then implement per command"
        },
        {
          "text": "@human: What testing strategy should we use for help output?",
          "selected": true,
          "answer": "Integration tests that verify help output contains required sections and examples"
        }
      ],
      "assumptions": [
        "Whatever works best given current setup and custom help system that overrides Commander's, and existing fspec --help",
        "Whatever works best - could be smoke tests, integration tests, or manual testing",
        "Integration tests that verify help output contains required sections and examples",
        "Integration tests that verify help output contains required sections and examples"
      ]
    },
    "CLI-006": {
      "id": "CLI-006",
      "title": "Implement scalable help system for all commands",
      "status": "done",
      "createdAt": "2025-10-13T06:06:34.397Z",
      "updatedAt": "2025-10-13T06:26:59.486Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T06:06:40.458Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T06:12:23.135Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T06:13:25.161Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T06:25:58.574Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T06:26:59.487Z"
        }
      ],
      "rules": [
        "Help system must automatically discover and register help configs without manual registration in index.ts",
        "Each command should have its help config in a dedicated file (command-name-help.ts) co-located with command implementation",
        "Commander.js should automatically handle --help flag for all commands without explicit handlers in action callbacks",
        "Help configs should use a naming convention that maps to command names (e.g., remove-tag-from-scenario -> remove-tag-from-scenario-help.ts)",
        "Missing help config files should fall back to Commander.js default help (current behavior) rather than error"
      ],
      "examples": [
        "When user runs 'fspec remove-tag-from-scenario --help' and help config exists at src/commands/remove-tag-from-scenario-help.ts, display detailed help from config",
        "When user runs 'fspec some-command --help' and no help config file exists, fall back to Commander.js default help"
      ],
      "questions": [
        {
          "text": "@human: Should we use Commander.js custom help configuration or a global --help interceptor to avoid modifying 91 command registrations?",
          "selected": true,
          "answer": "Use process-level help interceptor with registry Set. Intercept --help before Commander.js, use dynamic imports, graceful fallback for missing configs, zero modifications to 91 command registrations."
        }
      ]
    },
    "BUG-004": {
      "id": "BUG-004",
      "title": "Fix generate-scenarios to use capability-based feature file names",
      "status": "done",
      "createdAt": "2025-10-13T07:23:50.426Z",
      "updatedAt": "2025-10-13T07:31:08.560Z",
      "description": "The generate-scenarios command currently defaults to using work unit ID as feature file name (e.g., auth-001.feature) which violates the naming principle. Should require --feature flag or use work unit title as default.",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T07:24:10.294Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T07:26:43.645Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T07:27:36.963Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T07:30:19.171Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T07:31:08.561Z"
        }
      ],
      "rules": [
        "Feature files must be named after capabilities, NOT work unit IDs",
        "Work unit title should be used as default suggestion when --feature not provided",
        "Command should fail with helpful error if --feature not provided and AI needs to choose name",
        "Auto-default to work unit title (kebab-cased). User can override with --feature flag if they want a different name.",
        "Throw error requiring --feature flag with helpful message suggesting capability-based name."
      ],
      "examples": [
        "User runs 'fspec generate-scenarios AUTH-001', command suggests using work unit title as feature name",
        "User runs 'fspec generate-scenarios AUTH-001 --feature=user-authentication', creates spec/features/user-authentication.feature",
        "Work unit AUTH-001 has title 'User Login', defaults to spec/features/user-login.feature when --feature not provided"
      ],
      "questions": [
        {
          "text": "@human: Should we make --feature flag required, or auto-default to work unit title?",
          "selected": true,
          "answer": "Auto-default to work unit title (kebab-cased). User can override with --feature flag if they want a different name."
        },
        {
          "text": "@human: What should happen if work unit title is empty or not set?",
          "selected": true,
          "answer": "Throw error requiring --feature flag with helpful message suggesting capability-based name."
        }
      ]
    },
    "REMIND-002": {
      "id": "REMIND-002",
      "title": "Comprehensive System-Reminder Overhaul",
      "status": "done",
      "createdAt": "2025-10-13T07:56:29.390Z",
      "updatedAt": "2025-10-13T08:19:36.823Z",
      "description": "Audit existing system-reminders, expand to all critical commands based on analysis, add file naming detection, tag validation, and discovery phase reminders",
      "children": [
        "REMIND-003",
        "REMIND-004",
        "REMIND-005",
        "REMIND-006",
        "REMIND-007"
      ],
      "estimate": 13,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:18:35.217Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:19:35.726Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:19:36.092Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:19:36.462Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:19:36.824Z"
        }
      ],
      "rules": [
        "All child work units (REMIND-003, 004, 005, 006, 007) must be in done status",
        "System-reminder functions implemented in src/utils/system-reminder.ts",
        "System-reminders integrated into create-feature, add-tag-to-feature, generate-scenarios, show-work-unit, and update-work-unit-status commands"
      ],
      "examples": [
        "All 5 child work units completed successfully with tests passing",
        "Build passing with 843 tests, all system-reminder functionality working"
      ]
    },
    "REMIND-003": {
      "id": "REMIND-003",
      "title": "File Naming Anti-Pattern Detection",
      "status": "done",
      "createdAt": "2025-10-13T07:56:47.607Z",
      "updatedAt": "2025-10-13T08:02:40.554Z",
      "description": "Add system-reminders to create-feature command to detect task-based naming (implement-, add-, create-, work-unit-ID) and remind to use capability-based naming",
      "parent": "REMIND-002",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T07:57:27.395Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T07:58:22.240Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T07:58:32.755Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:01:48.189Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:02:40.555Z"
        }
      ],
      "rules": [
        "System-reminders must detect task-based file naming patterns (implement-, add-, create-, fix-, build-)",
        "System-reminders must detect work unit ID patterns in file names (e.g., AUTH-001, REMIND-003)",
        "Reminders must provide correct examples of capability-based naming"
      ],
      "examples": [
        "User runs 'fspec create-feature implement-authentication', reminder shows '❌ WRONG: implement-authentication → ✅ CORRECT: user-authentication'",
        "User runs 'fspec create-feature AUTH-001', reminder shows work unit IDs are not capability names",
        "User runs 'fspec create-feature user-authentication', no reminder (correct naming)"
      ]
    },
    "REMIND-004": {
      "id": "REMIND-004",
      "title": "Tag Validation Reminders",
      "status": "done",
      "createdAt": "2025-10-13T07:56:49.298Z",
      "updatedAt": "2025-10-13T13:01:25.736Z",
      "description": "Add reminders to add-tag-to-feature for unregistered tags and missing required tags",
      "parent": "REMIND-002",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:06:04.788Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:06:29.915Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:06:31.632Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:07:43.185Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:07:44.888Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:46.258Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:50.474Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:07.724Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:25.737Z"
        }
      ],
      "rules": [
        "System-reminders must check if tag exists in tags.json before adding to feature file",
        "System-reminders must check for missing required tags after adding a tag",
        "Required tags are: phase tag, component tag, and feature-group tag"
      ],
      "examples": [
        "User runs 'fspec add-tag-to-feature login.feature @unregistered-tag', reminder shows 'Tag not registered in tags.json'",
        "User runs 'fspec add-tag-to-feature login.feature @phase1', no unregistered tag reminder but may show missing required tags reminder",
        "User adds all required tags, no reminder shown"
      ]
    },
    "REMIND-005": {
      "id": "REMIND-005",
      "title": "Discovery Phase Reminders",
      "status": "done",
      "createdAt": "2025-10-13T07:56:51.073Z",
      "updatedAt": "2025-10-13T13:01:28.324Z",
      "description": "Add reminders to generate-scenarios for unanswered questions, empty Example Mapping, and post-generation validation",
      "parent": "REMIND-002",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:08:01.105Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:08:14.931Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:08:15.225Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:09:45.064Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:09:45.355Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:55.259Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:52.611Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:10.713Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:28.325Z"
        }
      ],
      "rules": [
        "System-reminders must check for unanswered questions before allowing scenario generation",
        "System-reminders must check for empty Example Mapping (no rules AND no examples)",
        "System-reminders must provide post-generation guidance after successful scenario generation"
      ],
      "examples": [
        "User runs 'fspec generate-scenarios WORK-001' with unanswered questions, reminder blocks generation",
        "User runs 'fspec generate-scenarios WORK-001' with no rules or examples, reminder suggests adding Example Mapping data",
        "After successful generation, reminder shows next steps (validate, add tags, move to testing)"
      ]
    },
    "REMIND-006": {
      "id": "REMIND-006",
      "title": "Show Work Unit Reminders",
      "status": "done",
      "createdAt": "2025-10-13T07:56:52.746Z",
      "updatedAt": "2025-10-13T13:01:30.534Z",
      "description": "Add reminders to show-work-unit for missing estimates, empty Example Mapping in specifying phase, and long duration warnings",
      "parent": "REMIND-002",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:10:17.524Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:16:22.073Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:16:28.519Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:16:34.669Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:17:10.348Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:55.554Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:54.822Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:12.669Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:30.535Z"
        }
      ],
      "rules": [
        "Display system-reminder when work unit is missing estimate",
        "Display system-reminder when work unit in specifying status has empty Example Mapping (no rules AND no examples)",
        "Display system-reminder when work unit has been in current state for more than 24 hours"
      ],
      "examples": [
        "Show work unit without estimate displays missing estimate reminder",
        "Show work unit in specifying with no rules/examples displays Example Mapping reminder",
        "Show work unit that has been in specifying for 25 hours displays long duration reminder"
      ]
    },
    "REMIND-007": {
      "id": "REMIND-007",
      "title": "Update Status Reminder Enhancement",
      "status": "done",
      "createdAt": "2025-10-13T07:56:54.417Z",
      "updatedAt": "2025-10-13T13:01:32.609Z",
      "description": "Enhanced status reminders with blocked and done states - completed as part of REMIND-003",
      "parent": "REMIND-002",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:10:15.372Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:18:08.040Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:18:08.403Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:18:08.765Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:18:13.970Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:54:55.851Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T13:00:56.856Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T13:01:15.325Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T13:01:32.610Z"
        }
      ],
      "rules": [
        "Enhance getStatusChangeReminder to include 'done' state reminder about feature file tag updates",
        "Enhance getStatusChangeReminder to include 'blocked' state reminder about documenting blocker reasons"
      ],
      "examples": [
        "Update status to 'done' displays reminder to update feature file tags",
        "Update status to 'blocked' displays reminder to document blocker reason"
      ]
    },
    "REMIND-008": {
      "id": "REMIND-008",
      "title": "Feature File Prefill Detection and CLI Enforcement",
      "status": "done",
      "createdAt": "2025-10-13T08:31:34.385Z",
      "updatedAt": "2025-10-13T08:52:57.425Z",
      "description": "Detect when feature files contain placeholder/prefill text and emit system-reminders instructing LLMs to use CLI commands. Block workflow state transitions if prefill remains.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T08:31:52.511Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T08:47:32.759Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T08:52:11.546Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T08:52:44.911Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T08:52:57.426Z"
        }
      ],
      "rules": [
        "Example Mapping must capture the complete user story (role, action, benefit) as the yellow card",
        "fspec generate-scenarios should generate complete user story from example map data, not placeholders",
        "Prefill detection should identify ALL placeholder patterns: [role], [action], TODO:, @phase1, @component, etc.",
        "System-reminders must suggest specific CLI commands to fix detected prefill",
        "Workflow state transitions must be blocked if linked feature files contain prefill placeholders",
        "generate-scenarios should only run AFTER user story is complete (no [role], [action], [benefit] placeholders in Background)",
        "Yes, add explicit userStory fields (role, action, benefit) to work-units.json schema and update JSON Schema validation",
        "Write-time only, when all information has been collected. Detect prefill during fspec create-feature and fspec generate-scenarios, emit system-reminders with CLI commands to fix.",
        "Yes, BOTH write-time and read-time. Write-time for immediate feedback when creating/generating. Read-time for ongoing reminders when showing features, validating, or advancing work unit status.",
        "Until fixed - keep showing system-reminders every time a command interacts with a feature file that has prefill, until the prefill is completely removed.",
        "Hard error (exit 1) - Command must fail completely when trying to advance work unit status if linked feature file contains prefill. Forces LLM to fix prefill before proceeding.",
        "Hybrid approach - Try to intelligently extract Given/When/Then from example text (e.g., 'User logs in with valid credentials' → Given/When/Then steps). Fall back to prefill with system-reminders if parsing fails.",
        "Work units need CLI commands to set user story fields: fspec set-user-story <work-unit-id> --role='...' --action='...' --benefit='...'"
      ],
      "examples": [
        "LLM runs 'fspec create-feature Auth' and gets file with [role], [action], [benefit] placeholders. System-reminder tells LLM to use 'fspec add-background' instead of Edit tool",
        "LLM runs 'fspec generate-scenarios AUTH-001' and gets scenarios with [precondition], [action], [expected outcome]. System-reminder tells LLM to use 'fspec add-step' instead of Write tool",
        "Work unit AUTH-001 has user story in Example Mapping: role='developer', action='authenticate users', benefit='secure access'. generate-scenarios uses this data to create complete Background section without placeholders",
        "LLM tries 'fspec update-work-unit-status AUTH-001 testing' but linked feature file has [role] placeholder. Command fails with error: 'Cannot advance: feature file contains prefill. Use fspec add-background to complete user story.'",
        "LLM completes Example Mapping with user story fields. Runs 'fspec generate-scenarios AUTH-001'. Scenarios are generated BUT steps still have [precondition], [action], [outcome]. System-reminder tells LLM to use 'fspec add-step' for each scenario."
      ],
      "questions": [
        {
          "text": "@human: Should Example Mapping capture user story fields (role, action, benefit) as explicit fields in work-units.json?",
          "selected": true,
          "answer": "Yes, add explicit userStory fields (role, action, benefit) to work-units.json schema and update JSON Schema validation"
        },
        {
          "text": "@human: Should prefill detection happen at read-time (when showing feature) or write-time (when creating feature)?",
          "selected": true,
          "answer": "Write-time only, when all information has been collected. Detect prefill during fspec create-feature and fspec generate-scenarios, emit system-reminders with CLI commands to fix."
        },
        {
          "text": "@human: Should system-reminders for prefill appear every time or only once per session/work unit?",
          "selected": true,
          "answer": "Until fixed - keep showing system-reminders every time a command interacts with a feature file that has prefill, until the prefill is completely removed."
        },
        {
          "text": "@human: Should workflow blocking be a hard error (exits 1) or a warning (exits 0 with reminder)?",
          "selected": true,
          "answer": "Hard error (exit 1) - Command must fail completely when trying to advance work unit status if linked feature file contains prefill. Forces LLM to fix prefill before proceeding."
        },
        {
          "text": "@human: Should generate-scenarios create scenarios with prefill steps OR should it extract Given/When/Then from the example text itself?",
          "selected": true,
          "answer": "Hybrid approach - Try to intelligently extract Given/When/Then from example text (e.g., 'User logs in with valid credentials' → Given/When/Then steps). Fall back to prefill with system-reminders if parsing fails."
        },
        {
          "text": "@human: Going back to question 1 - actually BOTH read-time and write-time?",
          "selected": true,
          "answer": "Yes, BOTH write-time and read-time. Write-time for immediate feedback when creating/generating. Read-time for ongoing reminders when showing features, validating, or advancing work unit status."
        }
      ],
      "estimate": 5,
      "userStory": {
        "role": "AI agent (LLM) using fspec",
        "action": "detect and fix feature file prefill using CLI commands",
        "benefit": "proper workflow enforcement and no direct file editing"
      }
    },
    "COV-001": {
      "id": "COV-001",
      "title": "Feature-to-Code Coverage Tracking",
      "status": "done",
      "createdAt": "2025-10-13T09:49:22.476Z",
      "updatedAt": "2025-10-13T12:30:18.223Z",
      "description": "Create .coverage files that map Gherkin scenarios to test files and implementation code lines, with statistics and AI-assisted verification",
      "epic": "coverage-tracking",
      "children": [
        "COV-002",
        "COV-003",
        "COV-004",
        "COV-005",
        "COV-006"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T09:49:22.866Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:24:55.611Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:25:17.670Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:30:17.638Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:30:17.932Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:30:18.224Z"
        }
      ],
      "userStory": {
        "role": "developer using ACDD",
        "action": "track which test files and implementation code lines map to each Gherkin scenario",
        "benefit": "I can see exactly what code is covered by acceptance criteria and identify gaps"
      },
      "rules": [
        "Every .feature file must have a corresponding .feature.coverage file",
        "Coverage files must be in JSON format with scenario-to-test-to-code mappings",
        "Coverage files must include calculated statistics (total scenarios, covered scenarios, coverage percentage)",
        "Automatically create .feature.coverage files when feature files are created via create-feature command",
        "AI discovers test-to-scenario mappings using reverse ACDD (rspec.md) for existing code, or tracks mappings during forward ACDD. fspec provides CLI commands for AI to record these mappings",
        "fspec prompts AI agent via interactive 'link-coverage' command (or similar name) to specify which implementation files and lines are covered by tests",
        "Use 'audit-coverage' command that works with AI agent in a loop, prompting it to verify each file's mappings one by one. AI looks up current line numbers and updates coverage file",
        "All statistics: coverage percentage, uncovered scenarios, number of test cases per scenario, implementation files touched, lines covered per file",
        "Separate commands since coverage tracking is interactive and requires AI agent collaboration (link-coverage, audit-coverage, show-coverage, etc.)",
        "JSON schema: {scenarios: [{name, testMappings: [{file, lines, implMappings: [{file, lines}]}]}], stats: {totalScenarios, coveredScenarios, coveragePercent, testFiles, implFiles, totalLinesCovered}}",
        "Yes to both: scenarios can have multiple test files (array of testMappings), and test files can appear in multiple scenario mappings (many-to-many relationship)",
        "Yes, show uncovered scenarios with empty testMappings array. Integrate with ACDD: block work units from moving to 'done' if linked feature has uncovered scenarios. Emit system-reminder to prompt AI to add coverage",
        "Yes, validate file paths exist when linking coverage. Fail with clear error if test file or implementation file path is invalid"
      ],
      "examples": [
        "Feature file 'user-login.feature' has companion file 'user-login.feature.coverage' in same directory",
        "Coverage file maps scenario 'Login with valid credentials' to test file 'src/__tests__/auth.test.ts' lines 45-62",
        "Coverage file shows test at lines 45-62 covers implementation file 'src/auth/login.ts' lines 10,11,12,15,20",
        "User runs 'fspec create-feature User Login', creates user-login.feature AND user-login.feature.coverage automatically",
        "AI runs 'fspec link-coverage user-login --scenario \"Login with valid credentials\" --test-file src/__tests__/auth.test.ts --test-lines 45-62', fspec prompts AI for implementation files",
        "AI runs 'fspec audit-coverage user-login', fspec shows first mapping and asks AI to verify line numbers are still correct, repeats for all mappings",
        "Developer runs 'fspec show-coverage user-login', sees output: 5 scenarios, 4 covered (80%), 2 test files, 3 implementation files, 45 lines covered"
      ],
      "questions": [
        {
          "text": "@human: Should coverage files be created automatically when a feature file is created (via create-feature), or on-demand with a separate command (like init-coverage)?",
          "selected": true,
          "answer": "Automatically create .feature.coverage files when feature files are created via create-feature command"
        },
        {
          "text": "@human: How should the system discover which test files map to which scenarios? Should AI read test files and match them to scenario names, or should users manually link them with a command?",
          "selected": true,
          "answer": "AI discovers test-to-scenario mappings using reverse ACDD (rspec.md) for existing code, or tracks mappings during forward ACDD. fspec provides CLI commands for AI to record these mappings"
        },
        {
          "text": "@human: How should we track which implementation code lines are covered? Should AI parse test code to find which files are imported/used, or should this be manually specified?",
          "selected": true,
          "answer": "fspec prompts AI agent via interactive 'link-coverage' command (or similar name) to specify which implementation files and lines are covered by tests"
        },
        {
          "text": "@human: What happens when code changes and line numbers shift? Should we store line numbers at all, or use some other identifier (like function names, AST nodes, code hashes)?",
          "selected": true,
          "answer": "Use 'audit-coverage' command that works with AI agent in a loop, prompting it to verify each file's mappings one by one. AI looks up current line numbers and updates coverage file"
        },
        {
          "text": "@human: What does 'AI-assisted verification' mean exactly? Should the AI read coverage files and suggest corrections, or interactively ask the developer to confirm mappings?",
          "selected": true,
          "answer": "AI does all verification work during audit-coverage command by reading files, checking line numbers, and confirming mappings are correct"
        },
        {
          "text": "@human: What statistics are most important? Coverage percentage, uncovered scenarios, number of test cases, implementation files touched, something else?",
          "selected": true,
          "answer": "All statistics: coverage percentage, uncovered scenarios, number of test cases per scenario, implementation files touched, lines covered per file"
        },
        {
          "text": "@human: Should coverage validation be integrated into existing commands (like 'fspec check', 'fspec validate'), or be separate commands?",
          "selected": true,
          "answer": "Separate commands since coverage tracking is interactive and requires AI agent collaboration (link-coverage, audit-coverage, show-coverage, etc.)"
        },
        {
          "text": "@human: What should the JSON schema look like? Should it be: {scenarios: [{name, testMappings: [{file, lines, implMappings: [{file, lines}]}]}], stats: {...}}?",
          "selected": true,
          "answer": "JSON schema: {scenarios: [{name, testMappings: [{file, lines, implMappings: [{file, lines}]}]}], stats: {totalScenarios, coveredScenarios, coveragePercent, testFiles, implFiles, totalLinesCovered}}"
        },
        {
          "text": "@human: Can one scenario map to multiple test files? Can one test file cover multiple scenarios?",
          "selected": true,
          "answer": "Yes to both: scenarios can have multiple test files (array of testMappings), and test files can appear in multiple scenario mappings (many-to-many relationship)"
        },
        {
          "text": "@human: What if a scenario has no tests yet (ACDD testing phase not started)? Should coverage file show it as uncovered with empty test mappings?",
          "selected": true,
          "answer": "Yes, show uncovered scenarios with empty testMappings array. Integrate with ACDD: block work units from moving to 'done' if linked feature has uncovered scenarios. Emit system-reminder to prompt AI to add coverage"
        },
        {
          "text": "@human: Should we validate that test files and implementation files actually exist when linking coverage? Fail if file paths are invalid?",
          "selected": true,
          "answer": "Yes, validate file paths exist when linking coverage. Fail with clear error if test file or implementation file path is invalid"
        },
        {
          "text": "@human: Should coverage files be formatted/validated like feature files? Should there be 'fspec validate-coverage' command?",
          "selected": true,
          "answer": "No validation command needed. Coverage files are only modified by fspec commands (link-coverage, audit-coverage), never manually edited. fspec maintains file integrity automatically"
        }
      ],
      "assumptions": [
        "AI does all verification work during audit-coverage command by reading files, checking line numbers, and confirming mappings are correct",
        "No validation command needed. Coverage files are only modified by fspec commands (link-coverage, audit-coverage), never manually edited. fspec maintains file integrity automatically"
      ],
      "estimate": 8
    },
    "COV-002": {
      "id": "COV-002",
      "title": "Auto-create Coverage Files",
      "status": "done",
      "createdAt": "2025-10-13T10:04:49.597Z",
      "updatedAt": "2025-10-13T10:30:26.647Z",
      "description": "Modify create-feature command to automatically generate .feature.coverage JSON files alongside feature files with empty scenario mappings",
      "epic": "coverage-tracking",
      "children": [],
      "parent": "COV-001",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T10:08:21.423Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T10:22:20.882Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T10:25:15.136Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T10:29:47.242Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T10:30:26.647Z"
        }
      ],
      "userStory": {
        "role": "developer creating feature files",
        "action": "have .feature.coverage files automatically created when I run create-feature",
        "benefit": "I don't have to manually create coverage tracking files"
      },
      "rules": [
        "Coverage files must be auto-created when create-feature command runs",
        "Coverage file must be named <feature-name>.feature.coverage (same name as .feature file with .coverage extension)",
        "Coverage file must be in same directory as .feature file (spec/features/)",
        "Coverage file must be valid JSON with schema: {scenarios: [{name, testMappings: []}], stats: {totalScenarios, coveredScenarios, coveragePercent, testFiles, implFiles, totalLinesCovered}}",
        "Initial coverage file must have empty testMappings arrays (no coverage yet)",
        "Scenarios array must be populated from feature file scenarios (read from Gherkin AST)",
        "Stats must be calculated: totalScenarios=count, coveredScenarios=0, coveragePercent=0, testFiles=[], implFiles=[], totalLinesCovered=0",
        "Display message: 'Created <filename>.feature.coverage' so user knows coverage file was generated",
        "If .coverage file exists: read and validate JSON. If valid, skip creation (preserve existing coverage). If invalid JSON, overwrite with fresh coverage file",
        "Scenario names must exactly match Gherkin scenario names (case-sensitive, preserve whitespace) for accurate mapping"
      ],
      "examples": [
        "Run 'fspec create-feature User Login', creates spec/features/user-login.feature AND spec/features/user-login.feature.coverage",
        "Coverage file contains {scenarios: [{name: 'Login with valid credentials', testMappings: []}], stats: {totalScenarios: 1, coveredScenarios: 0, coveragePercent: 0, testFiles: [], implFiles: [], totalLinesCovered: 0}}",
        "Feature file with 3 scenarios creates coverage file with 3 entries in scenarios array, totalScenarios: 3",
        "If create-feature fails (invalid name), no .coverage file should be created",
        "Coverage file exists with valid JSON, create-feature skips creation and displays 'Skipped user-login.feature.coverage (already exists)'",
        "Coverage file exists with invalid JSON, create-feature overwrites it and displays 'Recreated user-login.feature.coverage (previous file was invalid)'"
      ],
      "questions": [
        {
          "text": "@human: Should coverage file creation be silent (no output), or should create-feature display 'Created user-login.feature.coverage'?",
          "selected": true,
          "answer": "Display message: 'Created <filename>.feature.coverage' so user knows coverage file was generated"
        },
        {
          "text": "@human: What if a .coverage file already exists? Should we overwrite it, skip it, or error?",
          "selected": true,
          "answer": "If .coverage file exists: read and validate JSON. If valid, skip creation (preserve existing coverage). If invalid JSON, overwrite with fresh coverage file"
        },
        {
          "text": "@human: Should scenario names in coverage file exactly match Gherkin scenario names (including case/whitespace), or should they be normalized?",
          "selected": true,
          "answer": "Scenario names must exactly match Gherkin scenario names (case-sensitive, preserve whitespace) for accurate mapping"
        }
      ]
    },
    "COV-003": {
      "id": "COV-003",
      "title": "Link Coverage Command",
      "status": "done",
      "createdAt": "2025-10-13T10:04:51.632Z",
      "updatedAt": "2025-10-13T11:25:03.758Z",
      "description": "Implement 'fspec link-coverage' command for mapping scenarios to test files and implementation files with interactive AI prompting and file path validation",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-002"
      ],
      "parent": "COV-001",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T11:03:16.421Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T11:17:50.164Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T11:19:34.215Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T11:24:59.487Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T11:25:03.759Z"
        }
      ],
      "questions": [
        {
          "text": "@human: Should one command support BOTH adding test mapping AND implementation mapping, or separate them into distinct operations?",
          "selected": true,
          "answer": "Non-interactive command-line interface. Support partial additions (test-only, or test+impl). After execution, display helpful message showing how to add more mappings or remove existing ones. No interactive prompts that wait for user input. All operations complete immediately with instructional output."
        },
        {
          "text": "@human: How should the link-coverage command be invoked? (all-in-one, two-step, or interactive prompting?)",
          "selected": true,
          "answer": "Single flexible link-coverage command. Support three modes: (1) test-only (--test-file + --test-lines), (2) impl-only (--impl-file + --impl-lines), (3) both at once (all four flags). Command validates required flag combinations and provides helpful error messages if incorrect combination provided."
        },
        {
          "text": "@human: When adding impl-only (no test flags), which test mapping should it attach to? Most recent test for that scenario, or require test file specification?",
          "selected": true,
          "answer": "Always require --test-file when adding implementation mappings. Implementation mappings attach to specific test mappings, so test file must be specified to identify which test mapping to update. This ensures explicit, unambiguous attachment."
        },
        {
          "text": "@human: For line numbers, should we support ranges (45-62), individual lines (10,11,12), or both? Should format be consistent between test and impl lines?",
          "selected": true,
          "answer": "Test lines: range format only (e.g., '45-62'). Implementation lines: comma-separated primary (e.g., '10,11,12,15,20'), but also accept ranges as convenience (e.g., '10-15' expands to [10,11,12,13,14,15]). This matches storage format and mirrors reality: tests are contiguous, impl can be scattered."
        },
        {
          "text": "@human: Should file paths be validated (check if they exist on disk) before adding to coverage? Error if missing, or allow with warning?",
          "selected": true,
          "answer": "Validate file paths by default (error if file doesn't exist). Support --skip-validation flag to bypass validation for forward planning scenarios. When validation fails, display clear error with file path and suggestion. When --skip-validation used, show warning that file doesn't exist but continue."
        },
        {
          "text": "@human: What happens if you try to link a test mapping that already exists (same scenario + same test file)? Overwrite, append, or error?",
          "selected": true,
          "answer": "Append mode: allow multiple test mappings for the same file in one scenario. Each mapping is independent with its own line range and impl mappings. Display message showing all mappings for that file. This supports scenarios where one scenario is tested multiple times in the same file (e.g., different test suites or contexts)."
        },
        {
          "text": "@human: When adding impl mapping to existing test, what if that test already has impl mappings? Append to the array or replace?",
          "selected": true,
          "answer": "Smart append: check if impl file already exists in the test mapping's implMappings array. If exists, update the line numbers for that file. If doesn't exist, append as new impl mapping. Display whether updated or added. This allows one test to cover multiple impl files while preventing duplicate entries."
        },
        {
          "text": "@human: Should the command support removing/unlinking mappings, or should that be a separate command (like unlink-coverage or remove-coverage)?",
          "selected": true,
          "answer": "Separate command for removal. link-coverage only adds/updates mappings. Display helpful message after linking showing how to remove: 'To remove this mapping: fspec unlink-coverage <feature> --scenario ... --test-file ...'. Removal command (unlink-coverage) is separate work unit, follows fspec pattern of separate add/remove commands."
        }
      ],
      "rules": [
        "Non-interactive command-line interface. Support partial additions (test-only, or test+impl). After execution, display helpful message showing how to add more mappings or remove existing ones. No interactive prompts that wait for user input. All operations complete immediately with instructional output.",
        "Single flexible link-coverage command. Support three modes: (1) test-only (--test-file + --test-lines), (2) impl-only (--impl-file + --impl-lines), (3) both at once (all four flags). Command validates required flag combinations and provides helpful error messages if incorrect combination provided.",
        "Always require --test-file when adding implementation mappings. Implementation mappings attach to specific test mappings, so test file must be specified to identify which test mapping to update. This ensures explicit, unambiguous attachment.",
        "Test lines: range format only (e.g., '45-62'). Implementation lines: comma-separated primary (e.g., '10,11,12,15,20'), but also accept ranges as convenience (e.g., '10-15' expands to [10,11,12,13,14,15]). This matches storage format and mirrors reality: tests are contiguous, impl can be scattered.",
        "Validate file paths by default (error if file doesn't exist). Support --skip-validation flag to bypass validation for forward planning scenarios. When validation fails, display clear error with file path and suggestion. When --skip-validation used, show warning that file doesn't exist but continue.",
        "Append mode: allow multiple test mappings for the same file in one scenario. Each mapping is independent with its own line range and impl mappings. Display message showing all mappings for that file. This supports scenarios where one scenario is tested multiple times in the same file (e.g., different test suites or contexts).",
        "Smart append: check if impl file already exists in the test mapping's implMappings array. If exists, update the line numbers for that file. If doesn't exist, append as new impl mapping. Display whether updated or added. This allows one test to cover multiple impl files while preventing duplicate entries.",
        "Separate command for removal. link-coverage only adds/updates mappings. Display helpful message after linking showing how to remove: 'To remove this mapping: fspec unlink-coverage <feature> --scenario ... --test-file ...'. Removal command (unlink-coverage) is separate work unit, follows fspec pattern of separate add/remove commands."
      ],
      "examples": [
        "User runs 'fspec link-coverage user-login --scenario \"Login with valid credentials\" --test-file src/__tests__/auth.test.ts --test-lines 45-62', creates test mapping, displays success and helpful message",
        "User runs 'fspec link-coverage user-login --scenario \"Login with valid credentials\" --test-file src/__tests__/auth.test.ts --impl-file src/auth/login.ts --impl-lines 10,11,12', adds impl mapping to existing test",
        "User runs command with both test and impl flags at once, creates test mapping with impl mapping in one operation",
        "Test file doesn't exist, validation fails with error and suggestion to use --skip-validation",
        "User provides --skip-validation flag with non-existent file, command succeeds with warning message",
        "Impl lines '10-15' (range format) expands to array [10,11,12,13,14,15] in coverage file",
        "Adding impl file that already exists in test mapping updates line numbers instead of creating duplicate entry",
        "Adding test mapping with same test file but different lines appends as second mapping"
      ],
      "userStory": {
        "role": "developer tracking test coverage",
        "action": "link scenarios to test files and implementation files",
        "benefit": "I can track which code covers which acceptance criteria"
      }
    },
    "COV-004": {
      "id": "COV-004",
      "title": "Show Coverage Statistics",
      "status": "done",
      "createdAt": "2025-10-13T10:04:53.307Z",
      "updatedAt": "2025-10-13T11:01:35.541Z",
      "description": "Implement 'fspec show-coverage' command to display coverage statistics including percentage, test files, implementation files, and line counts",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-002"
      ],
      "parent": "COV-001",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T10:35:18.928Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T10:58:41.331Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T10:59:49.378Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T11:01:24.285Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T11:01:35.542Z"
        }
      ],
      "questions": [
        {
          "text": "@human: What output format(s) should show-coverage support? (text/json/markdown, with --format flag?)",
          "selected": true,
          "answer": "Markdown and JSON output formats. Default to markdown. Use --format flag (--format=json for JSON output, --format=markdown or no flag for markdown)"
        },
        {
          "text": "@human: For text output, what level of detail by default? (summary only, full breakdown, or configurable with --verbose?)",
          "selected": true,
          "answer": "Full breakdown always shown by default in markdown. Include summary stats + scenario-by-scenario coverage details (test files, implementation files, line numbers). Show which scenarios are covered and uncovered."
        },
        {
          "text": "@human: Should uncovered scenarios be highlighted in red and/or listed separately?",
          "selected": true,
          "answer": "Use both visual symbols (✅ for covered, ❌ for uncovered) throughout scenario list AND create a separate 'Coverage Gaps' section at the end listing all uncovered scenarios with action items"
        },
        {
          "text": "@human: Should show-coverage work on single file, all files, or both? (Usage: fspec show-coverage [file])",
          "selected": true,
          "answer": "Support both modes: show all files when no argument provided, show specific file when file path is provided. File path can be relative (user-login.feature) or full path (spec/features/user-login.feature)"
        },
        {
          "text": "@human: If showing all files, display aggregated stats, per-feature breakdown, or both?",
          "selected": true,
          "answer": "Both: show aggregated project summary at top (overall coverage, total features/scenarios, features overview table), then full per-feature breakdowns with scenario details for each feature file"
        },
        {
          "text": "@human: How to calculate covered scenarios? (has test mapping, or test + impl mappings?)",
          "selected": true,
          "answer": "Three-tier coverage system: 'Fully Covered' (has test mapping AND implementation mappings), 'Partially Covered' (has test mapping but empty implMappings), 'Uncovered' (no test mappings). Statistics should count fully covered + partially covered as total covered scenarios."
        },
        {
          "text": "@human: For line counts, count impl lines only, or test + impl lines separately?",
          "selected": true,
          "answer": "Separate counts for test lines and implementation lines. Display 'Test Lines', 'Implementation Lines', and 'Total Lines' in statistics. Parse line ranges (e.g., '45-62' = 18 lines) and count individual lines in arrays."
        },
        {
          "text": "@human: Should we validate that mapped files/lines still exist? (always, never, or --validate flag?)",
          "selected": true,
          "answer": "Always validate file paths exist when displaying coverage. Check that test files and implementation files exist on disk. Display warnings for missing files but still show the coverage data. This ensures users are immediately aware of stale mappings."
        },
        {
          "text": "@human: What happens if .coverage file doesn't exist? (error, show 0% with message, or suggest creating?)",
          "selected": true,
          "answer": "Error and exit with code 1 when .coverage file doesn't exist. Display clear error message with suggestion to create coverage file using appropriate command (fspec create-feature or manually). This ensures explicit coverage tracking setup."
        },
        {
          "text": "@human: What happens if .coverage file has invalid JSON? (error, warning, or try to parse?)",
          "selected": true,
          "answer": "Error and exit with code 1 when .coverage file has invalid JSON. Display parse error details (line number, error message) and suggest validating/recreating the file. Keep error message focused on the parse failure."
        }
      ],
      "rules": [
        "Markdown and JSON output formats. Default to markdown. Use --format flag (--format=json for JSON output, --format=markdown or no flag for markdown)",
        "Full breakdown always shown by default in markdown. Include summary stats + scenario-by-scenario coverage details (test files, implementation files, line numbers). Show which scenarios are covered and uncovered.",
        "Use both visual symbols (✅ for covered, ❌ for uncovered) throughout scenario list AND create a separate 'Coverage Gaps' section at the end listing all uncovered scenarios with action items",
        "Support both modes: show all files when no argument provided, show specific file when file path is provided. File path can be relative (user-login.feature) or full path (spec/features/user-login.feature)",
        "Both: show aggregated project summary at top (overall coverage, total features/scenarios, features overview table), then full per-feature breakdowns with scenario details for each feature file",
        "Three-tier coverage system: 'Fully Covered' (has test mapping AND implementation mappings), 'Partially Covered' (has test mapping but empty implMappings), 'Uncovered' (no test mappings). Statistics should count fully covered + partially covered as total covered scenarios.",
        "Separate counts for test lines and implementation lines. Display 'Test Lines', 'Implementation Lines', and 'Total Lines' in statistics. Parse line ranges (e.g., '45-62' = 18 lines) and count individual lines in arrays.",
        "Always validate file paths exist when displaying coverage. Check that test files and implementation files exist on disk. Display warnings for missing files but still show the coverage data. This ensures users are immediately aware of stale mappings.",
        "Error and exit with code 1 when .coverage file doesn't exist. Display clear error message with suggestion to create coverage file using appropriate command (fspec create-feature or manually). This ensures explicit coverage tracking setup.",
        "Error and exit with code 1 when .coverage file has invalid JSON. Display parse error details (line number, error message) and suggest validating/recreating the file. Keep error message focused on the parse failure."
      ],
      "examples": [
        "User runs 'fspec show-coverage user-login.feature', displays markdown report with 80% coverage (4/5 scenarios), full breakdown with symbols, and Coverage Gaps section",
        "User runs 'fspec show-coverage user-login.feature --format=json', outputs JSON with scenarios array, stats object, three-tier coverage status",
        "User runs 'fspec show-coverage' (no args), displays project summary with aggregated stats + per-feature breakdown for all .coverage files",
        "Scenario has test mapping with empty implMappings array, displayed as '⚠️ PARTIALLY COVERED' with warning icon",
        "Test file path doesn't exist on disk, display '⚠️ File not found: src/__tests__/deleted.test.ts' warning but still show coverage",
        "Line range '45-62' counts as 18 test lines, array [10,11,12,15,20] counts as 5 impl lines, displayed separately in stats",
        "User runs 'fspec show-coverage missing.feature', .coverage file doesn't exist, error with exit code 1 and suggestion message",
        ".coverage file has invalid JSON, command fails with parse error showing line number and suggestion to recreate"
      ],
      "userStory": {
        "role": "developer tracking test coverage",
        "action": "view coverage statistics for feature files",
        "benefit": "I can identify gaps in test coverage and track testing progress"
      }
    },
    "COV-005": {
      "id": "COV-005",
      "title": "Audit Coverage Command",
      "status": "done",
      "createdAt": "2025-10-13T10:04:55.178Z",
      "updatedAt": "2025-10-13T12:13:39.422Z",
      "description": "Implement 'fspec audit-coverage' command with interactive AI loop to verify and update line number mappings when code changes",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-002"
      ],
      "parent": "COV-001",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T11:58:47.194Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:09:52.214Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:10:30.001Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:12:54.205Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:13:39.422Z"
        }
      ],
      "userStory": {
        "role": "developer maintaining coverage tracking",
        "action": "audit and update line number mappings when code changes",
        "benefit": "I keep coverage data accurate as code evolves"
      },
      "questions": [
        {
          "text": "@human: Should audit-coverage automatically update line numbers if it detects they've shifted, or prompt AI to manually verify?",
          "selected": true,
          "answer": "Prompt AI to change (but unclear how to detect line shifts automatically)"
        },
        {
          "text": "@human: Should audit-coverage check that test files and implementation files still exist?",
          "selected": true,
          "answer": "Yes, verify that test files and implementation files exist"
        },
        {
          "text": "@human: Should audit-coverage be interactive or just display a report?",
          "selected": true,
          "answer": "Display good information on what to do next if something's not right (report with actionable recommendations)"
        }
      ],
      "assumptions": [
        "Prompt AI to change (but unclear how to detect line shifts automatically)"
      ],
      "rules": [
        "Yes, verify that test files and implementation files exist",
        "Display good information on what to do next if something's not right (report with actionable recommendations)",
        "Audit command must validate that all test files referenced in coverage exist on disk",
        "Audit command must validate that all implementation files referenced in coverage exist on disk",
        "Report must show missing files with clear actionable recommendations (remove stale mappings or restore deleted files)",
        "Command accepts feature file name as argument (e.g., 'fspec audit-coverage user-login')",
        "Output format: markdown report with sections for each scenario's mappings and issues found"
      ],
      "examples": [
        "Run 'fspec audit-coverage user-login', checks all files exist, displays report showing 3/3 files found, all mappings valid",
        "Audit finds test file missing, displays '❌ Test file not found: src/__tests__/deleted.test.ts' with recommendation to remove mapping",
        "Audit finds impl file missing, displays '❌ Implementation file not found: src/auth/deleted.ts' with recommendation"
      ]
    },
    "COV-006": {
      "id": "COV-006",
      "title": "ACDD Workflow Integration",
      "status": "done",
      "createdAt": "2025-10-13T10:04:57.016Z",
      "updatedAt": "2025-10-13T12:24:09.837Z",
      "description": "Integrate coverage tracking with ACDD workflow: block work unit progression to 'done' if coverage incomplete, emit system-reminders for uncovered scenarios",
      "epic": "coverage-tracking",
      "children": [],
      "dependsOn": [
        "COV-003",
        "COV-004",
        "COV-005"
      ],
      "parent": "COV-001",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T12:15:18.461Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:18:09.260Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:19:26.284Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:22:37.057Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:24:09.838Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec with ACDD workflow",
        "action": "ensure work units cannot be marked done when coverage is incomplete",
        "benefit": "I maintain quality standards and prevent incomplete work from being considered complete"
      },
      "rules": [
        "Block work unit status update to 'done' if linked feature file has uncovered scenarios (scenarios with empty testMappings array)",
        "Emit system-reminder when work unit cannot advance to done due to incomplete coverage, showing which scenarios lack coverage",
        "System-reminder must include specific commands to add coverage (e.g., 'fspec link-coverage <feature> --scenario ...')",
        "Check coverage completeness by reading .feature.coverage file and looking for scenarios with empty testMappings arrays",
        "Coverage checking is always enforced (no optional flag) to maintain consistent quality standards",
        "If .coverage file doesn't exist, allow status update with warning. If .coverage file exists, enforce coverage completeness.",
        "Only check coverage when moving to 'done' status, not when moving to 'validating'"
      ],
      "examples": [
        "Work unit AUTH-001 linked to user-login.feature with all 5 scenarios covered (all have testMappings), status update to 'done' succeeds",
        "Work unit AUTH-001 linked to user-login.feature with 2/5 scenarios uncovered (empty testMappings), status update to 'done' fails with error message and system-reminder",
        "System-reminder displays: '❌ Cannot mark work unit done: 2 scenarios uncovered in user-login.feature' with list of uncovered scenario names"
      ],
      "questions": [
        {
          "text": "@human: Should this blocking behavior be optional (via flag) or always enforced?",
          "selected": true,
          "answer": "Always enforced - this maintains quality standards consistently"
        },
        {
          "text": "@human: What happens if the .coverage file doesn't exist for a linked feature - should that block the status update?",
          "selected": true,
          "answer": "If .coverage file doesn't exist, allow the status update with a warning (coverage tracking is optional). But if .coverage file exists, enforce coverage completeness."
        },
        {
          "text": "@human: Should we only check coverage when moving to 'done' status, or also when moving to 'validating'?",
          "selected": true,
          "answer": "Only check coverage when moving to 'done' status - validating is still part of the development process"
        }
      ]
    },
    "BUG-005": {
      "id": "BUG-005",
      "title": "Remove work unit ID tags from generate-scenarios",
      "status": "done",
      "createdAt": "2025-10-13T11:30:51.399Z",
      "updatedAt": "2025-10-13T11:55:59.660Z",
      "description": "Fixed generate-scenarios to add work unit IDs as FEATURE-LEVEL tags only (not scenario-level). Modified check.ts to use proper validateTags function. Removed scenario-level work unit ID tags from all feature files. This implements the optimal two-tier linking system: feature-level tags for coarse-grained work unit → feature association, with coverage files providing fine-grained scenario traceability.",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T11:31:08.692Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T11:55:24.402Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T11:55:30.552Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T11:55:36.124Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T11:55:59.661Z"
        }
      ],
      "userStory": {
        "role": "developer maintaining fspec",
        "action": "verify that generate-scenarios adds work unit ID tags only at feature level",
        "benefit": "I ensure the two-tier linking system (feature-level tags + coverage files) works correctly"
      },
      "rules": [
        "Work unit ID tags must appear at feature level only, not scenario level",
        "generate-scenarios command must add work unit ID as feature-level tag",
        "Existing feature files must not have scenario-level work unit ID tags",
        "check.ts validation must use proper validateTags function",
        "Yes, add automated tests to verify generate-scenarios adds work unit ID at feature level only (check if tests already exist first)",
        "Yes, create validation rule to reject scenario-level work unit ID tags. However, many existing features already have work unit IDs, so the script (Q3) must fix them first before validation can be enforced",
        "Write a script to scan all feature files and move scenario-level work unit ID tags to feature level. This must run before validation enforcement"
      ],
      "examples": [
        "Run generate-scenarios for a work unit, verify the generated feature file has work unit ID as feature-level tag (e.g., @BUG-005 at top)",
        "Run generate-scenarios for a work unit, verify generated scenarios do NOT have work unit ID tags at scenario level",
        "Check existing feature files to verify no scenario-level work unit ID tags remain (like @COV-001 on individual scenarios)",
        "Verify check.ts uses validateTags() function instead of inline validation logic",
        "Write script that scans spec/features/*.feature files, finds scenario-level work unit ID tags (like @COV-001 on scenarios), moves them to feature-level tags",
        "After script runs, validate-tags command should reject any feature file with scenario-level work unit ID tags (pattern: @[A-Z]+-[0-9]+)"
      ],
      "questions": [
        {
          "text": "@human: Should we add automated tests to verify generate-scenarios adds work unit ID at feature level only?",
          "selected": true,
          "answer": "Yes, add automated tests to verify generate-scenarios adds work unit ID at feature level only (check if tests already exist first)"
        },
        {
          "text": "@human: Should we create a validation rule in check.ts or validate-tags to reject scenario-level work unit ID tags?",
          "selected": true,
          "answer": "Yes, create validation rule to reject scenario-level work unit ID tags. However, many existing features already have work unit IDs, so the script (Q3) must fix them first before validation can be enforced"
        },
        {
          "text": "@human: Is manual verification of existing feature files sufficient, or should we write a script to scan all feature files?",
          "selected": true,
          "answer": "Write a script to scan all feature files and move scenario-level work unit ID tags to feature level. This must run before validation enforcement"
        }
      ]
    },
    "BUG-006": {
      "id": "BUG-006",
      "title": "Parent work units shouldn't require scenarios",
      "status": "done",
      "createdAt": "2025-10-13T12:26:15.841Z",
      "updatedAt": "2025-10-13T12:30:03.560Z",
      "description": "Parent work units without linkedFeatures should only require all children to be done, not require scenarios to exist when moving to testing status",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T12:26:21.933Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T12:29:49.558Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T12:29:49.849Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T12:29:50.141Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T12:30:03.561Z"
        }
      ],
      "userStory": {
        "role": "developer working on parent work units",
        "action": "move parent work units through workflow without requiring scenarios",
        "benefit": "parent work units are containers that don't need their own feature files"
      },
      "rules": [
        "Parent work units (work units with children array) should skip scenario validation when moving to testing",
        "checkScenariosExist function should return true immediately if work unit has children",
        "Only leaf work units (no children) need to have scenarios tagged with @WORK-UNIT-ID",
        "Parent work units can only move to done when ALL children are done (existing validation)"
      ],
      "examples": [
        "COV-001 (parent with 5 children all done) can move from specifying -> testing -> implementing -> validating -> done without scenario validation",
        "COV-002 (leaf work unit, no children) requires @COV-002 tag in feature file to move to testing",
        "Parent work unit with incomplete children (COV-001 with COV-006 still in implementing) cannot move to done"
      ]
    },
    "COV-007": {
      "id": "COV-007",
      "title": "Generate Coverage Files for Existing Features",
      "status": "done",
      "createdAt": "2025-10-13T22:05:01.056Z",
      "updatedAt": "2025-10-13T22:14:08.318Z",
      "description": "Add a command to generate .feature.coverage files for existing feature files that don't have coverage tracking yet",
      "epic": "coverage-tracking",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T22:05:07.139Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T22:10:05.598Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T22:11:20.482Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T22:13:34.764Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T22:14:08.318Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for coverage tracking",
        "action": "generate coverage files for existing feature files that lack them",
        "benefit": "I can start tracking test coverage for features created before coverage tracking was implemented"
      },
      "rules": [
        "Command must scan spec/features/ directory for .feature files",
        "For each .feature file without a corresponding .feature.coverage file, generate one",
        "Skip files that already have valid .feature.coverage files (preserve existing coverage data)",
        "Overwrite .feature.coverage files that have invalid JSON (corrupted files)",
        "Generated coverage files must have same JSON schema as auto-created coverage files from create-feature",
        "Display summary: X files created, Y files skipped, Z files recreated (invalid JSON)",
        "Support --dry-run flag to preview what would be generated without creating files"
      ],
      "examples": [
        "Project has 66 .feature files, 0 .coverage files → command creates 66 .coverage files",
        "Project has 50 .feature files, 30 valid .coverage files → command creates 20 new .coverage files, skips 30",
        "Project has user-login.feature with 5 scenarios → generates user-login.feature.coverage with 5 entries in scenarios array, all with empty testMappings",
        "Run with --dry-run flag → displays what would be created but doesn't create any files",
        "Corrupted .coverage file with invalid JSON → overwrites with valid empty coverage file, displays 'Recreated'"
      ]
    },
    "COV-008": {
      "id": "COV-008",
      "title": "Unlink Coverage Mappings",
      "status": "done",
      "createdAt": "2025-10-13T22:20:53.067Z",
      "updatedAt": "2025-10-13T22:29:19.706Z",
      "description": "Add unlink-coverage command to remove test and implementation mappings from scenarios",
      "epic": "coverage-tracking",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-13T22:22:54.879Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-13T22:25:51.670Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-13T22:26:42.302Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-13T22:28:53.095Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-13T22:29:19.707Z"
        }
      ],
      "userStory": {
        "role": "developer managing coverage tracking",
        "action": "remove incorrect or outdated test and implementation mappings from scenarios",
        "benefit": "I can correct mistakes and update coverage as code evolves without manual JSON editing"
      },
      "rules": [
        "Support --all flag to remove all mappings for a scenario (reset to uncovered)",
        "Support removing specific test mapping by test-file path",
        "Support removing only implementation mapping while keeping test mapping",
        "Removing test mapping must also remove all its implementation mappings",
        "Must recalculate stats after any removal operation",
        "Error if scenario not found in coverage file"
      ],
      "examples": [
        "Remove all mappings: unlink-coverage user-login --scenario 'Login' --all → scenario becomes uncovered, stats recalculated",
        "Remove test mapping: unlink-coverage user-login --scenario 'Login' --test-file src/__tests__/auth.test.ts → removes test and all its impl mappings",
        "Remove only impl: unlink-coverage user-login --scenario 'Login' --test-file src/__tests__/auth.test.ts --impl-file src/auth/old.ts → keeps test mapping",
        "Error if scenario not found → displays available scenarios"
      ]
    },
    "DOC-003": {
      "id": "DOC-003",
      "title": "Clarify backward movement in workflow documentation",
      "status": "done",
      "createdAt": "2025-10-14T01:57:04.564Z",
      "updatedAt": "2025-10-14T10:51:21.943Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-14T01:57:11.127Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-14T10:47:23.806Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-14T10:50:35.138Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-14T10:50:42.296Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-14T10:51:21.944Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec workflow",
        "action": "understand backward state transitions",
        "benefit": "I can confidently move work backward when fixing mistakes"
      },
      "rules": [
        "Cannot skip states forward (ACDD enforcement)",
        "CAN move backward from validating to implementing or specifying to fix issues",
        "CAN move backward from done to any previous state when mistakes discovered",
        "Cannot move back to backlog (use blocked state instead)",
        "Blocked state can transition back to any non-done state",
        "Just text - CLI help should be text-based for terminal readability"
      ],
      "examples": [
        "Move from testing to specifying when tests revealed incomplete acceptance criteria",
        "Move from implementing to testing when test cases need refactoring",
        "Move from validating to implementing when quality checks fail",
        "Move from done to implementing when bug discovered in completed feature",
        "Try to move from backlog to testing - blocked (must go through specifying)"
      ],
      "questions": [
        {
          "text": "@human: Should help include visual state diagram or just text describing backward transitions?",
          "selected": true,
          "answer": "Just text - CLI help should be text-based for terminal readability"
        }
      ],
      "estimate": 2
    },
    "COV-010": {
      "id": "COV-010",
      "title": "Test: Example mapping commands auto-create work-units.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:11.075Z",
      "updatedAt": "2025-10-15T00:24:35.178Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. Need to create tests and implementation for example mapping commands using ensure utilities.",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:17:47.933Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:24:28.002Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:24:34.500Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:24:34.830Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:24:35.179Z"
        }
      ],
      "estimate": 2,
      "epic": "test-coverage"
    },
    "COV-011": {
      "id": "COV-011",
      "title": "Test: Dependency commands auto-create work-units.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:12.810Z",
      "updatedAt": "2025-10-15T00:25:55.102Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Implementation exists in ensure-files.ts, need tests to verify dependency commands use it.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:25:53.922Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:25:54.220Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:25:54.512Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:25:54.805Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:25:55.102Z"
        }
      ]
    },
    "COV-012": {
      "id": "COV-012",
      "title": "Test: Ensure utilities validate JSON structure",
      "status": "done",
      "createdAt": "2025-10-15T00:10:14.369Z",
      "updatedAt": "2025-10-15T00:29:07.394Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No tests found for validation within ensure utilities. Tests verify creation but not schema validation.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:27:05.485Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:27:54.504Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:28:30.230Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:29:07.099Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:29:07.395Z"
        }
      ],
      "rules": [
        "Ensure utilities must detect corrupted JSON files",
        "Ensure utilities must provide helpful error messages indicating what went wrong"
      ],
      "examples": [
        "Corrupted JSON with trailing comma throws parse error with file path",
        "Invalid JSON with missing closing brace throws parse error with line number"
      ],
      "estimate": 3
    },
    "COV-013": {
      "id": "COV-013",
      "title": "Test: All 48+ commands use ensure utilities",
      "status": "done",
      "createdAt": "2025-10-15T00:10:16.274Z",
      "updatedAt": "2025-10-15T00:33:46.472Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Need integration tests to verify all commands use ensure utilities instead of direct file reads.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:31:57.735Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:32:52.803Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:33:40.011Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:33:46.175Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:33:46.473Z"
        }
      ],
      "estimate": 2
    },
    "COV-014": {
      "id": "COV-014",
      "title": "Test: List work units command auto-creates work-units.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:17.732Z",
      "updatedAt": "2025-10-15T00:34:01.759Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Implementation exists (ensureWorkUnitsFile), need test to verify list-work-units command uses it.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:32:40.879Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:00.881Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:01.174Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:01.467Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:01.760Z"
        }
      ],
      "estimate": 2
    },
    "COV-015": {
      "id": "COV-015",
      "title": "Test: Update work unit uses ensureWorkUnitsFile",
      "status": "done",
      "createdAt": "2025-10-15T00:10:19.515Z",
      "updatedAt": "2025-10-15T00:34:03.243Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Need to verify update-work-unit command implementation uses ensure utility.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:32:42.787Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:02.357Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:02.648Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:02.942Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:03.243Z"
        }
      ],
      "estimate": 2
    },
    "COV-016": {
      "id": "COV-016",
      "title": "Test: Register tag auto-creates tags.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:31.606Z",
      "updatedAt": "2025-10-15T00:34:04.720Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_TEST_ONLY. Implementation likely exists but no specific test for register-tag using ensure utilities.",
      "epic": "test-coverage",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:32:44.610Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:03.831Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:04.127Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:04.425Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:04.720Z"
        }
      ],
      "estimate": 2
    },
    "COV-017": {
      "id": "COV-017",
      "title": "Test: Update foundation auto-creates foundation.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:31.907Z",
      "updatedAt": "2025-10-15T00:34:38.486Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No ensure utility or test found for foundation.json auto-creation.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:35.262Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:37.605Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:37.899Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:38.193Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:38.486Z"
        }
      ]
    },
    "COV-018": {
      "id": "COV-018",
      "title": "Test: List tags auto-creates tags.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:32.205Z",
      "updatedAt": "2025-10-15T00:34:39.662Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No test found verifying list-tags auto-creates tags.json.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:35.845Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:38.783Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:39.078Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:39.371Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:39.662Z"
        }
      ]
    },
    "COV-019": {
      "id": "COV-019",
      "title": "Test: Show foundation auto-creates foundation.json",
      "status": "done",
      "createdAt": "2025-10-15T00:10:32.497Z",
      "updatedAt": "2025-10-15T00:34:40.844Z",
      "description": "Feature: automatic-json-file-initialization. Status: CREATE_BOTH. No test found verifying show-foundation auto-creates foundation.json.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:36.429Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:34:39.958Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:34:40.255Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:34:40.549Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:34:40.845Z"
        }
      ]
    },
    "COV-020": {
      "id": "COV-020",
      "title": "Test: Register example mapping commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:42.265Z",
      "updatedAt": "2025-10-15T00:40:47.452Z",
      "description": "Feature: cli-command-registration. Status: CREATE_BOTH. Test file only verifies 39 commands excluding example mapping. Need to add example mapping commands to registration test.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:34:59.479Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:40:24.923Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:40:46.567Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:40:46.863Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:40:47.453Z"
        }
      ],
      "rules": [
        "Example mapping commands must be registered in CLI"
      ],
      "examples": [
        "add-rule, add-example, add-question commands should be accessible via CLI"
      ]
    },
    "COV-021": {
      "id": "COV-021",
      "title": "Test: Register workflow automation commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:42.555Z",
      "updatedAt": "2025-10-15T00:43:06.614Z",
      "description": "Feature: cli-command-registration. Status: CREATE_BOTH. No tests found for workflow automation command registration.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:01.240Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:42:15.799Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:42:39.547Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:42:59.849Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:43:06.615Z"
        }
      ],
      "rules": [
        "Workflow commands must be registered: auto-advance, board, workflow-automation"
      ],
      "examples": [
        "Running 'fspec workflow-automation' should show workflow automation options"
      ]
    },
    "COV-022": {
      "id": "COV-022",
      "title": "Test: Register validation commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:42.849Z",
      "updatedAt": "2025-10-15T00:43:28.938Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. Validation commands likely registered but no specific test verifies registration.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:03.008Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:43:21.439Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:43:28.062Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:43:28.356Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:43:28.938Z"
        }
      ],
      "rules": [
        "Validation commands must be registered: validate-spec-alignment, validate-work-units, repair-work-units"
      ],
      "examples": [
        "Running 'fspec validate-work-units' should verify work unit data integrity"
      ]
    },
    "COV-023": {
      "id": "COV-023",
      "title": "Test: Register assumption management command",
      "status": "done",
      "createdAt": "2025-10-15T00:10:43.142Z",
      "updatedAt": "2025-10-15T00:43:46.185Z",
      "description": "Feature: cli-command-registration. Status: CREATE_BOTH. No tests found for assumption management command.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:04.770Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:43:45.014Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:43:45.311Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:43:45.603Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:43:46.185Z"
        }
      ],
      "rules": [
        "Assumption management command must be registered: add-assumption"
      ],
      "examples": [
        "Running 'fspec add-assumption feature-name \"assumption\"' should add assumption to feature file"
      ]
    },
    "COV-024": {
      "id": "COV-024",
      "title": "Test: Update help text for all command categories",
      "status": "done",
      "createdAt": "2025-10-15T00:10:53.824Z",
      "updatedAt": "2025-10-15T00:44:02.469Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. Need test to verify help text is complete for all categories.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:06.523Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:44:01.294Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:44:01.588Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:44:01.883Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:44:02.469Z"
        }
      ],
      "rules": [
        "Help text must include all commands in their respective categories"
      ],
      "examples": [
        "Running 'fspec help project' should show all work unit commands"
      ]
    },
    "COV-025": {
      "id": "COV-025",
      "title": "Test: Help system shows all commands",
      "status": "done",
      "createdAt": "2025-10-15T00:10:54.124Z",
      "updatedAt": "2025-10-15T00:44:19.832Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. No test verifies help output includes all commands.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:08.285Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:44:18.664Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:44:18.959Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:44:19.250Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:44:19.833Z"
        }
      ],
      "rules": [
        "Help output must list all available commands organized by category"
      ],
      "examples": [
        "Running 'fspec --help' should show commands for spec, tags, foundation, query, and project management"
      ]
    },
    "COV-026": {
      "id": "COV-026",
      "title": "Test: Build succeeds with no errors",
      "status": "done",
      "createdAt": "2025-10-15T00:10:54.426Z",
      "updatedAt": "2025-10-15T00:44:52.043Z",
      "description": "Feature: cli-command-registration. Status: CREATE_TEST_ONLY. Integration test needed to verify build success.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:10.042Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:44:50.873Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:44:51.164Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:44:51.457Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:44:52.044Z"
        }
      ],
      "rules": [
        "Build must succeed with exit code 0 after command registration changes"
      ],
      "examples": [
        "Running 'npm run build' should create dist/index.js with no TypeScript errors"
      ]
    },
    "COV-027": {
      "id": "COV-027",
      "title": "Test: System-reminder after create-feature with prefill",
      "status": "done",
      "createdAt": "2025-10-15T00:10:54.737Z",
      "updatedAt": "2025-10-15T00:45:17.872Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_TEST_ONLY. Tests verify prefill detection but no integration test for create-feature command displaying the reminder.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:11.805Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:16.989Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:17.286Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:17.579Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:17.873Z"
        }
      ],
      "rules": [
        "System-reminder must appear when create-feature generates prefill"
      ],
      "examples": [
        "After creating feature, reminder suggests 'fspec set-user-story' for [role]/[action]/[benefit] placeholders"
      ]
    },
    "COV-028": {
      "id": "COV-028",
      "title": "Test: System-reminder after generate-scenarios with prefill",
      "status": "done",
      "createdAt": "2025-10-15T00:11:05.298Z",
      "updatedAt": "2025-10-15T00:45:28.016Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_TEST_ONLY. Need integration test for generate-scenarios command.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:13.572Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:27.132Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:27.426Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:27.723Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:28.017Z"
        }
      ],
      "rules": [
        "System-reminder must appear when generate-scenarios creates prefill steps"
      ],
      "examples": [
        "After generating scenarios, reminder suggests 'fspec add-step' for placeholder steps"
      ]
    },
    "COV-029": {
      "id": "COV-029",
      "title": "Test: User story from Example Mapping generates complete Background",
      "status": "done",
      "createdAt": "2025-10-15T00:11:05.606Z",
      "updatedAt": "2025-10-15T00:45:38.597Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_BOTH. No tests found for Example Mapping user story to Background conversion.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:15.340Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:37.713Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:38.009Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:38.302Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:38.598Z"
        }
      ],
      "rules": [
        "User story from Example Mapping must generate complete Background without placeholders"
      ],
      "examples": [
        "When work unit has role/action/benefit set, generated Background should contain full user story"
      ]
    },
    "COV-030": {
      "id": "COV-030",
      "title": "Test: Workflow blocking prevents status change with prefill",
      "status": "done",
      "createdAt": "2025-10-15T00:11:05.899Z",
      "updatedAt": "2025-10-15T00:45:48.589Z",
      "description": "Feature: feature-file-prefill-detection. Status: CREATE_BOTH. No tests found for workflow blocking based on prefill detection.",
      "epic": "test-coverage",
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:17.102Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:45:47.707Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:45:48.003Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:45:48.298Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:45:48.590Z"
        }
      ],
      "rules": [
        "Workflow status change must be blocked when linked feature file has prefill"
      ],
      "examples": [
        "Trying to move work unit to testing status should fail with error if feature file has [role]/[action] placeholders"
      ]
    },
    "COV-031": {
      "id": "COV-031",
      "title": "Test: Support custom output path for generate-foundation-md",
      "status": "done",
      "createdAt": "2025-10-15T00:11:06.192Z",
      "updatedAt": "2025-10-19T13:17:25.558Z",
      "description": "Feature: generate-foundation-md. Status: CREATE_TEST_ONLY. No test found for custom output path option.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:18.861Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T05:19:25.404Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:19:33.637Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:20:18.071Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:20:19.824Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T13:13:06.763Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T13:17:25.285Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T13:17:25.559Z"
        }
      ],
      "rules": [
        "generate-foundation-md must support custom output path option"
      ],
      "examples": [
        "'fspec generate-foundation-md --output custom/path.md' should create file at custom path"
      ]
    },
    "COV-032": {
      "id": "COV-032",
      "title": "Test: Support custom output path for generate-tags-md",
      "status": "done",
      "createdAt": "2025-10-15T00:11:16.150Z",
      "updatedAt": "2025-10-15T00:46:36.449Z",
      "description": "Feature: generate-tags-md. Status: CREATE_TEST_ONLY. No test found for custom output path option.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:20.631Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:46:35.511Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:46:35.806Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:46:36.103Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:46:36.450Z"
        }
      ],
      "rules": [
        "generate-tags-md must support custom output path option"
      ],
      "examples": [
        "'fspec generate-tags-md --output custom/path.md' should create file at custom path"
      ]
    },
    "COV-033": {
      "id": "COV-033",
      "title": "Test: List all scenarios for multiple work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:16.442Z",
      "updatedAt": "2025-10-15T05:24:22.365Z",
      "description": "Feature: get-scenarios. Status: CREATE_TEST_ONLY. No test found for listing scenarios from multiple work units simultaneously.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:22.406Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T05:24:21.188Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:24:21.481Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:24:22.071Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:24:22.366Z"
        }
      ],
      "rules": [
        "get-scenarios must support listing scenarios from multiple work units"
      ],
      "examples": [
        "'fspec get-scenarios AUTH-001 AUTH-002' should list scenarios from both work units"
      ]
    },
    "COV-034": {
      "id": "COV-034",
      "title": "Test: Rollback if markdown generation fails",
      "status": "done",
      "createdAt": "2025-10-15T00:11:16.747Z",
      "updatedAt": "2025-10-15T00:47:53.359Z",
      "description": "Feature: register-tag-json-backed. Status: CREATE_TEST_ONLY. No test found for rollback behavior on TAGS.md generation failure.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:24.174Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:47:52.447Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:47:52.752Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:47:53.056Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:47:53.360Z"
        }
      ],
      "rules": [
        "Tag registration must rollback if TAGS.md generation fails"
      ],
      "examples": [
        "If TAGS.md generation errors, tags.json should revert to previous state"
      ]
    },
    "COV-035": {
      "id": "COV-035",
      "title": "Test: Update statistics after registering tag",
      "status": "done",
      "createdAt": "2025-10-15T00:11:17.039Z",
      "updatedAt": "2025-10-15T00:48:04.694Z",
      "description": "Feature: register-tag-json-backed. Status: CREATE_TEST_ONLY. No test verifies statistics section is updated when registering tags.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:25.928Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:48:03.784Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:48:04.090Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:48:04.395Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:48:04.694Z"
        }
      ],
      "rules": [
        "Statistics section must be updated when tag is registered"
      ],
      "examples": [
        "After registering new tag, TAGS.md statistics should show incremented tag count"
      ]
    },
    "COV-036": {
      "id": "COV-036",
      "title": "Test: List scenario tags with category information",
      "status": "done",
      "createdAt": "2025-10-15T00:11:27.483Z",
      "updatedAt": "2025-10-15T00:49:36.550Z",
      "description": "Feature: scenario-level-tag-management. Status: CREATE_TEST_ONLY. Test exists for listing tags but doesn't verify category information is shown.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:27.690Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T00:49:35.622Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T00:49:35.928Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T00:49:36.234Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T00:49:36.550Z"
        }
      ],
      "rules": [
        "Scenario tags must be listed with category information"
      ],
      "examples": [
        "Tag display should show category grouping"
      ]
    },
    "COV-037": {
      "id": "COV-037",
      "title": "Test: Show steps with proper indentation (text format)",
      "status": "done",
      "createdAt": "2025-10-15T00:11:27.777Z",
      "updatedAt": "2025-10-15T03:17:39.051Z",
      "description": "Feature: show-acceptance-criteria. Status: CREATE_TEST_ONLY. Tests exist for markdown format but no specific test for text format indentation.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:29.448Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:27.565Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:38.457Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:38.756Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:39.052Z"
        }
      ]
    },
    "COV-038": {
      "id": "COV-038",
      "title": "Test: Handle malformed JSON file",
      "status": "done",
      "createdAt": "2025-10-15T00:11:28.072Z",
      "updatedAt": "2025-10-15T05:26:37.315Z",
      "description": "Feature: validate-json-schema. Status: CREATE_TEST_ONLY. No test found for malformed/unparseable JSON files.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:31.213Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T05:26:12.060Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:26:36.715Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:26:37.018Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:26:37.315Z"
        }
      ]
    },
    "COV-039": {
      "id": "COV-039",
      "title": "Test: Show work unit with all dependencies",
      "status": "done",
      "createdAt": "2025-10-15T00:11:28.367Z",
      "updatedAt": "2025-10-15T03:17:41.481Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No dedicated show/display test for work unit with all dependency types visible.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:32.974Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:30.931Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:40.880Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:41.181Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:41.482Z"
        }
      ]
    },
    "COV-040": {
      "id": "COV-040",
      "title": "Test: Display dependency graph for single work unit",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.027Z",
      "updatedAt": "2025-10-15T03:17:44.118Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. Export dependency graph test exists but not display for single work unit.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:34.742Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:32.661Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:43.518Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:43.817Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:44.119Z"
        }
      ]
    },
    "COV-041": {
      "id": "COV-041",
      "title": "Test: Show all work units blocked by specific unit",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.336Z",
      "updatedAt": "2025-10-15T03:17:46.469Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No query test for finding all work units blocked by a specific unit.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:36.502Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.064Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:45.868Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:46.173Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:46.469Z"
        }
      ]
    },
    "COV-042": {
      "id": "COV-042",
      "title": "Test: Find all currently blocked work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.639Z",
      "updatedAt": "2025-10-15T03:17:48.816Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No test for querying all blocked work units.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:38.265Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.372Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:48.218Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:48.519Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:48.816Z"
        }
      ]
    },
    "COV-043": {
      "id": "COV-043",
      "title": "Test: Show impact analysis when completing work unit",
      "status": "done",
      "createdAt": "2025-10-15T00:11:38.944Z",
      "updatedAt": "2025-10-15T03:17:52.275Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No test for impact analysis feature.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:40.036Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.678Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:17:51.680Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:17:51.977Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:17:52.276Z"
        }
      ]
    },
    "COV-044": {
      "id": "COV-044",
      "title": "Test: Show dependency chain depth",
      "status": "done",
      "createdAt": "2025-10-15T00:11:48.157Z",
      "updatedAt": "2025-10-15T03:18:04.022Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_TEST_ONLY. No test for calculating/displaying dependency chain depth.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:41.799Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:42.978Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:03.423Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:03.725Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:04.023Z"
        }
      ]
    },
    "COV-045": {
      "id": "COV-045",
      "title": "Test: Calculate critical path",
      "status": "done",
      "createdAt": "2025-10-15T00:11:48.451Z",
      "updatedAt": "2025-10-15T03:18:06.429Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_BOTH. No tests or implementation found for critical path calculation.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:43.559Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:43.290Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:05.829Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:06.128Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:06.429Z"
        }
      ]
    },
    "COV-046": {
      "id": "COV-046",
      "title": "Test: Identify bottleneck work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:48.741Z",
      "updatedAt": "2025-10-15T04:54:36.576Z",
      "description": "COMPLETED: Tests written, implementation done, coverage linked. query-bottlenecks.ts working correctly.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:45.332Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T04:04:02.216Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T04:52:38.745Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T04:54:16.382Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T04:54:36.588Z"
        }
      ],
      "rules": [
        "A bottleneck is a work unit that blocks multiple other work units (directly or transitively)",
        "Only work units NOT in 'done' status are bottlenecks (completed work doesn't block)",
        "Bottleneck score = total work units blocked (direct blocks + transitive blocks)",
        "Rank bottlenecks by score (highest to lowest) to prioritize what to complete first",
        "Only blocks/blockedBy relationships. dependsOn is a soft dependency that doesn't prevent work from starting, so it shouldn't factor into bottleneck calculation.",
        "Include bottlenecks with score >= 2 (blocking 2+ work units). A work unit blocking only 1 other is not significant enough to be called a bottleneck.",
        "No. Work units in 'blocked' status cannot be progressed, so they should not be identified as bottlenecks to prioritize. Only consider work units in states that can be actively worked on (backlog, specifying, testing, implementing, validating)."
      ],
      "examples": [
        "AUTH-001 blocks API-001 and UI-001 directly → bottleneck score: 2 (blocks 2 work units)",
        "DB-001 blocks API-001, API-001 blocks UI-001 → DB-001 bottleneck score: 2 (1 direct + 1 transitive)",
        "AUTH-001 blocks API-001, API-002, API-003, and API-001 blocks UI-001 → AUTH-001 score: 4 (highest bottleneck)",
        "DEPLOY-001 status='done' and blocks UI-001 → NOT a bottleneck (already complete)",
        "UI-001 has no 'blocks' relationships → bottleneck score: 0 (not a bottleneck)"
      ],
      "questions": [
        {
          "text": "@human: Should bottleneck calculation include 'dependsOn' relationships or only 'blocks/blockedBy'?",
          "selected": true,
          "answer": "No. Work units in 'blocked' status cannot be progressed, so they should not be identified as bottlenecks to prioritize. Only consider work units in states that can be actively worked on (backlog, specifying, testing, implementing, validating)."
        },
        {
          "text": "@human: Should we consider work unit estimates when ranking bottlenecks (e.g., 8-point story blocks more value than 1-point)?",
          "selected": true,
          "answer": "Only blocks/blockedBy relationships. dependsOn is a soft dependency that doesn't prevent work from starting, so it shouldn't factor into bottleneck calculation."
        },
        {
          "text": "@human: What is the minimum bottleneck score to be included in output (1+, 2+, 3+)?",
          "selected": true,
          "answer": "No. For simplicity, rank bottlenecks by count of blocked work units only. Estimate weighting could be a future enhancement."
        },
        {
          "text": "@human: Should work units in 'blocked' status be considered bottlenecks even though they can't progress themselves?",
          "selected": true,
          "answer": "Include bottlenecks with score >= 2 (blocking 2+ work units). A work unit blocking only 1 other is not significant enough to be called a bottleneck."
        }
      ],
      "userStory": {
        "role": "project manager or AI agent",
        "action": "identify bottleneck work units blocking the most work",
        "benefit": "I can prioritize completing high-impact work to unblock the project"
      },
      "assumptions": [
        "No. For simplicity, rank bottlenecks by count of blocked work units only. Estimate weighting could be a future enhancement."
      ]
    },
    "COV-047": {
      "id": "COV-047",
      "title": "Test: Auto-suggest dependency relationships",
      "status": "done",
      "createdAt": "2025-10-15T00:11:49.033Z",
      "updatedAt": "2025-10-15T05:05:29.014Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_BOTH. No tests or implementation found for auto-suggesting dependencies.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:47.103Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T04:04:03.849Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:04:14.467Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:05:25.400Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:05:29.015Z"
        }
      ],
      "rules": [
        "Auto-suggest analyzes work unit metadata (title, description, epic, prefix) to recommend likely dependency relationships",
        "Sequential IDs in same prefix suggest dependency (AUTH-001 → AUTH-002 implies AUTH-002 depends on AUTH-001)",
        "Build/Test pairs suggest dependency (work with 'Test X' depends on 'Build X')",
        "Infrastructure before features (e.g., 'Setup Auth' should be suggested as blocker for 'Login Flow')",
        "Suggestions are recommendations only - user must confirm before creating dependency relationships"
      ],
      "examples": [
        "AUTH-001 'Setup OAuth' and AUTH-002 'Login Flow' → Suggest: AUTH-002 depends on AUTH-001 (sequential IDs)",
        "'Build User API' and 'Test User API' → Suggest: 'Test User API' depends on 'Build User API' (build/test pair)",
        "'Database Schema Migration' and 'Add User Data' → Suggest: 'Add User Data' depends on 'Database Schema Migration' (infrastructure first)",
        "Work units in same epic 'User Management' → Suggest: relatesTo relationships for context",
        "AUTH-003 with no semantic relationship to AUTH-001 or AUTH-002 → No suggestion (avoid false positives)"
      ],
      "questions": [
        {
          "text": "@human: Should auto-suggest use AI/LLM for semantic analysis or only rule-based heuristics?",
          "selected": true,
          "answer": "Start with rule-based heuristics only (simpler, faster, no external dependencies). AI/LLM integration could be a future enhancement."
        },
        {
          "text": "@human: What confidence threshold should be used for suggestions (e.g., only suggest if >70% confidence)?",
          "selected": true,
          "answer": "No confidence scoring initially. Suggest only when rules match clearly (e.g., exact sequential IDs, exact 'Build X'/'Test X' match). Avoid ambiguous suggestions."
        },
        {
          "text": "@human: Should suggestions be presented interactively or in batch for approval?",
          "selected": true,
          "answer": "Batch mode. Display all suggestions and let user review/approve them together. Interactive mode could be added later with --interactive flag."
        },
        {
          "text": "@human: Should the system learn from user acceptance/rejection of suggestions over time?",
          "selected": true,
          "answer": "No learning capability in v1. Keep it simple and deterministic. Machine learning could be considered for future versions."
        }
      ],
      "userStory": {
        "role": "AI agent or developer",
        "action": "receive automatic suggestions for dependency relationships between work units",
        "benefit": "I can quickly establish connections without manually analyzing all work units"
      },
      "assumptions": [
        "Start with rule-based heuristics only (simpler, faster, no external dependencies). AI/LLM integration could be a future enhancement.",
        "No confidence scoring initially. Suggest only when rules match clearly (e.g., exact sequential IDs, exact 'Build X'/'Test X' match). Avoid ambiguous suggestions.",
        "Batch mode. Display all suggestions and let user review/approve them together. Interactive mode could be added later with --interactive flag.",
        "No learning capability in v1. Keep it simple and deterministic. Machine learning could be considered for future versions."
      ]
    },
    "COV-048": {
      "id": "COV-048",
      "title": "Test: Detect orphaned work units",
      "status": "done",
      "createdAt": "2025-10-15T00:11:58.176Z",
      "updatedAt": "2025-10-15T05:15:43.344Z",
      "description": "Feature: work-unit-dependency-management. Status: CREATE_BOTH. No tests or implementation found for orphan detection.",
      "epic": "test-coverage",
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:48.863Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T04:04:05.720Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T05:15:23.827Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T05:15:41.265Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T05:15:43.345Z"
        }
      ],
      "rules": [
        "An orphaned work unit has NO dependency relationships (no blocks, blockedBy, dependsOn, or relatesTo)",
        "An orphaned work unit has NO epic assignment (epic field is null or empty)",
        "Orphaned work units are isolated from the project context and may indicate abandoned or misconfigured work",
        "Detecting orphans helps identify work that should be connected, reassigned, or deleted",
        "No. Prefix alone does not provide sufficient context. A work unit must have either an epic OR at least one relationship to not be considered orphaned.",
        "Yes. Show suggested actions: 'Assign to epic', 'Add relationship to related work', 'Delete if no longer needed'. Make it actionable, not just informational."
      ],
      "examples": [
        "UI-999 has no epic, no blocks, no blockedBy, no dependsOn, no relatesTo → ORPHANED (completely isolated)",
        "AUTH-001 has epic='user-management' but no relationships → NOT orphaned (has epic context)",
        "API-001 has no epic but dependsOn DB-001 → NOT orphaned (has dependency relationship)",
        "TEST-042 has no epic, no relationships, status='done' → ORPHANED (even done work can be orphaned)",
        "MISC-005 has relatesTo relationship to SEC-001 → NOT orphaned (any relationship counts)"
      ],
      "questions": [
        {
          "text": "@human: Should work units with only a prefix (but no epic or relationships) be considered orphaned?",
          "selected": true,
          "answer": "No. Prefix alone does not provide sufficient context. A work unit must have either an epic OR at least one relationship to not be considered orphaned."
        },
        {
          "text": "@human: Should orphan detection exclude work units in 'done' status (completed work may not need connections)?",
          "selected": true,
          "answer": "No. Include all work units regardless of status. Even 'done' work can be orphaned and may indicate cleanup needed. Use --exclude-done flag if user wants to filter them out."
        },
        {
          "text": "@human: Should the command suggest actions for orphaned work (e.g., 'assign epic', 'add dependency', 'delete')?",
          "selected": true,
          "answer": "Yes. Show suggested actions: 'Assign to epic', 'Add relationship to related work', 'Delete if no longer needed'. Make it actionable, not just informational."
        }
      ],
      "userStory": {
        "role": "project manager or AI agent",
        "action": "detect orphaned work units with no epic or dependency relationships",
        "benefit": "I can identify isolated work that needs to be connected, reassigned, or cleaned up"
      },
      "assumptions": [
        "No. Include all work units regardless of status. Even 'done' work can be orphaned and may indicate cleanup needed. Use --exclude-done flag if user wants to filter them out."
      ]
    },
    "COV-049": {
      "id": "COV-049",
      "title": "Test: Query by status and prefix",
      "status": "done",
      "createdAt": "2025-10-15T00:11:58.467Z",
      "updatedAt": "2025-10-15T03:18:09.151Z",
      "description": "Feature: work-unit-query-and-reporting. Status: CREATE_TEST_ONLY. Status query exists, epic query exists, but no prefix query test.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:50.614Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:45.037Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:08.555Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:08.852Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:09.152Z"
        }
      ]
    },
    "COV-050": {
      "id": "COV-050",
      "title": "Test: Query with sorting by updated date",
      "status": "done",
      "createdAt": "2025-10-15T00:11:58.760Z",
      "updatedAt": "2025-10-15T03:18:11.671Z",
      "description": "Feature: work-unit-query-and-reporting. Status: CREATE_TEST_ONLY. No test found for sorting functionality.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:52.377Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:45.345Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:11.075Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:11.374Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:11.672Z"
        }
      ]
    },
    "COV-051": {
      "id": "COV-051",
      "title": "Test: Export filtered results to CSV",
      "status": "done",
      "createdAt": "2025-10-15T00:11:59.052Z",
      "updatedAt": "2025-10-15T03:18:14.131Z",
      "description": "Feature: work-unit-query-and-reporting. Status: CREATE_TEST_ONLY. JSON export exists but no CSV export test.",
      "epic": "test-coverage",
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T00:35:54.123Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T03:12:45.650Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T03:18:13.529Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T03:18:13.832Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T03:18:14.132Z"
        }
      ]
    },
    "BUG-007": {
      "id": "BUG-007",
      "title": "generate-coverage does not detect new scenarios in existing feature files",
      "status": "done",
      "createdAt": "2025-10-15T04:09:40.314Z",
      "updatedAt": "2025-10-15T14:28:00.000Z",
      "description": "When new scenarios are added to an existing feature file, the generate-coverage command does not update the .coverage file to include them. This blocks the link-coverage workflow in ACDD.",
      "epic": "test-coverage",
      "children": [],
      "userStory": {
        "role": "developer following ACDD workflow",
        "action": "have generate-coverage detect and add new scenarios to existing .coverage files",
        "benefit": "I can link test coverage for new scenarios without manual JSON editing"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T04:10:11.653Z"
        }
      ],
      "rules": [
        "generate-coverage should compare feature file scenarios against coverage file scenarios",
        "If feature file has MORE scenarios than coverage file, add missing scenarios with empty testMappings array",
        "If coverage file has scenarios NOT in feature file, remove them (cleanup orphaned entries)",
        "Preserve existing test/impl mappings for unchanged scenarios (don't overwrite)",
        "Update stats section to reflect new scenario count and coverage percentage",
        "Yes. generate-coverage must be idempotent - safe to run multiple times. It should UPDATE existing coverage files, not overwrite them."
      ],
      "examples": [
        "REPRODUCTION: work-unit-dependency-management.feature has 42 scenarios, but .coverage file only has 39 scenario entries",
        "MISSING: Scenario 'Identify bottleneck work units blocking the most work' (line 501-518) NOT in coverage file",
        "MISSING: Scenario 'Auto-suggest dependency relationships based on work unit metadata' (line 520-536) NOT in coverage file",
        "MISSING: Scenario 'Detect orphaned work units with no epic or dependencies' (line 538-553) NOT in coverage file",
        "COMMAND RESULT: 'fspec generate-coverage' runs without error but does NOT add missing scenarios",
        "ERROR WHEN LINKING: 'fspec link-coverage work-unit-dependency-management --scenario \"Identify bottleneck...\"' fails with 'Scenario not found'",
        "FILE: spec/features/work-unit-dependency-management.feature - grep shows 42 scenarios: 'grep -c \"^  Scenario:\" spec/features/work-unit-dependency-management.feature' returns 42",
        "FILE: spec/features/work-unit-dependency-management.feature.coverage - only has 39 entries in scenarios array (verified by reading JSON)",
        "EXACT LINE: Feature file line 501: '@COV-046' tag, Scenario: 'Identify bottleneck work units blocking the most work' - MISSING from coverage",
        "EXACT LINE: Feature file line 520: '@COV-047' tag, Scenario: 'Auto-suggest dependency relationships based on work unit metadata' - MISSING from coverage",
        "EXACT LINE: Feature file line 538: '@COV-048' tag, Scenario: 'Detect orphaned work units with no epic or dependencies' - MISSING from coverage",
        "COMMAND TO REPRODUCE: 1) Add new scenario to existing .feature file 2) Run 'fspec generate-coverage' 3) Check .coverage file - new scenario NOT added 4) Try 'fspec link-coverage <feature> --scenario <name>' - ERROR: Scenario not found"
      ],
      "questions": [
        {
          "text": "@human: Should generate-coverage be idempotent (safe to run multiple times without data loss)?",
          "selected": true,
          "answer": "Yes. generate-coverage must be idempotent - safe to run multiple times. It should UPDATE existing coverage files, not overwrite them."
        },
        {
          "text": "@human: Should generate-coverage create backup of .coverage file before modifying?",
          "selected": true,
          "answer": "No backup needed. Since it's idempotent and git tracks changes, users can revert if needed."
        },
        {
          "text": "@human: Should there be a --force flag to overwrite coverage files vs update-only mode?",
          "selected": true,
          "answer": "No. Default behavior should be update mode (merge new scenarios). Keep it simple."
        }
      ],
      "estimate": 3,
      "assumptions": [
        "No backup needed. Since it's idempotent and git tracks changes, users can revert if needed.",
        "No. Default behavior should be update mode (merge new scenarios). Keep it simple."
      ]
    },
    "BUG-008": {
      "id": "BUG-008",
      "title": "generate-scenarios produces malformed Gherkin steps from example titles",
      "status": "done",
      "createdAt": "2025-10-15T04:16:17.565Z",
      "updatedAt": "2025-10-15T14:24:00.000Z",
      "description": "The generate-scenarios command is creating scenarios with malformed Given/When/Then steps that include the entire example title text instead of proper Gherkin syntax. This results in invalid scenarios with prefill placeholders and prevents moving work units through the workflow.",
      "children": [],
      "userStory": {
        "role": "developer using fspec with Example Mapping",
        "action": "have generate-scenarios create proper Gherkin Given/When/Then steps from example titles",
        "benefit": "generated scenarios are valid and don't block workflow progression with prefill errors"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T04:16:39.895Z"
        }
      ],
      "rules": [
        "Example titles that start with keywords like 'REPRODUCTION:', 'MISSING:', 'ERROR WHEN:', 'COMMAND RESULT:' should be parsed to extract the actual scenario content, not used verbatim as Given steps",
        "Generated scenarios must follow proper Gherkin structure: Given [precondition] / When [action] / Then [expected outcome]",
        "Steps should never include the full example title - they should be semantically meaningful Given/When/Then statements",
        "Scenario titles must be cleaned by removing common prefixes (REPRODUCTION, MISSING, ERROR WHEN, COMMAND RESULT, FILE, EXACT LINE, COMMAND TO REPRODUCE) to create readable scenario names",
        "Original example text must be preserved as a comment (# Example: ...) above each scenario to maintain traceability to Example Mapping"
      ],
      "examples": [
        "CURRENT: Example 'REPRODUCTION: work-unit-dependency-management.feature has 42 scenarios' → Scenario with 'Given REPRODUCTION: work-unit-dependency-management.feature has 42 scenarios, but .coverage file only has 39 scenario entries' | EXPECTED: → Scenario with 'Given a feature file exists with 42 scenarios / When I check the coverage file / Then it should have 42 scenario entries'",
        "CURRENT: Example 'MISSING: Scenario X (line 501-518) NOT in coverage file' → Generates 'Given [precondition] / When [action] / Then [expected outcome]' (placeholders\\!) | EXPECTED: → 'Given a scenario exists in feature file at lines 501-518 / When I run generate-coverage / Then the scenario should be added to the coverage file'",
        "CURRENT: Example 'ERROR WHEN LINKING: fspec link-coverage fails with Scenario not found' → Generates 'Given I have an invalid condition / When I execute ERROR WHEN LINKING...' (malformed\\!) | EXPECTED: → 'Given a scenario is missing from coverage file / When I run fspec link-coverage with that scenario name / Then it should fail with error Scenario not found'",
        "CURRENT: Example 'COMMAND RESULT: fspec generate-coverage runs without error but does NOT add missing scenarios' → 'Given I am COMMAND RESULT: fspec generate-coverage / When I runs without error...' (grammatically broken\\!) | EXPECTED: → 'Given I have a feature file with new scenarios / When I run fspec generate-coverage / Then it should run without error / And it should NOT add missing scenarios to existing coverage files' (documents the bug behavior)",
        "CURRENT: Example 'FILE: spec/features/work-unit.feature - grep shows 42 scenarios' → 'Given I am FILE: spec/features... / When I shows 42 scenarios...' (nonsensical grammar\\!) | EXPECTED: → 'Given a feature file spec/features/work-unit.feature exists / When I count scenarios using grep / Then it should return 42 scenarios'",
        "CURRENT: Example 'COMMAND TO REPRODUCE: 1) Add scenario 2) Run command 3) Check file 4) Try link' → 'Given I am COMMAND TO REPRODUCE: 1) / When I Add new scenario...' (truncated and malformed\\!) | EXPECTED: → 'Given I add a new scenario to an existing feature file / When I run fspec generate-coverage / And I check the coverage file / Then the new scenario should NOT be added / When I try to link coverage for the scenario / Then it should fail with Scenario not found'"
      ],
      "questions": [
        {
          "text": "Should generate-scenarios attempt to parse example titles to extract semantic meaning, or should users write proper Given/When/Then examples in the first place?",
          "selected": true,
          "answer": "Clean scenario titles by removing prefixes like 'REPRODUCTION:', 'MISSING:', etc. Keep full example as comment. Use existing extractStepsFromExample() for parsing."
        },
        {
          "text": "If examples contain complex reproduction steps (multiple actions), should generate-scenarios create multiple Given/When/Then steps or a single scenario outline?",
          "selected": true,
          "answer": "Use existing extractStepsFromExample() which already generates multiple Given/When/Then steps based on pattern matching. No changes needed - current system handles this."
        },
        {
          "text": "What should happen if an example title doesn't fit the Given/When/Then structure at all (e.g., purely descriptive)?",
          "selected": true,
          "answer": "Fall back to [placeholders] which triggers prefill detection. This is already implemented in extractStepsFromExample(). No changes needed."
        }
      ],
      "estimate": 2
    },
    "FEAT-006": {
      "id": "FEAT-006",
      "title": "Work item type system - Core foundation",
      "status": "done",
      "createdAt": "2025-10-15T05:44:47.532Z",
      "updatedAt": "2025-10-15T06:39:15.374Z",
      "description": "Add support for different work item types (story, task, bug) similar to JIRA, allowing better categorization of work units based on their nature (user-facing features vs operational work vs defects)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T05:54:25.542Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T06:06:59.919Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T06:09:03.428Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-15T06:15:05.862Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T06:25:53.799Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T06:26:03.435Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T06:26:09.298Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T06:39:12.885Z",
          "reason": "All child work units complete (FEAT-007, 008, 009, 010 all done)"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T06:39:15.377Z",
          "reason": "All child work units done, full test suite passes (1002/1002), build succeeds"
        }
      ],
      "userStory": {
        "role": "AI agent managing project work with fspec",
        "action": "categorize work units by type (story, task, bug)",
        "benefit": "I can track meta-work and housekeeping through Kanban without violating ACDD discipline for user-facing features"
      },
      "rules": [
        "Work units must have a type field: 'story', 'task', or 'bug'",
        "Default type is 'story' for backward compatibility with existing work units",
        "Stories require full ACDD workflow: backlog → specifying → testing → implementing → validating → done",
        "Tasks use simplified workflow: backlog → in-progress → done (+ blocked)",
        "Bugs use same ACDD workflow as stories but may skip Example Mapping in favor of reproduction scenarios",
        "Stories must have linked feature file before moving to testing state",
        "Tasks do not require feature files or tests",
        "Bugs must have reproduction scenario in feature file before moving to testing state",
        "Yes, existing work units without type field automatically get type='story' (backward compatible). New work units default to 'story' unless --type specified.",
        "Tasks CANNOT have feature files. Feature files represent user stories with acceptance criteria, which makes them stories by definition. Tasks are for operational work without user-facing behavior.",
        "Bugs MUST link to an existing feature file. If no feature file exists for the buggy behavior, it's a story, not a bug. Bugs fix/update existing documented features. Validation error should explain: 'Bugs must link to existing feature file. If feature has no spec, create a story instead.'",
        "Tasks support Example Mapping fields (rules, examples, questions) but they are OPTIONAL and only for clarity about what needs to be done. Unlike stories, tasks don't require these fields to be filled before progressing.",
        "Treat all estimates the same way (combined velocity), but reporting commands should have ability to break down metrics by type (--type=story, --type=task, --type=bug) or show combined.",
        "Type is immutable once set. If wrong, work unit must be deleted and recreated with correct type. This prevents confusion about workflow rules changing mid-flight.",
        "All work unit types can use 'in-progress' state. Stories map: specifying/testing/implementing/validating → all represent 'in-progress'. Tasks use 'in-progress' explicitly. Bugs follow story states. This provides consistency across types.",
        "Tasks use workflow: backlog → specifying → implementing → validating → done (+ blocked). They skip 'testing' state since no tests are required.",
        "Tasks in specifying state do NOT require feature files (unlike stories). Specifying is for internal clarity only - can use description, rules, examples fields.",
        "Yes, remove old rule #4. The corrected workflow is: backlog → specifying → implementing → validating → done. Tasks need 'specifying' for clarity but skip 'testing' since no tests required."
      ],
      "examples": [
        "Create story work unit: 'fspec create-work-unit AUTH \"User Login\" --type=story' creates AUTH-XXX with type='story'",
        "Create task work unit: 'fspec create-work-unit CLEAN \"Audit coverage files\" --type=task' creates CLEAN-XXX with type='task'",
        "Create bug work unit: 'fspec create-work-unit BUG \"Login fails with @ symbol\" --type=bug' creates BUG-XXX with type='bug'",
        "Default type: 'fspec create-work-unit AUTH \"Feature\"' creates work unit with type='story' (backward compatible)",
        "Filter by type: 'fspec list-work-units --type=task' shows only task work units",
        "Task workflow: CLEAN-001 moves backlog → in-progress → done (skipping specifying/testing/implementing/validating)",
        "Story validation: Moving AUTH-001 (type=story) to testing without feature file shows error 'Cannot move to testing: no feature file linked'",
        "Task flexibility: CLEAN-001 (type=task) can move from backlog directly to done without any validation errors",
        "Board visualization: 'fspec board' shows three sections: STORIES (full workflow), TASKS (simplified), BUGS (full workflow)",
        "Task workflow detail: CLEAN-001 (type=task) moves backlog → specifying (clarify what to do) → implementing (do the work) → validating (verify done) → done",
        "Task specifying phase: CLEAN-001 in specifying state can use optional Example Mapping (rules, examples) to clarify work scope before implementing"
      ],
      "questions": [
        {
          "text": "@human: Should existing work units without a type field automatically get type='story', or should we require manual migration?",
          "selected": true,
          "answer": "Yes, existing work units without type field automatically get type='story' (backward compatible). New work units default to 'story' unless --type specified."
        },
        {
          "text": "@human: Can a task optionally have a feature file linked for documentation purposes, or should tasks be completely prohibited from having feature files?",
          "selected": true,
          "answer": "Tasks CANNOT have feature files. Feature files represent user stories with acceptance criteria, which makes them stories by definition. Tasks are for operational work without user-facing behavior."
        },
        {
          "text": "@human: Should the board command show all three types together, or should it have separate views/sections for each type?",
          "selected": true,
          "answer": "No changes to board visualization. All types shown in same board view with their respective workflow states."
        },
        {
          "text": "@human: For bugs, should we enforce that they must link to an existing feature file (the one with the bug), or should they create a separate bug-fix feature file?",
          "selected": true,
          "answer": "Bugs MUST link to an existing feature file. If no feature file exists for the buggy behavior, it's a story, not a bug. Bugs fix/update existing documented features. Validation error should explain: 'Bugs must link to existing feature file. If feature has no spec, create a story instead.'"
        },
        {
          "text": "@human: Should tasks support Example Mapping fields (rules, examples, questions), or should those be story/bug-only features?",
          "selected": true,
          "answer": "Tasks support Example Mapping fields (rules, examples, questions) but they are OPTIONAL and only for clarity about what needs to be done. Unlike stories, tasks don't require these fields to be filled before progressing."
        },
        {
          "text": "@human: Should we track different velocity metrics for stories vs tasks vs bugs, or treat all estimates the same way?",
          "selected": true,
          "answer": "Treat all estimates the same way (combined velocity), but reporting commands should have ability to break down metrics by type (--type=story, --type=task, --type=bug) or show combined."
        },
        {
          "text": "@human: Can a work unit's type be changed after creation, or is it immutable once set?",
          "selected": true,
          "answer": "Type is immutable once set. If wrong, work unit must be deleted and recreated with correct type. This prevents confusion about workflow rules changing mid-flight."
        },
        {
          "text": "@human: Should 'in-progress' state be available for ALL work unit types, or should it remain task-only?",
          "selected": true,
          "answer": "All work unit types can use 'in-progress' state. Stories map: specifying/testing/implementing/validating → all represent 'in-progress'. Tasks use 'in-progress' explicitly. Bugs follow story states. This provides consistency across types."
        },
        {
          "text": "@human: Should I remove the old rule #4 that says 'Tasks use simplified workflow: backlog → in-progress → done' since it's been superseded by the corrected workflow?",
          "selected": true,
          "answer": "Yes, remove old rule #4. The corrected workflow is: backlog → specifying → implementing → validating → done. Tasks need 'specifying' for clarity but skip 'testing' since no tests required."
        }
      ],
      "assumptions": [
        "No changes to board visualization. All types shown in same board view with their respective workflow states."
      ],
      "estimate": 5,
      "epic": "work-item-types"
    },
    "FEAT-011": {
      "id": "FEAT-011",
      "title": "Prevent retroactive state walking - enforce temporal ordering",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T06:49:06.299Z",
      "updatedAt": "2025-10-15T07:07:46.452Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T06:49:30.983Z",
          "reason": "Need to add Example Mapping rules"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T07:06:20.805Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T07:06:36.424Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T07:06:42.872Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T07:07:46.453Z"
        }
      ],
      "rules": [
        "System must prevent AI agents from doing all work first, then retroactively walking through states as theater",
        "When moving to testing state: system must verify tests were created AFTER entering testing state, not before",
        "When moving to implementing state: system must verify tests currently FAIL (red phase). Tests failing proves they actually test something.",
        "When moving to validating state: system must verify tests now PASS (green phase) and implementation was modified AFTER entering implementing",
        "If work unit has artifacts (specs/tests/code) all timestamped BEFORE entering testing state, then: either delete the work unit if it has no unique value OR move it back to backlog and require proper ACDD workflow"
      ],
      "examples": [
        "FEAT-007, FEAT-008, FEAT-009, FEAT-010: All work (specs, tests, code) completed in previous session. Current session: AI moved each through specifying→testing→implementing→validating→done in 5 seconds each. System allowed it because @WORK-UNIT-ID tags existed in feature file and tests passed. Result: ACDD completely bypassed.",
        "work-item-types-for-stories-tasks-and-bugs.feature: Created before any child work units. Tests written before testing state. Implementation completed before implementing state. Feature file tagged with @FEAT-007 @FEAT-008 @FEAT-009 @FEAT-010 retroactively. checkScenariosExist() found tags and allowed testing state entry.",
        "System checks: (1) Does @WORK-UNIT-ID exist? YES. (2) Is state transition valid? YES. (3) Are children done? YES. Missing checks: (1) When was feature file created? (2) When were tests written? (3) Did tests fail first? (4) Was implementation written after tests?",
        "AI behavior enabled by current system: (1) Write all code in one session. (2) Tag feature file with work unit IDs. (3) Run tests to ensure they pass. (4) Walk through states as formality. (5) System approves everything. This is the opposite of ACDD.",
        "Correct ACDD sequence: (1) Enter specifying: write feature file. (2) Enter testing: write FAILING tests. (3) Run tests: verify they fail. (4) Enter implementing: write minimal code. (5) Run tests: verify they pass. (6) Enter validating: run full suite. System must enforce this temporal ordering."
      ],
      "userStory": {
        "role": "AI agent using fspec for ACDD workflow",
        "action": "ensure work is done in the correct temporal order",
        "benefit": "ACDD methodology is actually enforced, not just theatrical state walking"
      }
    },
    "DOC-004": {
      "id": "DOC-004",
      "title": "Validate Mermaid diagrams during foundation.json regeneration",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T07:36:09.439Z",
      "updatedAt": "2025-10-15T07:54:01.712Z",
      "description": "The generate-foundation-md command should validate all Mermaid diagrams in foundation.json before regenerating FOUNDATION.md. If any diagram has invalid syntax, the command should fail with detailed error information including the position in the JSON file and the specific Mermaid validation error, guiding the AI to fix and regenerate.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T07:36:16.916Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T07:45:13.894Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T07:47:31.554Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T07:51:32.720Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T07:54:01.712Z"
        }
      ],
      "userStory": {
        "role": "developer maintaining foundation.json documentation",
        "action": "validate all Mermaid diagrams when regenerating FOUNDATION.md",
        "benefit": "I catch syntax errors immediately with precise error locations and can fix them before the markdown file is written"
      },
      "rules": [
        "All Mermaid diagrams in foundation.json MUST be validated before writing FOUNDATION.md",
        "Validation errors MUST include the JSON position (architectureDiagrams array index) of the failing diagram",
        "Validation errors MUST include the diagram title for easy identification",
        "Validation errors MUST include the detailed Mermaid error message from mermaid.parse()",
        "The command MUST exit with code 1 if any diagram validation fails",
        "Error output MUST guide the AI to fix the diagram in foundation.json and regenerate",
        "Diagram validation MUST use the existing validateMermaidSyntax() function from add-diagram.ts",
        "After JSON schema validation - validate diagrams after the schema check passes",
        "Validate all diagrams at once and show all errors together - don't fail fast",
        "Yes, extract validateMermaidSyntax to src/utils/mermaid-validation.ts for reuse"
      ],
      "examples": [
        "Running 'fspec generate-foundation-md' with valid diagrams completes successfully and generates FOUNDATION.md",
        "Running 'fspec generate-foundation-md' with an invalid diagram at architectureDiagrams[2] shows: 'Error at architectureDiagrams[2] (title: \"Data Flow\"): Invalid Mermaid syntax: unexpected token' and exits with code 1",
        "Running 'fspec generate-foundation-md' with multiple invalid diagrams shows all failures with their positions, titles, and error messages",
        "Error message includes guidance: 'Fix the diagram(s) in spec/foundation.json and run fspec generate-foundation-md again'",
        "After fixing invalid diagrams in foundation.json and running 'fspec generate-foundation-md' again, the command succeeds and generates FOUNDATION.md"
      ],
      "questions": [
        {
          "text": "@human: Should validation happen BEFORE or AFTER JSON schema validation?",
          "selected": true,
          "answer": "After JSON schema validation - validate diagrams after the schema check passes"
        },
        {
          "text": "@human: Should we stop at the first invalid diagram or validate all diagrams and show all errors at once?",
          "selected": true,
          "answer": "Validate all diagrams at once and show all errors together - don't fail fast"
        },
        {
          "text": "@human: Should the validateMermaidSyntax function be extracted to a shared utility file for reuse?",
          "selected": true,
          "answer": "Yes, extract validateMermaidSyntax to src/utils/mermaid-validation.ts for reuse"
        }
      ],
      "estimate": 3
    },
    "BUG-010": {
      "id": "BUG-010",
      "title": "fspec init performs unnecessary string replacements on generic slash command template",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-15T08:07:58.029Z",
      "updatedAt": "2025-10-15T08:13:07.810Z",
      "description": "The init command replaces fspec-specific examples (user-authentication.feature, CLI-003, etc.) with generic placeholders (example-feature.feature, EXAMPLE-001). These replacements are unnecessary because the slash command file contains illustrative examples that work for any project. The replacements also cause issues when running init from fspec's own directory, overwriting the original examples. Solution: Remove all string replacement logic from generateTemplate() function.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T08:08:12.311Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T08:11:59.282Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T08:12:08.189Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T08:12:08.484Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T08:13:07.810Z"
        }
      ],
      "rules": [
        "The slash command file is generic guidance that works for any project",
        "Examples in the file are illustrative only - showing patterns not specific project details",
        "String replacements provide no value and cause issues when run from fspec directory"
      ],
      "examples": [
        "Running init from fspec dir overwrites original examples with generic ones",
        "External projects see user-authentication.feature in examples which works fine as illustration"
      ]
    },
    "EXMAP-002": {
      "id": "EXMAP-002",
      "title": "Preserve example mapping context as comments in generated feature files",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T08:34:45.292Z",
      "updatedAt": "2025-10-15T09:00:08.967Z",
      "description": "When generate-scenarios runs, embed full example mapping data (rules, examples, questions, assumptions) as comment blocks that persist through format cycles. This provides permanent context for AI and humans writing scenarios.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T08:34:53.790Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T08:39:15.384Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T08:44:19.099Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T08:57:40.553Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T09:00:08.967Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec for ACDD workflow",
        "action": "see full example mapping context when writing scenarios",
        "benefit": "I can write meaningful Given/When/Then steps based on business rules and concrete examples"
      },
      "rules": [
        "Comments in Gherkin AST MUST be preserved through format cycles",
        "Example mapping context embedded as comments MUST NOT conflict with add-architecture doc strings",
        "Generated feature files MUST contain zero scenarios initially (context-only)",
        "System-reminder MUST guide AI to write scenarios based on embedded examples",
        "Comment blocks MUST be visually distinct and easy to locate",
        "All example mapping data (rules, examples, questions, assumptions) MUST be embedded"
      ],
      "examples": [
        "FORMATTER PRESERVES COMMENTS: AI runs generate-scenarios, gets file with # comments, runs fspec format, comments are still present in file",
        "COMMENTS DON'T CONFLICT WITH ARCHITECTURE: File has # example mapping comments AND \"\"\" architecture notes doc string, both coexist without overwriting",
        "CONTEXT-ONLY GENERATION: generate-scenarios produces file with # comments + Background but ZERO scenarios, AI writes scenarios using Edit tool",
        "USER STORY IN TWO PLACES: User story appears in # comments AND in Background section, both updated when set-user-story runs",
        "SYSTEM-REMINDER GUIDES AI: After generate-scenarios, system-reminder tells AI 'write scenarios based on # EXAMPLES section', AI sees reminder and writes proper scenarios",
        "RULES IN COMMENTS INFORM SCENARIOS: # BUSINESS RULES says 'password 8+ chars', AI writes scenario with Given step checking password length",
        "ANSWERED QUESTIONS PRESERVED: # QUESTIONS section shows 'Q: OAuth support? A: Phase 2', developer reading file understands deferred decisions",
        "ASSUMPTIONS DOCUMENTED: # ASSUMPTIONS says 'email verification external', AI doesn't write scenarios for email verification",
        "VISUAL SEPARATION WITH BORDERS: Comment block has # === borders at top/bottom, easy to spot when scrolling through file",
        "MULTIPLE EXAMPLES TO SCENARIOS: # EXAMPLES has 3 items, AI writes 3 separate scenarios OR combines related ones into single scenario",
        "ADD-SCENARIO DOESN'T TOUCH COMMENTS: File has # example mapping comments, user runs add-scenario, comments remain untouched at top",
        "ADD-BACKGROUND DOESN'T TOUCH COMMENTS: File has # comments before Background, user runs add-background to update user story, comments persist",
        "PARSER PRESERVES COMMENTS IN AST: Gherkin parser reads file with # comments, ast.comments array contains comment objects with line numbers and text",
        "FORMATTER OUTPUTS COMMENTS FROM AST: formatGherkinDocument receives AST with comments, inserts comment lines at correct positions in output",
        "EMPTY EXAMPLE MAP HANDLED: Work unit has no rules/examples, generate-scenarios creates minimal comment block saying 'No example mapping data captured'",
        "PREFILL DETECTION STILL WORKS: Generated Background has [role] placeholder, prefill detector emits system-reminder about using set-user-story",
        "GIT DIFF SHOWS CONTEXT: Developer reviews PR, sees # example mapping comments in diff, understands why scenarios were written",
        "EXISTING COMMENT HANDLING: Feature file already has some # comments, generate-scenarios appends its comment block without conflict",
        "NO SCENARIOS MEANS FILE INCOMPLETE: generate-scenarios creates file with # comments + Background + zero scenarios, system-reminder says 'now write scenarios'",
        "AI USES EDIT TOOL WITH CONTEXT: AI reads file, sees # EXAMPLES: '1. User logs in with valid creds', writes Scenario with proper Given/When/Then using Edit tool"
      ],
      "assumptions": [
        "Gherkin parser (@cucumber/gherkin) already captures comments in AST",
        "Current formatter (gherkin-formatter.ts) ignores ast.comments field",
        "Comments use # syntax (Gherkin standard)",
        "Doc strings use triple quotes (architecture notes)",
        "AI agents have Edit tool access to feature files"
      ],
      "estimate": 5
    },
    "EXMAP-003": {
      "id": "EXMAP-003",
      "title": "Add system-reminder to generate-coverage command",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T08:49:29.798Z",
      "updatedAt": "2025-10-15T13:26:45.264Z",
      "description": "When generate-coverage creates coverage files, emit a system-reminder explaining that the LLM must manually link coverage using link-coverage command",
      "epic": "coverage-tracking",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T09:06:38.009Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T09:09:37.200Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T09:10:49.274Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T09:13:24.474Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T09:13:36.457Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-15T09:22:46.765Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T13:24:08.180Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T13:24:50.326Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:24:55.615Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:26:45.266Z"
        }
      ],
      "rules": [
        "Coverage files must be populated manually using link-coverage",
        "System reminder must be displayed after generate-coverage command",
        "Reminder must explain that coverage files are empty until linked",
        "Reminder must show example link-coverage commands",
        "Yes, reminder should be shown for both modes with contextual examples",
        "Yes, should mention show-coverage as verification step",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them",
        "Yes, should mention show-coverage as verification step",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them",
        "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
      ],
      "examples": [
        "User runs generate-coverage with no arguments and sees reminder",
        "User runs generate-coverage --dry-run and sees reminder",
        "User runs generate-coverage feature-name and sees reminder with feature-specific examples",
        "Reminder includes link-coverage command syntax with test file example",
        "Reminder includes link-coverage command syntax with implementation file example",
        "Reminder explains three-step ACDD workflow: write specs → link tests → link implementation"
      ],
      "questions": [
        {
          "text": "Should the reminder be shown for both single-feature and all-features modes?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        },
        {
          "text": "Should the reminder include show-coverage command as next step?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        },
        {
          "text": "Should the reminder be suppressible with a --quiet flag?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        },
        {
          "text": "Should the reminder explain the difference between generate-coverage and link-coverage?",
          "selected": true,
          "answer": "Yes, reminder should clearly explain generate-coverage creates empty files and link-coverage populates them"
        }
      ],
      "assumptions": [
        "No, reminder should always be shown as it's critical for ACDD workflow",
        "No, reminder should always be shown as it's critical for ACDD workflow",
        "No, reminder should always be shown as it's critical for ACDD workflow"
      ],
      "userStory": {
        "role": "developer using fspec with ACDD workflow",
        "action": "be reminded to manually link coverage after running generate-coverage",
        "benefit": "I don't forget the critical step of linking tests and implementation to scenarios"
      }
    },
    "HOOK-001": {
      "id": "HOOK-001",
      "title": "Kanban Lifecycle Hooks System",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T10:55:43.651Z",
      "updatedAt": "2025-10-21T00:50:35.164Z",
      "description": "Implement a hooks system similar to Claude Code hooks that allows executing custom commands before/after Kanban state transitions. Hooks are configured in spec/fspec-hooks.json and scripts live in spec/hooks/ directory. Enables quality gates, test automation, notifications, and CI/CD integration at each ACDD workflow stage.",
      "children": [
        "HOOK-002",
        "HOOK-003",
        "HOOK-004",
        "HOOK-005",
        "HOOK-006",
        "HOOK-007",
        "HOOK-008",
        "HOOK-009"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T10:55:52.838Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T13:28:29.038Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T13:28:40.015Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:28:40.379Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:28:40.739Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-20T22:40:32.638Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T00:50:33.128Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T00:50:34.521Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T00:50:34.844Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T00:50:35.168Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "configure lifecycle hooks to run custom scripts at Kanban transition points",
        "benefit": "I can automate quality gates, testing, notifications, and CI/CD workflows throughout the ACDD process"
      },
      "rules": [
        "Hooks are configured in spec/fspec-hooks.json file",
        "Hook scripts live in spec/hooks/ directory",
        "Hooks trigger before and after Kanban state transitions (pre-* and post-*)",
        "Hooks can be blocking (prevent transition on failure) or non-blocking (run but don't block)",
        "Hooks receive work unit context as JSON via stdin",
        "Hooks can trigger on Example Mapping actions (add-rule, add-example, add-question, answer-question)",
        "Hooks can trigger on generation commands (generate-scenarios, generate-coverage, generate-foundation-md, generate-tags-md)",
        "Hooks can trigger on coverage operations (link-coverage, unlink-coverage, audit-coverage)",
        "Hooks can block create operations (prevent resource creation if conditions not met)",
        "Hooks can block delete operations (prevent accidental deletion of critical resources)",
        "Hooks can return structured system messages that fspec passes back to the AI agent",
        "Blocking hooks that fail will halt the command and return an error with the hook's system message",
        "Hook system messages can include instructions, warnings, suggestions, or error details for the AI to act upon",
        "Hooks can return structured feedback (JSON) that AI agents consume to improve ACDD workflow",
        "Hooks enforce ACDD ordering by blocking transitions when prerequisites are not met",
        "Hooks can spawn separate Claude Code sessions with specific personas (roles) for peer review and validation",
        "Multi-agent hooks enable AI pair programming with different expertise (reviewer, QA, security, BDD expert, product owner)",
        "fspec provides the hooks framework and execution engine, users write their own hook scripts",
        "Hook scripts can be in any language (bash, python, node, etc) as long as they are executable",
        "fspec passes work unit context to hooks via stdin (JSON) and environment variables",
        "Hook scripts return exit codes and optional JSON output to fspec for processing",
        "Hooks can trigger on program lifecycle events (startup and exit)",
        "Startup hooks run before command logic executes (for setup, validation, or blocking)",
        "Exit hooks receive command output and can intercept, modify, or augment the response before returning to user",
        "Sequential execution only. Hooks for the same event run one after another in the order defined in fspec-hooks.json. This provides predictable execution order, easier debugging, and allows later hooks to depend on earlier hooks' side effects.",
        "No skip mechanism. When a blocking hook fails, the command is blocked and the user must fix the issue. To bypass a hook, the user must edit spec/fspec-hooks.json to remove or disable it (more intentional than a flag). This maintains discipline and ensures hooks enforce their intended policies.",
        "Always run for all work units. No matcher system. This keeps the framework simple and predictable. If users need conditional execution, they can implement it inside their hook scripts by reading the work unit context and exiting early if conditions aren't met.",
        "Default timeout is 60 seconds (matching Claude Code). Hooks can override with 'timeout' field in fspec-hooks.json. Global default can be set in 'global.timeout'. When timeout is exceeded, the hook process is killed and an error is returned.",
        "Plain stdout/stderr only. Exit code determines success (0) or failure (non-zero). Hook output is displayed as-is to the user. If blocking hook fails (exit != 0), fspec shows stderr in a system-reminder block for AI agent consumption. This keeps hooks simple and works with any tool.",
        "No dry-run mode. Users can use 'fspec list-hooks' to see configured hooks and 'fspec validate-hooks' to validate configuration syntax. To test a hook, users can temporarily make it non-blocking or run it manually outside of fspec.",
        "CLI commands 'fspec add-hook' and 'fspec remove-hook' manage hooks in fspec-hooks.json programmatically",
        "No chaining. Each hook receives the same original work unit context via stdin. Hooks execute sequentially but independently. If users need chaining logic, they can implement it inside their hook scripts (e.g., read files left by previous hooks or use pipes within the script).",
        "No chaining for any hooks. All hooks (event hooks and exit hooks) receive the original context/output via stdin. Hooks execute sequentially but independently for side effects (validation, logging, notifications). The original command output is returned to the user unchanged by hooks.",
        "Hooks inherit the parent process environment naturally (as spawned child processes). fspec does NOT set custom FSPEC_* environment variables. Hooks receive all context via stdin as JSON. Hooks are independent programs that manage their own environment.",
        "Support optional conditions in hook configuration. Hooks can specify 'condition' object with fields like 'tags', 'prefix', 'epic', 'estimateMin', 'estimateMax'. If condition doesn't match, hook is skipped. If no condition specified, hook always runs. This allows context-aware hooks without requiring logic in every script.",
        "Support hooks for ANY fspec command using convention: 'pre-<command-name>' and 'post-<command-name>'. Examples: pre-create-work-unit, post-add-rule, pre-link-coverage, post-generate-scenarios. Plus special lifecycle hooks: pre-start (before any command) and pre-exit (before returning output). This makes the system extensible for current and future commands.",
        "Yes. When a blocking hook fails (exit code != 0), fspec wraps the stderr output in a <system-reminder> block for AI agent consumption. This allows hooks to provide guidance, suggestions, and instructions to AI through plain text stderr output. Non-blocking hooks just display output normally.",
        "No standard schema. Hooks output freeform text to stdout/stderr. AI agents read and interpret the text naturally. This maximizes flexibility for hook authors and keeps the framework simple. Documentation can provide examples of effective hook output patterns.",
        "No. fspec provides the hooks framework only. Users can implement multi-agent patterns (spawning multiple Claude sessions, parallel execution, etc.) in their hook scripts using standard shell tools. This keeps fspec focused and avoids framework bloat."
      ],
      "examples": [
        "Developer configures post-implementing hook to run ESLint before allowing transition to validating",
        "Developer configures post-testing hook to run Playwright tests to verify E2E scenarios work",
        "Developer configures post-done hook to send Slack notification that work unit is complete",
        "Developer configures pre-validating hook to check test coverage is above 80%",
        "Developer configures post-add-rule hook to check if rule needs clarification (AI analysis)",
        "Developer configures post-generate-scenarios hook to auto-format generated feature files",
        "Developer configures post-generate-coverage hook to run test suite with coverage reporter and extract actual line mappings",
        "Developer configures post-answer-question hook to automatically add answer as rule or assumption based on AI classification",
        "Developer configures pre-generate-scenarios hook to validate that all questions are answered before allowing scenario generation",
        "Developer configures post-link-coverage hook to verify linked files exist and line ranges are valid",
        "Developer configures pre-create-work-unit hook to block creation if work unit title contains placeholder text like TODO or TBD",
        "Developer configures pre-delete-work-unit hook to prevent deletion of work units with status 'implementing' or 'validating'",
        "Developer configures pre-unlink-coverage hook to confirm before removing coverage mappings (safety check)",
        "Developer configures pre-delete-scenario hook to block deletion if scenario has existing test coverage",
        "Code quality hook fails with message: 'BLOCKED: TypeScript errors in src/auth.ts:42. Fix type annotation for loginUser function before proceeding to validating state.'",
        "Coverage hook returns: 'WARNING: Test coverage is 65%, below 80% threshold. Consider adding tests for edge cases in src/validator.ts:23-45 before moving to validating.'",
        "Example mapping hook suggests: 'SUGGESTION: Question 0 contains implementation details. Consider rephrasing to focus on behavior: What should happen when... instead of How should we implement...'",
        "AI uses post-testing hook to analyze test failures and suggest missing scenarios or edge cases",
        "AI uses post-implementing hook to compare code against acceptance criteria and flag deviations",
        "AI uses post-generate-scenarios hook to review generated Gherkin and suggest improvements for clarity",
        "AI uses pre-implementing hook to verify all scenarios have corresponding test mappings before allowing code to be written",
        "AI uses post-add-example hook to detect duplicate or conflicting examples and suggest consolidation",
        "AI uses post-validating hook to analyze coverage gaps and suggest missing test scenarios",
        "Developer configures post-implementing hook to spawn a separate Claude Code session as a 'code reviewer' persona to review implementation before validating",
        "Developer configures post-generate-scenarios hook to spawn Claude Code as 'BDD expert' persona to critique Gherkin quality",
        "Developer configures post-testing hook to spawn Claude Code as 'QA engineer' persona to review test coverage and suggest edge cases",
        "Developer configures post-add-example hook to spawn Claude Code as 'product owner' persona to validate examples match business requirements",
        "Developer configures pre-done hook to spawn Claude Code as 'security auditor' persona to review code for security vulnerabilities",
        "User writes custom bash hook in spec/hooks/check-quality.sh that runs ESLint and returns JSON feedback",
        "User writes Python hook in spec/hooks/analyze-coverage.py that uses pytest-cov to generate coverage reports",
        "User writes Node.js hook in spec/hooks/validate-api.js that spawns separate Claude session for review",
        "User configures startup hook to validate project configuration and block fspec execution if settings are invalid",
        "User configures startup hook to initialize external services (database connection, API tokens) before fspec runs",
        "User configures exit hook to send fspec command results to external dashboard or logging service",
        "User configures exit hook to intercept validation errors and add project-specific troubleshooting guidance to AI agent",
        "User configures exit hook to format fspec output for different consumers (JSON for CI, markdown for humans, structured for AI)",
        "User runs 'fspec add-hook post-implementing code-quality spec/hooks/check-quality.sh --blocking' to add a new hook to configuration",
        "User runs 'fspec remove-hook post-implementing code-quality' to remove a hook from configuration"
      ],
      "questions": [
        {
          "text": "@human: Should hooks for the same event run in parallel (all at once) or sequentially (one after another)? Claude Code runs them in parallel.",
          "selected": true,
          "answer": "Sequential execution only. Hooks for the same event run one after another in the order defined in fspec-hooks.json. This provides predictable execution order, easier debugging, and allows later hooks to depend on earlier hooks' side effects."
        },
        {
          "text": "@human: When a blocking hook fails, should we provide a way for the user to override and force the transition anyway (like --skip-hooks flag)?",
          "selected": true,
          "answer": "No skip mechanism. When a blocking hook fails, the command is blocked and the user must fix the issue. To bypass a hook, the user must edit spec/fspec-hooks.json to remove or disable it (more intentional than a flag). This maintains discipline and ensures hooks enforce their intended policies."
        },
        {
          "text": "@human: Should hooks be able to match specific work units (e.g., only run for AUTH-* prefixes or specific epics)? Or always run for all work units?",
          "selected": true,
          "answer": "Always run for all work units. No matcher system. This keeps the framework simple and predictable. If users need conditional execution, they can implement it inside their hook scripts by reading the work unit context and exiting early if conditions aren't met."
        },
        {
          "text": "@human: What should the default timeout be? Claude Code uses 60 seconds. Should we allow per-hook timeout overrides?",
          "selected": true,
          "answer": "Default timeout is 60 seconds (matching Claude Code). Hooks can override with 'timeout' field in fspec-hooks.json. Global default can be set in 'global.timeout'. When timeout is exceeded, the hook process is killed and an error is returned."
        },
        {
          "text": "@human: Should hook scripts be able to return structured output (JSON) that fspec displays to the user, or just stdout/stderr?",
          "selected": true,
          "answer": "Plain stdout/stderr only. Exit code determines success (0) or failure (non-zero). Hook output is displayed as-is to the user. If blocking hook fails (exit != 0), fspec shows stderr in a system-reminder block for AI agent consumption. This keeps hooks simple and works with any tool."
        },
        {
          "text": "@human: Do you want a dry-run mode to test hooks without actually running them (just show what would execute)?",
          "selected": true,
          "answer": "No dry-run mode. Users can use 'fspec list-hooks' to see configured hooks and 'fspec validate-hooks' to validate configuration syntax. To test a hook, users can temporarily make it non-blocking or run it manually outside of fspec."
        },
        {
          "text": "@human: Should we support hook chaining where one hook's output becomes the next hook's input?",
          "selected": true,
          "answer": "No chaining for any hooks. All hooks (event hooks and exit hooks) receive the original context/output via stdin. Hooks execute sequentially but independently for side effects (validation, logging, notifications). The original command output is returned to the user unchanged by hooks."
        },
        {
          "text": "@human: What environment variables should be available to hooks? (e.g., FSPEC_WORK_UNIT_ID, FSPEC_STATUS, FSPEC_FEATURE_FILES, etc.)",
          "selected": true,
          "answer": "Hooks inherit the parent process environment naturally (as spawned child processes). fspec does NOT set custom FSPEC_* environment variables. Hooks receive all context via stdin as JSON. Hooks are independent programs that manage their own environment."
        },
        {
          "text": "@human: Should we support hook conditions (e.g., only run if estimate > 5 points, or only for @critical tagged features)?",
          "selected": true,
          "answer": "Support optional conditions in hook configuration. Hooks can specify 'condition' object with fields like 'tags', 'prefix', 'epic', 'estimateMin', 'estimateMax'. If condition doesn't match, hook is skipped. If no condition specified, hook always runs. This allows context-aware hooks without requiring logic in every script."
        },
        {
          "text": "@human: Do you want hooks for non-transition events like create-work-unit, add-dependency, or link-coverage?",
          "selected": true,
          "answer": "Support hooks for ANY fspec command using convention: 'pre-<command-name>' and 'post-<command-name>'. Examples: pre-create-work-unit, post-add-rule, pre-link-coverage, post-generate-scenarios. Plus special lifecycle hooks: pre-start (before any command) and pre-exit (before returning output). This makes the system extensible for current and future commands."
        },
        {
          "text": "@human: Should we have hooks that run on commands like create-work-unit, add-dependency, or prioritize-work-unit for workflow automation?",
          "selected": true,
          "answer": "Yes - already answered in Question 9. All fspec commands support pre/post hooks including create-work-unit, add-dependency, prioritize-work-unit, etc. This enables workflow automation like auto-prioritizing critical work units or validating dependencies."
        },
        {
          "text": "@human: Should hooks be able to provide AI-consumable feedback that influences the next steps (e.g., suggest missing scenarios, recommend refactoring)?",
          "selected": true,
          "answer": "Yes. When a blocking hook fails (exit code != 0), fspec wraps the stderr output in a <system-reminder> block for AI agent consumption. This allows hooks to provide guidance, suggestions, and instructions to AI through plain text stderr output. Non-blocking hooks just display output normally."
        },
        {
          "text": "@human: Should we provide a standard schema for hook output that includes 'suggestions', 'warnings', 'blockers', and 'insights' for AI consumption?",
          "selected": true,
          "answer": "No standard schema. Hooks output freeform text to stdout/stderr. AI agents read and interpret the text naturally. This maximizes flexibility for hook authors and keeps the framework simple. Documentation can provide examples of effective hook output patterns."
        },
        {
          "text": "@human: Should hooks support spawning multiple Claude Code sessions in parallel for multi-perspective review (e.g., security + performance + maintainability reviewers)?",
          "selected": true,
          "answer": "No. fspec provides the hooks framework only. Users can implement multi-agent patterns (spawning multiple Claude sessions, parallel execution, etc.) in their hook scripts using standard shell tools. This keeps fspec focused and avoids framework bloat."
        }
      ],
      "assumptions": [
        "Yes - already answered in Question 9. All fspec commands support pre/post hooks including create-work-unit, add-dependency, prioritize-work-unit, etc. This enables workflow automation like auto-prioritizing critical work units or validating dependencies."
      ],
      "estimate": 13,
      "epic": "hooks-system"
    },
    "HOOK-002": {
      "id": "HOOK-002",
      "title": "Hook configuration schema and validation",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:40.720Z",
      "updatedAt": "2025-10-19T13:17:31.592Z",
      "description": "Create JSON schema for spec/fspec-hooks.json. Implement configuration loading, validation, and error handling. Support hook definition with name, command, blocking flag, timeout, and conditions.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T11:50:26.414Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T11:53:06.432Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T11:55:57.393Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T11:56:34.878Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T11:57:55.781Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T13:13:13.128Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T13:17:31.318Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T13:17:31.593Z"
        }
      ],
      "userStory": {
        "role": "fspec developer",
        "action": "define hook configuration in spec/fspec-hooks.json",
        "benefit": "the hooks system knows which scripts to execute at which events"
      },
      "rules": [
        "Configuration file is spec/fspec-hooks.json in JSON format",
        "Each hook has: name (string), command (path to executable), blocking (boolean, default false), timeout (number in seconds, default 60)",
        "Hooks can have optional condition object with: tags (array), prefix (array), epic (string), estimateMin (number), estimateMax (number)",
        "Configuration must be valid JSON and conform to hooks schema",
        "Hook command paths must point to executable files",
        "Global defaults can be set in 'global' object: timeout, shell"
      ],
      "examples": [
        "Valid config with single hook: {hooks: {'post-implementing': [{name: 'lint', command: 'spec/hooks/lint.sh', blocking: true}]}}",
        "Hook with timeout override: {name: 'e2e-tests', command: 'test.sh', timeout: 300}",
        "Hook with conditions: {name: 'security', command: 'audit.sh', condition: {tags: ['@security'], prefix: ['AUTH']}}",
        "Invalid JSON causes validation error with helpful message",
        "Non-existent hook command path causes validation error",
        "Missing hook file returns clear error: 'Hook command not found: spec/hooks/missing.sh'"
      ]
    },
    "HOOK-003": {
      "id": "HOOK-003",
      "title": "Hook execution engine",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:44.580Z",
      "updatedAt": "2025-10-15T12:09:58.633Z",
      "description": "Implement core hook execution: spawn processes, pass context via stdin JSON, collect stdout/stderr, handle exit codes, implement 60s default timeout with override support, sequential execution of hooks.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:00:26.203Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:03:56.276Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:05:03.823Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:08:33.750Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:09:58.633Z"
        }
      ],
      "userStory": {
        "role": "fspec developer",
        "action": "execute hook scripts at lifecycle events",
        "benefit": "I can run custom automation, quality gates, and notifications during fspec commands"
      },
      "rules": [
        "Hook execution engine spawns child processes for each hook script",
        "Hook context is passed as JSON to stdin (workUnitId, event, timestamp, etc.)",
        "stdout and stderr are captured and displayed to user/AI agent",
        "Exit code 0 indicates success, non-zero indicates failure",
        "Hooks timeout after configured duration (default 60s)",
        "Blocking hooks halt command execution on failure (non-zero exit)",
        "Hooks execute sequentially in the order defined in config",
        "Hook processes inherit parent environment variables"
      ],
      "examples": [
        "Execute single non-blocking hook that succeeds (exit 0) - output shown, command continues",
        "Execute single non-blocking hook that fails (exit 1) - warning shown, command continues",
        "Execute blocking hook that fails - command halted, error returned to user/AI",
        "Hook times out after 60s - process killed, timeout error shown",
        "Hook receives context via stdin: {\"workUnitId\":\"AUTH-001\",\"event\":\"post-implementing\",\"timestamp\":\"2025-01-15T10:30:00Z\"}",
        "Multiple hooks execute sequentially - first runs to completion, then second starts",
        "Hook stdout/stderr captured and displayed: 'Running tests...' visible to user"
      ]
    },
    "HOOK-004": {
      "id": "HOOK-004",
      "title": "Hook discovery and event naming",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:48.300Z",
      "updatedAt": "2025-10-15T12:17:01.555Z",
      "description": "Implement hook discovery for any command using pre-/post- convention. Support special lifecycle hooks: pre-start and pre-exit. Build event name from command name dynamically.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:11:00.282Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:14:07.598Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:14:54.286Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:15:29.403Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:17:01.555Z"
        }
      ],
      "userStory": {
        "role": "fspec system",
        "action": "discover and execute hooks for lifecycle events",
        "benefit": "hooks can be triggered at the right moments during command execution"
      },
      "rules": [
        "Event names follow pre-/post- convention: pre-<command-name>, post-<command-name>",
        "Special lifecycle hooks: pre-start (before any command), pre-exit (before returning output)",
        "Hook discovery searches config.hooks for matching event name",
        "If no hooks match event name, return empty array (no error)",
        "Event names are case-sensitive (pre-implementing != pre-Implementing)",
        "Command name extraction: 'fspec update-work-unit-status' -> 'update-work-unit-status'"
      ],
      "examples": [
        "Discover hooks for 'post-implementing' event - returns array of matching hooks",
        "Discover hooks for 'pre-start' special lifecycle event - returns global pre-start hooks",
        "Discover hooks for non-existent event 'pre-xyz' - returns empty array (no error)",
        "Event name for command 'update-work-unit-status' generates 'pre-update-work-unit-status' and 'post-update-work-unit-status'",
        "Case-sensitive matching: 'post-implementing' finds hooks, 'post-Implementing' does not",
        "Multiple hooks for same event - returns all matching hooks in config order"
      ]
    },
    "HOOK-005": {
      "id": "HOOK-005",
      "title": "Hook condition evaluation",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:52.221Z",
      "updatedAt": "2025-10-15T12:24:15.115Z",
      "description": "Implement optional condition matching: tags, prefix, epic, estimateMin, estimateMax. Skip hook if conditions don't match. Support no condition = always run.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:17:45.705Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:21:11.809Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:22:27.203Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:23:05.811Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:24:15.116Z"
        }
      ],
      "userStory": {
        "role": "hook execution system",
        "action": "evaluate hook conditions to determine if a hook should run",
        "benefit": "hooks only execute when their conditions match the current context"
      },
      "rules": [
        "Hooks with no condition always match (condition is optional)",
        "Condition with tags: hook runs if work unit has ANY of the specified tags (OR logic)",
        "Condition with prefix: hook runs if work unit ID starts with ANY of the specified prefixes (OR logic)",
        "Condition with epic: hook runs if work unit belongs to specified epic",
        "Condition with estimateMin/estimateMax: hook runs if work unit estimate is within range",
        "Multiple condition fields use AND logic (all must match)",
        "If context has no workUnitId, only hooks without conditions run"
      ],
      "examples": [
        "Hook with no condition matches any context - always runs",
        "Hook with tags:[@security] matches work unit with @security tag",
        "Hook with prefix:[AUTH,SEC] matches AUTH-001 but not DASH-001",
        "Hook with epic:'user-management' matches work unit in that epic",
        "Hook with estimateMin:5, estimateMax:13 matches work unit with estimate 8",
        "Hook with tags:[@security] AND prefix:[AUTH] - both must match (AND logic)",
        "Context with no workUnitId - only unconditional hooks match"
      ]
    },
    "HOOK-006": {
      "id": "HOOK-006",
      "title": "System reminder formatting for AI",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:44:56.257Z",
      "updatedAt": "2025-10-15T12:32:11.238Z",
      "description": "When blocking hook fails, wrap stderr in <system-reminder> block for AI consumption. Display hook name, exit code, and error message. Include 'DO NOT mention this reminder to the user' footer.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:26:08.503Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:29:26.029Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:30:18.689Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:30:56.713Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:32:11.239Z"
        }
      ],
      "userStory": {
        "role": "fspec system",
        "action": "format blocking hook stderr as system-reminders for AI agents",
        "benefit": "AI agents receive actionable feedback when hooks fail"
      },
      "rules": [
        "Blocking hook stderr is wrapped in <system-reminder> tags",
        "Non-blocking hook stderr is displayed as-is (no wrapping)",
        "System-reminder content includes hook name, exit code, and stderr output",
        "Empty stderr produces no system-reminder (only if stderr has content)",
        "System-reminder is appended to command output (not replacing it)"
      ],
      "examples": [
        "Blocking hook fails with stderr 'Invalid config' - wrapped in system-reminder",
        "Non-blocking hook fails with stderr - displayed as-is, no wrapping",
        "Blocking hook succeeds - no system-reminder generated",
        "Blocking hook fails with empty stderr - no system-reminder",
        "System-reminder includes: hook name 'validate', exit code 1, stderr content"
      ]
    },
    "HOOK-007": {
      "id": "HOOK-007",
      "title": "Hook management CLI commands",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:45:00.480Z",
      "updatedAt": "2025-10-15T12:51:50.899Z",
      "description": "Implement: fspec list-hooks, fspec validate-hooks, fspec add-hook, fspec remove-hook. List shows all configured hooks. Validate checks config syntax. Add/remove modify fspec-hooks.json.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:42:06.760Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:47:49.741Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:48:36.967Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T12:49:21.484Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T12:51:50.899Z"
        }
      ],
      "userStory": {
        "role": "fspec user",
        "action": "manage hooks via CLI commands",
        "benefit": "I can list, validate, add, and remove hooks without manually editing JSON"
      },
      "rules": [
        "list-hooks command displays all configured hooks grouped by event",
        "validate-hooks command checks config syntax and verifies hook scripts exist",
        "add-hook command adds a hook to config and creates the event array if needed",
        "remove-hook command removes a hook by name and event",
        "Commands fail gracefully if spec/fspec-hooks.json does not exist",
        "add-hook command requires: name, event, command (path to script)"
      ],
      "examples": [
        "list-hooks displays: post-implementing: lint, test",
        "validate-hooks passes - all scripts exist, JSON valid",
        "validate-hooks fails - missing script spec/hooks/missing.sh",
        "add-hook --name lint --event post-implementing --command spec/hooks/lint.sh --blocking",
        "remove-hook --name lint --event post-implementing - hook removed from config",
        "list-hooks when no config file - displays friendly message"
      ]
    },
    "HOOK-008": {
      "id": "HOOK-008",
      "title": "Integrate hooks into all commands",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:45:04.467Z",
      "updatedAt": "2025-10-15T13:01:53.657Z",
      "description": "Add hook execution to every fspec command. Call runHooks() before/after command logic. Support pre-start lifecycle hook. Support pre-exit lifecycle hook. Pass appropriate context to each hook.",
      "epic": "hooks-system",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T12:56:41.998Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T12:58:43.162Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T12:59:55.073Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:00:34.477Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:01:53.657Z"
        }
      ],
      "userStory": {
        "role": "fspec CLI user",
        "action": "have hooks execute automatically with every command",
        "benefit": "I can enforce policies and automations without manually invoking hooks"
      },
      "rules": [
        "Commands execute pre- hooks before main logic and post- hooks after main logic",
        "Hook event names follow pattern: pre-{command} and post-{command}",
        "Hooks receive context with workUnitId (if applicable), event name, and timestamp",
        "Blocking hook failures prevent command execution (pre-hooks) or prevent exit with success (post-hooks)",
        "Non-blocking hook failures do not prevent command execution or success",
        "Hooks are filtered by conditions before execution (tags, prefix, epic, estimate)",
        "Hook output is displayed using formatHookOutput() with system-reminders for blocking failures"
      ],
      "examples": [
        "Command update-work-unit-status triggers pre-update-work-unit-status and post-update-work-unit-status hooks",
        "Pre-hook validates work unit has feature file before allowing status change to testing",
        "Post-hook runs tests after implementing status change",
        "Blocking pre-hook failure prevents command from executing",
        "Non-blocking post-hook failure allows command to succeed",
        "Hook with tag condition only runs for work units with matching tag",
        "Hook output formatted with system-reminder shows blocking hook failure details"
      ]
    },
    "HOOK-009": {
      "id": "HOOK-009",
      "title": "Hook system documentation and examples",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T11:45:08.399Z",
      "updatedAt": "2025-10-15T13:08:41.103Z",
      "description": "Write comprehensive documentation: configuration format, hook script examples (bash/python/node), best practices for output, example hooks for common use cases (linting, testing, notifications).",
      "epic": "hooks-system",
      "children": [],
      "estimate": 3,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T13:02:40.697Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T13:04:34.908Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T13:05:21.697Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T13:07:19.458Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T13:08:41.104Z"
        }
      ],
      "userStory": {
        "role": "fspec user writing hook scripts",
        "action": "have comprehensive documentation and working examples",
        "benefit": "I can quickly create custom hooks without trial and error"
      },
      "rules": [
        "Documentation explains hook configuration JSON schema with all fields",
        "Example hooks provided for bash, python, and node.js",
        "Documentation explains hook context JSON passed via stdin",
        "Best practices documented for stdout/stderr usage and exit codes",
        "Common use case examples: linting, testing, notifications, validation",
        "Documentation includes troubleshooting section for common errors"
      ],
      "examples": [
        "Configuration doc shows complete fspec-hooks.json with global defaults and multiple hooks",
        "Bash hook reads JSON context from stdin and validates work unit has feature file",
        "Python hook parses JSON stdin and runs pytest on work unit tests",
        "Node.js hook reads stdin and sends Slack notification about status change",
        "Lint hook example shows proper exit codes: 0 for success, 1 for lint errors",
        "Troubleshooting doc explains 'Hook command not found' error and solution"
      ]
    },
    "BUG-011": {
      "id": "BUG-011",
      "title": "generate-scenarios missing architecture docstring",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T22:51:07.833Z",
      "updatedAt": "2025-10-15T23:10:52.876Z",
      "description": "The generate-scenarios command creates feature files without architecture docstrings, violating CLAUDE.md requirements. Older files created with create-feature have docstrings, but newer files created with generate-scenarios are missing them.",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T22:51:16.440Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T22:53:06.162Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T22:53:45.139Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:09:40.344Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:10:52.876Z"
        }
      ],
      "userStory": {
        "role": "developer using generate-scenarios",
        "action": "have feature files with architecture docstrings",
        "benefit": "all feature files meet CLAUDE.md requirements and have consistent structure"
      },
      "rules": [
        "All feature files MUST have architecture docstrings (CLAUDE.md requirement)",
        "generate-scenarios output MUST match create-feature template structure",
        "Docstring MUST come before example mapping comments",
        "Docstring MUST include TODO placeholders for architecture notes"
      ],
      "examples": [
        "User runs generate-scenarios, file contains both docstring and example mapping comments",
        "Generated file matches structure: tags → feature → docstring → comments → background",
        "Existing tests pass with new docstring addition"
      ]
    },
    "FEAT-012": {
      "id": "FEAT-012",
      "title": "Capture architecture notes during Example Mapping",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T22:58:05.227Z",
      "updatedAt": "2025-10-15T23:23:02.738Z",
      "description": "Add ability to capture architecture notes and non-functional requirements during Example Mapping discovery phase, and populate feature file docstrings with this information during generate-scenarios.",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T22:58:14.705Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T23:15:36.150Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T23:16:21.173Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:21:08.805Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:23:02.739Z"
        }
      ],
      "userStory": {
        "role": "AI agent doing Example Mapping",
        "action": "capture architecture notes and non-functional requirements",
        "benefit": "generated feature files have complete technical context in docstrings"
      },
      "rules": [
        "Architecture notes must be stored in WorkUnit during Example Mapping",
        "Architecture notes must populate docstring in generate-scenarios output",
        "Must support adding/removing/viewing architecture notes via CLI",
        "Architecture notes should include: dependencies, performance reqs, security considerations, implementation constraints"
      ],
      "examples": [
        "User runs 'fspec add-architecture-note WORK-001 \"Uses @cucumber/gherkin parser\"' during Example Mapping",
        "User runs 'fspec generate-scenarios WORK-001' and docstring contains captured architecture notes instead of TODO placeholders",
        "User runs 'fspec show-work-unit WORK-001' and sees architecture notes section with all captured notes",
        "Generated docstring includes sections for dependencies, performance, security based on captured notes"
      ],
      "questions": [
        {
          "text": "@human: Should architectureNotes be a separate array field in WorkUnit, or reuse assumptions field?",
          "selected": true,
          "answer": "Separate architectureNotes array field in WorkUnit (clearer separation from assumptions)"
        },
        {
          "text": "@human: Should we ask about architecture notes as a separate Example Mapping step (purple cards), or integrate with existing steps?",
          "selected": true,
          "answer": "Integrate with existing steps - ask architecture questions during Step 3 (Ask Questions phase) for natural flow"
        },
        {
          "text": "@human: What specific NFR questions should AI ask during discovery? (performance, security, dependencies, scalability, etc.)",
          "selected": true,
          "answer": "Ask about: libraries/dependencies, code that should be refactored/shared, code quality considerations, UI/UX examples (websites/screenshots), implementation patterns to follow"
        },
        {
          "text": "@human: Should architecture notes have categories/types, or just be free-form strings?",
          "selected": true,
          "answer": "Free-form strings initially - users can prefix naturally (e.g., 'Dependency: ...', 'Refactoring: ...'). Add categorization later if needed."
        }
      ]
    },
    "FEAT-013": {
      "id": "FEAT-013",
      "title": "Attachment support for discovery process",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-15T23:42:01.192Z",
      "updatedAt": "2025-10-15T23:47:36.516Z",
      "description": "Add ability to attach files (diagrams, mockups, documents) to work units during Example Mapping to supplement architecture notes and NFRs",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-15T23:42:21.297Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T23:42:57.989Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T23:43:10.317Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:43:11.875Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:44:54.141Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-15T23:46:00.822Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-15T23:46:24.484Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-15T23:47:32.452Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-15T23:47:34.074Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-15T23:47:36.517Z"
        }
      ],
      "userStory": {
        "role": "AI agent or developer using fspec",
        "action": "attach files to work units during Example Mapping",
        "benefit": "I can supplement architecture notes and NFRs with diagrams, mockups, and documents"
      },
      "rules": [
        "Attachments must be stored in spec/attachments/<work-unit-id>/ directory",
        "Attachment paths must be stored as relative paths from project root",
        "Source file must exist before copying to attachments directory"
      ],
      "examples": [
        "User runs 'fspec add-attachment AUTH-001 diagrams/auth-flow.png', file is copied to spec/attachments/AUTH-001/ and tracked in work unit",
        "User runs 'fspec list-attachments AUTH-001', sees all attached files with sizes and modification dates",
        "User runs 'fspec remove-attachment AUTH-001 diagram.png', file is deleted and tracking entry removed"
      ],
      "architectureNotes": [
        "Attachments array added to WorkUnit interface in src/types/index.ts",
        "Three new commands: add-attachment, list-attachments, remove-attachment",
        "Uses fs/promises for file operations (copyFile, stat, unlink)"
      ]
    },
    "HOOK-010": {
      "id": "HOOK-010",
      "title": "Migrate hook execution to use execa library",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T00:49:47.693Z",
      "updatedAt": "2025-10-16T01:18:17.009Z",
      "description": "Replace Node.js child_process.spawn with execa library for hook execution, following the patterns used in the cage project for better process management and cross-platform compatibility",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T00:49:52.619Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T00:55:20.542Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T00:57:07.118Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T01:06:35.448Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T01:18:17.009Z"
        }
      ],
      "userStory": {
        "role": "fspec developer",
        "action": "use execa for hook execution instead of child_process.spawn",
        "benefit": "better process management, improved error handling, and cross-platform compatibility"
      },
      "rules": [
        "Hook execution must maintain timeout behavior (default 60s)",
        "Hook context must be passed to stdin as JSON",
        "stdout and stderr must be captured separately",
        "Hook execution results must include hookName, success, exitCode, stdout, stderr, timedOut, duration",
        "execa library must be installed as a dependency",
        "All existing hook tests must continue to pass",
        "Non-detached behavior - hooks run attached to fspec process",
        "Keep custom timeout implementation integrated with execa - use AbortController signal to cancel subprocess",
        "Use execa's input option for passing JSON context - it's the best practice and handles stream management automatically"
      ],
      "examples": [
        "Hook executes successfully and returns exitCode 0 with captured stdout/stderr",
        "Hook times out after configured timeout period and is killed",
        "Hook fails with non-zero exit code and error message in stderr",
        "Hook receives context via stdin as JSON string",
        "Multiple hooks execute sequentially in order"
      ],
      "architectureNotes": [
        "Use execa library (same as cage project) for better process management",
        "Modify src/hooks/executor.ts executeHook() function",
        "Install execa as dependency in package.json",
        "Reference cage's server.ts implementation for execa usage patterns"
      ],
      "questions": [
        {
          "text": "@human: Should we support detached processes like cage does for server.ts, or keep the current non-detached behavior?",
          "selected": true,
          "answer": "Non-detached behavior - hooks run attached to fspec process"
        },
        {
          "text": "@human: Should we use execa's built-in timeout option or keep the custom timeout implementation?",
          "selected": true,
          "answer": "Keep custom timeout implementation integrated with execa - use AbortController signal to cancel subprocess"
        },
        {
          "text": "@human: Should we use execa's input option for passing context or stick with stdin.write()?",
          "selected": true,
          "answer": "Use execa's input option for passing JSON context - it's the best practice and handles stream management automatically"
        }
      ],
      "estimate": 3
    },
    "TEST-004": {
      "id": "TEST-004",
      "title": "Write missing tests for partially covered features",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-16T01:54:24.619Z",
      "updatedAt": "2025-10-16T11:07:03.554Z",
      "description": "Complete test coverage for 3 features: architecture-notes-in-example-mapping (2 scenarios), generate-scenarios-include-architecture-docstring (1 scenario), and preserve-example-mapping-context-as-comments-in-generated-feature-files (11 scenarios). Total: 14 uncovered scenarios that need tests.",
      "children": [],
      "estimate": 8,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T10:32:36.675Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T10:40:42.515Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T10:50:27.809Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T10:50:43.392Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T10:57:29.589Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T11:07:03.243Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T11:07:03.554Z"
        }
      ],
      "questions": [
        {
          "text": "@human: For these uncovered scenarios, should I write (A) full test implementations (traditional forward ACDD) or (B) skeleton tests (reverse ACDD style - structure only with TODOs)?",
          "selected": true,
          "answer": "Forward ACDD where there's no implementation/tests, reverse ACDD where there's no tests/features"
        },
        {
          "text": "@human: Should I examine the implementation files (e.g., generate-scenarios.ts, show-work-unit.ts) to infer what the tests should validate for scenarios that have existing code?",
          "selected": true,
          "answer": "Yes, examine implementation files to infer what the tests should validate. Figure out what code the test is running by analyzing existing implementation."
        },
        {
          "text": "@human: Are there any specific testing patterns or conventions in this codebase I should follow when writing tests for the generate-scenarios and example mapping commands?",
          "selected": true,
          "answer": "Follow the ACDD process - no special testing patterns beyond what's defined in CLAUDE.md"
        },
        {
          "text": "@human: I see the third feature has 11 uncovered scenarios. Should I tackle all 14 scenarios (2 from architecture-notes + 1 from generate-scenarios-include-architecture + 11 from preserve-example-mapping) in this single work unit, or should I break this into smaller work units?",
          "selected": true,
          "answer": "Do all 14 scenarios in one work unit - don't break it up"
        }
      ],
      "rules": [
        "Forward ACDD where there's no implementation/tests, reverse ACDD where there's no tests/features",
        "Yes, examine implementation files to infer what the tests should validate. Figure out what code the test is running by analyzing existing implementation.",
        "Do all 14 scenarios in one work unit - don't break it up"
      ],
      "assumptions": [
        "Follow the ACDD process - no special testing patterns beyond what's defined in CLAUDE.md"
      ],
      "examples": [
        "For 'View architecture notes in work unit' scenario - check show-work-unit command displays architecture notes added during example mapping",
        "For scenarios in preserve-example-mapping feature - test that add-scenario and add-background commands don't remove existing example mapping comments"
      ]
    },
    "FOUND-001": {
      "id": "FOUND-001",
      "title": "Design Generic Foundation Schema",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:12:53.931Z",
      "updatedAt": "2025-10-17T00:05:44.115Z",
      "description": "Create new TypeScript types and JSON schema for generic PRD structure focusing on WHY and WHAT",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:13:02.563Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T23:23:00.347Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:00:17.011Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T00:05:04.272Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T00:05:44.116Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for any project type",
        "action": "create a generic foundation document that captures WHY and WHAT",
        "benefit": "I have clear product requirements without mixing in implementation details"
      },
      "questions": [],
      "assumptions": [
        "Unlimited personas allowed, but suggest 3-7 in documentation as best practice. No hard limits enforced by schema."
      ],
      "rules": [
        "Multiple problems supported. Complex products can have thousands of problems. Foundation.json can reference external sub-foundation documents for scalability (all built from single foundation.json). This creates a hierarchical PRD structure.",
        "Broad capabilities only (3-7 high-level abilities). Granular features belong in .feature files. Example: 'User Authentication' is a capability in foundation.json, 'Login with OAuth' is a feature in user-authentication.feature.",
        "REQUIRED: project identity, problem statement, solution overview. OPTIONAL: architecture diagrams, constraints, detailed personas. This ensures minimum viable PRD while allowing detailed documentation.",
        "Schema must focus ONLY on WHY (problem) and WHAT (solution), never HOW (implementation)",
        "Schema must work for ANY project type: web apps, CLI tools, libraries, services, mobile apps",
        "Mermaid diagram validation must be preserved from current implementation",
        "JSON Schema must use Ajv for validation with clear error messages"
      ],
      "examples": [
        "Web app foundation includes personas: 'End User', 'Admin', 'API Consumer'",
        "CLI tool foundation includes persona: 'Developer using CLI in terminal'",
        "Library foundation includes persona: 'Developer integrating library into their codebase'",
        "Problem space includes multiple problems with impact ratings (high/medium/low)",
        "Solution includes 3-7 high-level capabilities like 'User Authentication', 'Data Visualization', 'API Integration'",
        "Foundation.json can reference sub-foundations: { 'subFoundations': ['spec/foundations/auth-subsystem.foundation.json'] }"
      ],
      "architectureNotes": [
        "TypeScript interfaces must map exactly to JSON Schema definitions",
        "Use Ajv with ajv-formats for validation (uri, email, date-time formats)",
        "Hierarchical foundations: parent foundation.json can reference child foundations in subFoundations array",
        "Migration path needed: old schema → new schema with backward compatibility flag",
        "Mermaid validation must use mermaid.parse() with jsdom (existing pattern)"
      ]
    },
    "FOUND-002": {
      "id": "FOUND-002",
      "title": "Implement Automated Discovery - Code Analysis",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:35.741Z",
      "updatedAt": "2025-10-17T02:20:14.997Z",
      "description": "Scan existing codebase to infer project type, personas, and capabilities using reverse ACDD techniques",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 8,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T00:09:59.672Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T00:29:37.164Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:34:52.164Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T00:37:07.269Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T00:38:38.932Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T02:04:30.871Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T02:05:39.193Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-17T02:06:41.226Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T02:17:17.252Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T02:18:45.665Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T02:19:03.302Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T02:20:14.997Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec to document an existing codebase",
        "action": "automatically discover project structure and infer personas/capabilities",
        "benefit": "I can quickly bootstrap a foundation document without manual analysis"
      },
      "rules": [
        "Code analysis must detect project type (web app, CLI tool, library, service, mobile app, desktop app, API)",
        "Code analysis must infer personas from user-facing interactions (routes, commands, UI components, API endpoints)",
        "Code analysis must infer capabilities from code structure (high-level features, not implementation details)",
        "Analysis must be fast enough for interactive use (< 5 seconds for typical projects)",
        "fspec provides GUIDANCE to AI, not implementation - AI decides how to analyze code",
        "Discovery must infer: project type, personas, capabilities, AND problems/pain points",
        "Support monorepos - AI analyzes all packages that are part of the same project"
      ],
      "examples": [
        "CLI tool with commander.js commands → project type: cli-tool, persona: Developer using CLI",
        "Express.js with /api routes → project type: web-app, personas: API Consumer, End User",
        "Package with exports in package.json → project type: library, persona: Developer integrating library",
        "React components in src/ → capability: User Interface, not implementation detail like 'Uses React hooks'",
        "AI discovers React app → infers problem: 'Users need interactive web UI' not 'Code needs React'"
      ],
      "questions": [
        {
          "text": "@human: Should code analysis support monorepos with multiple package.json files, or just single-project repositories?",
          "selected": true,
          "answer": "Yes, support monorepos - analyze all package.json files that are part of the same project"
        },
        {
          "text": "@human: What file patterns should we analyze to detect project type? (package.json, tsconfig.json, Cargo.toml, go.mod, etc.)",
          "selected": true,
          "answer": "AI decides file patterns - fspec guides AI to discover project type using available clues, not prescriptive tool list"
        },
        {
          "text": "@human: Should we infer problems/pain points from code, or only project type and personas?",
          "selected": true,
          "answer": "Yes, infer everything: project type, personas, capabilities, AND problems/pain points - all critical for complete foundation"
        },
        {
          "text": "@human: How deep should directory traversal go? Should we limit to specific directories (src/, lib/, cmd/) or scan entire project?",
          "selected": true,
          "answer": "AI decides traversal depth - fspec guides AI to intelligently explore codebase, not prescriptive directory limits"
        }
      ]
    },
    "FOUND-003": {
      "id": "FOUND-003",
      "title": "Implement Interactive Questionnaire",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:36.482Z",
      "updatedAt": "2025-10-17T00:55:12.776Z",
      "description": "Build Ink-based CLI questionnaire to gather WHY/WHAT information from users",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 5,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:20:17.487Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T00:45:42.074Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:47:44.622Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T00:54:48.957Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T00:55:12.776Z"
        }
      ],
      "architectureNotes": [
        "Questionnaire must guide AI through structured discovery workflow with specific question templates",
        "Section 1: Vision Questions - 'What is the core purpose?', 'Who are the primary users?', 'What problem does this solve?'",
        "Section 2: Problem Space - 'What are the top 3-5 pain points?', 'What is the impact?', 'What is the frequency?'",
        "Section 3: Solution Space - 'What are the 3-7 key capabilities?', 'What makes this solution unique?', 'What is out of scope?'",
        "Section 4: Architecture - 'What is the tech stack?' (optional if detected), 'What are system boundaries?', 'What are external dependencies?'",
        "Section 5: Constraints - 'Business constraints?', 'Technical constraints?', 'Timeline/budget constraints?'",
        "Prefill mode: If code analysis detected values, show as defaults with [DETECTED] tag, allow AI to confirm/edit/skip",
        "AI guidance: Each question includes HELP text explaining WHY it's asked and EXAMPLES of good answers"
      ],
      "rules": [
        "Questions must be grouped by section with progress indicator (Question 3 of 15)",
        "Must support both prefilled mode (--from-discovery) and blank slate (--interactive)",
        "Must validate answers before accepting (e.g. non-empty strings, valid format)"
      ],
      "examples": [
        "Vision question with help: 'What is the core purpose? [HELP: One sentence elevator pitch. Example: fspec helps AI agents follow ACDD workflow]'",
        "Prefilled answer: 'Primary user: Developer using CLI [DETECTED from code analysis] - Keep/Edit/Skip?'"
      ],
      "userStory": {
        "role": "developer using fspec with AI to bootstrap foundation documents",
        "action": "gather WHY/WHAT information through structured questionnaire",
        "benefit": "I can create complete foundation.json without manual analysis"
      }
    },
    "FOUND-004": {
      "id": "FOUND-004",
      "title": "Implement discover-foundation Command",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:37.238Z",
      "updatedAt": "2025-10-17T02:15:18.183Z",
      "description": "Orchestrate code analysis + questionnaire to generate foundation.json with validation",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 8,
      "dependsOn": [
        "FOUND-001",
        "FOUND-002",
        "FOUND-003"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:20:49.620Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T00:58:37.167Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T00:59:52.936Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:01:33.811Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:01:53.733Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T02:04:31.237Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T02:05:39.561Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-17T02:06:41.599Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T02:08:36.356Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T02:11:49.901Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T02:13:55.861Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T02:15:18.183Z"
        }
      ],
      "architectureNotes": [
        "System-reminder integration: Wrap questionnaire output in <system-reminder> tags when running in AI context (detectable via environment)",
        "System-reminder triggers: (1) After code analysis completes - show detected personas/capabilities (2) During questionnaire - provide examples of good answers (3) After foundation.json generated - next steps guidance",
        "System-reminder content: 'Code analysis detected 3 personas [list]. Review and confirm during questionnaire. Focus on WHY/WHAT, not HOW. See CLAUDE.md for boundary guidance.'"
      ],
      "rules": [
        "Must emit system-reminders to guide AI through discovery process (persona review, WHY/WHAT boundary, next steps)",
        "The command should output all questions at once in a structured format. The AI (Claude) sees the questions, analyzes the codebase based on the guidance, and then the command collects answers through a partial foundation.json file that the AI edits.",
        "The command creates a partial foundation.json with prefilled [DETECTED] values and [QUESTION] placeholders. The AI edits this file directly using Write/Edit tools, filling in answers based on code analysis. Then running the command again validates and completes the foundation.",
        "Two-phase execution: (1) First run outputs questions and creates partial foundation.json with placeholders. AI edits the file. (2) Second run (or --finalize flag) validates the completed foundation.json and writes the final version."
      ],
      "examples": [
        "After code analysis: <system-reminder>Detected 3 user personas from routes: End User, Admin, API Consumer. Review in questionnaire. Use 'fspec show-work-unit FOUND-002' for details.</system-reminder>"
      ],
      "userStory": {
        "role": "developer using fspec with AI to bootstrap foundation documents",
        "action": "run discover-foundation command to orchestrate analysis and questionnaire",
        "benefit": "I get a complete validated foundation.json without manual work"
      },
      "questions": [
        {
          "text": "@human: How should the interactive questionnaire work? Does it output all questions at once and expect answers in a file, or does it prompt question-by-question?",
          "selected": true,
          "answer": "The command should output all questions at once in a structured format. The AI (Claude) sees the questions, analyzes the codebase based on the guidance, and then the command collects answers through a partial foundation.json file that the AI edits."
        },
        {
          "text": "@human: When the command outputs questions, how does the AI provide answers? Through command arguments, through editing a file, or through some other mechanism?",
          "selected": true,
          "answer": "The command creates a partial foundation.json with prefilled [DETECTED] values and [QUESTION] placeholders. The AI edits this file directly using Write/Edit tools, filling in answers based on code analysis. Then running the command again validates and completes the foundation."
        },
        {
          "text": "@human: Should the command run multiple times (once to output questions, again to collect answers), or should it be a single execution that somehow waits for input?",
          "selected": true,
          "answer": "Two-phase execution: (1) First run outputs questions and creates partial foundation.json with placeholders. AI edits the file. (2) Second run (or --finalize flag) validates the completed foundation.json and writes the final version."
        }
      ]
    },
    "FOUND-005": {
      "id": "FOUND-005",
      "title": "Migrate Existing foundation.json",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:38.001Z",
      "updatedAt": "2025-10-17T01:09:17.482Z",
      "description": "Extract WHY/WHAT from current fspec foundation.json, move HOW content elsewhere, automated migration",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 3,
      "dependsOn": [
        "FOUND-001"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T01:03:24.343Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T01:05:56.004Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:07:10.808Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:08:03.028Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:09:17.482Z"
        }
      ],
      "userStory": {
        "role": "developer migrating fspec to generic foundation schema",
        "action": "migrate existing foundation.json to v2.0.0 format",
        "benefit": "foundation document follows the new generic schema and supports all project types"
      },
      "rules": [
        "Must preserve all existing architecture diagrams in architectureDiagrams array",
        "WHY/WHAT content stays in foundation.json, HOW content moves to CLAUDE.md or other docs",
        "Migration must be automated via CLI command 'fspec migrate-foundation'",
        "Migrated foundation.json must pass generic foundation schema validation"
      ],
      "examples": [
        "Current 'whatWeAreBuilding.projectOverview' maps to 'project.vision'",
        "Current 'whyWeAreBuildingIt.problemDefinition.primary' maps to 'problemSpace.primaryProblem'",
        "Current 'architectureDiagrams' array preserved as-is (already compatible)",
        "HOW content like 'technicalRequirements.coreTechnologies' moves to CLAUDE.md"
      ]
    },
    "FOUND-006": {
      "id": "FOUND-006",
      "title": "Update Documentation and Help",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:19:38.837Z",
      "updatedAt": "2025-10-17T01:23:48.715Z",
      "description": "Update CLAUDE.md, help system, and create discovery guide with examples",
      "epic": "foundation-document-redesign",
      "children": [],
      "estimate": 3,
      "dependsOn": [
        "FOUND-004"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T01:09:42.788Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T01:11:37.151Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:12:53.339Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:12:53.748Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:14:09.494Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:16:23.508Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:23:09.031Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:23:48.716Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for foundation document discovery",
        "action": "have comprehensive documentation and help for discovery commands",
        "benefit": "I can effectively use discover-foundation, questionnaire, and code analysis features"
      },
      "rules": [
        "CLAUDE.md must document discover-foundation workflow with examples",
        "Help system must have comprehensive --help output for discover-foundation command",
        "Discovery guide must explain code analysis patterns (CLI tool, web app, library)",
        "Documentation must show integration with Example Mapping workflow"
      ],
      "examples": [
        "CLAUDE.md shows: 'Run discover-foundation to analyze codebase and generate foundation.json'",
        "Help output includes WHEN TO USE, WORKFLOW, and EXAMPLES sections",
        "Discovery guide explains CLI tool pattern: bin field in package.json, commander usage"
      ]
    },
    "BUG-012": {
      "id": "BUG-012",
      "title": "Fix show-epic command returning undefined",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-16T23:24:12.754Z",
      "updatedAt": "2025-10-16T23:28:27.652Z",
      "description": "The show-epic command accepts invalid epic IDs and returns 'undefined' for epic and title instead of showing proper error message or help text",
      "children": [],
      "estimate": 2,
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:25:18.576Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T23:25:51.736Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T23:26:50.136Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T23:27:29.673Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T23:28:27.652Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "see a clear error when querying non-existent epics",
        "benefit": "I understand what went wrong and how to fix it"
      },
      "rules": [
        "Command must validate epic ID exists before attempting to display",
        "Must show clear error message with epic ID when not found",
        "Must exit with non-zero code on error"
      ],
      "examples": [
        "Run 'fspec show-epic invalid-epic' shows error: Epic 'invalid-epic' not found",
        "Error message suggests 'fspec list-epics' to see available epics",
        "Valid epic ID works correctly: 'fspec show-epic user-management' displays epic details"
      ]
    },
    "BUG-013": {
      "id": "BUG-013",
      "title": "Prevent story point estimation before feature file completion",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-16T23:34:28.036Z",
      "updatedAt": "2025-10-16T23:44:51.565Z",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-16T23:34:32.599Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-16T23:36:34.521Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-16T23:37:23.155Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-16T23:44:34.790Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-16T23:44:51.565Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec",
        "action": "be prevented from estimating story points before feature file is complete",
        "benefit": "I follow ACDD properly and estimate based on actual acceptance criteria"
      },
      "rules": [
        "Story and Bug work units CANNOT be estimated until feature file exists and is complete (specifying phase finished)",
        "Task work units CAN be estimated at any stage (tasks don't require feature files)",
        "When AI attempts invalid estimation, emit system-reminder explaining ACDD estimation rules",
        "Estimation requires completed feature file to understand complexity from acceptance criteria"
      ],
      "examples": [
        "Story work unit AUTH-001 in 'backlog' state with no feature file → estimation BLOCKED with system-reminder",
        "Story work unit AUTH-001 in 'testing' state with completed feature file → estimation ALLOWED",
        "Task work unit TASK-001 in 'backlog' state with no feature file → estimation ALLOWED (tasks exempt)",
        "Bug work unit BUG-001 in 'specifying' state but feature file has placeholders → estimation BLOCKED until prefill removed"
      ],
      "architectureNotes": [
        "Check work unit type: if type='task', skip validation (tasks don't require feature files)",
        "For story/bug types: find linked feature file via work unit ID tag (e.g., @AUTH-001)",
        "If no feature file found OR file has prefill placeholders, block estimation and emit system-reminder",
        "System-reminder should explain: ACDD requires feature file completion before estimation, suggest completing specifying phase first",
        "Reuse existing prefill detection logic from temporal validation (similar pattern)"
      ],
      "estimate": 2
    },
    "FOUND-007": {
      "id": "FOUND-007",
      "title": "Foundation existence check in commands",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-17T01:22:59.515Z",
      "updatedAt": "2025-10-17T01:49:42.199Z",
      "description": "Add check for foundation.json existence in key commands (board, create-work-unit, etc.). Commands should exit with helpful message if foundation.json missing, directing user to run discover-foundation first. CRITICAL: System reminder must tell AI agent to return to the original task after completing discover-foundation command.",
      "epic": "foundation-document-redesign",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T01:25:10.420Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T01:30:47.830Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:32:38.194Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:38:39.487Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:38:58.984Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T01:43:25.715Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T01:49:24.427Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T01:49:42.199Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec",
        "action": "ensure foundation.json exists before running project management commands",
        "benefit": "I prevent work from proceeding without proper project foundation and can resume my original task after discovery"
      },
      "rules": [
        "Commands that manage work units MUST check for foundation.json existence before executing",
        "If foundation.json is missing, command MUST exit with error code 1 and display helpful message",
        "Error message MUST direct user to run 'fspec discover-foundation' command",
        "System reminder MUST tell AI agent to return to original task after discover-foundation completes",
        "Check applies to: fspec board, create-work-unit, update-work-unit-status, create-epic, and other PM commands",
        "Yes, include exact command arguments. System reminders in Claude Code are used for actionable guidance - including the original command makes it clear what to retry after discover-foundation completes.",
        "No, only create/modify commands need foundation.json. Read-only commands like show-foundation, list-features, validate can run without foundation.json.",
        "Check only spec/foundation.json - this is the canonical location used by show-foundation, update-foundation, and generate-foundation-md commands."
      ],
      "examples": [
        "AI runs 'fspec board' without foundation.json → Command exits with error, displays message with discover-foundation instructions, system reminder tells AI to run board again after discovery",
        "AI runs 'fspec create-work-unit AUTH \"Login\"' without foundation.json → Command exits with error, system reminder includes original command to retry",
        "AI runs 'fspec board' with foundation.json present → Command executes normally, no check triggered",
        "AI runs 'fspec validate' (non-PM command) without foundation.json → Command executes normally, foundation check not required for spec-only commands"
      ],
      "questions": [
        {
          "text": "@human: Should the system reminder include the exact command arguments that were originally attempted?",
          "selected": true,
          "answer": "Yes, include exact command arguments. System reminders in Claude Code are used for actionable guidance - including the original command makes it clear what to retry after discover-foundation completes."
        },
        {
          "text": "@human: Should read-only commands like 'fspec show-foundation' also require foundation.json, or only commands that create/modify work units?",
          "selected": true,
          "answer": "No, only create/modify commands need foundation.json. Read-only commands like show-foundation, list-features, validate can run without foundation.json."
        },
        {
          "text": "@human: Should the check look for BOTH foundation.json AND spec/foundation.json paths, or just spec/foundation.json?",
          "selected": true,
          "answer": "Check only spec/foundation.json - this is the canonical location used by show-foundation, update-foundation, and generate-foundation-md commands."
        }
      ],
      "estimate": 3
    },
    "BUG-014": {
      "id": "BUG-014",
      "title": "validate-foundation-schema uses wrong schema for generic foundations",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T02:39:24.338Z",
      "updatedAt": "2025-10-17T02:43:30.783Z",
      "description": "The validate-foundation-schema command validates against fspec-specific schema instead of detecting schema version and using appropriate validator (generic v2.0.0 or fspec-specific)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T02:39:28.719Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T02:40:53.846Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T02:41:31.662Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T02:43:24.348Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T02:43:30.783Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "validate foundation.json files",
        "benefit": "I get correct validation regardless of schema version"
      },
      "rules": [
        "Command must detect schema version from foundation.json 'version' field",
        "Version 2.0.0 and above should use generic-foundation-validator",
        "Version 1.x should use fspec-specific validator for backward compatibility"
      ],
      "examples": [
        "Foundation with version: 2.0.0 validates using generic schema successfully",
        "Foundation with version: 1.0.0 validates using fspec-specific schema"
      ]
    },
    "TEST-005": {
      "id": "TEST-005",
      "title": "Update test fixtures to use generic foundation schema",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-17T02:53:51.917Z",
      "updatedAt": "2025-10-17T04:36:30.647Z",
      "description": "Update test fixtures in 9 test files that are currently using old fspec-specific schema format to use the new generic v2.0.0 schema format. This is cleanup work following BUG-014 where we simplified validate-foundation-schema to only use generic schema.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T04:36:22.446Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T04:36:30.071Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T04:36:30.360Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T04:36:30.647Z"
        }
      ]
    },
    "REFAC-001": {
      "id": "REFAC-001",
      "title": "Migrate old fspec-specific schema commands to generic schema",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-17T03:12:44.169Z",
      "updatedAt": "2025-10-17T04:25:47.145Z",
      "description": "Complete migration from old foundation.schema.json (fspec-specific) to generic-foundation.schema.json. Update all commands and tests that still reference whatWeAreBuilding/whyWeAreBuildingIt fields.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T03:13:09.841Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T03:13:10.534Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T04:18:34.350Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T04:25:47.145Z"
        }
      ]
    },
    "COV-052": {
      "id": "COV-052",
      "title": "Fix coverage gaps and align with foundation v2.0.0 migration",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-17T04:41:45.465Z",
      "updatedAt": "2025-10-17T04:50:39.148Z",
      "description": "Complete coverage mapping for all features, remove obsolete foundation-schema-guidance references, and ensure 100% coverage after REFAC-001 migration",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T04:41:57.147Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T04:41:57.435Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T04:44:59.582Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T04:46:21.862Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T04:50:39.148Z"
        }
      ]
    },
    "HELP-001": {
      "id": "HELP-001",
      "title": "Audit and sync all help files with command implementations",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-17T04:55:11.179Z",
      "updatedAt": "2025-10-17T05:24:40.447Z",
      "description": "Verify every command help file (src/commands/*-help.ts) accurately reflects the actual command arguments, options, and behavior registered with Commander.js. Ensure src/help.ts grouping is complete and accurate.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T04:55:17.079Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T04:55:17.370Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T05:24:40.157Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T05:24:40.447Z"
        }
      ]
    },
    "HELP-002": {
      "id": "HELP-002",
      "title": "Register 7 missing commands with Commander",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-17T05:37:10.832Z",
      "updatedAt": "2025-10-17T05:42:41.825Z",
      "description": "7 fully-implemented commands with help files are not registered with Commander.js: add-hook, list-hooks, remove-hook, validate-hooks, dependencies, workflow-automation, migrate-foundation. Also remove 2 duplicate legacy help files (delete-features-help.ts, delete-scenarios-help.ts).",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T05:37:22.320Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T05:37:27.623Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T05:42:41.537Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T05:42:41.825Z"
        }
      ]
    },
    "FOUND-009": {
      "id": "FOUND-009",
      "title": "Foundation missing error message is not imperative enough",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T05:57:24.673Z",
      "updatedAt": "2025-10-17T06:04:32.745Z",
      "description": "When foundation.json is missing, the error message in src/utils/foundation-check.ts is not imperative or detailed enough. It must: (1) FORBID manual JSON creation, (2) Explain the complete interactive workflow, (3) Emphasize foundation.json is a detailed PRD not a summary, (4) Show exact command sequence for draft->finalize workflow",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T05:57:49.057Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T05:59:37.205Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-17T06:01:14.358Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T06:02:04.914Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T06:02:43.048Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T06:03:26.554Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T06:04:32.745Z"
        }
      ],
      "userStory": {
        "role": "AI agent without foundation.json",
        "action": "receive imperative guidance on foundation discovery workflow",
        "benefit": "I follow the correct interactive workflow instead of manually creating JSON files"
      },
      "rules": [
        "Error message must FORBID manual creation of foundation.json files",
        "Error message must explain foundation.json is a detailed PRD, not a quick summary",
        "Error message must show exact command sequence: discover-foundation creates draft, AI fills placeholders, discover-foundation --finalize creates final file"
      ],
      "examples": [
        "AI tries to create work unit, gets error saying 'NEVER manually create foundation.json - use discover-foundation workflow'",
        "Error message shows: Step 1: fspec discover-foundation (creates draft), Step 2: Fill [QUESTION:] placeholders, Step 3: fspec discover-foundation --finalize"
      ],
      "estimate": 2
    },
    "FOUND-010": {
      "id": "FOUND-010",
      "title": "Project type detection incorrectly identifies CLI tools as web-apps",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T05:57:26.180Z",
      "updatedAt": "2025-10-17T06:27:34.821Z",
      "description": "The discover-foundation command should NOT have automated project type detection. It must be 100% interactive questionnaire where AI asks human about project type, personas, capabilities. Remove all automated detection code from src/guidance/automated-discovery-code-analysis.ts",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T06:05:33.155Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T06:06:27.667Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-17T06:07:40.429Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T06:08:47.536Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T06:09:16.927Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-17T06:17:17.434Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T06:20:43.565Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T06:24:08.400Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T06:26:18.558Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T06:27:34.821Z"
        }
      ],
      "userStory": {
        "role": "AI agent running discover-foundation",
        "action": "correctly detect CLI tool projects",
        "benefit": "foundation.json has accurate project type and personas"
      },
      "rules": [
        "foundation.json.draft IS the guidance file - it defines structure and what needs to be filled",
        "Draft contains [QUESTION: text] placeholders for fields requiring human/AI input",
        "Draft contains [DETECTED: value] for auto-detected fields that AI should verify with human",
        "discover-foundation reads draft and identifies unfilled/placeholder fields",
        "For each unfilled field, command emits system-reminder prompting AI to gather information",
        "AI must analyze codebase AND ask human to gather accurate information",
        "AI must use fspec update-foundation command to set values (NOT manual editing)",
        "After each field is set, command re-reads draft and chains to next unfilled field",
        "When all [QUESTION:] placeholders resolved, command validates against JSON schema",
        "Final step: command creates foundation.json and deletes draft"
      ],
      "examples": [
        "Draft has projectType:[QUESTION: What type?] → Command prompts AI → AI analyzes commander.js usage → AI asks human 'Is this cli-tool, web-app, or library?' → Human: 'cli-tool' → AI runs: fspec update-foundation --field project.projectType --value cli-tool → Command re-reads draft and moves to next field",
        "Draft has personas with [QUESTION: Describe persona] → Command prompts AI to gather persona info → AI analyzes CLI commands, no web UI → AI asks human 'Who uses this and their goals?' → Human: 'Developers in terminal managing specs' → AI runs: fspec update-foundation --field personas[0].description --value 'Developer using fspec to manage Gherkin specs' → Command chains to next field",
        "Draft has all [QUESTION:] resolved → Command validates against schema → If valid: creates foundation.json, deletes draft → If invalid: shows validation errors, prompts AI to fix",
        "AI tries to manually edit foundation.json.draft → Command detects file change outside fspec → Emits system-reminder: 'You must use fspec update-foundation commands, not manual editing'",
        "Draft has [DETECTED: web-app] for projectType → Command prompts AI to verify → AI asks human 'Detected web-app, is this correct?' → Human: 'No, it's cli-tool' → AI runs: fspec update-foundation --field project.projectType --value cli-tool"
      ],
      "estimate": 3
    },
    "DISC-001": {
      "id": "DISC-001",
      "title": "Implement draft-driven discovery workflow with AI chaining",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-17T06:32:17.502Z",
      "updatedAt": "2025-10-17T07:03:28.396Z",
      "description": "discover-foundation must read draft, identify next unfilled field, prompt AI with system-reminders, re-read after each fspec update-foundation command, chain to next field, validate when complete, and auto-regenerate FOUNDATION.md from foundation.json",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T06:32:29.265Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T06:49:02.418Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T06:51:45.257Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T06:57:04.523Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T06:57:23.540Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T06:58:27.988Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T07:03:05.753Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T07:03:28.396Z"
        }
      ],
      "userStory": {
        "role": "AI agent running discover-foundation",
        "action": "be guided step-by-step through filling foundation.json.draft",
        "benefit": "foundation.json is created accurately with all required fields and FOUNDATION.md is auto-generated"
      },
      "rules": [
        "discover-foundation creates foundation.json.draft with [QUESTION:] and [DETECTED:] placeholders",
        "After creating draft, command scans for FIRST unfilled [QUESTION:] field",
        "For each unfilled field, command emits system-reminder with: field path, guidance text, example values",
        "System-reminder instructs AI to: analyze codebase, ask human, use fspec update-foundation command",
        "After AI runs fspec update-foundation, command automatically re-runs to find NEXT unfilled field",
        "Command must NOT advance if AI tries to manually edit draft - emit system-reminder to use commands",
        "When all [QUESTION:] placeholders resolved, command validates draft against JSON schema",
        "If validation passes: create foundation.json, delete draft, auto-run fspec generate-foundation-md",
        "If validation fails: show errors, keep draft, prompt AI to fix and re-run",
        "[DETECTED:] fields must be verified with human before accepting",
        "Command tracks progress: shows N of M fields completed in each system-reminder",
        "System-reminders must be actionable: specific field, specific command to run, example value",
        "AI must NEVER skip fields - command enforces sequential field completion",
        "Final FOUNDATION.md generation happens automatically without AI intervention",
        "Command must detect if draft was manually edited between runs and reject with error"
      ],
      "examples": [
        "INITIAL RUN: Human runs 'fspec discover-foundation' → Command creates foundation.json.draft with structure → Draft has REQUIRED fields: project{name,vision,projectType}, problemSpace{primaryProblem{title,description,impact}}, solutionSpace{overview,capabilities[]}, personas[] → All fields contain [QUESTION: ...] or [DETECTED: ...] placeholders → Command emits system-reminder: 'Draft created. To complete foundation, you must ULTRATHINK the entire codebase. Analyze EVERYTHING: commands, routes, UI, tests, README, package.json. Understand HOW it works, then determine WHY it exists and WHAT users can do. I will guide you field-by-field. Field 1/9: project.name'",
        "FIELD 1 (project.name): Command reads draft → Finds [QUESTION: What is the project name?] → Emits: 'Field 1/9: project.name. Analyze package.json name field. Confirm with human. Run: fspec update-foundation --field project.name --value <name>' → AI reads package.json, sees 'fspec' → AI asks human 'Package name is fspec, correct?' → Human confirms → AI runs 'fspec update-foundation --field project.name --value fspec' → Command detects update, re-scans draft, finds next unfilled field",
        "FIELD 2 (project.vision): Command re-scans → Finds [QUESTION: What is the one-sentence vision?] → Emits: 'Field 2/9: project.vision (elevator pitch). ULTRATHINK: Read ALL code, understand the system deeply. What is the core PURPOSE? Focus on WHY this exists, not HOW it works. Ask human. Run: fspec update-foundation --field project.vision --value \"your vision\"' → AI reads README, analyzes commands (validate, format, list-features), understands it manages Gherkin specs → AI formulates: 'CLI tool for managing Gherkin specifications using ACDD' → AI asks human 'Is vision correct?' → Human confirms → AI updates field",
        "FIELD 3 (project.projectType): Command re-scans → Finds [DETECTED: cli-tool] → Emits: 'Field 3/9: project.projectType. Auto-detected cli-tool from commander.js usage and bin field. Verify with human. Options: cli-tool, web-app, library, sdk, mobile-app, desktop-app, service, api, other. Run: fspec update-foundation --field project.projectType --value cli-tool' → AI analyzes code: sees commander.js imports, .command() calls, bin field in package.json → AI confirms: yes, this is cli-tool → AI asks human 'Detected cli-tool, correct?' → Human confirms → AI updates field → Command chains to problemSpace",
        "FIELD 4 (problemSpace.primaryProblem): Command re-scans → Finds [QUESTION: What problem does this solve?] → Emits: 'Field 4/9: problemSpace.primaryProblem. CRITICAL: Think from USER perspective. WHO uses this (persona)? WHAT problem do THEY face? WHY do they need this solution? Analyze codebase to understand user pain, ask human. Required: title, description, impact (high/medium/low). Run: fspec update-foundation --field problemSpace.primaryProblem.title --value \"Problem Title\"' → AI analyzes: this is CLI for specs, users are developers, they need structured spec workflow → AI asks human 'Primary problem: Developers lack structured workflow for managing specifications?' → Human elaborates → AI updates title,description,impact",
        "FIELD 5 (solutionSpace.capabilities): Command re-scans → Finds [QUESTION: What can users DO?] → Emits: 'Field 5/9: solutionSpace.capabilities. List 3-7 HIGH-LEVEL abilities users have. Focus on WHAT not HOW. Example: \"Spec Validation\" (WHAT), not \"Uses Cucumber parser\" (HOW). Analyze commands/features to identify user-facing capabilities. Run: fspec update-foundation --field solutionSpace.capabilities[0].name --value \"Capability Name\"' → AI analyzes commands: validate, format, list, create → Groups into capabilities: Spec Management, Validation, Work Unit Tracking → AI asks human → Human confirms → AI adds each capability with description",
        "FIELD 6 (personas): Command re-scans → Finds [QUESTION: Who uses this?] → Emits: 'Field 6/9: personas. Identify ALL user types from interactions. CLI tools: who runs commands? Web apps: who uses UI + who calls API? Analyze ALL user-facing code. Ask human about goals and pain points. Run: fspec update-foundation --field personas[0].name --value \"Persona Name\"' → AI analyzes: CLI commands used by developers, no web UI, no API consumers → Identifies persona: \"Developer using CLI in terminal\" → AI asks human about goals: managing specs, following ACDD → AI asks about pain points: fragmented tools, no workflow → AI updates persona with name, description, goals, painPoints",
        "COMPLETION: AI fills last required field → Command re-scans → ALL required fields complete (no [QUESTION:] in required fields) → Command validates draft against JSON schema → Schema validation PASSES → Command creates spec/foundation.json from draft → Command deletes spec/foundation.json.draft → Command AUTOMATICALLY runs 'fspec generate-foundation-md' (no AI action needed) → Command emits: 'Discovery complete\\! Created: spec/foundation.json, spec/FOUNDATION.md. Foundation is ready. You can now run fspec commands that require foundation.' → AI can now proceed with other work",
        "ERROR: Manual Editing → AI uses Write tool to edit foundation.json.draft directly → Command detects: draft mtime changed without fspec command → Command compares last known state vs current → Command emits ERROR in system-reminder: 'CRITICAL: You manually edited foundation.json.draft. This violates the workflow. You MUST use: fspec update-foundation --field <path> --value <value>. Reverting your changes. Draft restored to last valid state. Try again with proper command.' → Draft is restored → AI must use fspec commands",
        "ERROR: Validation Failure → AI fills all fields → Command validates against schema → Validation FAILS: missing required field problemSpace.primaryProblem.description → Command emits: 'Schema validation failed. Missing required: problemSpace.primaryProblem.description. Draft NOT finalized. Fix by running: fspec update-foundation --field problemSpace.primaryProblem.description --value \"your description\". Then re-run discover-foundation to validate.' → Draft kept, foundation.json NOT created → AI fixes missing field and re-runs"
      ],
      "attachments": [
        "spec/attachments/DISC-001/discovery-feedback-loop.mmd"
      ]
    },
    "BUG-015": {
      "id": "BUG-015",
      "title": "Foundation discovery workflow cannot update nested fields (capabilities, personas)",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T07:18:39.226Z",
      "updatedAt": "2025-10-17T07:52:53.614Z",
      "description": "The discover-foundation workflow guides AI to use 'fspec update-foundation --field <path> --value <value>' syntax, but the actual update-foundation command uses '<section> <content>' syntax and cannot update nested array fields like capabilities[] and personas[]. This breaks the field-by-field discovery feedback loop.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T07:18:52.919Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T07:21:32.389Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T07:22:28.653Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T07:24:04.760Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T07:25:17.038Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T07:25:48.358Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T07:37:31.310Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T07:52:53.615Z"
        }
      ],
      "examples": [
        "AI runs 'fspec discover-foundation' → system-reminder says 'Run: fspec update-foundation --field project.name --value <name>' → AI tries command → Error: 'unknown option --field'",
        "AI checks help with 'fspec update-foundation --help' → discovers actual syntax is '<section> <content>' not '--field <path> --value <value>'",
        "AI successfully uses 'fspec update-foundation projectName \"fspec\"' for simple fields → works correctly",
        "AI encounters foundation.json.draft with capabilities[] array placeholder → no CLI command exists to update array fields → workflow breaks",
        "AI encounters personas[] array with nested structure → update-foundation command cannot handle nested JSON objects → must manually edit file (violates automation principle)"
      ],
      "rules": [
        "discover-foundation system-reminders MUST use syntax that matches actual update-foundation command implementation",
        "update-foundation command MUST support updating nested array fields (capabilities[], personas[]) through CLI without manual file editing",
        "Foundation discovery workflow MUST be fully automatable by AI without requiring manual JSON editing",
        "All fields in foundation.json.draft MUST have corresponding CLI commands to update them programmatically"
      ],
      "architectureNotes": [
        "Root Cause: src/commands/discover-foundation.ts emits system-reminders with '--field <path> --value <value>' syntax, but src/commands/update-foundation.ts implements '<section> <content>' syntax with no --field option",
        "Impact: Breaks field-by-field discovery feedback loop documented in CLAUDE.md 'Foundation Document Discovery' section. AI cannot complete foundation without manual file editing.",
        "Current Workaround: AI must manually edit foundation.json or foundation.json.draft using Write tool, which violates the automation principle and bypasses validation",
        "Affected Fields: capabilities[] (array of {name, description} objects), personas[] (array of {name, description, goals[]} objects), architectureDiagrams[] (array of Mermaid diagrams)",
        "Schema Reference: src/schemas/generic-foundation.schema.json defines required structure - capabilities[] requires minItems:1, personas[] is optional but must follow persona definition structure"
      ],
      "questions": [
        {
          "text": "@human: Should update-foundation support JSON path syntax (e.g., 'capabilities[0].name') or add separate commands (e.g., 'add-capability', 'add-persona')?",
          "selected": true,
          "answer": "Add separate commands for better UX: 'fspec add-capability <name> <description>' and 'fspec add-persona <name> <description> --goal <goal>'. This follows existing command patterns (add-scenario, add-step) and is more intuitive than JSON path syntax."
        },
        {
          "text": "@human: Should the fix update discover-foundation to emit correct syntax, or extend update-foundation to support --field flag?",
          "selected": true,
          "answer": "Create new commands (add-capability, add-persona) that update foundation.json programmatically. Update discover-foundation to emit system-reminders with correct command syntax. This is cleaner than retrofitting --field flag to update-foundation."
        },
        {
          "text": "@human: How should AI update array elements - append to array, or replace entire array?",
          "selected": true,
          "answer": "Append to arrays for add-capability and add-persona commands. This allows building up the foundation iteratively during discovery. Provide separate clear-capabilities and clear-personas commands if replacement is needed."
        }
      ],
      "assumptions": [
        "Add separate commands for better UX: 'fspec add-capability <name> <description>' and 'fspec add-persona <name> <description> --goal <goal>'. This follows existing command patterns (add-scenario, add-step) and is more intuitive than JSON path syntax.",
        "Create new commands (add-capability, add-persona) that update foundation.json programmatically. Update discover-foundation to emit system-reminders with correct command syntax. This is cleaner than retrofitting --field flag to update-foundation.",
        "Append to arrays for add-capability and add-persona commands. This allows building up the foundation iteratively during discovery. Provide separate clear-capabilities and clear-personas commands if replacement is needed."
      ],
      "userStory": {
        "role": "AI agent using fspec discover-foundation workflow",
        "action": "update nested array fields in foundation.json through CLI commands",
        "benefit": "I can complete foundation discovery without manual file editing"
      }
    },
    "BUG-016": {
      "id": "BUG-016",
      "title": "discover-foundation --finalize doesn't show validation errors",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T08:37:12.330Z",
      "updatedAt": "2025-10-17T08:43:45.249Z",
      "description": "When 'fspec discover-foundation --finalize' fails validation, it only shows '✗ Foundation validation failed' without showing WHAT validation errors occurred. The validationErrors field is populated in the code (lines 132-139 in discover-foundation.ts) but never printed to the user in the CLI action handler (lines 280-288). This leaves users/AI with no feedback on what needs to be fixed.",
      "epic": "foundation-document-redesign",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T08:37:55.679Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T08:39:33.216Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T08:40:43.274Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T08:41:42.645Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T08:43:20.424Z"
        }
      ],
      "userStory": {
        "role": "AI agent using draft-driven discovery workflow",
        "action": "see detailed validation errors when finalize fails",
        "benefit": "I know exactly what fields to fix without guessing"
      },
      "rules": [
        "When finalize fails validation, MUST show detailed error messages",
        "Error messages MUST list missing/invalid fields",
        "Error messages MUST show commands to fix each type of issue",
        "Error messages MUST be visible to both users and AI agents"
      ],
      "examples": [
        "User runs 'fspec discover-foundation --finalize' with empty personas array, sees error: 'Missing required: personas[0].name' with command to fix",
        "User runs finalize with placeholder persona data, sees error listing ALL missing fields in personas",
        "User runs finalize with empty capabilities array, sees error: 'Missing required: solutionSpace.capabilities' with example command"
      ],
      "estimate": 2
    },
    "BUG-017": {
      "id": "BUG-017",
      "title": "update-foundation doesn't chain to next field during discovery",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T08:52:34.641Z",
      "updatedAt": "2025-10-17T08:57:37.226Z",
      "description": "When AI runs 'fspec update-foundation' during draft-driven discovery, the command updates the draft but doesn't automatically scan for and emit the next field guidance. This breaks the automatic field-by-field chaining workflow, forcing AI to manually call discover-foundation again or guess what field comes next.",
      "epic": "foundation-document-redesign",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T08:52:50.903Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T08:54:25.470Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T08:55:56.939Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T08:57:04.254Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T08:57:36.662Z"
        }
      ],
      "userStory": {
        "role": "AI agent using draft-driven discovery",
        "action": "automatically see next field guidance after updating a field",
        "benefit": "I don't have to manually re-run discover-foundation or guess what comes next"
      },
      "rules": [
        "After updating draft field, MUST automatically scan draft for next field",
        "MUST emit system-reminder with guidance for next unfilled field",
        "If all fields complete, MUST tell AI to run finalize",
        "Chaining MUST be automatic, no manual intervention required"
      ],
      "examples": [
        "AI runs 'fspec update-foundation projectName \"MyProject\"', sees success message PLUS system-reminder for Field 2/8: project.vision",
        "AI runs 'fspec update-foundation projectVision \"My vision\"', sees success message PLUS system-reminder for Field 3/8: project.projectType",
        "AI fills last field, sees success message PLUS system-reminder saying 'All fields complete. Run: fspec discover-foundation --finalize'"
      ],
      "estimate": 3
    },
    "BUG-018": {
      "id": "BUG-018",
      "title": "add-persona and add-capability don't work with foundation.json.draft",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-17T09:08:55.578Z",
      "updatedAt": "2025-10-17T09:15:50.916Z",
      "description": "During draft-driven discovery workflow, add-persona and add-capability commands fail because they check for foundation.json instead of foundation.json.draft. This prevents AI from adding personas/capabilities during the discovery phase.",
      "epic": "foundation-document-redesign",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T09:09:00.995Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T09:11:14.730Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T09:12:19.941Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T09:13:32.198Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T09:15:50.917Z"
        }
      ],
      "userStory": {
        "role": "AI agent using draft-driven discovery",
        "action": "add personas and capabilities during discovery phase",
        "benefit": "I can complete all foundation fields without waiting for finalization"
      },
      "rules": [
        "add-persona MUST check for foundation.json.draft first, then foundation.json",
        "add-capability MUST check for foundation.json.draft first, then foundation.json",
        "Commands MUST prefer draft over final foundation.json (draft takes precedence)",
        "Error messages MUST be helpful when neither file exists"
      ],
      "examples": [
        "AI runs 'fspec add-persona' during discovery, draft exists, persona added to draft",
        "AI runs 'fspec add-capability' during discovery, draft exists, capability added to draft",
        "AI runs 'fspec add-persona', no draft but foundation.json exists, persona added to foundation.json (backward compatibility)",
        "AI runs 'fspec add-capability', neither file exists, shows helpful error with 'fspec discover-foundation' suggestion"
      ],
      "estimate": 3
    },
    "FEAT-014": {
      "id": "FEAT-014",
      "title": "Add remove-persona and remove-capability commands",
      "type": "feature",
      "status": "done",
      "createdAt": "2025-10-17T09:22:49.579Z",
      "updatedAt": "2025-10-17T09:30:23.946Z",
      "description": "Users need commands to remove personas and capabilities from foundation.json or foundation.json.draft. Currently they must manually edit JSON files to remove unwanted placeholder entries.",
      "epic": "foundation-document-redesign",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T09:22:55.289Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T09:25:00.500Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T09:29:24.677Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T09:29:24.949Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T09:30:23.946Z"
        }
      ],
      "userStory": {
        "role": "user managing foundation document",
        "action": "remove unwanted personas and capabilities",
        "benefit": "I can clean up placeholders without manually editing JSON"
      },
      "rules": [
        "remove-persona MUST work with both foundation.json and foundation.json.draft (same file priority as add-persona)",
        "remove-capability MUST work with both foundation.json and foundation.json.draft (same file priority as add-capability)",
        "Remove commands MUST match by exact name (case-sensitive)",
        "If persona/capability not found, show error with list of available names"
      ],
      "examples": [
        "User runs 'fspec remove-persona Developer', persona removed from draft",
        "User runs 'fspec remove-capability \"Mind Mapping\"', capability removed from foundation.json",
        "User runs 'fspec remove-persona NonExistent', shows error listing available personas"
      ],
      "estimate": 2
    },
    "FEAT-015": {
      "id": "FEAT-015",
      "title": "Validate Mermaid diagrams in attachments",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-17T10:13:18.110Z",
      "updatedAt": "2025-10-17T10:27:24.865Z",
      "description": "Add validation for Mermaid diagram attachments using the same validation logic as add-diagram command, providing detailed syntax error feedback when diagrams are invalid",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-17T10:13:25.228Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-17T10:20:44.838Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-17T10:23:28.000Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-17T10:25:36.448Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-17T10:27:24.865Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec with AI agents",
        "action": "attach Mermaid diagrams to work units with automatic validation",
        "benefit": "I catch diagram syntax errors immediately and get helpful feedback to fix them"
      },
      "rules": [
        "Mermaid diagram attachments must be validated using the same mermaid.parse() logic as add-diagram command",
        "Only files with .mmd or .mermaid extensions should trigger Mermaid validation",
        "Invalid Mermaid syntax must prevent attachment with detailed error message including line numbers",
        "Valid Mermaid diagrams should be attached successfully with confirmation message",
        "Use similar error format to add-diagram but adapted for attachment context (e.g., 'Failed to attach diagram.mmd' instead of 'Failed to add diagram')",
        "No --skip-validation flag - all Mermaid diagrams must pass validation before attachment",
        "Yes, validate .md files that contain mermaid code blocks (triple-backtick mermaid syntax)"
      ],
      "examples": [
        "User attaches valid flowchart.mmd with 'graph TD' syntax - attachment succeeds with confirmation",
        "User attaches sequence.mermaid with invalid syntax - attachment fails with detailed error message showing line number",
        "User attaches diagram.png - no Mermaid validation performed (not .mmd or .mermaid extension)",
        "User attaches erDiagram.mmd with valid ER diagram syntax - attachment succeeds"
      ],
      "questions": [
        {
          "text": "@human: Should we also validate .md files that contain mermaid code blocks?",
          "selected": true,
          "answer": "Yes, validate .md files that contain mermaid code blocks (triple-backtick mermaid syntax)"
        },
        {
          "text": "@human: Should the error message format match exactly with add-diagram errors for consistency?",
          "selected": true,
          "answer": "Use similar error format to add-diagram but adapted for attachment context (e.g., 'Failed to attach diagram.mmd' instead of 'Failed to add diagram')"
        },
        {
          "text": "@human: Should we add a --skip-validation flag to allow attaching invalid diagrams for drafts?",
          "selected": true,
          "answer": "No --skip-validation flag - all Mermaid diagrams must pass validation before attachment"
        }
      ],
      "estimate": 3
    },
    "MCP-001": {
      "id": "MCP-001",
      "title": "Attachment categorization system",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-18T23:26:49.209Z",
      "updatedAt": "2025-10-18T23:26:49.209Z",
      "description": "Add metadata to attachments to categorize them as 'architecture', 'example', 'mockup', or 'diagram'. This enables system-reminders to distinguish code examples from other attachments when transitioning workflow states.",
      "epic": "example-driven-discovery",
      "children": []
    },
    "MCP-002": {
      "id": "MCP-002",
      "title": "MCP tool integration framework",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-18T23:26:50.151Z",
      "updatedAt": "2025-10-18T23:26:50.151Z",
      "description": "Implement client integration for Model Context Protocol (MCP), including configuration for MCP servers, abstraction layer for invoking MCP tools, and error handling for external tool failures.",
      "epic": "example-driven-discovery",
      "children": []
    },
    "MCP-003": {
      "id": "MCP-003",
      "title": "Attachment-aware workflow transitions",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-18T23:26:51.165Z",
      "updatedAt": "2025-10-18T23:26:51.165Z",
      "description": "Emit system-reminders when transitioning to testing or implementing states if work unit has attachments. Reminders should list attached examples and prompt AI to review them before writing tests or code.",
      "epic": "example-driven-discovery",
      "children": []
    },
    "MCP-004": {
      "id": "MCP-004",
      "title": "Context7 code discovery command",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-18T23:26:52.165Z",
      "updatedAt": "2025-10-18T23:27:05.300Z",
      "description": "Implement 'fspec discover-code-examples <work-unit-id> <query>' command that uses context7 MCP tool to search codebase for relevant patterns, generates markdown summaries, and auto-attaches results to work unit.",
      "epic": "example-driven-discovery",
      "children": [],
      "dependsOn": [
        "MCP-002",
        "MCP-001"
      ]
    },
    "MCP-005": {
      "id": "MCP-005",
      "title": "Enhanced discovery prompts with example guidance",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-18T23:26:53.140Z",
      "updatedAt": "2025-10-18T23:27:07.168Z",
      "description": "Update system-reminders during specifying state to encourage AI to use 'fspec discover-code-examples' and attach architectural examples. Update CLAUDE.md with guidance on example-driven discovery workflow.",
      "epic": "example-driven-discovery",
      "children": [],
      "dependsOn": [
        "MCP-003",
        "MCP-004"
      ]
    },
    "BUG-019": {
      "id": "BUG-019",
      "title": "Dependencies command throws 'Invalid action' error",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-18T23:33:40.052Z",
      "updatedAt": "2025-10-18T23:38:21.107Z",
      "description": "The 'fspec dependencies <work-unit-id>' command throws 'Error: Invalid action: <work-unit-id>' when invoked. The command registration expects an action argument first, but users/AI expect to pass work-unit-id directly to query dependencies.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-18T23:33:40.419Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-18T23:35:11.478Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-18T23:36:33.004Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-18T23:38:08.835Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-18T23:38:21.108Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec CLI",
        "action": "query work unit dependencies with simple syntax",
        "benefit": "I can understand dependency relationships without parsing complex multi-action commands"
      },
      "rules": [
        "Command must accept work-unit-id as first positional argument",
        "Command must display all dependency types: blocks, blockedBy, dependsOn, relatesTo",
        "Command must provide AI-friendly error wrapped in system-reminder if work unit does not exist"
      ],
      "examples": [
        "AI runs 'fspec dependencies MCP-001' and sees 'Dependencies for MCP-001:' with empty lists (no dependencies)",
        "AI runs 'fspec dependencies MCP-004' and sees 'Depends on: MCP-001, MCP-002'",
        "AI runs 'fspec dependencies INVALID-999' and gets system-reminder with suggestions to run 'fspec list-work-units'"
      ],
      "architectureNotes": [
        "Root cause: registerDependenciesCommand() uses multi-action router pattern with .argument('<action>') expecting 'list', 'add', 'remove', etc. but help docs suggest direct work-unit-id usage",
        "Solution: Simplify to single-purpose command accepting .command('dependencies <work-unit-id>') and call showDependencies() directly with AI-friendly error handling",
        "Error handling: Wrap errors in system-reminder tags to make failures highly visible to AI agents in Claude Code"
      ]
    },
    "DOCS-001": {
      "id": "DOCS-001",
      "title": "Clarify estimation timing in documentation and system-reminders",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-19T12:10:39.283Z",
      "updatedAt": "2025-10-19T12:34:31.582Z",
      "description": "System-reminders and documentation don't make it clear enough that story point estimation happens AFTER Example Mapping during the specifying phase, not before. AI agents are suggesting to add estimates before moving work units to specifying state, which violates ACDD workflow.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-19T12:10:47.439Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-19T12:18:22.138Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T12:22:04.487Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T12:33:00.375Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T12:34:31.583Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec",
        "action": "understand when to estimate story points",
        "benefit": "I follow ACDD workflow correctly without suggesting premature estimation"
      },
      "rules": [
        "Story point estimation happens AFTER Example Mapping, during specifying state",
        "Cannot estimate accurately without understanding scope from Example Mapping",
        "System-reminders in backlog state must NOT suggest adding estimates",
        "System-reminders in specifying state SHOULD remind to estimate after Example Mapping",
        "System-reminders must align with ACDD violation enforcement (feature file required before estimation)"
      ],
      "examples": [
        "AI shows MCP epic with 5 work units in backlog, suggests adding estimates before moving to specifying (WRONG)",
        "AI moves work unit to specifying, does Example Mapping, THEN suggests estimate based on discovered complexity (CORRECT)",
        "AI reads show-work-unit output showing 'no estimate' reminder in backlog state, incorrectly offers to add estimate immediately (WRONG)",
        "AI completes Example Mapping, generates scenarios, THEN sees reminder 'After generating scenarios, estimate based on feature file complexity' (CORRECT)"
      ],
      "architectureNotes": [
        "Files to check: src/commands/show-work-unit.ts (system-reminder logic), src/commands/update-work-unit-status.ts (state transition reminders), CLAUDE.md (workflow documentation), .claude/commands/fspec.md (slash command docs)",
        "CRITICAL FIX: System-reminder in show-work-unit.ts currently says 'Use Example Mapping results to estimate story points' but should say 'After generating scenarios from Example Mapping, estimate story points based on feature file complexity' to match ACDD violation enforcement",
        "Also update .claude/commands/fspec.md Step 2.5 section to explicitly state: estimate AFTER generating scenarios from Example Mapping, not before"
      ],
      "questions": [
        {
          "text": "@human: Are there other places in the codebase besides system-reminders where estimation timing should be clarified?",
          "selected": true,
          "answer": "Yes - update help documentation for update-work-unit-estimate command, add workflow examples to README.md and spec/CLAUDE.md showing correct timing, and potentially add validation to prevent estimating work units not yet in specifying state"
        }
      ],
      "estimate": 3
    },
    "FEAT-016": {
      "id": "FEAT-016",
      "title": "Warn AI when estimate is > 13 points to break down work unit",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-19T12:40:51.573Z",
      "updatedAt": "2025-10-19T13:17:50.986Z",
      "description": "When AI estimates a work unit at more than 13 points (21+), emit system-reminder warnings to guide breaking down into smaller work units (1-13 points each)",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-19T12:40:58.524Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-19T13:03:29.376Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T13:05:27.211Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T13:11:11.102Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T13:17:50.986Z"
        }
      ],
      "userStory": {
        "role": "AI agent estimating work units",
        "action": "receive clear warnings and guidance when estimate is too large",
        "benefit": "I break down large work into manageable chunks without getting lost in the process"
      },
      "rules": [
        "Warning must include SPECIFIC step-by-step commands (not generic advice) to break down the work unit",
        "Warning should guide AI to review feature file scenarios for natural split boundaries (not arbitrary splitting)",
        "Warning is non-blocking (allows estimate to be set) but strongly recommends breaking down",
        "Warning triggers IMMEDIATELY when estimate > 13 points (21 is too large, but 13 is acceptable)",
        "Warning ONLY applies to story and bug types, NOT task types (tasks can legitimately be large)",
        "Warning should suggest breaking into smaller stories (1-13 points each) for clear guidance",
        "Warning persists in show-work-unit while estimate > 13 AND status is not done",
        "Warning guidance adapts based on context: if feature file exists suggest reviewing it for natural boundaries, if no feature file exists suggest creating it first before breaking down"
      ],
      "examples": [
        "AI estimates BUG-005 at 21 points → warning shown → AI ignores and continues → runs show-work-unit BUG-005 → warning shown again in system-reminder section → AI finally breaks it down",
        "AI estimates INFRA-001 (type=task, infrastructure setup) at 21 points → NO warning (task type exempt) → estimate accepted",
        "AI sees warning → reads feature file → identifies natural scenario groupings → creates child work units for each group → estimates each child (all <= 13) → links with dependencies"
      ],
      "architectureNotes": [
        "TWO PLACEMENT POINTS: (1) update-work-unit-estimate.ts - immediate warning when estimate set, (2) show-work-unit.ts - persistent reminder via getLargeEstimateReminder() in system-reminder.ts",
        "SYSTEM-REMINDER MUST BE HIGHLY SPECIFIC: Include exact fspec commands (create-work-unit, add-dependency, create-epic), not generic advice like 'break this down'",
        "GUIDE FEATURE FILE ANALYSIS: Remind AI to 'Review feature file linked to this work unit. Look for scenario groupings that could be separate stories. Each group should deliver incremental value.'",
        "PERSISTENCE STRATEGY: Warning appears in TWO contexts (immediate + show-work-unit) creating 'sticky' reminder. AI will see it multiple times, increasing likelihood of following through.",
        "STEP-BY-STEP WORKFLOW IN WARNING: (1) Review feature file (or create if missing), (2) Identify boundaries, (3) Create child work units with fspec create-work-unit, (4) Link with fspec add-dependency --depends-on, (5) Optionally create epic to group, (6) Delete original work unit or convert to epic using fspec create-epic"
      ],
      "questions": [],
      "estimate": 5
    },
    "BUG-020": {
      "id": "BUG-020",
      "title": "remove-question command shows '[object Object]' instead of question text",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-19T12:58:26.949Z",
      "updatedAt": "2025-10-20T20:43:10.871Z",
      "description": "When running 'fspec remove-question <id> <index>', the success message displays 'Removed question: [object Object]' instead of showing the actual question text that was removed",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T20:37:44.322Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T20:39:47.790Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T20:41:22.510Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T20:42:02.948Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T20:43:10.871Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "see the actual question text when removing a question",
        "benefit": "I can confirm I'm removing the correct question"
      },
      "rules": [
        "Success message must display the actual question text, not '[object Object]'",
        "Message format should be 'Removed question: <question text>'"
      ],
      "examples": [
        "Remove question 'Should we support OAuth?' displays 'Removed question: Should we support OAuth?'",
        "Remove question with special characters '@human: What happens?' displays correctly"
      ],
      "estimate": 1
    },
    "REV-001": {
      "id": "REV-001",
      "title": "Interactive reverse ACDD strategy planning command",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-19T20:57:37.321Z",
      "updatedAt": "2025-10-19T21:51:43.660Z",
      "description": "Refactor reverse ACDD workflow from prescriptive /rspec command to interactive strategy planning session. Implement 'fspec reverse' command that analyzes project state, detects gaps (missing features, tests, coverage, work units), offers strategic options, and guides AI step-by-step through gap-filling process. This command is a planning/guidance tool only - it does NOT execute reverse ACDD work itself, but helps AI make informed decisions about the best approach based on project state. Similar to discover-foundation interactive session with system-reminders.",
      "epic": "reverse-acdd-refactor",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-19T20:57:42.682Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-19T21:06:32.964Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T21:09:44.583Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-19T21:18:12.503Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-19T21:39:19.514Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T21:39:29.035Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T21:50:29.445Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T21:51:43.661Z"
        }
      ],
      "userStory": {
        "role": "AI agent (Claude) working on legacy codebase",
        "action": "plan and execute reverse ACDD strategy to fill specification/test gaps",
        "benefit": "I can intelligently choose the right approach based on project state rather than following rigid instructions"
      },
      "rules": [
        "Command must be interactive like discover-foundation (session-based with system-reminders)",
        "Command analyzes project state but does NOT execute reverse ACDD itself - it only guides",
        "Must detect gaps: missing features, missing tests, missing coverage mappings, missing work units",
        "Must offer multiple strategies based on gap analysis (Spec Gap Filling, Test Gap Filling, Coverage Mapping, Full Reverse ACDD)",
        "Must emit step-by-step guidance via system-reminders (NOT execute the steps)",
        "Must replace /rspec command in .claude/commands/fspec.md and deprecate it",
        "Must update spec/CLAUDE.md section on Reverse ACDD with new workflow",
        "Session file must be deleted on completion (--complete) or reset (--reset)",
        "State machine phases: analyzing → gap-detection → strategy-planning → executing → complete",
        "Show summary with counts, paginate detailed gap list, suggest --strategy to narrow scope",
        "Yes - include story point estimates in strategy suggestions (helps AI prioritize)",
        "Yes - support --dry-run for preview analysis without creating session file",
        "Must detect existing session and prevent overwrite - show status and suggest options (--continue, --status, --reset, --complete)",
        "Must persist session state in OS temp directory (tmpdir) using project-specific hash for filename isolation - ephemeral, OS-managed cleanup",
        "Must support CLI flags: --continue, --strategy=X, --status, --reset, --complete, --dry-run"
      ],
      "examples": [
        "User runs 'fspec reverse' → command analyzes project → finds 3 test files without features → suggests Strategy A (Spec Gap Filling) via system-reminder",
        "AI runs 'fspec reverse --strategy=A' → emits system-reminder with step 1 guidance → AI reads test file, creates feature, links coverage → AI runs 'fspec reverse --continue' → emits step 2 guidance",
        "User runs 'fspec reverse --status' → shows current phase (executing), detected gaps (3 test files without features), chosen strategy (A), current step (2 of 3)",
        "User runs 'fspec reverse --reset' → deletes session file → outputs 'Session reset' → user can start fresh with 'fspec reverse'",
        "Project has features but no tests → analysis detects 2 feature files without tests → suggests Strategy B (Test Gap Filling) → guides AI through creating test skeletons with --skip-validation",
        "Project has both features and tests but unmapped → analysis detects 5 scenarios without coverage links → suggests Strategy C (Coverage Mapping) → guides AI through linking existing tests to scenarios",
        "Project has raw implementation code only (no features, no tests) → analysis detects 10 implementation files → suggests Strategy D (Full Reverse ACDD) → guides through creating features, tests, and work units from scratch",
        "AI completes all steps → runs 'fspec reverse --complete' → command validates work done → deletes session file → emits system-reminder with completion summary",
        "User runs 'fspec reverse' while session exists → command detects existing session → exits with error → shows current status → suggests --continue, --status, --reset, --complete → does NOT overwrite session"
      ],
      "questions": [
        {
          "text": "@human: Should the session file be human-readable JSON or optimized binary format?",
          "selected": true,
          "answer": "Human-readable JSON - easier to debug, inspect, and aligns with foundation.json pattern"
        },
        {
          "text": "@human: Should we support parallel strategies (e.g., Strategy A + Strategy C simultaneously)?",
          "selected": true,
          "answer": "No parallel strategies in MVP - keep it simple. AI chooses one strategy, completes it, then can run reverse again for other gaps"
        },
        {
          "text": "@human: How should we handle very large projects (100+ gaps detected)? Paginate output?",
          "selected": true,
          "answer": "Show summary with counts, paginate detailed gap list, suggest --strategy to narrow scope"
        },
        {
          "text": "@human: Should --strategy=custom trigger an interactive Q&A session with the user?",
          "selected": true,
          "answer": "Defer --strategy=custom to Phase 2 - start with four predefined strategies (A, B, C, D)"
        },
        {
          "text": "@human: Should we track time/effort estimates for each strategy in the guidance output?",
          "selected": true,
          "answer": "Yes - include story point estimates in strategy suggestions (helps AI prioritize)"
        },
        {
          "text": "@human: Should the command support --dry-run mode to preview analysis without creating session?",
          "selected": true,
          "answer": "Yes - support --dry-run for preview analysis without creating session file"
        }
      ],
      "architectureNotes": [
        "State machine phases: analyzing → gap-detection → strategy-planning → executing → complete (similar to discover-foundation feedback loop)",
        "System-reminders emitted at phase transitions and for step-by-step guidance (wrapped in <system-reminder> tags)",
        "Reuses existing analysis utilities: file scanners (Glob), Gherkin parser, test file pattern matching",
        "NO execution logic in command - all work done by AI using existing fspec commands (create-feature, link-coverage, etc.)",
        "Integration point 1: .claude/commands/fspec.md must mention 'fspec reverse' and deprecate /rspec command",
        "Integration point 2: spec/CLAUDE.md section 'Reverse ACDD for Existing Codebases' must be updated with new workflow",
        "Strategy templates: A=Spec Gap Filling, B=Test Gap Filling, C=Coverage Mapping, D=Full Reverse ACDD (each has predefined guidance steps)",
        "Session state stored in tmpdir()/fspec-reverse-{hash}.json where hash=sha256(projectRoot).substring(0,12) - ephemeral, OS-managed cleanup, zero project pollution"
      ],
      "attachments": [
        "spec/attachments/REV-001/reverse-session-state-machine.mmd",
        "spec/attachments/REV-001/strategy-decision-tree.mmd",
        "spec/attachments/REV-001/reverse-session-sequence.mmd"
      ],
      "assumptions": [
        "Human-readable JSON - easier to debug, inspect, and aligns with foundation.json pattern",
        "No parallel strategies in MVP - keep it simple. AI chooses one strategy, completes it, then can run reverse again for other gaps",
        "Defer --strategy=custom to Phase 2 - start with four predefined strategies (A, B, C, D)"
      ],
      "estimate": 13
    },
    "UX-001": {
      "id": "UX-001",
      "title": "System-reminder for missing scenarios in link-coverage",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-19T21:40:43.514Z",
      "updatedAt": "2025-10-19T22:00:01.065Z",
      "description": "When link-coverage fails because a scenario is not found in the coverage file but exists in the feature file, emit a system-reminder telling the AI to run generate-coverage first",
      "epic": "cli-ux-improvements",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-19T21:40:52.678Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-19T21:52:58.263Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T21:54:10.182Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T21:59:49.858Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T22:00:01.066Z"
        }
      ],
      "userStory": {
        "role": "AI agent (Claude) using fspec",
        "action": "receive helpful guidance when link-coverage fails due to missing scenarios",
        "benefit": "I can quickly fix the issue without trial and error"
      },
      "rules": [
        "When link-coverage fails with 'Scenario not found', check if scenario exists in feature file",
        "If scenario exists in feature file but not in coverage file, emit system-reminder suggesting generate-coverage",
        "System-reminder must be wrapped in <system-reminder> tags (visible to AI, invisible to user)",
        "If scenario doesn't exist in feature file either, show normal error without system-reminder"
      ],
      "examples": [
        "AI adds new scenario to feature file, runs link-coverage before generate-coverage → error with system-reminder: 'Run generate-coverage first'",
        "AI tries to link non-existent scenario (typo in scenario name) → error without system-reminder, just shows available scenarios",
        "Coverage file missing entirely → system-reminder suggests running generate-coverage to create it"
      ],
      "estimate": 3
    },
    "DOCS-002": {
      "id": "DOCS-002",
      "title": "Update all documentation to replace /rspec with fspec reverse",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-19T22:25:10.476Z",
      "updatedAt": "2025-10-22T00:19:11.595Z",
      "description": "REV-001 implementation is complete but documentation still references deprecated /rspec command. Update all docs to use 'fspec reverse' instead.",
      "epic": "reverse-acdd-refactor",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-19T22:25:15.775Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-19T22:26:02.269Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-19T22:45:25.166Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-19T22:51:53.017Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T00:00:13.282Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T00:18:57.973Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T00:19:11.595Z"
        }
      ],
      "rules": [
        "All references to /rspec command must be replaced with 'fspec reverse'",
        "File .claude/commands/rspec.md must be deleted as it is deprecated by fspec reverse",
        "Command fspec reverse must have comprehensive help file at src/commands/reverse-help.ts following CommandHelpConfig pattern",
        "File src/commands/help.ts must include reverse command in command list",
        "File spec/foundation.json must include Interactive Reverse ACDD capability with proper description",
        "After foundation.json changes, spec/FOUNDATION.md must be regenerated using fspec generate-foundation-md"
      ],
      "examples": [
        "Update .claude/commands/fspec.md: Replace '(see /rspec)' with '(see fspec reverse command)'",
        "Update spec/CLAUDE.md section 'Reverse ACDD for Existing Codebases': Replace 'via /rspec command' with 'via fspec reverse command'",
        "Update README.md: Replace '/rspec - For reverse engineering' with 'fspec reverse - Interactive strategy planning for reverse ACDD'",
        "Create src/commands/reverse-help.ts with sections: name, description, usage, whenToUse, options (--continue, --strategy, --status, --reset, --complete, --dry-run), examples, commonErrors, typicalWorkflow",
        "Add to foundation.json capabilities: {name: 'Interactive Reverse ACDD Strategy Planning', description: 'Analyzes project gaps and guides AI through reverse ACDD workflow with step-by-step system-reminders'}"
      ]
    },
    "BUG-021": {
      "id": "BUG-021",
      "title": "fspec --help displays hardcoded version 0.0.1 instead of package.json version",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-20T20:24:28.844Z",
      "updatedAt": "2025-10-20T20:35:39.022Z",
      "description": "The --help command shows 'Version 0.0.1' which appears to be hardcoded. It should dynamically read the version from package.json to stay in sync with releases.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T20:24:55.239Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T20:29:02.950Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T20:30:35.528Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T20:34:32.979Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T20:35:39.023Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "run fspec --help to check version",
        "benefit": "I see the current version from package.json, not a hardcoded value"
      },
      "rules": [
        "Version displayed in --help must match package.json version exactly",
        "Version should update automatically when package.json changes (no manual hardcoding)",
        "Build time - version embedded in dist bundle during build (typical for CLI tools)",
        "Don't display version string if unavailable"
      ],
      "examples": [
        "When package.json has version 0.2.1, running 'fspec --help' displays 'Version 0.2.1'",
        "After bumping package.json to version 0.3.0 and rebuilding, 'fspec --help' displays 'Version 0.3.0'",
        "Currently shows 'Version 0.0.1' regardless of package.json value (bug to fix)"
      ],
      "questions": [
        {
          "text": "@human: Should version be read at build time (embedded in dist bundle) or runtime (reading package.json when --help runs)? Build-time is typical for CLI tools.",
          "selected": true,
          "answer": "Build time - version embedded in dist bundle during build (typical for CLI tools)"
        },
        {
          "text": "@human: If we can't read the version (edge case), should we show 'unknown' or fallback to a default value?",
          "selected": true,
          "answer": "Don't display version string if unavailable"
        }
      ],
      "estimate": 2
    },
    "BUG-022": {
      "id": "BUG-022",
      "title": "Feature file naming for bug work units",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-20T20:47:04.871Z",
      "updatedAt": "2025-10-20T20:59:44.477Z",
      "description": "When creating a bug work unit and generating scenarios, fspec creates feature files named after the bug description (task-oriented) instead of the capability being tested (capability-oriented). It should also check if an existing feature file covers the capability and either update that file or create a properly-named new file.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T20:47:35.812Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T20:53:30.604Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T20:55:16.828Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T20:58:32.397Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T20:59:44.477Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec to fix bugs",
        "action": "create feature files with capability-oriented names",
        "benefit": "bug tests document capabilities, not problems"
      },
      "questions": [
        {
          "text": "@human: When generating feature files from bug work units, what rules should determine the capability name? Should we extract it from the bug description or ask the developer?",
          "selected": true,
          "answer": "AI should extract capability from bug context and search for existing feature files before creating new ones"
        },
        {
          "text": "@human: Should the system check for existing feature files covering the same capability before creating a new file? How should it determine if a match exists?",
          "selected": true,
          "answer": "AI agent should determine if an existing feature file is suitable for the bug scenario"
        },
        {
          "text": "@human: If an existing feature file is found that covers the capability, should we add a bug-fix scenario to that file or create a separate file?",
          "selected": true,
          "answer": "Add or update bug scenario in existing feature file (and update associated tests)"
        }
      ],
      "rules": [
        "AI should extract capability from bug context and search for existing feature files before creating new ones",
        "AI agent should determine if an existing feature file is suitable for the bug scenario",
        "Add or update bug scenario in existing feature file (and update associated tests)",
        "Feature file names must be capability-oriented (what the system CAN DO), not task-oriented (the bug description)",
        "AI should analyze existing feature descriptions, scenarios, and tags to determine capability match",
        "If no suitable existing feature file exists, create new file with capability-oriented name derived from bug context"
      ],
      "examples": [
        "Bug: 'fspec help displays hardcoded version 0.0.1' → AI searches features, finds 'help-command.feature' → Adds bug-fix scenario to existing file",
        "Bug: 'fspec help displays hardcoded version 0.0.1' → AI searches features, no match found → Creates 'cli-version-display.feature' (capability-oriented name)",
        "Bug: 'validate command crashes on empty file' → AI finds 'gherkin-validation.feature' → Adds edge-case scenario to existing file",
        "Bug: 'format removes valid doc strings' → AI finds 'gherkin-formatting.feature' → Updates existing scenario or adds new regression scenario"
      ],
      "architectureNotes": [
        "Fix should be in src/commands/generate-scenarios.ts - the command responsible for creating feature files from work units",
        "Need to add capability extraction logic - analyze bug description to identify underlying capability being tested",
        "Need to add existing feature search - use fspec list-features or directly scan spec/features/ directory with feature file parsing",
        "When adding to existing file, use fspec add-scenario command to properly insert scenario with correct formatting and tags"
      ],
      "estimate": 5
    },
    "SPEC-002": {
      "id": "SPEC-002",
      "title": "Scenario deduplication and refactoring detection during generation",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-20T21:05:14.096Z",
      "updatedAt": "2025-10-20T21:35:48.787Z",
      "description": "When generating scenarios from Example Mapping, detect if any scenarios are refactors of existing scenarios in other feature files. Update existing feature files for refactored scenarios, fix tests, regenerate coverage. Create new feature files only for truly new scenarios.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T21:05:19.135Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T21:19:22.664Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T21:21:14.009Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T21:34:35.856Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T21:35:48.788Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for ACDD workflow",
        "action": "detect and handle scenario refactoring during generation",
        "benefit": "I avoid duplicate scenarios across feature files and maintain proper test coverage"
      },
      "rules": [
        "When generating scenarios, check if any match existing scenarios in other feature files",
        "If a scenario is a refactor of an existing scenario, update the existing feature file instead of creating a duplicate",
        "When refactoring scenarios, update corresponding tests and regenerate coverage mappings",
        "Create new feature files only for truly new scenarios that don't match existing ones",
        "AI agent searches all feature files first, analyzes scenario titles and steps, takes hints from user's intent to determine if this is a refactor or genuinely new functionality",
        "Old scenario should be updated (changed into the new scenario) because it already has associated test, implementation, and coverage mappings that should be preserved",
        "System MUST automatically update tests and regenerate coverage when refactoring scenarios - this is enforced and non-negotiable",
        "Detection happens during 'fspec generate-scenarios' command as primary workflow. Before generating scenarios, search existing features for matches, prompt user to confirm if refactor, then update existing feature OR create new. Also provide 'fspec audit-scenarios' as standalone command for finding duplicates across all features for maintenance/cleanup.",
        "When generating scenarios, check if any match existing scenarios in other feature files",
        "If a scenario is a refactor of an existing scenario, update the existing feature file instead of creating a duplicate",
        "When refactoring scenarios, update corresponding tests and regenerate coverage mappings",
        "Create new feature files only for truly new scenarios that don't match existing ones",
        "AI agent searches all feature files first, analyzes scenario titles and steps, takes hints from user's intent to determine if this is a refactor or genuinely new functionality",
        "Old scenario should be updated (changed into the new scenario) because it already has associated test, implementation, and coverage mappings that should be preserved",
        "System MUST automatically update tests and regenerate coverage when refactoring scenarios - this is enforced and non-negotiable",
        "Detection happens during 'fspec generate-scenarios' command as primary workflow. Before generating scenarios, search existing features for matches, prompt user to confirm if refactor, then update existing feature OR create new. Also provide 'fspec audit-scenarios' as standalone command for finding duplicates across all features for maintenance/cleanup."
      ],
      "questions": [
        {
          "text": "@human: How should we detect if a scenario is a 'refactor' vs a 'new' scenario? Should we use semantic similarity, exact title matching, or analyze the Given-When-Then steps?",
          "selected": true,
          "answer": "AI agent searches all feature files first, analyzes scenario titles and steps, takes hints from user's intent to determine if this is a refactor or genuinely new functionality"
        },
        {
          "text": "@human: When we detect a refactored scenario, what should happen to the old scenario? Should it be marked as deprecated, deleted, or should we prompt the user to decide?",
          "selected": true,
          "answer": "Old scenario should be updated (changed into the new scenario) because it already has associated test, implementation, and coverage mappings that should be preserved"
        },
        {
          "text": "@human: Should the system automatically update tests when refactoring scenarios, or should it flag them for manual review? What about cases where tests might break?",
          "selected": true,
          "answer": "System MUST automatically update tests and regenerate coverage when refactoring scenarios - this is enforced and non-negotiable"
        },
        {
          "text": "@human: Should this detection happen during 'fspec generate-scenarios' command, or should it be a separate validation step that can be run independently?",
          "selected": true,
          "answer": "Detection happens during 'fspec generate-scenarios' command as primary workflow. Before generating scenarios, search existing features for matches, prompt user to confirm if refactor, then update existing feature OR create new. Also provide 'fspec audit-scenarios' as standalone command for finding duplicates across all features for maintenance/cleanup."
        },
        {
          "text": "@human: You mentioned 'similar to how the last bug story we fixed did' - which bug story are you referring to? Can you provide the work unit ID so I can review that approach?",
          "selected": true,
          "answer": "BUG-008: generate-scenarios produces malformed Gherkin steps from example titles. This bug fix improved how generate-scenarios parses example titles and creates proper Gherkin scenarios. The pattern we should follow is similar - analyzing example text and intelligently transforming it into proper scenarios."
        },
        {
          "text": "@human: How should we detect if a scenario is a 'refactor' vs a 'new' scenario? Should we use semantic similarity, exact title matching, or analyze the Given-When-Then steps?",
          "selected": true,
          "answer": "AI agent searches all feature files first, analyzes scenario titles and steps, takes hints from user's intent to determine if this is a refactor or genuinely new functionality"
        },
        {
          "text": "@human: When we detect a refactored scenario, what should happen to the old scenario? Should it be marked as deprecated, deleted, or should we prompt the user to decide?",
          "selected": true,
          "answer": "Old scenario should be updated (changed into the new scenario) because it already has associated test, implementation, and coverage mappings that should be preserved"
        },
        {
          "text": "@human: Should the system automatically update tests when refactoring scenarios, or should it flag them for manual review? What about cases where tests might break?",
          "selected": true,
          "answer": "System MUST automatically update tests and regenerate coverage when refactoring scenarios - this is enforced and non-negotiable"
        },
        {
          "text": "@human: Should this detection happen during 'fspec generate-scenarios' command, or should it be a separate validation step that can be run independently?",
          "selected": true,
          "answer": "Detection happens during 'fspec generate-scenarios' command as primary workflow. Before generating scenarios, search existing features for matches, prompt user to confirm if refactor, then update existing feature OR create new. Also provide 'fspec audit-scenarios' as standalone command for finding duplicates across all features for maintenance/cleanup."
        },
        {
          "text": "@human: You mentioned 'similar to how the last bug story we fixed did' - which bug story are you referring to? Can you provide the work unit ID so I can review that approach?",
          "selected": true,
          "answer": "BUG-022: Feature file naming for bug work units. AI searches existing feature files, extracts capability from bug context, and either updates existing feature file OR creates capability-oriented new file. This demonstrates the search-before-create pattern we need for scenario deduplication."
        }
      ],
      "assumptions": [
        "BUG-008: generate-scenarios produces malformed Gherkin steps from example titles. This bug fix improved how generate-scenarios parses example titles and creates proper Gherkin scenarios. The pattern we should follow is similar - analyzing example text and intelligently transforming it into proper scenarios.",
        "CORRECTION: Reference work unit is BUG-022 (not BUG-008). BUG-022 'Feature file naming for bug work units' - AI searches existing feature files, extracts capability from bug context, and either updates existing feature file OR creates capability-oriented new file. This demonstrates the exact pattern we need: search before create, intelligently match scenarios, update existing features instead of duplicating.",
        "BUG-022 demonstrates the pattern: AI searches existing feature files, determines if scenario matches existing capability, and updates existing feature files instead of creating duplicates."
      ],
      "examples": [
        "User runs 'fspec generate-scenarios AUTH-005' where examples describe login validation. System finds existing scenario 'Validate user credentials' in user-authentication.feature. System prompts: 'Scenario appears to refactor existing scenario in user-authentication.feature. Update existing? (y/n)'. User confirms 'y'. System updates existing scenario, updates test file header comment, regenerates coverage.",
        "User runs 'fspec generate-scenarios AUTH-006' where examples describe OAuth integration. System searches all feature files, finds no OAuth-related scenarios. System creates new feature file 'oauth-integration.feature' with new scenarios.",
        "User runs 'fspec generate-scenarios BUG-009' with 3 examples. System detects: Example 1 matches existing scenario in feature-validation.feature (refactor), Example 2 matches scenario in tag-management.feature (refactor), Example 3 is new. System prompts for each match, updates 2 existing features with refactored scenarios, creates new feature file for Example 3 only.",
        "User runs 'fspec audit-scenarios' after several months of development. System finds 5 duplicate scenarios across different feature files. System reports: 'Found 5 potential duplicates' with file names, scenario titles, and similarity scores. User can choose to merge duplicates interactively.",
        "User runs 'fspec generate-scenarios AUTH-005' where examples describe login validation. System finds existing scenario 'Validate user credentials' in user-authentication.feature. System prompts: 'Scenario appears to refactor existing scenario in user-authentication.feature. Update existing? (y/n)'. User confirms 'y'. System updates existing scenario, updates test file header comment, regenerates coverage.",
        "User runs 'fspec generate-scenarios AUTH-006' where examples describe OAuth integration. System searches all feature files, finds no OAuth-related scenarios. System creates new feature file 'oauth-integration.feature' with new scenarios.",
        "User runs 'fspec generate-scenarios BUG-009' with 3 examples. System detects: Example 1 matches existing scenario in feature-validation.feature (refactor), Example 2 matches scenario in tag-management.feature (refactor), Example 3 is new. System prompts for each match, updates 2 existing features with refactored scenarios, creates new feature file for Example 3 only.",
        "User runs 'fspec audit-scenarios' after several months of development. System finds 5 duplicate scenarios across different feature files. System reports: 'Found 5 potential duplicates' with file names, scenario titles, and similarity scores. User can choose to merge duplicates interactively."
      ],
      "architectureNotes": [],
      "estimate": 8
    },
    "SPEC-003": {
      "id": "SPEC-003",
      "title": "Improve scenario similarity matching accuracy",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-20T21:44:50.450Z",
      "updatedAt": "2025-10-20T22:24:22.484Z",
      "description": "Replace simple Levenshtein distance with hybrid algorithm combining Jaro-Winkler, Token Set Ratio, Gherkin Structural analysis, Trigrams, and Jaccard similarity. Fix 7 critical bugs and improve accuracy from 60% to 88%.",
      "epic": "example-driven-discovery",
      "children": [],
      "attachments": [
        "spec/attachments/SPEC-003/SIMILARITY_ANALYSIS.md",
        "spec/attachments/SPEC-003/ALGORITHM_ANALYSIS.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T21:48:29.525Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T22:02:09.310Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T22:17:20.053Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T22:22:54.783Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T22:24:22.484Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec for scenario deduplication",
        "action": "have accurate scenario similarity matching that handles edge cases and different phrasings",
        "benefit": "I can confidently detect duplicate scenarios and refactoring opportunities without false positives or false negatives"
      },
      "rules": [
        "Similarity scoring must handle empty strings without division by zero crashes",
        "Gherkin keywords (Given/When/Then/And/But) must be stripped from steps before similarity comparison",
        "Keyword extraction must include numbers and special characters (OAuth2, SHA256, Base64, etc.)",
        "Division by zero must be prevented when comparing scenarios with empty keyword sets",
        "Step reordering must not penalize similarity (Given A, Given B should match Given B, Given A)",
        "Partial step matching must be supported (3/4 identical steps should score high)",
        "Short scenario titles (< 20 chars) must use stricter thresholds to prevent false positives",
        "Hybrid algorithm must combine at least 5 different similarity algorithms with weighted scoring",
        "Overall accuracy must reach 88% (improvement from current 60%)",
        "Algorithm must handle word reordering without penalty (Token Set Ratio approach)",
        "Algorithm must handle typos and minor character variations (trigram similarity)",
        "Algorithm must respect Gherkin structure (Given/When/Then sections analyzed separately)",
        "Use 20 characters as threshold for short string detection (as recommended in attachments). Apply stricter threshold of 0.85 for short titles to prevent false positives.",
        "Yes - weight 'Then' steps 1.5x higher than 'Given/When' in Gherkin Structural analysis. Outcomes (Then) are more critical for determining scenario equivalence than preconditions/actions."
      ],
      "examples": [
        "BUG-1: Comparing two scenarios with empty titles should return 1.0 (both empty = identical) without division by zero crash",
        "BUG-2: Steps 'Given user exists, When login, Then success' should have keywords stripped to 'user exists, login, success' before comparison",
        "BUG-5: Technical terms like 'OAuth2', 'SHA256', 'Base64' must be extracted as keywords (regex must include numbers)",
        "BUG-4: Comparing scenarios with no extractable keywords should return 0 similarity without division by zero crash",
        "ISSUE-1: 'Given user exists, Given database connected, When login' should match 100% with 'Given database connected, Given user exists, When login' (reordered steps)",
        "ISSUE-2: Scenario A with steps [X, Y, Z, W] should score 75% step similarity with Scenario B with steps [X, Y, Z, Q] (3/4 match)",
        "ISSUE-3: 'User login' vs 'User logout' should NOT score 83.3% (false positive due to short strings)",
        "Jaro-Winkler: 'User login validation' vs 'User login verification' should score ~0.92 (better than Levenshtein for prefix matching)",
        "Token Set Ratio: 'Given user exists and database connected' vs 'Given database connected and user exists' should score 1.0 (word order independence)",
        "Trigram: 'authenticate' vs 'authentcate' (typo) should score ~0.85 (typo tolerance)",
        "Gherkin Structural: Compare Given/When/Then sections separately with Jaccard similarity, weight Then steps higher (outcomes matter more)",
        "Hybrid: Weighted combination of 5 algorithms (Jaro-Winkler 30%, Token Set 25%, Gherkin Structural 20%, Trigram 15%, Jaccard 10%) achieves 88% accuracy"
      ],
      "questions": [
        {
          "text": "@human: Should algorithm weights (Jaro-Winkler 30%, Token Set 25%, etc.) be configurable via options, or hardcoded based on the analysis recommendations?",
          "selected": true,
          "answer": "Configurable via options/parameters - allows dynamic tuning if results aren't optimal"
        },
        {
          "text": "@human: Should we implement Phase 1 only (80% accuracy, simpler) or both Phase 1 + Phase 2 (88% accuracy, more complex) in this work unit?",
          "selected": true,
          "answer": "Yes - implement both Phase 1 + Phase 2 for 88% accuracy target"
        },
        {
          "text": "@human: Are we okay with zero external dependencies (Phase 1+2 recommendation), or should we consider Phase 3 with Sentence-BERT ML library for 92% accuracy?",
          "selected": true,
          "answer": "Investigate semantic-chunking (https://www.npmjs.com/package/semantic-chunking) and other npm packages for semantic similarity as potential enhancement"
        },
        {
          "text": "@human: Should the similarity threshold (currently 0.7) be configurable per use case, or should we optimize it based on testing?",
          "selected": true,
          "answer": "No - threshold optimized based on testing, not user-configurable"
        },
        {
          "text": "@human: For short string bias handling, what should be the character threshold (attachments propose < 20 chars)? Should this be configurable?",
          "selected": true,
          "answer": "Use 20 characters as threshold for short string detection (as recommended in attachments). Apply stricter threshold of 0.85 for short titles to prevent false positives."
        },
        {
          "text": "@human: Should 'Then' steps (outcomes) be weighted higher than 'Given/When' steps in Gherkin Structural analysis, as proposed in the attachments?",
          "selected": true,
          "answer": "Yes - weight 'Then' steps 1.5x higher than 'Given/When' in Gherkin Structural analysis. Outcomes (Then) are more critical for determining scenario equivalence than preconditions/actions."
        },
        {
          "text": "@human: Should we prioritize speed or accuracy if there's a trade-off? (e.g., caching, two-stage filtering for large codebases)",
          "selected": true,
          "answer": "Prioritize accuracy over speed for Phase 1+2. All algorithms (Jaro-Winkler, Token Set, Gherkin Structural, Trigram, Jaccard) are O(n*m) or better. For 100+ scenarios, implement two-stage filtering: (1) fast keyword filtering, (2) full similarity on candidates."
        },
        {
          "text": "@human: Should we keep the old Levenshtein algorithm available via a flag for backward compatibility and comparison testing?",
          "selected": true,
          "answer": "Yes - keep old Levenshtein algorithm behind a flag for backward compatibility and A/B testing. Allows users to compare old vs new algorithm results during transition period."
        }
      ],
      "architectureNotes": [
        "Current Implementation: src/utils/scenario-similarity.ts uses Levenshtein distance (character-level edit distance) with 70/30 weighted scoring (title vs steps). Has 7 critical bugs and achieves only 60% accuracy.",
        "Proposed Hybrid Algorithm: Combine 5 algorithms with weighted scoring - Jaro-Winkler (30% - title matching), Token Set Ratio (25% - word reordering), Gherkin Structural (20% - Given/When/Then awareness), Trigram Similarity (15% - fuzzy matching), Jaccard Similarity (10% - keyword overlap). Expected 88% accuracy.",
        "Bug Fixes Required: (1) Division by zero for empty strings/keywords, (2) Strip Gherkin keywords before comparison, (3) Include numbers in keyword regex for technical terms, (4) Fix keyword extraction for match objects, (5) Remove redundant lowercasing, (6) Handle step reordering, (7) Support partial step matching.",
        "Performance: All Phase 1+2 algorithms have no external dependencies and run in O(n*m) time or better. For large codebases (100+ scenarios), consider two-stage matching: (1) Fast keyword filtering, (2) Full similarity only on candidates.",
        "Test Coverage: Must cover empty strings, empty steps, empty keywords, special characters, numbers in terms (OAuth2/SHA256), short titles, reordered steps, partial matches, typos, and performance with 100+ scenarios. See src/commands/__tests__/scenario-deduplication.test.ts",
        "References: (1) spec/attachments/SPEC-003/SIMILARITY_ANALYSIS.md - Bug analysis and test gaps, (2) spec/attachments/SPEC-003/ALGORITHM_ANALYSIS.md - Algorithm comparison and implementation guide, (3) Jaro-Winkler, Token Set Ratio, Trigram algorithms ~200 lines total with no dependencies"
      ],
      "assumptions": [
        "Configurable via options/parameters - allows dynamic tuning if results aren't optimal",
        "Yes - implement both Phase 1 + Phase 2 for 88% accuracy target",
        "Investigate semantic-chunking (https://www.npmjs.com/package/semantic-chunking) and other npm packages for semantic similarity as potential enhancement",
        "No - threshold optimized based on testing, not user-configurable",
        "semantic-chunking provides semantic embeddings via ONNX models (all-MiniLM-L6-v2 at 23MB) and cosine similarity. Can be added as optional Phase 3 enhancement for semantic matching when higher accuracy needed beyond 88% target.",
        "Prioritize accuracy over speed for Phase 1+2. All algorithms (Jaro-Winkler, Token Set, Gherkin Structural, Trigram, Jaccard) are O(n*m) or better. For 100+ scenarios, implement two-stage filtering: (1) fast keyword filtering, (2) full similarity on candidates.",
        "Yes - keep old Levenshtein algorithm behind a flag for backward compatibility and A/B testing. Allows users to compare old vs new algorithm results during transition period."
      ],
      "estimate": 8
    },
    "HOOK-011": {
      "id": "HOOK-011",
      "title": "Work unit-scoped hooks for dynamic validation",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-20T22:40:29.609Z",
      "updatedAt": "2025-10-21T00:52:25.364Z",
      "description": "Enable AI agents to attach hooks to specific work units without modifying global hook configuration",
      "children": [],
      "userStory": {
        "role": "AI agent working on a specific work unit",
        "action": "attach validation hooks (like eslint) to this work unit dynamically",
        "benefit": "I can enforce quality checks for this story without modifying global hook configuration"
      },
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-20T22:41:29.303Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-20T23:11:34.037Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T23:14:41.456Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T23:18:21.442Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T23:23:22.138Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T23:23:59.562Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T23:35:46.088Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T23:35:58.490Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T23:36:45.753Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-20T23:51:10.746Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-20T23:51:29.247Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-20T23:57:49.686Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T00:48:39.048Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T00:48:55.509Z"
        }
      ],
      "questions": [
        {
          "text": "@human: Should work unit-scoped hooks be saved permanently (persisted in work-units.json) or ephemeral (exist only during the current session)?",
          "selected": true,
          "answer": "Ephemeral by default - hooks run once when requested without persisting. AI can offer to convert useful virtual hooks into permanent hooks (saved to spec/fspec-hooks.json) if the user wants to reuse them."
        },
        {
          "text": "@human: How should the AI discover what virtual hooks are available? Should we have predefined templates (like 'eslint', 'prettier', 'test-coverage') or allow arbitrary commands (like 'npm run custom-lint'), or both?",
          "selected": true,
          "answer": "Virtual hooks are created conversationally - AI proactively asks user 'Do you want me to run anything at specific stages?' User names tools (e.g., 'eslint', 'stylelint'). AI then: 1) Checks if tools exist/are installed, 2) Looks up how to use them (help commands, web search), 3) Creates virtual hooks dynamically. No predefined registry needed."
        },
        {
          "text": "@human: When should the AI ask 'Do you want me to run anything at specific stages?' - at the start of the story, at specific workflow stages (like before implementing), or any time during the story?",
          "selected": true,
          "answer": "At the end of specifying phase - after specifications are complete and before moving to testing. This is when AI has full context of what will be built and can meaningfully ask about quality checks."
        },
        {
          "text": "@human: When a virtual hook executes (e.g., eslint at post-validating), should it only run for THIS work unit or apply globally to all work units until removed?",
          "selected": true,
          "answer": "Scoped to current work unit only by default. After the virtual hook executes successfully, AI should ask: 'This [tool] hook worked well. Do you want to make it permanent so it runs for all work units at this stage?' If yes, AI saves it to spec/fspec-hooks.json using 'fspec add-hook' command."
        },
        {
          "text": "@human: If a virtual hook fails (e.g., eslint finds errors), should it be blocking (prevent workflow transition) or non-blocking (show output but allow transition)? Or should AI ask the user which behavior they want?",
          "selected": true,
          "answer": "AI asks user when setting up hook: 'Should I block transitions if [tool] fails?' If user says blocking: STRICT ENFORCEMENT with <system-reminder> wrapping the failure output, AI CANNOT proceed with workflow transition until issues are fixed. If non-blocking: show output but allow transition."
        },
        {
          "text": "@human: What happens to virtual hooks when the work unit reaches 'done' status? Should they automatically be removed, or persist for potential future edits to this work unit?",
          "selected": true,
          "answer": "When work unit reaches 'done' status, AI asks user: 'Do you want to keep these virtual hooks for future edits to this story, or remove them?' If keep: hooks remain attached to work unit. If remove: hooks are cleaned up."
        },
        {
          "text": "@human: Where should virtual hooks be stored temporarily? Should they be in work-units.json (in a 'virtualHooks' field), or in a separate temporary file, or in memory only during the AI session?",
          "selected": true,
          "answer": "Virtual hooks stored in work-units.json as a 'virtualHooks' array field on the work unit. This ties hooks to the story lifecycle, persists across sessions, visible in 'fspec show-work-unit', and can be cleaned up when story is done."
        },
        {
          "text": "@human: When AI creates a virtual hook to run a tool (like eslint), should it: 1) Execute the command directly (e.g., store 'eslint src/' as the command), or 2) Generate a temporary script file in spec/hooks/.virtual/ that wraps the command?",
          "selected": true,
          "answer": "AI decides based on complexity: simple commands use direct execution (e.g., 'eslint src/'), complex ones generate script files in spec/hooks/.virtual/. If hook fails to execute (command not found, script errors, permission issues), AI must: 1) Detect execution failure, 2) Show error to user with <system-reminder>, 3) Offer to fix or remove the broken hook, 4) Ask user if they want to try a different approach."
        },
        {
          "text": "@human: Can a user add multiple virtual hooks to different stages (e.g., eslint at post-implementing AND prettier at post-validating)? And can they add multiple hooks to the SAME stage (e.g., both eslint and stylelint at post-implementing)?",
          "selected": true,
          "answer": "Unlimited virtual hooks allowed. User can add multiple hooks to different stages (eslint at post-implementing, prettier at post-validating) AND multiple hooks to the same stage (eslint AND stylelint both at post-implementing). Hooks execute sequentially in the order they were added."
        },
        {
          "text": "@human: How should users view and manage their virtual hooks after they're created? Should there be commands like 'fspec list-virtual-hooks HOOK-011' or should they appear in 'fspec show-work-unit HOOK-011' output? And how should users remove unwanted virtual hooks?",
          "selected": true,
          "answer": "Both dedicated commands AND AI conversational management. Commands: 'fspec add-virtual-hook HOOK-011 <event> <command>', 'fspec list-virtual-hooks HOOK-011', 'fspec remove-virtual-hook HOOK-011 <hook-name>'. Virtual hooks also appear in 'fspec show-work-unit HOOK-011' output. AI uses these commands when user says 'add eslint hook' or 'remove the prettier hook'. Commands MUST have comprehensive --help documentation so AI can use them correctly."
        },
        {
          "text": "@human: If a work unit has a virtual hook AND there's a global hook configured for the same event (both at post-implementing), what order should they run? Virtual first then global, or global first then virtual?",
          "selected": true,
          "answer": "Virtual hooks run BEFORE global hooks. Execution order: 1) Virtual hooks (work unit-specific), 2) Global hooks (from spec/fspec-hooks.json). This allows work unit-specific validation to happen first before broader project-wide checks."
        },
        {
          "text": "@human: How should users copy virtual hooks from one work unit to another? Should there be a command like 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011', or should AI handle it conversationally ('use the same hooks as AUTH-001')? And should it copy all hooks or allow selecting specific ones?",
          "selected": true,
          "answer": "Both dedicated command AND AI conversational management. Command: 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011' (copies all hooks) or 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011 --hook-name eslint' (copies specific hook). AI can handle conversationally: 'use the same hooks as AUTH-001' (all) or 'copy the eslint hook from AUTH-001' (specific). Command must have comprehensive --help."
        }
      ],
      "rules": [
        "Ephemeral by default - hooks run once when requested without persisting. AI can offer to convert useful virtual hooks into permanent hooks (saved to spec/fspec-hooks.json) if the user wants to reuse them.",
        "Virtual hooks are created conversationally - AI proactively asks user 'Do you want me to run anything at specific stages?' User names tools (e.g., 'eslint', 'stylelint'). AI then: 1) Checks if tools exist/are installed, 2) Looks up how to use them (help commands, web search), 3) Creates virtual hooks dynamically. No predefined registry needed.",
        "When AI asks 'Do you want me to run anything at specific stages?', it MUST list the available hook events (post-implementing, post-testing, post-validating, pre-specifying, etc.) so the human knows their options",
        "At the end of specifying phase - after specifications are complete and before moving to testing. This is when AI has full context of what will be built and can meaningfully ask about quality checks.",
        "AI must phrase the question clearly with examples: 'Do you want me to run a command or program at any stage of this story? For example, I could run eslint after implementing, or run prettier before validating. Here are the available stages: [list stages]'",
        "Scoped to current work unit only by default. After the virtual hook executes successfully, AI should ask: 'This [tool] hook worked well. Do you want to make it permanent so it runs for all work units at this stage?' If yes, AI saves it to spec/fspec-hooks.json using 'fspec add-hook' command.",
        "AI asks user when setting up hook: 'Should I block transitions if [tool] fails?' If user says blocking: STRICT ENFORCEMENT with <system-reminder> wrapping the failure output, AI CANNOT proceed with workflow transition until issues are fixed. If non-blocking: show output but allow transition.",
        "When work unit reaches 'done' status, AI asks user: 'Do you want to keep these virtual hooks for future edits to this story, or remove them?' If keep: hooks remain attached to work unit. If remove: hooks are cleaned up.",
        "Virtual hooks stored in work-units.json as a 'virtualHooks' array field on the work unit. This ties hooks to the story lifecycle, persists across sessions, visible in 'fspec show-work-unit', and can be cleaned up when story is done.",
        "AI decides based on complexity: simple commands use direct execution (e.g., 'eslint src/'), complex ones generate script files in spec/hooks/.virtual/. If hook fails to execute (command not found, script errors, permission issues), AI must: 1) Detect execution failure, 2) Show error to user with <system-reminder>, 3) Offer to fix or remove the broken hook, 4) Ask user if they want to try a different approach.",
        "Unlimited virtual hooks allowed. User can add multiple hooks to different stages (eslint at post-implementing, prettier at post-validating) AND multiple hooks to the same stage (eslint AND stylelint both at post-implementing). Hooks execute sequentially in the order they were added.",
        "Both dedicated commands AND AI conversational management. Commands: 'fspec add-virtual-hook HOOK-011 <event> <command>', 'fspec list-virtual-hooks HOOK-011', 'fspec remove-virtual-hook HOOK-011 <hook-name>'. Virtual hooks also appear in 'fspec show-work-unit HOOK-011' output. AI uses these commands when user says 'add eslint hook' or 'remove the prettier hook'. Commands MUST have comprehensive --help documentation so AI can use them correctly.",
        "Virtual hooks run BEFORE global hooks. Execution order: 1) Virtual hooks (work unit-specific), 2) Global hooks (from spec/fspec-hooks.json). This allows work unit-specific validation to happen first before broader project-wide checks.",
        "Both dedicated command AND AI conversational management. Command: 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011' (copies all hooks) or 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011 --hook-name eslint' (copies specific hook). AI can handle conversationally: 'use the same hooks as AUTH-001' (all) or 'copy the eslint hook from AUTH-001' (specific). Command must have comprehensive --help.",
        "Virtual hooks can receive git context (staged/unstaged files) via hook context JSON. AI can create hooks that target specific changed files. For complex hooks needing git context, AI generates script files in spec/hooks/.virtual/ that process the file list.",
        "Git context is OPTIONAL. When setting up a virtual hook, AI asks: 'Do you want this hook to target only changed files (staged/unstaged)? For example, I can run eslint only on your modified .ts files.' If yes: AI generates script that uses git context. If no: command runs as-is without git context (e.g., 'eslint src/' runs against entire codebase)."
      ],
      "examples": [
        "User is working on AUTH-001. At end of specifying, AI asks: 'Do you want me to run a command or program at any stage? For example, eslint after implementing. Available stages: post-implementing, post-testing, post-validating.' User says: 'Yes, run eslint and prettier.' AI creates two virtual hooks, asks if blocking, stores in work-units.json.",
        "Virtual hook 'eslint' runs at post-implementing. Eslint finds 3 errors. Hook is blocking. AI shows errors wrapped in <system-reminder>, CANNOT proceed to validating until user fixes errors. User fixes errors, re-runs transition, eslint passes, transition succeeds.",
        "Virtual hook runs successfully. AI asks: 'The eslint hook worked well. Do you want to make it permanent for all work units?' User says yes. AI runs 'fspec add-hook post-implementing eslint spec/hooks/.virtual/eslint-HOOK-011.sh --blocking' to save to spec/fspec-hooks.json.",
        "Work unit reaches done status. AI asks: 'Do you want to keep these virtual hooks for future edits to this story, or remove them?' User says remove. AI cleans up virtualHooks array from work-units.json and deletes generated script files.",
        "User says 'use the same hooks as AUTH-001'. AI runs 'fspec copy-virtual-hooks --from AUTH-001 --to HOOK-011', copies all virtual hooks (eslint, prettier) with their configurations (blocking status, event names) to current work unit.",
        "Virtual hook command 'eslint src/' fails to execute (command not found). AI detects execution failure, shows error in <system-reminder>: 'Hook failed to execute: eslint: command not found. Install eslint or check PATH.' AI offers to remove broken hook or try different command.",
        "User runs 'fspec show-work-unit HOOK-011'. Output includes 'Virtual Hooks' section showing: 'post-implementing: eslint (blocking), prettier (non-blocking)', 'post-validating: test-coverage (blocking)'. User can see all active hooks at a glance.",
        "User says 'run eslint only on changed files'. AI creates virtual hook with script in spec/hooks/.virtual/eslint-changed-files.sh. Hook context includes git info: {stagedFiles: ['src/auth.ts'], unstagedFiles: ['src/utils.ts']}. Script runs: eslint $STAGED_FILES. This is more efficient than linting entire codebase."
      ],
      "estimate": 8,
      "virtualHooks": [],
      "attachments": [
        "spec/attachments/HOOK-011/HOOK-011-issues-found.md"
      ]
    },
    "BUG-023": {
      "id": "BUG-023",
      "title": "commonPatterns displays [object Object] in help output",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-21T00:28:59.162Z",
      "updatedAt": "2025-10-21T01:38:22.549Z",
      "children": [],
      "description": "Detailed bug analysis in spec/bugs/BUG-023-commonpatterns-formatting.md\n\nThe COMMON PATTERNS section in command help displays '[object Object]' instead of formatted pattern information. \n\nRoot cause: Type mismatch between CommandHelpConfig interface (expects string[]) and help file implementations (use objects with pattern/example/description).\n\nAffects: All help files including add-hook-help.ts and all 5 new virtual-hook help files.\n\nSee attached markdown for full analysis, reproduction steps, and recommended solutions.",
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T01:32:35.146Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T01:34:32.725Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T01:35:33.322Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T01:38:06.003Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T01:38:22.550Z"
        }
      ],
      "userStory": {
        "role": "AI agent using fspec CLI",
        "action": "view properly formatted COMMON PATTERNS in help output",
        "benefit": "I can understand usage patterns without seeing [object Object]"
      },
      "rules": [
        "Help formatter must support both string[] and object[] formats for commonPatterns (backward compatibility)",
        "Object format commonPatterns must display pattern name, example command, and description",
        "Interface must accept both formats: string[] | Array<{pattern,example,description}>"
      ],
      "examples": [
        "Running 'fspec add-virtual-hook --help' displays formatted patterns with name, example, and description instead of [object Object]",
        "All 20+ affected help commands display COMMON PATTERNS section correctly after fix",
        "Help commands still using string[] format continue to work (backward compatibility)"
      ],
      "estimate": 2
    },
    "HELP-003": {
      "id": "HELP-003",
      "title": "Regenerate help output for 20+ commands after BUG-023 fix",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-21T01:32:08.102Z",
      "updatedAt": "2025-10-21T01:41:10.513Z",
      "description": "After fixing the commonPatterns formatting bug (BUG-023), regenerate and verify help output for all affected commands to ensure proper display of COMMON PATTERNS section",
      "children": [],
      "attachments": [
        "spec/attachments/HELP-003/affected-help-files.md",
        "spec/attachments/HELP-003/verification-report.md",
        "spec/attachments/HELP-003/verify-help-patterns.sh"
      ],
      "dependsOn": [
        "BUG-023"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T01:39:35.953Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T01:39:37.906Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T01:41:01.813Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T01:41:10.514Z"
        }
      ],
      "estimate": 1
    },
    "GIT-001": {
      "id": "GIT-001",
      "title": "Replace git CLI usage with isomorphic-git library",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T01:48:10.185Z",
      "updatedAt": "2025-10-21T02:21:42.908Z",
      "description": "Replace all external git command calls with isomorphic-git, a pure JavaScript git implementation that can be bundled into fspec without external dependencies",
      "children": [],
      "attachments": [
        "spec/attachments/GIT-001/isomorphic-git-research.md",
        "spec/attachments/GIT-001/testing-patterns.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T01:52:37.646Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T02:10:46.791Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T02:14:18.345Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T02:20:14.711Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T02:21:42.908Z"
        }
      ],
      "userStory": {
        "role": "developer maintaining fspec",
        "action": "replace git CLI calls with isomorphic-git library",
        "benefit": "fspec can be bundled as a single executable without external dependencies"
      },
      "rules": [
        "Must create comprehensive git abstraction layer in src/git/ with common operations (status, add, commit, log) following best practices patterns",
        "Git abstraction layer must be architected as core shared infrastructure for all git operations across fspec",
        "Keep execa dependency (used for lifecycle hooks execution) but replace all git CLI calls with isomorphic-git",
        "Git abstraction layer must support configurable strict mode - callers can choose whether errors are thrown or silently return empty results",
        "No barrel exports (index.ts) - consumers must import directly from specific modules like src/git/status.ts",
        "Use modular structure with separate files per operation area: status.ts, add.ts, commit.ts, log.ts in src/git/ directory",
        "Create semantic wrapper types that hide isomorphic-git implementation details - consumers should not depend on library-specific types like StatusRow",
        "Internal modules can use isomorphic-git types internally but must transform to semantic types (e.g., FileStatus) at module boundaries",
        "Use isomorphic-git testing patterns from official documentation - research and document mock filesystem approach for unit tests",
        "No performance benchmarking required - isomorphic-git performance is acceptable for fspec use case",
        "Complete replacement of git-context.ts implementation - no feature flags or parallel implementations",
        "Must update existing feature file, tests, and coverage mappings to align with new isomorphic-git implementation"
      ],
      "examples": [
        "Virtual hook with git-context flag needs to get list of staged and unstaged files to pass to hook script (e.g., eslint only on changed files)",
        "Checkpoint system (GIT-002 dependency) needs to detect all modified, staged, and untracked files before creating intelligent stash snapshot",
        "Empty repository (git init, no commits yet) - should handle gracefully, treat all files as untracked without crashing",
        "Repository with .gitignore - operations should respect .gitignore by default, exclude ignored files (node_modules, dist, etc.) from status results",
        "Clean repository (no changes) - returns empty arrays efficiently for staged, unstaged, and untracked files"
      ],
      "estimate": 8
    },
    "GIT-002": {
      "id": "GIT-002",
      "title": "Intelligent checkpoint system for workflow transitions",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T01:48:11.753Z",
      "updatedAt": "2025-10-21T03:59:02.614Z",
      "description": "Implement automatic git stash/restore checkpointing when work units move through Kanban states, capturing all file changes (including fspec-modified files) for rollback capability",
      "children": [],
      "dependsOn": [
        "GIT-001"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T03:07:42.421Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T03:27:39.806Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T03:30:42.709Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T03:57:36.338Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T03:59:02.614Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec",
        "action": "automatically save my work at each workflow transition",
        "benefit": "I can safely experiment without losing progress and recover from mistakes"
      },
      "rules": [
        "Checkpoints are automatically created when work unit status changes (before leaving current state)",
        "Users can create named checkpoints manually at any time for experiments",
        "Checkpoints capture all file changes including untracked files (respecting .gitignore)",
        "Automatic checkpoints use pattern '{work-unit-id}-auto-{state}', manual use user-provided names",
        "Checkpoints persist until explicitly deleted (no automatic expiration)",
        "Checkpoints stored as git stashes with special message format for filtering",
        "When restoration causes conflicts, AI receives system-reminder to resolve using Read/Edit tools",
        "All tests must run and pass after checkpoint restoration with conflicts",
        "Show all checkpoints by default with clear visual indicators (emoji like 🤖 for auto, 📌 for manual) so users feel confident in the safety net",
        "Use 'fspec checkpoint' (short form) for AI efficiency - less verbose, faster to type in conversations",
        "Ask user interactively when dirty working directory detected - present options (commit first, stash and restore, force restore with merge) and explain risks of each approach"
      ],
      "examples": [
        "User runs 'fspec update-work-unit-status GIT-002 implementing', system creates checkpoint 'GIT-002-auto-testing' before transition",
        "User runs 'fspec create-checkpoint GIT-002 before-refactor', system creates named checkpoint for experimentation",
        "User creates checkpoint 'baseline', tries approach A (fails), restores 'baseline', tries approach B (succeeds)",
        "User restores checkpoint causing conflicts, AI receives system-reminder, reads conflicted files, resolves with Edit tool, tests run automatically, restoration completes when tests pass",
        "User runs 'fspec list-checkpoints GIT-002', sees both automatic and manual checkpoints with timestamps",
        "User runs 'fspec cleanup-checkpoints GIT-002 --keep-last 5', system deletes old checkpoints keeping 5 most recent"
      ],
      "architectureNotes": [
        "Git stash message format: fspec-checkpoint:{work-unit-id}:{checkpoint-name}:{timestamp}",
        "Use 'git stash push -u -m message' to include untracked files respecting .gitignore",
        "Use 'git stash apply stash@{N}' for restoration (preserves stash for re-restoration)",
        "Conflict detection: parse git output for CONFLICT markers and identify affected files",
        "AI conflict resolution: emit system-reminder with conflicted files, AI uses Read/Edit to resolve",
        "Test validation: automatically run 'npm test' after conflict resolution, block completion if tests fail",
        "Leverage existing isomorphic-git integration for git operations"
      ],
      "questions": [
        {
          "text": "@human: Should automatic checkpoints be hidden by default in 'fspec list-checkpoints GIT-002' (require --show-auto flag to display)?",
          "selected": true,
          "answer": "Show all checkpoints by default with clear visual indicators (emoji like 🤖 for auto, 📌 for manual) so users feel confident in the safety net"
        },
        {
          "text": "@human: Command naming preference: 'fspec checkpoint GIT-002 name' (short) or 'fspec create-checkpoint GIT-002 name' (explicit)?",
          "selected": true,
          "answer": "Use 'fspec checkpoint' (short form) for AI efficiency - less verbose, faster to type in conversations"
        },
        {
          "text": "@human: Should restoration fail if working directory is dirty (uncommitted changes) even without conflicts?",
          "selected": true,
          "answer": "Ask user interactively when dirty working directory detected - present options (commit first, stash and restore, force restore with merge) and explain risks of each approach"
        },
        {
          "text": "@human: Should test command be configurable (package.json 'test' script vs hardcoded 'npm test')?",
          "selected": true,
          "answer": "fspec does NOT run tests - it emits system-reminder to AI agent that tests must be run. AI chooses test command (npm test, vitest, etc). This is about the system-reminder message content only."
        }
      ],
      "assumptions": [
        "fspec does NOT run tests - it emits system-reminder to AI agent that tests must be run. AI chooses test command (npm test, vitest, etc). This is about the system-reminder message content only."
      ],
      "estimate": 8
    },
    "GIT-003": {
      "id": "GIT-003",
      "title": "Fix GIT-001 critical bugs and logic errors",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T02:35:34.991Z",
      "updatedAt": "2025-10-21T03:03:08.487Z",
      "description": "Fix blocker test failure, critical logic bugs in getUnstagedFiles(), type safety violations, and add comprehensive test coverage for edge cases identified in ULTRATHINK analysis",
      "epic": "example-driven-discovery",
      "children": [],
      "attachments": [
        "spec/attachments/GIT-003/git-001-critical-analysis.md"
      ],
      "dependsOn": [
        "GIT-001"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T02:36:12.870Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T02:41:19.861Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T03:02:35.465Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T03:02:43.916Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T03:03:08.488Z"
        }
      ],
      "rules": [
        "BLOCKER (S1): Fix failing test - getUnstagedFiles() returns empty array for modified files in memfs environment",
        "CRITICAL (S2): Fix logic bug - getUnstagedFiles() misses files that are staged then modified again (partial staging scenario)",
        "CRITICAL (S2): Fix FileStatus.modified semantic ambiguity - rename to hasUnstagedModifications or add separate hasUnstagedChanges field",
        "HIGH (S3): Replace fs parameter type 'any' with proper IFs interface type for type safety",
        "MEDIUM (S4): Add comprehensive test coverage for 14 missing scenarios including deleted files, nested directories, partial staging, and edge cases"
      ],
      "examples": [
        "Failing test: File modified after commit in memfs not detected by getUnstagedFiles() - returns [] instead of ['modified.txt']",
        "Partial staging miss: echo v2 > file.txt && git add file.txt && echo v3 >> file.txt results in file appearing in staged but NOT unstaged (should be in both)",
        "Type safety violation: Passing { someMethod: () => {} } as fs option causes runtime error instead of compile-time error"
      ],
      "userStory": {
        "role": "developer maintaining fspec",
        "action": "fix critical bugs and logic errors in GIT-001 isomorphic-git integration",
        "benefit": "virtual hooks and checkpoint system work correctly with all git scenarios"
      },
      "estimate": 8
    },
    "EST-002": {
      "id": "EST-002",
      "title": "AI token usage tracking",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-21T05:25:26.138Z",
      "updatedAt": "2025-10-21T05:25:26.138Z",
      "description": "Enable AI agents to record token usage cumulatively against work units throughout the development lifecycle, providing visibility into AI resource consumption per story from start to completion. Track input tokens, output tokens, and total cost across all iterations and state transitions.",
      "children": []
    },
    "TECH-001": {
      "id": "TECH-001",
      "title": "JSONL format investigation for work-units.json scalability",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-21T05:25:29.539Z",
      "updatedAt": "2025-10-21T05:25:29.539Z",
      "description": "Investigate migrating from JSON to JSONL (JSON Lines) format for work-units.json to address file size limitations as projects scale. Research: 1) performance comparison for large datasets (1000+ work units), 2) append-only operations vs full file rewrites, 3) streaming read/write capabilities, 4) git diff friendliness, 5) backward compatibility strategies, 6) migration path from JSON to JSONL. Deliver recommendation with proof-of-concept if beneficial.",
      "children": []
    },
    "BOARD-002": {
      "id": "BOARD-002",
      "title": "Interactive Kanban board CLI",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-21T05:25:48.725Z",
      "updatedAt": "2025-10-21T05:25:48.725Z",
      "description": "Create an interactive terminal interface for fspec board that allows keyboard navigation across columns and work units. Press Enter to view full work unit details including description, attachments, example mapping data, dependencies, metrics, and more. Support vim-style navigation (hjkl), arrow keys, tab to switch columns, and quick actions (e.g., 's' for status change, 'e' to edit, 'a' for attachments).",
      "epic": "interactive-cli",
      "children": []
    },
    "CLEAN-001": {
      "id": "CLEAN-001",
      "title": "Add ESLint and Prettier for code quality",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-21T05:53:29.407Z",
      "updatedAt": "2025-10-21T05:53:29.407Z",
      "description": "Set up ESLint and Prettier to enforce consistent code style and catch common errors. This includes configuration, fixing existing violations, and integrating with the development workflow.",
      "children": []
    },
    "INIT-004": {
      "id": "INIT-004",
      "title": "Support multiple AI agents beyond Claude",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T05:58:37.972Z",
      "updatedAt": "2025-10-21T10:50:48.434Z",
      "description": "Support multiple AI agents beyond Claude by cloning other AI agent tools to understand their capabilities and configuration requirements. Research how agents like Cursor, Aider, and Continue.dev work to design fspec integration patterns.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T08:45:16.988Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T10:22:39.520Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T10:31:02.888Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T10:37:36.334Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T10:38:20.381Z"
        }
      ],
      "attachments": [
        "spec/attachments/INIT-004/ai-coding-agents-october-2025.md",
        "spec/attachments/INIT-004/multi-agent-implementation-research.md",
        "spec/attachments/INIT-004/interactive-agent-selector-implementation.md",
        "spec/attachments/INIT-004/agent-auto-loading-capabilities-research.md",
        "spec/attachments/INIT-004/agent-instruction-mechanisms-research.md"
      ],
      "rules": [
        "Each AI agent must have its own documentation template (e.g., CLAUDE.md, AIDER.md, CURSOR.md)",
        "System-reminder tags are Claude Code specific and must be abstracted or made optional for other agents",
        "fspec init command must support --agent flag to specify which AI agent to configure",
        "Slash command directory paths vary by agent (e.g., .claude/commands/ vs .continue/commands/)",
        "Documentation must avoid hardcoded references to 'Claude' or 'Claude Code' in agent-agnostic sections",
        "Yes, support multiple agents: Allow 'fspec init --agent=aider --agent=cursor' to install configurations for multiple agents simultaneously. Generate spec/AGENT.md for each and install slash commands to respective directories",
        "Agent-specific prompting vocabulary (like 'ultrathink' for Claude) must be translated or removed for each agent based on their capabilities",
        "fspec init must create slash commands for ALL major fspec CLI commands (validate, format, list-features, create-work-unit, etc.), not just documentation",
        "All agent templates must be bundled in fspec distribution using Vite copy plugin",
        "Template directory structure must support both flat (cursor) and nested (claude) slash command paths",
        "Generate on-the-fly using TemplateManager pattern: shared command body + agent-specific wrappers (frontmatter, path, argument placeholders). Avoids 360-540 template files, enables consistency across agents",
        "Remove meta-cognitive prompts for CLI-only agents (Aider, Gemini CLI, Qwen CLI). Keep for IDE/extension-based agents (Cline, Windsurf, Cursor). Agent registry should have 'supportsMetaCognition' flag to control this",
        "Support both: 'fspec init' (no flags) shows interactive selector by default. 'fspec init --agent=X' runs non-interactive mode for automation/scripts",
        "Yes, auto-detect installed agents by checking for directories (.claude/, .cursor/, etc.). Sort list with: 1) Detected agents at top (pre-selected), 2) Popular agents (Claude Code, Codex, Copilot), 3) Remaining agents alphabetically",
        "Support all 18 agents in v1. Use dynamic generation - ONE base template that gets transformed based on agent capabilities (system-reminder support, meta-cognition support, slash command format). No separate template files per agent.",
        "Install THREE files per agent: 1) Root stub (AGENTS.md or AGENT_NAME.md) for auto-loading, 2) Full doc (spec/AGENT_NAME.md) for comprehensive workflow, 3) Slash command (.agent/commands/fspec.md) for manual trigger. Most agents (Claude, Cursor, Cline, Windsurf, Copilot, etc.) auto-load root stubs; CLI-only tools need slash commands.",
        "fspec init is idempotent and supports agent switching. Running 'fspec init --agent=cursor' after 'fspec init --agent=claude' should remove Claude-specific files (CLAUDE.md, spec/CLAUDE.md, .claude/commands/) and install Cursor-specific files (CURSOR.md or AGENTS.md, spec/CURSOR.md, .cursor/commands/). All files are auto-generated, safe to replace.",
        "Interactive selector is SINGLE-SELECT: arrow keys to navigate/highlight, Enter to confirm the currently highlighted agent. No multi-select, no checkboxes. For multiple agents, user must run 'fspec init --agent=X --agent=Y' using CLI flags.",
        "Default highlighted agent should be the FIRST DETECTED agent (if any were auto-detected). If no agents detected, default to first agent in sorted list.",
        "No --no-interactive flag needed. Presence of --agent flags is sufficient to determine mode: if --agent present, use CLI mode; if no --agent, use interactive mode. A --no-interactive flag without --agent makes no sense.",
        "fspec init is NON-DESTRUCTIVE: if .cursor/commands/ already exists with custom files, create fspec.md alongside them. Never delete or overwrite user's custom files. Only manage fspec-specific files (AGENTS.md, spec/AGENT.md, .agent/commands/fspec.md).",
        "Validate agent IDs against registry before installation. Check file permissions before writing. Create directories recursively (mkdir -p). Handle missing templates gracefully with error messages. Wrap blocking hook failures in <system-reminder> tags for AI visibility.",
        "Generate ONE comprehensive fspec.md per agent (1010-line pattern like current .claude/commands/fspec.md). NOT multiple smaller files. This file contains complete ACDD workflow, Example Mapping process, coverage tracking, etc. Format varies by agent: Markdown with YAML frontmatter (Claude, Cursor, Cline, etc.) or TOML (Gemini CLI, Qwen Code).",
        "Invalid agent ID: Show error with list of valid agents, exit code 1. Missing templates: Check dist/spec/templates/ and fallback to spec/templates/. If both missing, show error explaining distribution may be corrupted. Suggest reinstalling fspec. Permission errors: Show clear message about directory permissions, suggest chmod/chown fixes.",
        "Research complete - see spec/attachments/INIT-004/agent-instruction-mechanisms-research.md. Finding: Claude Code's <system-reminder> tags are UNIQUE. All other agents use visible Markdown patterns: bold text (**IMPORTANT:**), headers (###), code blocks, blockquotes. Transformation required: <system-reminder> → **⚠️ IMPORTANT:** (IDE agents) or **IMPORTANT:** (CLI agents). No equivalent invisible mechanism exists for other agents."
      ],
      "examples": [
        "User runs 'fspec init --agent=aider' and gets Aider-specific documentation template copied to spec/AIDER.md",
        "User runs 'fspec init --agent=cursor' and slash command is installed to .cursor/commands/fspec.md",
        "User runs 'fspec init --agent=cline' and gets Cline-specific docs without system-reminder references",
        "User runs 'fspec init --agent=cursor' and gets 20+ slash commands created (.cursor/commands/fspec-validate.md, .cursor/commands/fspec-format.md, etc.) plus spec/CURSOR.md",
        "After 'npm install -g fspec', global installation contains bundled templates at node_modules/fspec/dist/spec/templates/cursor/CURSOR.md",
        "CLAUDE.md contains 'ultrathink your next steps' but AIDER.md (CLI-based) removes meta-cognitive prompts entirely"
      ],
      "questions": [
        {
          "text": "@human: Should fspec init auto-detect which AI agent is being used, or always require explicit --agent flag?",
          "selected": true,
          "answer": "Support both: 'fspec init' (no flags) shows interactive selector by default. 'fspec init --agent=X' runs non-interactive mode for automation/scripts"
        },
        {
          "text": "@human: For agents without system-reminder support, should we strip those tags or replace with agent-specific patterns?",
          "selected": true,
          "answer": "Yes, auto-detect installed agents by checking for directories (.claude/, .cursor/, etc.). Sort list with: 1) Detected agents at top (pre-selected), 2) Popular agents (Claude Code, Codex, Copilot), 3) Remaining agents alphabetically"
        },
        {
          "text": "@human: Should 'fspec init' support multiple agents simultaneously (e.g., team with mixed Cursor + Aider users)?",
          "selected": true,
          "answer": "Support all 18 agents in v1. Use dynamic generation - ONE base template that gets transformed based on agent capabilities (system-reminder support, meta-cognition support, slash command format). No separate template files per agent."
        },
        {
          "text": "@human: Should we bundle ALL 18 agents' templates (increasing package size significantly) or allow dynamic generation?",
          "selected": true,
          "answer": "Research which agents support auto-loading project context files (AGENT.md pattern) vs requiring slash commands. Install both for v1 to maximize compatibility."
        },
        {
          "text": "@human: Should slash command templates be generated on-the-fly from shared logic or pre-built and bundled?",
          "selected": true,
          "answer": "Install THREE files per agent: 1) Root stub (AGENTS.md or AGENT_NAME.md) for auto-loading, 2) Full doc (spec/AGENT_NAME.md) for comprehensive workflow, 3) Slash command (.agent/commands/fspec.md) for manual trigger. Most agents (Claude, Cursor, Cline, Windsurf, Copilot, etc.) auto-load root stubs; CLI-only tools need slash commands."
        },
        {
          "text": "@human: How do we handle agents that don't support meta-cognitive prompts like 'ultrathink' (e.g., CLI-only Aider)?",
          "selected": true,
          "answer": "fspec init is idempotent and supports agent switching. Running 'fspec init --agent=cursor' after 'fspec init --agent=claude' should remove Claude-specific files (CLAUDE.md, spec/CLAUDE.md, .claude/commands/) and install Cursor-specific files (CURSOR.md or AGENTS.md, spec/CURSOR.md, .cursor/commands/). All files are auto-generated, safe to replace."
        },
        {
          "text": "@human: Should fspec init use interactive mode by default, or require explicit flags?",
          "selected": true,
          "answer": "Interactive selector is SINGLE-SELECT: arrow keys to navigate/highlight, Enter to confirm the currently highlighted agent. No multi-select, no checkboxes. For multiple agents, user must run 'fspec init --agent=X --agent=Y' using CLI flags."
        },
        {
          "text": "@human: Should interactive selector auto-detect installed agents and how should the list be sorted?",
          "selected": true,
          "answer": "Default highlighted agent should be the FIRST DETECTED agent (if any were auto-detected). If no agents detected, default to first agent in sorted list."
        },
        {
          "text": "@human: Should we support all 18 agents in v1, or start with a smaller set? Should we use separate template files or dynamic generation?",
          "selected": true,
          "answer": "No --no-interactive flag needed. Presence of --agent flags is sufficient to determine mode: if --agent present, use CLI mode; if no --agent, use interactive mode. A --no-interactive flag without --agent makes no sense."
        },
        {
          "text": "@human: Should we install both AGENT.md (for auto-load on startup) AND a slash command (for manual trigger), or just one? Which agents support auto-loading project context files?",
          "selected": true,
          "answer": "fspec init is NON-DESTRUCTIVE: if .cursor/commands/ already exists with custom files, create fspec.md alongside them. Never delete or overwrite user's custom files. Only manage fspec-specific files (AGENTS.md, spec/AGENT.md, .agent/commands/fspec.md)."
        },
        {
          "text": "@human: Should fspec init be idempotent? If user runs 'fspec init --agent=cursor' after already running 'fspec init --agent=claude', what should happen?",
          "selected": true,
          "answer": "Single base template with dynamic transformations based on agent.supportsSystemReminders, agent.supportsMetaCognition, and agent.category flags. Use TemplateManager pattern: ONE base template transformed via regex replacement and formatting functions."
        },
        {
          "text": "@human: Is the interactive selector single-select (arrow to highlight, enter to confirm) or multi-select (space to toggle checkboxes, enter to confirm multiple)?",
          "selected": true,
          "answer": "System-reminders: <system-reminder> → **⚠️ IMPORTANT:** (IDE agents with emoji) or **IMPORTANT:** (CLI agents). Meta-cognitive prompts: 'ultrathink', 'deeply consider' → removed for CLI-only agents. Use regex patterns. Agent placeholders: {{AGENT_NAME}}, {{SLASH_COMMAND_PATH}}, {{AGENT_ID}} replaced via string.replace()."
        },
        {
          "text": "@human: In interactive selector, which agent should be highlighted by default when the UI opens?",
          "selected": true,
          "answer": "ONE comprehensive fspec.md file per agent (like current 1010-line pattern), NOT multiple smaller files. Different formats: Markdown with YAML frontmatter (Claude, Cursor, Cline) or TOML (Gemini CLI, Qwen Code). Generate using TemplateManager pattern: shared body + agent-specific wrapper."
        },
        {
          "text": "@human: Do we need a --no-interactive flag, or is presence of --agent flags sufficient to disable interactive mode?",
          "selected": true,
          "answer": "Validate agent IDs against registry before installation. Check file permissions before writing. Create directories recursively (mkdir -p). Handle missing templates gracefully with error messages. Wrap blocking hook failures in <system-reminder> tags for AI visibility."
        },
        {
          "text": "@human: If target directories already exist with user's custom files (e.g., .cursor/commands/my-command.md), should fspec init be destructive or non-destructive?",
          "selected": true,
          "answer": "Use viteStaticCopy plugin to copy base template files (spec/templates/base/*.md) into dist/ during build. Templates bundled into dist/spec/templates/base/. Component code bundled normally by Vite. Template resolver tries production path first, falls back to dev path."
        },
        {
          "text": "@human: How do we transform the base template for different agents? Single base template with dynamic transformations based on agent.supportsSystemReminders, agent.supportsMetaCognition flags? Or multiple template tiers?",
          "selected": true,
          "answer": "id: string, name: string, description: string, slashCommandPath: string, slashCommandFormat: 'markdown' | 'toml', supportsSystemReminders: boolean, supportsMetaCognition: boolean, docTemplate: string, rootStubFile: string, detectionPaths: string[], available: boolean, category: 'ide' | 'cli' | 'extension'"
        },
        {
          "text": "@human: What exact patterns need transformation? 'ultrathink' → 'carefully consider'? '<system-reminder>' → '<\\!-- IMPORTANT: -->'? Any others? Should we use regex, string replacement, or AST parsing?",
          "selected": true,
          "answer": "Transform 'ultrathink' → removed (CLI agents) or kept (IDE agents). System-reminder: '<system-reminder>' → '**⚠️ IMPORTANT:**' (IDE with emoji) or '**IMPORTANT:**' (CLI). Also transform: 'deeply consider', 'take a moment to reflect' → removed for CLI agents. Use regex replacement: /<system-reminder>([\\s\\S]*?)<\\/system-reminder>/g. Placeholders: {{AGENT_NAME}}, {{SLASH_COMMAND_PATH}} via string.replace()."
        },
        {
          "text": "@human: Current .claude/commands/fspec.md is 1010 lines (comprehensive workflow guide). Should we generate ONE comprehensive fspec.md per agent (same pattern), or MULTIPLE smaller commands (fspec-validate.md, fspec-format.md, etc.)?",
          "selected": true,
          "answer": "Generate ONE comprehensive fspec.md per agent (1010-line pattern like current .claude/commands/fspec.md). NOT multiple smaller files. This file contains complete ACDD workflow, Example Mapping process, coverage tracking, etc. Format varies by agent: Markdown with YAML frontmatter (Claude, Cursor, Cline, etc.) or TOML (Gemini CLI, Qwen Code)."
        },
        {
          "text": "@human: Error handling: What should happen if user runs 'fspec init --agent=invalid-id'? Show list of valid agents? Exit with error code? What if template files missing from dist/?",
          "selected": true,
          "answer": "Invalid agent ID: Show error with list of valid agents, exit code 1. Missing templates: Check dist/spec/templates/ and fallback to spec/templates/. If both missing, show error explaining distribution may be corrupted. Suggest reinstalling fspec. Permission errors: Show clear message about directory permissions, suggest chmod/chown fixes."
        },
        {
          "text": "@human: Vite bundling: Should we bundle base template files (spec/templates/base/AGENT.md) in dist/, or bundle transformation logic as compiled code? What's the dist/ structure after build?",
          "selected": true,
          "answer": "Bundle base template files using viteStaticCopy plugin. Structure: dist/spec/templates/base/AGENT.md (ONE base template with placeholders). Runtime: templateGenerator.ts reads from dist/spec/templates/base/, transforms based on agent config, outputs to spec/AGENT.md. Dev mode: reads from spec/templates/base/. Template resolver tries production path first, falls back to dev."
        },
        {
          "text": "@human: Agent registry structure: Confirm complete AgentConfig interface fields (id, name, description, category, rootStubFile, fullDocFile, slashCommandPath, slashCommandFormat, detectionPaths, supportsSystemReminders, supportsMetaCognition, popularity for sorting). Missing any fields?",
          "selected": true,
          "answer": "AgentConfig fields confirmed: id (string), name (string), description (string), slashCommandPath (string), slashCommandFormat ('markdown' | 'toml'), supportsSystemReminders (boolean), supportsMetaCognition (boolean), docTemplate (string, e.g. 'CLAUDE.md'), rootStubFile (string, e.g. 'CLAUDE.md' or 'AGENTS.md'), detectionPaths (string[], e.g. ['.claude/', '.claude/commands/']), available (boolean), category ('ide' | 'cli' | 'extension'). Optional: popularity (number) for sorting."
        },
        {
          "text": "@human: Claude Code uses <system-reminder> tags for invisible-to-user workflow guidance. What equivalent mechanisms do other agents have for getting attention and providing hidden instructions? Need research on all 18 agents' attention/instruction mechanisms.",
          "selected": true,
          "answer": "Research complete - see spec/attachments/INIT-004/agent-instruction-mechanisms-research.md. Finding: Claude Code's <system-reminder> tags are UNIQUE. All other agents use visible Markdown patterns: bold text (**IMPORTANT:**), headers (###), code blocks, blockquotes. Transformation required: <system-reminder> → **⚠️ IMPORTANT:** (IDE agents) or **IMPORTANT:** (CLI agents). No equivalent invisible mechanism exists for other agents."
        }
      ],
      "architectureNotes": [
        "Create agent registry in spec/agents.json mapping agent names to configuration (doc template, slash command path, system-reminder support, etc.)",
        "Refactor init command: add --agent flag, read agent config from registry, copy appropriate templates, generate agent-specific documentation",
        "Create template system: templates/{agent-name}/AGENT.md and templates/{agent-name}/slash-command.md with variable substitution",
        "Add agent detection: check for .claude/, .cursor/, .continue/ directories or environment variables to auto-detect active agent",
        "Update vite.config.ts to copy spec/templates/{agent}/**/*.md to dist/spec/templates/{agent}/ for bundled distribution",
        "Template matrix challenge: 20-30 fspec commands × 18 agents = 360-540 template files. Consider shared template body + agent-specific wrappers to reduce duplication",
        "Init command must locate templates from bundled distribution (handle both dev: spec/templates/ and production: dist/spec/templates/ paths)",
        "ink/react Integration Architecture: Refactor fspec to use ink/react for ALL interactive commands (not just init). Create shared component library in src/components/ (AgentSelector, Spinner, ErrorMessage, SuccessMessage, ConfirmPrompt, etc.) and shared hooks in src/hooks/ (useKeyboardNavigation, useSafeInput, useAgentSelection). Follow DRY principles - reuse cage patterns (MainMenu navigation, keyboard input handling, visual feedback). Commands like 'fspec reverse', 'fspec board', future interactive commands should all use shared ink/react components. Vite build handles React/JSX compilation."
      ],
      "userStory": {
        "role": "developer using any AI coding agent",
        "action": "initialize fspec in my project with agent-specific configuration",
        "benefit": "I get properly formatted documentation and setup tailored to my agent without manual editing"
      },
      "assumptions": [
        "Auto-detect with fallback to explicit flag: Check for agent directories (.claude/, .cursor/, .continue/) and environment variables first, but allow --agent flag to override. Default to Claude Code if no detection",
        "Strip system-reminder tags for non-Claude agents: Use agent registry to check 'supportsSystemReminders' flag. For agents without support, strip tags but preserve content as comments or agent-specific annotations",
        "Bundle ALL 18 agents in v1 for simplicity and feature completeness. Future optimization: lazy-download popular agents on first use to reduce package size",
        "Research which agents support auto-loading project context files (AGENT.md pattern) vs requiring slash commands. Install both for v1 to maximize compatibility.",
        "Single base template with dynamic transformations based on agent.supportsSystemReminders, agent.supportsMetaCognition, and agent.category flags. Use TemplateManager pattern: ONE base template transformed via regex replacement and formatting functions.",
        "System-reminders: <system-reminder> → **⚠️ IMPORTANT:** (IDE agents with emoji) or **IMPORTANT:** (CLI agents). Meta-cognitive prompts: 'ultrathink', 'deeply consider' → removed for CLI-only agents. Use regex patterns. Agent placeholders: {{AGENT_NAME}}, {{SLASH_COMMAND_PATH}}, {{AGENT_ID}} replaced via string.replace().",
        "ONE comprehensive fspec.md file per agent (like current 1010-line pattern), NOT multiple smaller files. Different formats: Markdown with YAML frontmatter (Claude, Cursor, Cline) or TOML (Gemini CLI, Qwen Code). Generate using TemplateManager pattern: shared body + agent-specific wrapper.",
        "Use viteStaticCopy plugin to copy base template files (spec/templates/base/*.md) into dist/ during build. Templates bundled into dist/spec/templates/base/. Component code bundled normally by Vite. Template resolver tries production path first, falls back to dev path.",
        "id: string, name: string, description: string, slashCommandPath: string, slashCommandFormat: 'markdown' | 'toml', supportsSystemReminders: boolean, supportsMetaCognition: boolean, docTemplate: string, rootStubFile: string, detectionPaths: string[], available: boolean, category: 'ide' | 'cli' | 'extension'",
        "Transform 'ultrathink' → removed (CLI agents) or kept (IDE agents). System-reminder: '<system-reminder>' → '**⚠️ IMPORTANT:**' (IDE with emoji) or '**IMPORTANT:**' (CLI). Also transform: 'deeply consider', 'take a moment to reflect' → removed for CLI agents. Use regex replacement: /<system-reminder>([\\s\\S]*?)<\\/system-reminder>/g. Placeholders: {{AGENT_NAME}}, {{SLASH_COMMAND_PATH}} via string.replace().",
        "Bundle base template files using viteStaticCopy plugin. Structure: dist/spec/templates/base/AGENT.md (ONE base template with placeholders). Runtime: templateGenerator.ts reads from dist/spec/templates/base/, transforms based on agent config, outputs to spec/AGENT.md. Dev mode: reads from spec/templates/base/. Template resolver tries production path first, falls back to dev.",
        "AgentConfig fields confirmed: id (string), name (string), description (string), slashCommandPath (string), slashCommandFormat ('markdown' | 'toml'), supportsSystemReminders (boolean), supportsMetaCognition (boolean), docTemplate (string, e.g. 'CLAUDE.md'), rootStubFile (string, e.g. 'CLAUDE.md' or 'AGENTS.md'), detectionPaths (string[], e.g. ['.claude/', '.claude/commands/']), available (boolean), category ('ide' | 'cli' | 'extension'). Optional: popularity (number) for sorting."
      ],
      "estimate": 8
    },
    "RES-001": {
      "id": "RES-001",
      "title": "Interactive research command with multiple backend support",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-21T07:32:19.749Z",
      "updatedAt": "2025-10-21T07:32:27.373Z",
      "description": "Implement 'fspec research' command that provides AI agents with interactive choice of registered research endpoints during specifying phase (example mapping, architecture planning). Support multiple backends: (1) Perplexity via MCP (https://github.com/jsonallen/perplexity-mcp) for web search, (2) Nanobrowser via MCP for browser automation and web scraping, (3) Mindstrike via CLI for AI-powered knowledge queries. Command should register available endpoints, present interactive selection to AI agent, execute research query, and return formatted results.",
      "epic": "example-driven-discovery",
      "children": [],
      "dependsOn": [
        "MCP-002"
      ]
    },
    "BUG-024": {
      "id": "BUG-024",
      "title": "Fix dependencies command error with work unit ID argument",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T07:33:29.645Z",
      "updatedAt": "2025-10-21T07:50:38.438Z",
      "description": "The 'fspec dependencies <id>' command throws 'Invalid action: <id>' error instead of showing dependency tree. Error occurs at dist/index.js:8359. Command should accept work unit ID as argument and display dependency relationships (dependsOn, blocks, blockedBy, relatesTo).",
      "children": [],
      "attachments": [
        "spec/attachments/BUG-024/bug-024-error-details.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T07:35:58.546Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T07:38:45.398Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T07:49:54.638Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T07:50:09.592Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T07:50:38.438Z"
        }
      ],
      "rules": [
        "Legacy dependencies() function must be removed to prevent CLI routing conflicts"
      ],
      "examples": [
        "User runs 'fspec dependencies RES-001' and receives dependency list instead of 'Invalid action' error",
        "Command shows 'Dependencies for RES-001:' followed by relationship lists (blocks, blockedBy, dependsOn, relatesTo)"
      ],
      "architectureNotes": [
        "Root Cause: Legacy dependencies() function (line 1017-1072 in src/commands/dependencies.ts) is still exported and callable. This function expects (action, workUnitId, options) but CLI passes (workUnitId, options) directly to it. Solution: Remove the legacy function since registerDependenciesCommand() now uses showDependencies() instead."
      ],
      "userStory": {
        "role": "AI agent using fspec for project management",
        "action": "view work unit dependencies using 'fspec dependencies <id>'",
        "benefit": "I can understand dependency relationships and plan work order"
      }
    },
    "INIT-005": {
      "id": "INIT-005",
      "title": "Fix multi-agent support critical issues",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T10:50:08.007Z",
      "updatedAt": "2025-10-21T11:03:45.953Z",
      "description": "Address 25 bugs and anti-patterns discovered during INIT-004 implementation code review. Includes 3 critical issues (destructive file deletion, path traversal vulnerability, duplicate agent directories), 4 high priority, 6 medium, and 12 low priority issues.",
      "children": [],
      "attachments": [
        "spec/attachments/INIT-005/post-implementation-issues.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T10:51:51.424Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T10:55:38.963Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T10:58:21.113Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T11:03:12.454Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T11:03:45.953Z"
        }
      ],
      "userStory": {
        "role": "developer using fspec with multiple AI agents",
        "action": "have critical bugs and anti-patterns from INIT-004 implementation fixed",
        "benefit": "multi-agent support is production-ready, secure, and follows best practices"
      },
      "rules": [
        "Agent switching must ONLY delete fspec-specific files (AGENT.md, spec/AGENT.md, .agent/commands/fspec.md), never entire directories or user's custom files",
        "Agent registry slashCommandPath must be validated to prevent path traversal attacks (no ../, no absolute paths, must be relative to project root)",
        "Each agent must have unique slashCommandPath and rootStubFile to avoid conflicts (e.g., codex and codex-cli cannot both use .codex/commands/)",
        "System-reminder regex transformation must handle nested tags, multiline content, and edge cases without breaking content",
        "Meta-cognitive prompt removal must use word boundaries to avoid corrupting valid words containing 'think' (e.g., 'rethink', 'thinking')",
        "Invalid agent ID errors must include list of valid agent IDs to help users discover available options"
      ],
      "examples": [
        "Critical: User runs 'fspec init --agent=cursor' after 'fspec init --agent=claude', system deletes .claude/commands/fspec.md only (not entire .claude/commands/ directory with user's custom commands)",
        "Critical: Agent registry contains malicious slashCommandPath '../../../etc/passwd', validation rejects it before creating files",
        "Critical: codex and codex-cli agents both try to use .codex/commands/, installation detects conflict and shows clear error message",
        "High: Template contains nested system-reminders, transformation correctly handles both levels without breaking content structure",
        "High: Template contains 'rethinking' and 'thinking', meta-cognitive removal only strips 'ultrathink' and 'deeply consider', preserves valid words",
        "High: User runs 'fspec init --agent=invalid-agent', error message lists all 18 valid agent IDs with descriptions"
      ],
      "estimate": 5
    },
    "INIT-006": {
      "id": "INIT-006",
      "title": "Wire up multi-agent support to fspec init command",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T11:10:11.887Z",
      "updatedAt": "2025-10-21T13:14:07.492Z",
      "description": "Update registerInitCommand to use new multi-agent system (installAgents, agent registry, interactive selector). Deprecate and remove old single-agent code (init function, generateTemplate, copyClaudeTemplate). The new infrastructure exists but isn't being called - fspec init still defaults to Claude-only installation.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T11:10:26.993Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T11:13:42.750Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T11:14:27.089Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T11:17:31.868Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T11:39:48.433Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T11:49:45.027Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T11:50:30.315Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T12:01:28.869Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T12:04:45.819Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T12:05:34.971Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T12:07:20.322Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T12:13:16.564Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T12:16:35.634Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T12:19:06.529Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T12:21:12.211Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T12:31:51.329Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T12:34:59.166Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T12:36:46.905Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T12:45:27.354Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T12:45:47.085Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T12:47:53.774Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T12:49:29.009Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T12:49:35.452Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T12:52:10.515Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T12:52:18.545Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T13:09:33.571Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T13:10:54.118Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T13:12:16.851Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T13:12:24.992Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T13:14:07.492Z"
        }
      ],
      "rules": [
        "registerInitCommand must call installAgents() with interactive selector when no --agent flag provided",
        "Old init() function, generateTemplate(), and copyClaudeTemplate() must be removed after migration",
        "Command must accept --agent flag (can be repeated) for non-interactive mode",
        "Interactive selector must use agent auto-detection to pre-select detected agents",
        "fspec init must work after global npm install without requiring local files",
        "Generated files must be customized for each agent (agent-specific names, paths, features)",
        "Interactive selector uses single-select navigation (arrow keys + ENTER), NOT checkboxes",
        "Cursor highlights currently selected agent, ENTER key immediately installs that agent",
        "NO multi-select - user can only select ONE agent at a time in interactive mode"
      ],
      "examples": [
        "User runs 'fspec init' with no flags, sees interactive agent selector with auto-detected agents pre-selected",
        "User runs 'fspec init --agent=cursor', skips interactive selector and installs Cursor directly",
        "After migration, old init(), generateTemplate(), copyClaudeTemplate() functions are deleted from init.ts",
        "User installs fspec globally with 'npm install -g fspec', then runs 'fspec init' in new project - command works without errors",
        "After running 'fspec init --agent=cursor', generated files contain 'Cursor' not 'Claude Code' in agent names",
        "After completing migration, old code paths (reading from project's .claude/commands/fspec.md) are completely removed",
        "User runs 'fspec init', sees list with cursor on first agent, presses down arrow twice to move cursor to Cline, presses ENTER, Cline is selected and installation starts",
        "User runs 'fspec init' in a directory with .claude/ folder, cursor starts on Claude Code (auto-detected), user presses ENTER, Claude Code is installed"
      ],
      "userStory": {
        "role": "developer using any AI coding agent",
        "action": "run 'fspec init' and get an interactive agent selector",
        "benefit": "I can choose my agent and get proper setup without needing to know the --agent flag syntax"
      },
      "estimate": 3
    },
    "BUG-025": {
      "id": "BUG-025",
      "title": "Intermittent test failure: command-help-system main help test",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-21T11:38:00.009Z",
      "updatedAt": "2025-10-22T01:46:07.007Z",
      "description": "The test 'Feature: Command Help System > Scenario: Main help mentions individual command help availability' fails intermittently in the full test suite with exit code 1, but passes when run individually. This suggests a test isolation or timing issue. The test has been temporarily skipped in src/commands/__tests__/command-help-system.test.ts:198.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T01:38:08.404Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T01:42:10.310Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T01:42:20.544Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T01:45:20.920Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T01:45:54.840Z"
        }
      ],
      "rules": [
        "Tests must not rebuild dist/index.js during execution as it causes race conditions"
      ],
      "examples": [
        "version-display.test.ts runs 'npm run build' while command-help-system.test.ts executes node dist/index.js --help, causing exit code 1 or undefined",
        "Test passes when run in isolation but fails when run with full suite due to dist/index.js being rebuilt by version-display.test.ts"
      ],
      "architectureNotes": [
        "Root cause: version-display.test.ts rebuilds dist/index.js during test execution, causing race condition with command-help-system.test.ts",
        "Solution: Mark version-display.test.ts with test.sequential() to prevent parallel execution with other CLI tests"
      ],
      "userStory": {
        "role": "developer running fspec test suite",
        "action": "run all tests concurrently without race conditions",
        "benefit": "tests are reliable and pass consistently"
      },
      "estimate": 2
    },
    "BUG-026": {
      "id": "BUG-026",
      "title": "Flaky tests: command-help-system and foundation-existence-check fail in full suite but pass individually",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-21T13:01:16.689Z",
      "updatedAt": "2025-10-22T01:54:20.584Z",
      "description": "Two test files pass when run individually but fail in full suite - indicates test isolation issues.\n\nCOMMAND HELP TEST:\n- File: src/commands/__tests__/command-help-system.test.ts:223\n- Scenario: Display help for Example Mapping command with patterns\n- Expected: exitCode 0, Actual: exitCode 1 (full suite) | exitCode 0 (isolated)\n- Command: node dist/index.js add-question --help\n\nFOUNDATION EXISTENCE CHECK TEST:\n- File: src/commands/__tests__/foundation-existence-check.test.ts:172\n- Scenario: Run validate command without foundation.json (read-only exempt)\n- Expected: exitCode 0, Actual: exitCode undefined (full suite) | exitCode 0 (isolated)\n- Command: fspec validate (using execa)\n\nROOT CAUSE HYPOTHESIS:\n- Global state pollution from earlier tests\n- Async cleanup issues (tests completing out of order)\n- File system state not properly isolated\n- CLI process state leaking between tests\n\nNEXT STEPS:\n1. Add beforeEach/afterEach hooks for clean state\n2. Check for process.exit() calls affecting exit codes\n3. Investigate test execution order to find polluting tests\n4. Use vitest --sequence.shuffle to identify order dependencies",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T01:47:09.811Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T01:54:05.760Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T01:54:07.340Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T01:54:09.258Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T01:54:09.990Z"
        }
      ],
      "rules": [
        "Tests that execute dist/index.js must not run in parallel with tests that rebuild it"
      ],
      "examples": [
        "command-help-system.test.ts executes 'node dist/index.js add-question --help' and gets exit code 1 when version-display.test.ts rebuilds dist/index.js in parallel",
        "foundation-existence-check.test.ts executes 'fspec validate' and gets exit code undefined when version-display.test.ts rebuilds dist/index.js in parallel",
        "After fixing BUG-025 (marking version-display.test.ts as sequential), both tests pass consistently in full suite"
      ],
      "architectureNotes": [
        "Root cause: Same as BUG-025 - version-display.test.ts rebuilding dist/index.js created race conditions with ALL CLI tests",
        "Solution: Fixed by BUG-025 solution - marking version-display.test.ts with describe.sequential() prevents parallel execution",
        "Impact: Both command-help-system.test.ts:223 and foundation-existence-check.test.ts:172 now pass consistently in full suite (verified across multiple runs)"
      ],
      "userStory": {
        "role": "developer running full test suite",
        "action": "have all CLI tests pass reliably",
        "benefit": "I can trust test results without intermittent failures"
      },
      "estimate": 1
    },
    "INIT-007": {
      "id": "INIT-007",
      "title": "Agent-specific activation instructions in success message",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-21T13:27:47.865Z",
      "updatedAt": "2025-10-21T13:27:47.865Z",
      "description": "After running 'fspec init' in interactive mode, the success message says 'Run /fspec in your AI agent to activate' but not all agents use the /command format for slash commands. Need to display agent-specific instructions based on selected agent.\n\nResearch shows:\n- Claude Code: /fspec (nested slash commands)\n- Cursor: /fspec (flat slash commands)\n- Gemini CLI, Qwen Code: Use TOML format, may not have /command syntax\n- Other agents: Need to verify slash command syntax\n\nAcceptance Criteria:\n- Success message shows agent-specific activation instruction\n- Instructions accurate for each agent's slash command format\n- Uses research from INIT-004 attachments",
      "children": []
    },
    "INIT-008": {
      "id": "INIT-008",
      "title": "Agent runtime detection for context-aware CLI output",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T13:28:51.970Z",
      "updatedAt": "2025-10-22T08:46:47.154Z",
      "description": "WHAT ALREADY EXISTS:\n1. Template generation time transformations (during 'fspec init'):\n   - removeMetaCognitivePrompts() strips 'ultrathink', 'deeply consider' for CLI agents\n   - stripSystemReminders() transforms <system-reminder> tags to bold text for non-Claude\n   - Agent registry has supportsMetaCognition and supportsSystemReminders flags\n   - This works great for generated files (AGENT.md, slash commands)\n\n2. Environment variable:\n   - FSPEC_DISABLE_REMINDERS=1 disables system-reminders entirely\n\nWHAT'S MISSING (THE ACTUAL PROBLEM):\n1. Runtime detection: fspec commands don't know which agent is running them\n   - 'fspec validate' emits <system-reminder> for ALL agents (only Claude understands)\n   - 'fspec update-work-unit-status' uses system-reminders regardless of agent\n   - Error messages don't adapt (all use <system-reminder> tags)\n   - Help commands don't tailor output based on agent\n\n2. CLI output adaptation:\n   - Commands should emit <system-reminder> for Claude Code\n   - Commands should emit **⚠️ IMPORTANT:** for Cursor/Cline/IDE agents  \n   - Commands should emit **IMPORTANT:** for CLI-only agents (Aider, Gemini)\n   - Currently everything uses <system-reminder> by default\n\n3. No detection mechanism:\n   - Can't tell if it's Claude vs Cursor vs Aider running the command\n   - No FSPEC_AGENT environment variable\n   - No config file (~/.fspec/config.json)\n   - No auto-detection from project files (.claude/, .cursor/)\n\nDetection strategies to implement:\n1. Environment variable: FSPEC_AGENT=claude (highest priority)\n2. Config file: ~/.fspec/config.json with {\"defaultAgent\": \"claude\"}\n3. Auto-detect from project: Check for .claude/, .cursor/, etc. in cwd\n4. Fallback: Safe default (plain text, no system-reminders)\n\nAcceptance Criteria:\n- Runtime agent detection using priority chain (env > config > auto-detect > default)\n- All CLI commands adapt output based on detected agent\n- System-reminders only emitted for Claude Code at runtime\n- Other agents get transformed output (bold text + emoji or plain)\n- Detection works across all 18 supported agents\n- Fallback to safe defaults if detection fails\n- Documentation for FSPEC_AGENT env var and ~/.fspec/config.json",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T08:28:46.801Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T08:41:15.717Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T08:44:03.360Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T08:45:18.471Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T08:46:47.154Z"
        }
      ],
      "rules": [
        "Detection must use priority chain: FSPEC_AGENT env var > config file > auto-detect from project files > safe default",
        "System-reminders only emitted for Claude Code at runtime",
        "Cursor/Cline/IDE agents receive **⚠️ IMPORTANT:** with bold text and emoji",
        "CLI-only agents (Aider, Gemini) receive **IMPORTANT:** plain text without emoji",
        "Must support all 18 agents defined in existing agent registry",
        "Must fallback to safe default (plain text, no system-reminders) if detection fails",
        "Per-project config file at spec/fspec-config.json (consistent with other fspec config files like spec/fspec-hooks.json)",
        "No runtime auto-detection needed. Agent is detected during 'fspec init' (using existing detection logic) and written to spec/fspec-config.json. All subsequent commands read from config file.",
        "Agent registry already exists with all needed metadata. 'fspec init' detects agent and writes to config. Runtime commands read config to determine output format (system-reminder for Claude, bold+emoji for IDE agents, plain for CLI agents)."
      ],
      "examples": [
        "User sets FSPEC_AGENT=claude, runs 'fspec validate', output contains <system-reminder> tags",
        "Cursor user (no env var) runs 'fspec validate' in project with .cursor/ directory, output contains **⚠️ IMPORTANT:** with emoji",
        "Aider user runs 'fspec validate' with no env var or config, auto-detects CLI-only agent, output contains **IMPORTANT:** plain text",
        "User has ~/.fspec/config.json with defaultAgent=cursor but FSPEC_AGENT=claude is set, Claude is used (env var takes priority)",
        "Unknown environment with no detection clues, system falls back to safe default (plain text output, no system-reminders)"
      ],
      "questions": [
        {
          "text": "@human: Should config file be global (~/.fspec/config.json) or per-project (.fspec/config.json) or both with priority?",
          "selected": true,
          "answer": "Per-project config file at spec/fspec-config.json (consistent with other fspec config files like spec/fspec-hooks.json)"
        },
        {
          "text": "@human: What are the exact directory/file patterns for auto-detection (e.g., .claude/, .cursor/, .aider/config)?",
          "selected": true,
          "answer": "No runtime auto-detection needed. Agent is detected during 'fspec init' (using existing detection logic) and written to spec/fspec-config.json. All subsequent commands read from config file."
        },
        {
          "text": "@human: Should the agent registry be extended with output format preferences (system-reminder vs bold vs plain)?",
          "selected": true,
          "answer": "Agent registry already exists with all needed metadata. 'fspec init' detects agent and writes to config. Runtime commands read config to determine output format (system-reminder for Claude, bold+emoji for IDE agents, plain for CLI agents)."
        }
      ],
      "userStory": {
        "role": "AI agent (Claude Code, Cursor, Aider, etc.) running fspec commands",
        "action": "have CLI output adapted to my capabilities (system-reminders, bold text, plain text)",
        "benefit": "I can understand and act on fspec guidance effectively without confusion or unsupported syntax"
      },
      "estimate": 5
    },
    "TECH-002": {
      "id": "TECH-002",
      "title": "Audit AI agent files for .gitignore exclusions",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-21T13:50:11.071Z",
      "updatedAt": "2025-10-22T06:55:51.180Z",
      "description": "Review all supported AI agents/tools and identify which files should be excluded from version control via .gitignore. Agents to investigate: Claude Code, Cursor, Windsurf, Copilot, and any other AI coding assistants we support. Look for: 1) Agent-specific configuration files, 2) Temporary files, 3) Cache directories, 4) Session state files, 5) Any generated files that shouldn't be committed. Create comprehensive .gitignore entries to prevent these files from being tracked.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T06:52:28.874Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T06:52:35.525Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T06:55:49.589Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T06:55:51.180Z"
        }
      ]
    },
    "BUG-027": {
      "id": "BUG-027",
      "title": "Stash system not adding files before creating stash",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-21T13:51:56.223Z",
      "updatedAt": "2025-10-22T01:07:49.222Z",
      "description": "The stash/restore checkpoint system appears to not be stashing any files. Investigation suggests that files are not being added to git before creating the stash, resulting in empty stashes. Need to verify: 1) Are files being staged with 'git add' before 'git stash'? 2) Are untracked files being included? 3) Are there any error messages being suppressed? 4) Test with actual file modifications to confirm stash behavior.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T00:27:04.797Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T00:52:31.871Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T00:54:13.903Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T01:07:08.885Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T01:07:49.222Z"
        }
      ],
      "questions": [
        {
          "text": "@human: What is the stash system currently doing wrong? When I create a checkpoint, what files should be saved and what actually gets saved?",
          "selected": true,
          "answer": "The stash system is using isomorphic-git which doesn't support git stash. It tries to simulate stashing with git.commit() but never stages files first with git.add(), resulting in empty commits that capture nothing. Files should be stashed using real 'git stash push -u -m message' command via execa (which the project already uses elsewhere)."
        },
        {
          "text": "@human: Should the checkpoint system stash both tracked modified files AND untracked new files? Or only tracked files?",
          "selected": true,
          "answer": "Yes, both tracked modified files AND untracked new files should be included using 'git stash push -u' where -u flag includes untracked files while respecting .gitignore. This matches the feature specification line 11."
        },
        {
          "text": "@human: Should we update the feature specification (intelligent-checkpoint-system-for-workflow-transitions.feature line 11) to document that files must be staged before stashing, not using native git -u flag?",
          "selected": true,
          "answer": "Yes, update the feature spec to document that isomorphic-git requires staging untracked files with git.add() before git.stash({ op: 'create' }) can capture them. This is a limitation of isomorphic-git, not native git."
        },
        {
          "text": "@human: For checkpoint restoration, should we attempt to detect and handle merge conflicts (if user modified files since checkpoint), or simply overwrite with checkpoint contents?",
          "selected": true,
          "answer": "Detect and handle conflicts. Compare file contents byte-by-byte. If conflicts detected, emit system-reminder with conflicted files and recommend creating new checkpoint first. Do NOT overwrite without user awareness."
        },
        {
          "text": "@human: Should checkpoint restoration preserve file permissions and timestamps, or just content?",
          "selected": true,
          "answer": "Just content. File permissions and timestamps are not critical for checkpoint use case (experimentation and rollback). Focus on content restoration only."
        }
      ],
      "rules": [
        "isomorphic-git HAS native git.stash() API with 'create' operation that creates stash commit without modifying working directory or refs",
        "isomorphic-git stash only handles TRACKED files - untracked files must be staged with git.add() BEFORE creating checkpoint for them to be captured",
        "Must reset index after checkpoint creation to avoid polluting user's staging area",
        "Store checkpoint refs in custom namespace (refs/fspec-checkpoints/{work-unit-id}/{checkpoint-name}) for organization and easy listing",
        "Checkpoints must capture both modified tracked files AND new untracked files (respecting .gitignore)",
        "Restoration reads checkpoint from custom ref (refs/fspec-checkpoints/{work-unit-id}/{checkpoint-name}) then manually restores files using git.readBlob() and fs.writeFile()",
        "Conflict detection compares working directory file contents vs checkpoint file contents byte-by-byte - if different, file is marked as conflicted",
        "If conflicts detected, emit system-reminder with conflicted files list and recommended actions (create new checkpoint first) - do NOT modify any files",
        "Files in checkpoint but not in working directory are restored (recreated) - files in working directory but not in checkpoint are ignored (left untouched)",
        "Cannot use git.stash({ op: 'apply' }) because our custom ref namespace (refs/fspec-checkpoints) is incompatible with isomorphic-git's reflog-based stash access",
        "Detect and handle conflicts. Compare file contents byte-by-byte. If conflicts detected, emit system-reminder with conflicted files and recommend creating new checkpoint first. Do NOT overwrite without user awareness."
      ],
      "examples": [
        "Current bug: git.commit() called without git.add(), creates empty commit that captures nothing",
        "User modifies tracked file README.md, runs checkpoint, file is staged then stashed with git.stash({ op: 'create' }), working directory unchanged",
        "User creates new untracked file auth.test.ts, runs checkpoint, file is staged with git.add() then captured by stash, working directory unchanged",
        "User modifies README.md and creates new.ts, runs checkpoint, both files staged and captured, index reset afterward, working directory unchanged",
        "User restores checkpoint, files from stash commit are read and written back to working directory, all files (tracked + previously-staged untracked) restored",
        "User creates checkpoint 'baseline', modifies files more, runs restore, all files read from checkpoint commit using git.readBlob() and written to working directory",
        "User creates checkpoint with file A (v1), modifies file A to v2, runs restore, conflict detected (contents differ), system-reminder emitted, file A NOT overwritten (stays v2)",
        "User creates checkpoint with file A, deletes file A from working directory, runs restore, file A is recreated from checkpoint (no conflict)",
        "User creates checkpoint, adds new file B (not in checkpoint), runs restore, file B is left untouched (ignored), only checkpoint files restored",
        "User tries to restore non-existent checkpoint name, git.resolveRef() throws error, restoration returns success=false with 'checkpoint not found' message"
      ],
      "attachments": [
        "spec/attachments/BUG-027/checkpoint-implementation-strategy.md",
        "spec/attachments/BUG-027/checkpoint-restoration-strategy.md"
      ],
      "assumptions": [
        "Yes, update the feature spec to document that isomorphic-git requires staging untracked files with git.add() before git.stash({ op: 'create' }) can capture them. This is a limitation of isomorphic-git, not native git.",
        "Just content. File permissions and timestamps are not critical for checkpoint use case (experimentation and rollback). Focus on content restoration only."
      ],
      "userStory": {
        "role": "developer using fspec checkpoints",
        "action": "create and restore checkpoints that actually capture all file changes",
        "benefit": "I can safely experiment and rollback without losing work"
      },
      "estimate": 5
    },
    "CLI-007": {
      "id": "CLI-007",
      "title": "Add convenience commands for work unit creation by type",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-21T13:51:58.078Z",
      "updatedAt": "2025-10-21T13:51:58.078Z",
      "description": "Replace generic 'create-work-unit' with type-specific commands to make it obvious to AI agents which command to use. Add: 1) 'fspec create-story' for story work units, 2) 'fspec create-bug' for bug work units, 3) 'fspec create-task' for task work units, 4) 'fspec create-refactor' for refactor work units. These should be aliases/wrappers that call create-work-unit with the appropriate --type flag. Update all documentation and help text to use the new commands. Consider deprecating direct use of create-work-unit in favor of these explicit commands.",
      "children": []
    },
    "BUG-028": {
      "id": "BUG-028",
      "title": "spec/AGENT.md files contain stub instead of comprehensive workflow",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-21T21:09:20.138Z",
      "updatedAt": "2025-10-21T23:15:31.966Z",
      "description": "The spec/AGENT.md files (spec/CLAUDE.md, spec/CURSOR.md, etc.) currently contain only a 17-line stub that creates circular references. According to INIT-004 Rule 16, these files should contain the full ACDD workflow documentation (same 1019-line content as slash commands) with agent-specific transformations applied. Current implementation in templateGenerator.ts uses BASE_AGENT_TEMPLATE (17 lines) instead of getSlashCommandTemplate() content (1019 lines).",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-21T21:09:59.327Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T21:12:13.806Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T21:13:36.561Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T21:15:04.083Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T21:23:57.337Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-21T21:44:02.148Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-21T22:28:44.231Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-21T22:31:32.902Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-21T22:49:52.538Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-21T23:15:31.966Z"
        }
      ],
      "rules": [
        "spec/AGENT.md files must contain full Project Management Guidelines (2069 lines), not a 17-line stub",
        "generateAgentDoc() must use getProjectManagementTemplate() as base content, not BASE_AGENT_TEMPLATE",
        "Agent-specific transformations (stripSystemReminders, removeMetaCognitivePrompts, replacePlaceholders) must be applied to Project Management template",
        "Create projectManagementTemplate.ts following same pattern as slashCommandTemplate.ts with section files",
        "Keep BASE_AGENT_TEMPLATE only for root stub generation (CURSOR.md, AGENTS.md), use projectManagementTemplate for spec/AGENT.md",
        "Slash command generation (generateSlashCommandContent) is ALREADY CORRECT and should not be changed"
      ],
      "examples": [
        "Current spec/CLAUDE.md has 17 lines with circular reference: 'For using fspec commands and ACDD workflow: See spec/CLAUDE.md'",
        "Expected spec/CLAUDE.md should have ~2069 lines with full Project Management Guidelines including work unit management, ACDD workflow, coverage tracking, hooks, checkpoints",
        "Restored spec/CLAUDE.md (from GitHub) has 2069 lines titled 'Project Management and Specification Guidelines for fspec' - this content should be templated",
        "Slash command file .claude/commands/fspec.md has 1019 lines of ACDD workflow - this is DIFFERENT from spec/CLAUDE.md and should NOT be changed",
        "projectManagementTemplate.ts should follow same pattern as slashCommandTemplate.ts with section imports (getIntroSection, getProjectManagementSection, etc.)"
      ],
      "userStory": {
        "role": "AI agent (Cursor, Aider, etc.) reading spec/AGENT.md",
        "action": "read comprehensive ACDD workflow documentation",
        "benefit": "I understand the full fspec process without needing to read slash commands"
      },
      "architectureNotes": [
        "Create src/utils/projectManagementTemplate.ts following same pattern as slashCommandTemplate.ts",
        "Break spec/CLAUDE.md (2069 lines) into section files in src/utils/projectManagementSections/ directory",
        "Update generateAgentDoc() in src/utils/templateGenerator.ts to use getProjectManagementTemplate() instead of getSlashCommandTemplate()",
        "generateSlashCommandContent() is ALREADY CORRECT - it uses getSlashCommandTemplate() for .claude/commands/fspec.md (1019 lines)",
        "After fix, spec/CLAUDE.md should have ~2069 lines (Project Management Guidelines), .claude/commands/fspec.md should remain ~1019 lines (ACDD workflow)"
      ],
      "estimate": 2,
      "questions": [
        {
          "text": "@human: Should spec/CLAUDE.md contain the 'Project Management Guidelines' (current 139 lines) or the 'ACDD workflow from slash command' (1019 lines)? What is the actual bug we're fixing?",
          "selected": true,
          "answer": "spec/CLAUDE.md should contain 'Project Management and Specification Guidelines' (2069 lines), NOT the ACDD workflow from slash command (1019 lines). My original implementation was WRONG - I copied the slash command template instead of using the Project Management Guidelines template."
        }
      ],
      "attachments": [
        "spec/attachments/BUG-028/BUG-028-implementation-plan.md"
      ]
    },
    "BUG-029": {
      "id": "BUG-029",
      "title": "Fix failing tests after phase tag removal",
      "type": "bug",
      "status": "done",
      "createdAt": "2025-10-22T06:13:05.750Z",
      "updatedAt": "2025-10-22T06:47:21.878Z",
      "description": "14 tests are failing after removing phase tags from the codebase. Tests in feature-level-tag-management.test.ts, get-scenarios.test.ts, register-tag.test.ts, retag.test.ts, show-acceptance-criteria.test.ts, and hooks tests need to be updated to reflect that phase tags no longer exist and are not required.",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T06:13:31.902Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T06:31:30.323Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T06:31:44.751Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T06:44:27.847Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T06:47:21.878Z"
        }
      ],
      "rules": [
        "All test features must have both @component and @feature-group tags to pass validation",
        "Test expectations for TAGS.md must not check for Usage column (removed)",
        "Remove or update scenarios in feature files that test phase tag validation or usage metadata"
      ],
      "examples": [
        "feature-level-tag-management.test.ts expects result.success=true but gets false because validation fails",
        "generate-tags-md.test.ts and tags-md.test.ts check for Usage column in output but it no longer exists",
        "get-scenarios.test.ts expects 1 scenario but gets 3 because test features now have more tags after adding required @component/@feature-group",
        "retag.test.ts expects '@critical' in output but feature now has @cli @validation instead of @critical"
      ],
      "userStory": {
        "role": "developer maintaining test suite",
        "action": "fix failing tests after removing phase tags and usage metadata",
        "benefit": "all 1360 tests pass and the codebase is clean"
      },
      "estimate": 3
    },
    "BUG-030": {
      "id": "BUG-030",
      "title": "Agent-specific activation message not customized in fspec init success output",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T08:19:08.142Z",
      "updatedAt": "2025-10-22T08:54:43.782Z",
      "description": "The 'Run /fspec in your AI agent to activate' message appears in 2 places in the fspec init command output. This message is generic and doesn't provide agent-specific instructions. For example, Claude Code users see this message, but Gemini users would also see the same message, which may not be applicable. The message should be customized based on the detected AI agent (Claude Code, Gemini, Cursor, etc.) to provide relevant activation instructions. Related to INIT-008 (agent runtime detection).",
      "children": [],
      "dependsOn": [
        "INIT-008"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T08:49:32.630Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T08:51:50.634Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T08:52:50.210Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T08:53:24.438Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T08:54:43.782Z"
        }
      ],
      "rules": [
        "Activation message must be customized based on detected agent (from INIT-008 implementation)",
        "Message appears in 2 places in fspec init output and both must be updated",
        "Claude Code users should see: 'Run /fspec in Claude Code to activate'",
        "CLI agents (Aider, Gemini) should see agent-specific command format",
        "IDE agents (Cursor, Cline) should see instructions relevant to their IDE integration",
        "Default/unknown agents should see generic fallback message",
        "Two places: (1) src/commands/init.ts:234 in CLI success message (2) src/components/AgentSelector.tsx:56 in UI component"
      ],
      "examples": [
        "User runs 'fspec init' with Claude Code detected, sees 'Run /fspec in Claude Code to activate' in 2 places in output",
        "User runs 'fspec init' with Cursor detected, sees 'Open .cursor/commands/ in Cursor to activate' in output",
        "User runs 'fspec init' with Aider detected, sees 'Add .aider/ to your Aider configuration to activate' in output",
        "User runs 'fspec init' with unknown agent, sees generic fallback: 'Refer to your AI agent documentation to activate fspec'"
      ],
      "questions": [
        {
          "text": "@human: Where exactly are the 2 places in the init command output where this message appears?",
          "selected": true,
          "answer": "Two places: (1) src/commands/init.ts:234 in CLI success message (2) src/components/AgentSelector.tsx:56 in UI component"
        }
      ],
      "userStory": {
        "role": "developer running fspec init",
        "action": "see agent-specific activation instructions in the success message",
        "benefit": "I know exactly how to activate fspec in my specific AI agent"
      },
      "estimate": 2
    },
    "BUG-031": {
      "id": "BUG-031",
      "title": "No support for ULTRATHINK in discovery-driven feedback loop",
      "type": "story",
      "status": "backlog",
      "createdAt": "2025-10-22T08:19:09.971Z",
      "updatedAt": "2025-10-22T08:21:45.105Z",
      "description": "The discover-foundation command uses the term 'ULTRATHINK' in its guidance system-reminders to instruct AI agents to perform deep analysis. However, not all AI agents support extended thinking or use this terminology. Claude Code may understand 'ULTRATHINK', but Gemini, Cursor, and other agents do not. The discovery-driven feedback loop needs agent-specific language that adapts to the capabilities of the detected AI agent. For agents without extended thinking support, the term should be removed and replaced with standard instructions. This should integrate with INIT-008 (agent runtime detection) to provide appropriate guidance per agent.",
      "children": [],
      "dependsOn": [
        "INIT-008"
      ]
    },
    "FEAT-017": {
      "id": "FEAT-017",
      "title": "Duplicate scenario detection in generate-scenarios command",
      "type": "story",
      "status": "specifying",
      "createdAt": "2025-10-22T08:26:22.211Z",
      "updatedAt": "2025-10-22T08:27:30.719Z",
      "description": "When 'fspec generate-scenarios' is run, it should check for existing scenarios across all feature files that might be duplicates. Existing code already exists to search for duplicate scenarios and provide results back to the LLM. This work unit refactors generate-scenarios to:\n\n1. Search for possible duplicate scenarios before generating new ones\n2. If duplicates reach a similarity threshold, display them with clear instructions\n3. Emit a system-reminder with:\n   - List of existing feature files that contain similar scenarios\n   - Guidance on what to investigate\n   - Instructions on how to ignore the warning if it's a false positive\n4. Add '--ignore-possible-duplicates' flag to bypass the check and continue generation\n5. Ensure the warning is actionable and prevents accidental duplication\n\nAcceptance Criteria:\n- Search existing feature files for similar scenarios during generate-scenarios\n- Display duplicate matches if similarity threshold is met\n- Emit system-reminder with clear next steps (investigate files, or use --ignore flag)\n- Add '--ignore-possible-duplicates' flag to skip duplicate check\n- Document the duplicate detection behavior in command help\n- Ensure existing duplicate search code is properly integrated",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T08:27:15.376Z"
        }
      ],
      "rules": [
        "Existing code already exists to search for duplicate scenarios and provide results to LLM",
        "System-reminder must provide CLEAR instructions on what to do next",
        "Must show which existing feature files to investigate when duplicates are detected",
        "Must provide instructions on how to ignore warning if it's not valid",
        "Command must accept --ignore-possible-duplicates flag to bypass duplicate check"
      ],
      "examples": [
        "User runs 'fspec generate-scenarios WORK-001', duplicate scenarios are found above threshold, system-reminder shows list of feature files to investigate with clear next steps",
        "User reviews system-reminder, investigates suggested feature files, determines it's a false positive, runs 'fspec generate-scenarios WORK-001 --ignore-possible-duplicates' to proceed",
        "User runs 'fspec generate-scenarios WORK-001', no duplicates found, scenarios are generated normally without any warnings"
      ]
    },
    "BUG-032": {
      "id": "BUG-032",
      "title": "INIT-008 and BUG-030 implementation not integrated into actual codebase",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T09:02:16.255Z",
      "updatedAt": "2025-10-22T09:34:09.061Z",
      "description": "CRITICAL: The implementations for INIT-008 (agent runtime detection) and BUG-030 (agent-specific activation messages) exist as isolated utility functions with passing tests, but are NOT integrated into the actual codebase where they should be used.\n\nSYMPTOMS:\n1. BUG-030: getActivationMessage() function exists but init.ts:234 and AgentSelector.tsx:56 still show hardcoded generic message\n2. INIT-008: agentRuntimeConfig.ts functions (getAgentConfig, writeAgentConfig, formatAgentOutput) exist but are never called by any commands\n3. spec/fspec-config.json is never created during fspec init\n4. All commands still emit <system-reminder> tags unconditionally (formatAgentOutput not used)\n\nIMPACT:\n- Tests pass but user-facing functionality unchanged\n- Original bugs still exist in production code\n- 7 story points marked as 'done' but features not actually delivered\n- Integration gap between unit tests and real behavior\n\nROOT CAUSE:\n- TDD practiced at unit level only (isolated functions)\n- Missing integration/E2E tests showing actual command behavior\n- Work units marked 'done' without verifying end-to-end functionality\n- ACDD followed for isolated modules but not for system integration\n\nACCEPTANCE CRITERIA:\n- getActivationMessage() called from init.ts and AgentSelector.tsx\n- writeAgentConfig() called during fspec init (creates spec/fspec-config.json)\n- formatAgentOutput() used by all commands emitting system-reminders\n- Integration tests prove E2E functionality works\n- Manual testing confirms bugs are actually fixed\n\nRelated: INIT-008, BUG-030",
      "children": [],
      "attachments": [
        "spec/attachments/BUG-032/bug-032-integration-analysis.md"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T09:06:49.671Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T09:10:29.488Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T09:11:30.623Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T09:13:17.184Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T09:14:43.250Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T09:23:11.940Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T09:23:19.872Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T09:32:51.649Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T09:33:43.933Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T09:33:49.940Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T09:34:09.061Z"
        }
      ],
      "userStory": {
        "role": "developer who completed INIT-008 and BUG-030",
        "action": "have the utility functions actually integrated into the codebase",
        "benefit": "the features work for end users instead of just passing unit tests"
      },
      "rules": [
        "getActivationMessage() must be called from src/commands/init.ts:234 to show agent-specific activation instructions",
        "getActivationMessage() must be called from src/components/AgentSelector.tsx:56 to show agent-specific UI text",
        "writeAgentConfig() must be called during fspec init to create spec/fspec-config.json with detected agent",
        "Integration tests must verify end-to-end behavior, not just unit test isolation"
      ],
      "examples": [
        "Before: init.ts shows generic 'Run /fspec in your AI agent to activate'. After: init.ts calls getActivationMessage() and shows 'Run /fspec in Claude Code to activate' for Claude users",
        "Before: AgentSelector.tsx shows hardcoded text. After: AgentSelector calls getActivationMessage() and dynamically renders agent-specific text",
        "Before: fspec init completes but no spec/fspec-config.json created. After: init calls writeAgentConfig() and creates {'agent': 'claude'}"
      ],
      "estimate": 5
    },
    "INIT-009": {
      "id": "INIT-009",
      "title": "Remove initialization files",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T09:49:27.541Z",
      "updatedAt": "2025-10-22T10:15:04.951Z",
      "description": "Command to remove fspec init files from AI editors",
      "children": [],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T09:49:34.506Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T10:10:31.908Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T10:11:52.764Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T10:13:14.706Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T10:15:04.951Z"
        }
      ],
      "userStory": {
        "role": "developer who wants to remove fspec files or switch agents",
        "action": "remove all fspec init files",
        "benefit": "my project is clean when I switch agents or remove fspec entirely"
      },
      "questions": [
        {
          "text": "@human: Should fspec remove-init-files remove spec/fspec-config.json, or only agent-specific files (spec/AGENT.md and slash command files)?",
          "selected": true,
          "answer": "Use an interactive prompt (similar to agent selector in fspec init) to ask user if they want to keep or remove spec/fspec-config.json"
        },
        {
          "text": "@human: Should fspec remove-init-files prompt for confirmation before deleting, or support a --force flag?",
          "selected": true,
          "answer": "No additional confirmation needed - the interactive prompt about keeping/removing config serves as the confirmation step. Delete immediately after user makes their choice."
        },
        {
          "text": "@human: Should fspec remove-init-files auto-detect installed agents (from spec/fspec-config.json or detection) and only remove those files, or remove all known agent files regardless?",
          "selected": true,
          "answer": "Auto-detect installed agents using spec/fspec-config.json or file detection, and only remove files for detected agents (not all known agents)"
        },
        {
          "text": "@human: If some init files don't exist (e.g., .claude/commands/fspec.md is missing), should the command fail with an error, or silently skip and report what was removed?",
          "selected": true,
          "answer": "Silently skip missing files and continue removing what exists. No error if files are already deleted."
        }
      ],
      "rules": [
        "Use an interactive prompt (similar to agent selector in fspec init) to ask user if they want to keep or remove spec/fspec-config.json",
        "No additional confirmation needed - the interactive prompt about keeping/removing config serves as the confirmation step. Delete immediately after user makes their choice.",
        "Auto-detect installed agents using spec/fspec-config.json or file detection, and only remove files for detected agents (not all known agents)",
        "Silently skip missing files and continue removing what exists. No error if files are already deleted."
      ],
      "examples": [
        "User runs 'fspec remove-init-files', interactive prompt asks 'Keep spec/fspec-config.json?', user selects 'No', all files removed including config",
        "User runs 'fspec remove-init-files', interactive prompt asks 'Keep spec/fspec-config.json?', user selects 'Yes', only agent files removed (spec/CLAUDE.md, .claude/commands/fspec.md), config preserved",
        "User runs 'fspec remove-init-files', spec/fspec-config.json contains 'claude' agent, only Claude files removed (not Cursor or other agents)",
        "User runs 'fspec remove-init-files', .claude/commands/fspec.md already missing, command silently skips and removes other files without error"
      ],
      "estimate": 3
    },
    "INIT-010": {
      "id": "INIT-010",
      "title": "Agent switching prompt in fspec init",
      "type": "story",
      "status": "done",
      "createdAt": "2025-10-22T09:53:36.556Z",
      "updatedAt": "2025-10-22T11:32:17.078Z",
      "description": "When fspec init detects existing agent files, prompt user to switch agents (replacing old files except spec/fspec-config.json)",
      "children": [],
      "dependsOn": [
        "INIT-009"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T10:19:28.647Z"
        },
        {
          "state": "testing",
          "timestamp": "2025-10-22T11:26:40.105Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T11:30:20.262Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T11:31:55.506Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T11:32:17.079Z"
        }
      ],
      "userStory": {
        "role": "developer switching between AI coding agents",
        "action": "be prompted to switch agents when running fspec init with existing agent files",
        "benefit": "I can easily switch from one agent to another without manual cleanup"
      },
      "questions": [
        {
          "text": "@human: When should the agent switching prompt appear - always, or only when installing a different agent than currently installed?",
          "selected": true,
          "answer": "Detect current agent using BOTH spec/fspec-config.json AND file detection (like remove-init-files does), then prompt only if the new agent being installed is different from the detected agent"
        },
        {
          "text": "@human: What options should the agent switching prompt offer to the user?",
          "selected": true,
          "answer": "Two options: 'Switch to [NewAgent]' (removes old agent files, installs new agent) or 'Cancel' (keeps existing setup, aborts installation)"
        },
        {
          "text": "@human: Should spec/fspec-config.json be deleted, updated, or left unchanged when switching agents?",
          "selected": true,
          "answer": "Update spec/fspec-config.json to reflect the new agent ID (e.g., from {\"agent\": \"claude\"} to {\"agent\": \"cursor\"}) so runtime detection works correctly"
        },
        {
          "text": "@human: What happens in interactive mode when an existing agent is detected?",
          "selected": true,
          "answer": "Pre-select the detected agent in interactive selector. If user chooses the same agent, reinstall/refresh files (no prompt). If user chooses a different agent, show switch prompt ('Switch from Claude to Cursor?')"
        }
      ],
      "rules": [
        "Detect current agent using BOTH spec/fspec-config.json AND file detection (like remove-init-files does), then prompt only if the new agent being installed is different from the detected agent",
        "Two options: 'Switch to [NewAgent]' (removes old agent files, installs new agent) or 'Cancel' (keeps existing setup, aborts installation)",
        "Update spec/fspec-config.json to reflect the new agent ID (e.g., from {\"agent\": \"claude\"} to {\"agent\": \"cursor\"}) so runtime detection works correctly",
        "Pre-select the detected agent in interactive selector. If user chooses the same agent, reinstall/refresh files (no prompt). If user chooses a different agent, show switch prompt ('Switch from Claude to Cursor?')"
      ],
      "examples": [
        "User runs 'fspec init --agent=cursor', Claude files detected, prompt shows 'Switch from Claude to Cursor?', user selects 'Switch', Claude files removed, Cursor files installed, config updated to cursor",
        "User runs 'fspec init --agent=cursor', Claude files detected, prompt shows 'Switch from Claude to Cursor?', user selects 'Cancel', Claude files remain, Cursor not installed, exit code 0",
        "User runs 'fspec init' (interactive), Claude files detected and pre-selected, user selects Cursor instead, prompt shows 'Switch from Claude to Cursor?', user confirms, switch happens",
        "User runs 'fspec init' (interactive), Claude files detected and pre-selected, user presses Enter (keeps Claude), files reinstalled/refreshed without prompt",
        "User runs 'fspec init --agent=claude', Claude files already exist, no prompt shown (same agent), files reinstalled/refreshed (idempotent behavior)"
      ],
      "estimate": 5
    },
    "DOC-005": {
      "id": "DOC-005",
      "title": "Update documentation for remove-init-files and agent switching",
      "type": "task",
      "status": "done",
      "createdAt": "2025-10-22T10:21:21.357Z",
      "updatedAt": "2025-10-22T11:42:59.691Z",
      "description": "Update help files, README, and docs to document fspec remove-init-files command and agent switching prompt in fspec init. Files to update: src/commands/*-help.ts, src/help.ts, README.md, docs/*",
      "children": [],
      "dependsOn": [
        "INIT-009",
        "INIT-010"
      ],
      "stateHistory": [
        {
          "state": "specifying",
          "timestamp": "2025-10-22T11:35:49.247Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T11:35:51.701Z"
        },
        {
          "state": "specifying",
          "timestamp": "2025-10-22T11:36:36.909Z"
        },
        {
          "state": "implementing",
          "timestamp": "2025-10-22T11:37:20.647Z"
        },
        {
          "state": "validating",
          "timestamp": "2025-10-22T11:42:50.318Z"
        },
        {
          "state": "done",
          "timestamp": "2025-10-22T11:42:59.691Z"
        }
      ],
      "rules": [
        "Update src/help.ts to include remove-init-files in setup commands section",
        "Create src/commands/remove-init-files-help.ts with comprehensive help documentation",
        "Update init-help.ts to document agent switching behavior",
        "Update README.md with remove-init-files command and agent switching examples",
        "Update docs/getting-started.md and docs/user-guide.md with new commands"
      ],
      "examples": [
        "Help file follows same structure as other command help files (WHEN TO USE, PREREQUISITES, USAGE, EXAMPLES, etc.)",
        "README shows 'fspec remove-init-files' in CLI commands section with brief description",
        "init-help.ts includes note about agent switching prompt when different agent detected",
        "docs/getting-started.md shows how to remove fspec if user wants to uninstall"
      ],
      "estimate": 2
    }
  },
  "states": {
    "backlog": [
      "MCP-001",
      "MCP-002",
      "MCP-003",
      "MCP-004",
      "MCP-005",
      "EST-002",
      "TECH-001",
      "BOARD-002",
      "CLEAN-001",
      "RES-001",
      "INIT-007",
      "CLI-007",
      "BUG-031"
    ],
    "specifying": [
      "FEAT-017"
    ],
    "testing": [],
    "implementing": [],
    "validating": [],
    "done": [
      "BUG-007",
      "BUG-008",
      "EXMAP-001",
      "INIT-001",
      "DEP-001",
      "EST-001",
      "QRY-001",
      "CLI-001",
      "SPEC-001",
      "FEAT-001",
      "FEAT-002",
      "FEAT-003",
      "FEAT-004",
      "FEAT-005",
      "TEST-001",
      "INIT-002",
      "BOARD-001",
      "CLI-002",
      "SAFE-001",
      "REMIND-001",
      "SAFE-002",
      "CLI-003",
      "TEST-002",
      "TEST-003",
      "DOC-001",
      "BUG-001",
      "BUG-002",
      "CLI-004",
      "INIT-003",
      "DOC-002",
      "RSPEC-001",
      "BUG-003",
      "CLI-005",
      "CLI-006",
      "BUG-004",
      "REMIND-003",
      "REMIND-002",
      "REMIND-008",
      "COV-002",
      "COV-004",
      "COV-003",
      "BUG-005",
      "COV-005",
      "COV-006",
      "BUG-006",
      "COV-001",
      "REMIND-004",
      "REMIND-005",
      "REMIND-006",
      "REMIND-007",
      "COV-007",
      "COV-008",
      "DOC-003",
      "COV-010",
      "COV-011",
      "COV-012",
      "COV-013",
      "COV-014",
      "COV-015",
      "COV-016",
      "COV-017",
      "COV-018",
      "COV-019",
      "COV-020",
      "COV-021",
      "COV-022",
      "COV-023",
      "COV-024",
      "COV-025",
      "COV-026",
      "COV-027",
      "COV-028",
      "COV-029",
      "COV-030",
      "COV-032",
      "COV-034",
      "COV-035",
      "COV-036",
      "COV-037",
      "COV-039",
      "COV-040",
      "COV-041",
      "COV-042",
      "COV-043",
      "COV-044",
      "COV-045",
      "COV-049",
      "COV-050",
      "COV-051",
      "COV-046",
      "COV-047",
      "COV-048",
      "COV-033",
      "COV-038",
      "FEAT-006",
      "FEAT-011",
      "DOC-004",
      "BUG-010",
      "EXMAP-002",
      "HOOK-003",
      "HOOK-004",
      "HOOK-005",
      "HOOK-006",
      "HOOK-007",
      "HOOK-008",
      "HOOK-009",
      "EXMAP-003",
      "BUG-011",
      "FEAT-012",
      "FEAT-013",
      "HOOK-010",
      "TEST-004",
      "BUG-012",
      "BUG-013",
      "FOUND-001",
      "FOUND-003",
      "FOUND-005",
      "FOUND-006",
      "FOUND-007",
      "FOUND-004",
      "FOUND-002",
      "BUG-014",
      "REFAC-001",
      "TEST-005",
      "COV-052",
      "HELP-001",
      "HELP-002",
      "FOUND-009",
      "FOUND-010",
      "DISC-001",
      "BUG-015",
      "BUG-016",
      "BUG-017",
      "BUG-018",
      "FEAT-014",
      "FEAT-015",
      "BUG-019",
      "DOCS-001",
      "COV-031",
      "HOOK-002",
      "FEAT-016",
      "REV-001",
      "UX-001",
      "BUG-021",
      "BUG-020",
      "BUG-022",
      "SPEC-002",
      "SPEC-003",
      "HOOK-011",
      "HOOK-001",
      "BUG-023",
      "HELP-003",
      "GIT-001",
      "GIT-003",
      "GIT-002",
      "BUG-024",
      "INIT-004",
      "INIT-005",
      "INIT-006",
      "BUG-028",
      "DOCS-002",
      "BUG-027",
      "BUG-025",
      "BUG-026",
      "BUG-029",
      "TECH-002",
      "INIT-008",
      "BUG-030",
      "BUG-032",
      "INIT-009",
      "INIT-010",
      "DOC-005"
    ],
    "blocked": []
  }
}